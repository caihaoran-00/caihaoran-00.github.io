<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"caihaoran-00.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.22.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"mac"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="前言公司在做一个AI对话玩具，需要语音唤醒功能，想运行在ESP32-S3芯片上，经过调研，觉得microWakeWord项目最合适。另一个可能的方案是使用Edge Impulse平台进行训练，参考这里，有博主也是用的这个方案设计了小玩意，但是，我认为这个方案不怎么靠谱（我要我觉得）。还是使用microWakeWord吧，这个项目是基于tensorflow的，很久没使用tensorflow进行训练了">
<meta property="og:type" content="article">
<meta property="og:title" content="KWS之microWakeWord安装、训练与测试">
<meta property="og:url" content="https://caihaoran-00.github.io/2025/04/03/KWS%E4%B9%8BmicroWakeWord%E5%AE%89%E8%A3%85%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95/index.html">
<meta property="og:site_name" content="Chr&#39;s Blog">
<meta property="og:description" content="前言公司在做一个AI对话玩具，需要语音唤醒功能，想运行在ESP32-S3芯片上，经过调研，觉得microWakeWord项目最合适。另一个可能的方案是使用Edge Impulse平台进行训练，参考这里，有博主也是用的这个方案设计了小玩意，但是，我认为这个方案不怎么靠谱（我要我觉得）。还是使用microWakeWord吧，这个项目是基于tensorflow的，很久没使用tensorflow进行训练了">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://caihaoran-00.github.io/2025/04/03/KWS%E4%B9%8BmicroWakeWord%E5%AE%89%E8%A3%85%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95/9eecfa2b857a8bb9b05aa71619546346.png">
<meta property="og:image" content="https://caihaoran-00.github.io/2025/04/03/KWS%E4%B9%8BmicroWakeWord%E5%AE%89%E8%A3%85%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95/3bef79d612d7f6d664fc2cc1cfd97743.png">
<meta property="og:image" content="https://caihaoran-00.github.io/2025/04/03/KWS%E4%B9%8BmicroWakeWord%E5%AE%89%E8%A3%85%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95/90c149772bb0c8a0da6b0688b51979af.png">
<meta property="og:image" content="https://caihaoran-00.github.io/2025/04/03/KWS%E4%B9%8BmicroWakeWord%E5%AE%89%E8%A3%85%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95/a213cd73c57519b6aac53485bed42d71.png">
<meta property="article:published_time" content="2025-04-03T03:50:41.000Z">
<meta property="article:modified_time" content="2025-04-28T10:34:36.487Z">
<meta property="article:author" content="Chr">
<meta property="article:tag" content="KWS">
<meta property="article:tag" content="microWakeWord">
<meta property="article:tag" content="tensorflow">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://caihaoran-00.github.io/2025/04/03/KWS%E4%B9%8BmicroWakeWord%E5%AE%89%E8%A3%85%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95/9eecfa2b857a8bb9b05aa71619546346.png">


<link rel="canonical" href="https://caihaoran-00.github.io/2025/04/03/KWS%E4%B9%8BmicroWakeWord%E5%AE%89%E8%A3%85%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://caihaoran-00.github.io/2025/04/03/KWS%E4%B9%8BmicroWakeWord%E5%AE%89%E8%A3%85%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95/","path":"2025/04/03/KWS之microWakeWord安装、训练与测试/","title":"KWS之microWakeWord安装、训练与测试"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>KWS之microWakeWord安装、训练与测试 | Chr's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Chr's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Record and Share</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%A1%B9%E7%9B%AE%E5%AE%89%E8%A3%85"><span class="nav-number">2.</span> <span class="nav-text">项目安装</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D"><span class="nav-number">2.1.</span> <span class="nav-text">项目介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%A1%B9%E7%9B%AE%E5%AE%89%E8%A3%85-1"><span class="nav-number">2.2.</span> <span class="nav-text">项目安装</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D"><span class="nav-number">2.3.</span> <span class="nav-text">代码简单介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95"><span class="nav-number">2.4.</span> <span class="nav-text">训练与测试</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5"><span class="nav-number">3.</span> <span class="nav-text">参考链接</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Chr</p>
  <div class="site-description" itemprop="description">Welcome to my little world</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">86</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">99</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="mailto:1299964565@qq.com" title="E-Mail → mailto:1299964565@qq.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://caihaoran-00.github.io/2025/04/03/KWS%E4%B9%8BmicroWakeWord%E5%AE%89%E8%A3%85%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chr">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chr's Blog">
      <meta itemprop="description" content="Welcome to my little world">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="KWS之microWakeWord安装、训练与测试 | Chr's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          KWS之microWakeWord安装、训练与测试
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-04-03 11:50:41" itemprop="dateCreated datePublished" datetime="2025-04-03T11:50:41+08:00">2025-04-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-04-28 18:34:36" itemprop="dateModified" datetime="2025-04-28T18:34:36+08:00">2025-04-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/code/" itemprop="url" rel="index"><span itemprop="name">code</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>6k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>22 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>公司在做一个AI对话玩具，需要语音唤醒功能，想运行在ESP32-S3芯片上，经过调研，觉得<a target="_blank" rel="noopener" href="https://github.com/kahrendt/microWakeWord">microWakeWord</a>项目最合适。另一个可能的方案是使用<a target="_blank" rel="noopener" href="https://edgeimpulse.com/">Edge Impulse</a>平台进行训练，参考<a target="_blank" rel="noopener" href="https://wiki.seeedstudio.com/cn/xiao_esp32s3_keyword_spotting/">这里</a>，有博主也是用的这个方案设计了<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV11ZrTYrE4p/?buvid=XUA3832AA22EE78A7351BC87C3080F4E6E14D&from_spmid=search.search-result.0.0&is_story_h5=false&mid=l75wYmHAuHqmVrUJdy96xQ==&plat_id=116&share_from=ugc&share_medium=android&share_plat=android&share_session_id=d6a6e4b8-ca14-4af3-a280-0c14c9c628d5&share_source=WEIXIN&share_source=weixin&share_tag=s_i&spmid=united.player-video-detail.0.0&timestamp=1743391874&unique_k=nQCe0ax&up_id=1171991528&vd_source=075a061948e76c87e2ee8754e264056e">小玩意</a>，但是，我认为这个方案不怎么靠谱（我要我觉得）。还是使用microWakeWord吧，这个项目是基于tensorflow的，很久没使用tensorflow进行训练了，基于这个机会也是把ubuntu22.04的显卡驱动、cuda和cudnn都更新了下，见<a href="https://caihaoran-00.github.io/2025/04/02/Ubuntu22-04%E6%9B%B4%E6%96%B0NVIDIA%E9%A9%B1%E5%8A%A8/">这里</a>。本文记录实际使用历程，包括项目安装、代码介绍、训练和简单实际使用测试。</p>
<p><strong>github:<a target="_blank" rel="noopener" href="https://github.com/kahrendt/microWakeWord">https://github.com/kahrendt/microWakeWord</a></strong></p>
<span id="more"></span>

<hr>
<h2 id="项目安装"><a href="#项目安装" class="headerlink" title="项目安装"></a>项目安装</h2><h3 id="项目介绍"><a href="#项目介绍" class="headerlink" title="项目介绍"></a>项目介绍</h3><p>首先介绍下microWakeWord这个开源项目是做什么的，项目的About写到：一个基于 TensorFlow 的唤醒词检测训练框架，使用合成样本生成，适用于特定的微控制器。然后在readme中写到：microWakeWord 是一个开源唤醒词库，用于检测低功耗设备上的自定义唤醒词。它生成的模型适合在微控制器上使用<a target="_blank" rel="noopener" href="https://www.tensorflow.org/lite/microcontrollers">TensorFlow Lite</a>。这些模型适合实际使用，具有较低的误接受率和误拒绝率。</p>
<p><strong>microWakeword 目前为早期版本。训练新模型旨在供高级用户使用。训练一个运行良好的模型仍然非常困难，因为它通常需要试验超参数和样本生成设置。请分享您发现的有关训练良好模型的任何见解！</strong></p>
<h3 id="项目安装-1"><a href="#项目安装-1" class="headerlink" title="项目安装"></a>项目安装</h3><p>开两个bash，</p>
<p>第一个bash:</p>
<figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">conda create -n microwakeword <span class="attr">python=</span><span class="number">3.10</span></span><br><span class="line"></span><br><span class="line">conda activate microwakeword</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建jupyter内核</span></span><br><span class="line">conda install ipykernel</span><br><span class="line">python -m ipykernel install --<span class="keyword">user</span> <span class="title">--name</span> microwakeword --display-name <span class="string">&quot;microwakeword&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 占位符：pip install XXX</span></span><br></pre></td></tr></table></figure>

<p>第二个bash(base环境)：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/kahrendt/microWakeWord.git</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> microwakeword/notebooks</span><br><span class="line"></span><br><span class="line">jupyter notebook</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="代码简单介绍"><a href="#代码简单介绍" class="headerlink" title="代码简单介绍"></a>代码简单介绍</h3><p>原代码见<a target="_blank" rel="noopener" href="https://github.com/kahrendt/microWakeWord/blob/main/notebooks/basic_training_notebook.ipynb">这里</a>，microWakeWord提供了一个基于jupyter notebook的”起点”，即训练示例，下面我们简单看一下该jupyter notebook文件。以下为原文翻译和简单的代码解读：</p>
<p><strong>训练微型唤醒词模型</strong></p>
<p>本笔记本将指导您训练一个基础的 <strong>microWakeWord</strong> 模型，适用于高级用户作为起点。建议使用 Python 3.10 运行。</p>
<p><strong>请注意</strong>，生成的模型可能难以触发或误触频繁，因此 <strong>需要尝试多种不同的设置</strong> 以获得可用的模型。在某些代码块的开头，我会标注可以调整的重要参数。</p>
<p>该代码可在 <strong>Google Colab</strong> 上运行，但训练速度 <strong>远低于本地 GPU</strong>。如果必须使用 Colab，请确保 <strong>更改运行时类型为 GPU</strong>，即便如此，训练仍然较慢！</p>
<p><strong>最终成果</strong></p>
<p>运行完本笔记本后，您将获得一个 <strong>tflite 文件</strong>。如果要在 <strong>ESPHome</strong> 中使用此模型，还需要编写 <strong>模型清单 JSON 文件</strong>。请参考 ESPHome 文档和相关模型仓库示例以获取详细信息。</p>
<p><strong>第一块</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Installs microWakeWord. Be sure to restart the session after this is finished.</span></span><br><span class="line"><span class="keyword">import</span> platform</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> platform.system() == <span class="string">&quot;Darwin&quot;</span>:</span><br><span class="line">    <span class="comment"># `pymicro-features` is installed from a fork to support building on macOS</span></span><br><span class="line">    !pip install <span class="string">&#x27;git+https://github.com/puddly/pymicro-features@puddly/minimum-cpp-version&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># `audio-metadata` is installed from a fork to unpin `attrs` from a version that breaks Jupyter</span></span><br><span class="line">!pip install <span class="string">&#x27;git+https://github.com/whatsnowplaying/audio-metadata@d4ebb238e6a401bb1a5aaaac60c9e2b3cb30929f&#x27;</span></span><br><span class="line"></span><br><span class="line">!git clone https://github.com/kahrendt/microWakeWord</span><br><span class="line">!pip install -e ./microWakeWord</span><br></pre></td></tr></table></figure>

<p>这里使用 <code>platform.system()</code> 检测操作系统，如果是 <strong>macOS（Darwin）</strong>，则执行额外的安装步骤。<code>pymicro-features</code> 是一个用于提取微型音频特征的 Python 库。由于官方版本可能在 macOS 上无法正确编译，所以这里从 <strong>puddly</strong> 维护的分支安装了一个兼容版本。</p>
<p><code>audio-metadata</code> 用于处理音频文件的元数据。官方版本依赖 <code>attrs</code> 库的特定版本，但某些版本的 <code>attrs</code> 可能会导致 Jupyter Notebook 运行问题，因此这里安装了 <strong>whatsnowplaying</strong> 维护的分支。</p>
<p>下载 <code>microWakeWord</code> 项目到当前工作目录。</p>
<p><code>-e</code> 选项表示<strong>以开发模式安装</strong>，这样你可以直接修改 <code>microWakeWord</code> 代码，而无需每次都重新安装。</p>
<p>由于 <code>pymicro-features</code> 和 <code>audio-metadata</code> 可能涉及 C++ 依赖库的构建，安装完成后需要重启 Jupyter 内核或 Python 解释器，确保新安装的库能正确加载。</p>
<p><strong>我安装这些库（以及下面的需要安装的库）的时候都是在两个bash窗口中进行的pip安装和克隆，当然小友也可以直接运行jupyter notebook块进行安装。</strong></p>
<p><strong>第二块</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Generates 1 sample of the target word for manual verification.</span></span><br><span class="line"></span><br><span class="line">target_word = <span class="string">&#x27;khum_puter&#x27;</span>  <span class="comment"># Phonetic spellings may produce better samples</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> platform</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Audio</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&quot;./piper-sample-generator&quot;</span>):</span><br><span class="line">    <span class="keyword">if</span> platform.system() == <span class="string">&quot;Darwin&quot;</span>:</span><br><span class="line">        !git clone -b mps-support https://github.com/kahrendt/piper-sample-generator</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        !git clone https://github.com/rhasspy/piper-sample-generator</span><br><span class="line"></span><br><span class="line">    !wget -O piper-sample-generator/models/en_US-libritts_r-medium.pt <span class="string">&#x27;https://github.com/rhasspy/piper-sample-generator/releases/download/v2.0.0/en_US-libritts_r-medium.pt&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Install system dependencies</span></span><br><span class="line">    !pip install torch torchaudio piper-phonemize-cross==<span class="number">1.2</span><span class="number">.1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;piper-sample-generator/&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> sys.path:</span><br><span class="line">        sys.path.append(<span class="string">&quot;piper-sample-generator/&quot;</span>)</span><br><span class="line"></span><br><span class="line">!python3 piper-sample-generator/generate_samples.py <span class="string">&quot;&#123;target_word&#125;&quot;</span> \</span><br><span class="line">--<span class="built_in">max</span>-samples <span class="number">1</span> \</span><br><span class="line">--batch-size <span class="number">1</span> \</span><br><span class="line">--output-<span class="built_in">dir</span> generated_samples</span><br><span class="line"></span><br><span class="line">Audio(<span class="string">&quot;generated_samples/0.wav&quot;</span>, autoplay=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>此代码用于<strong>生成一个目标唤醒词的音频样本</strong>，以便手动验证生成效果。</li>
<li>目标唤醒词设置为 <code>&quot;khum_puter&quot;</code>，使用<strong>拼音化拼写</strong>可能会生成更好的音频样本。</li>
<li>检查 <code>piper-sample-generator</code> 目录是否已存在，若不存在则进行克隆和安装。<strong>Mac 用户</strong> 克隆 <code>kahrendt</code> 维护的 <code>mps-support</code> 分支（支持 Apple M1&#x2F;M2）。<strong>其他系统（Linux&#x2F;Windows）</strong> 克隆 <code>rhasspy</code> 官方仓库。</li>
<li>下载一个 <strong>英文 TTS（Text-to-Speech）模型</strong>，用于合成语音。</li>
<li>安装系统依赖，<code>piper-phonemize-cross==1.2.1</code>：用于将文本转换为语音所需的发音标注工具。</li>
<li>将 <code>piper-sample-generator</code> 加入 Python 路径，确保 <code>piper-sample-generator</code> 可以作为 Python 模块被调用。</li>
<li>生成目标词的音频样本。</li>
<li>调用 <code>generate_samples.py</code> 脚本，<strong>生成 1 个目标唤醒词的音频样本</strong>：<ul>
<li><code>--max-samples 1</code>：生成 1 个样本。</li>
<li><code>--batch-size 1</code>：批处理大小为 1。</li>
<li><code>--output-dir generated_samples</code>：将音频保存到 <code>generated_samples/</code> 目录。</li>
</ul>
</li>
<li>播放生成的音频。读取生成的 <code>0.wav</code> 文件，并自动播放以供验证。</li>
</ul>
<p><strong>第三块：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Generates a larger amount of wake word samples.</span></span><br><span class="line"><span class="comment"># Start here when trying to improve your model.</span></span><br><span class="line"><span class="comment"># See https://github.com/rhasspy/piper-sample-generator for the full set of</span></span><br><span class="line"><span class="comment"># parameters. In particular, experiment with noise-scales and noise-scale-ws,</span></span><br><span class="line"><span class="comment"># generating negative samples similar to the wake word, and generating many more</span></span><br><span class="line"><span class="comment"># wake word samples, possibly with different phonetic pronunciations.</span></span><br><span class="line"></span><br><span class="line">!python3 piper-sample-generator/generate_samples.py <span class="string">&quot;&#123;target_word&#125;&quot;</span> \</span><br><span class="line">--<span class="built_in">max</span>-samples <span class="number">1000</span> \</span><br><span class="line">--batch-size <span class="number">100</span> \</span><br><span class="line">--output-<span class="built_in">dir</span> generated_samples</span><br></pre></td></tr></table></figure>

<p>生成大量唤醒词样本。当尝试改进模型时，从这里开始。请参阅<a target="_blank" rel="noopener" href="https://github.com/rhasspy/piper-sample-generator%E8%8E%B7%E5%8F%96%E5%85%A8%E5%A5%97%E5%8F%82%E6%95%B0%E3%80%82%E7%89%B9%E5%88%AB%E6%98%AF%EF%BC%8C%E7%94%A8noise-scale%E5%92%8Cnoise-scale-ws%E8%BF%9B%E8%A1%8C%E5%AE%9E%E9%AA%8C%EF%BC%8C%E7%94%9F%E6%88%90%E4%B8%8E%E5%94%A4%E9%86%92%E8%AF%8D%E7%9B%B8%E4%BC%BC%E7%9A%84%E8%B4%9F%E6%A0%B7%E6%9C%AC%EF%BC%8C%E5%B9%B6%E7%94%9F%E6%88%90%E6%9B%B4%E5%A4%9A%E7%9A%84%E5%94%A4%E9%86%92%E8%AF%8D%E6%A0%B7%E6%9C%AC%EF%BC%8C%E8%BF%99%E4%BA%9B%E6%A0%B7%E6%9C%AC%E5%8F%AF%E8%83%BD%E5%85%B7%E6%9C%89%E4%B8%8D%E5%90%8C%E7%9A%84%E8%AF%AD%E9%9F%B3%E5%8F%91%E9%9F%B3%E3%80%82">https://github.com/rhasspy/piper-sample-generator获取全套参数。特别是，用noise-scale和noise-scale-ws进行实验，生成与唤醒词相似的负样本，并生成更多的唤醒词样本，这些样本可能具有不同的语音发音。</a></p>
<p>该代码用于 <strong>批量生成大量唤醒词音频样本</strong>，以提高模型训练效果。参数含义见第二块。</p>
<p><strong>第四块：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Downloads audio data for augmentation. This can be slow!</span></span><br><span class="line"><span class="comment"># Borrowed from openWakeWord&#x27;s automatic_model_training.ipynb, accessed March 4, 2024</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># **Important note!** The data downloaded here has a mixture of difference</span></span><br><span class="line"><span class="comment"># licenses and usage restrictions. As such, any custom models trained with this</span></span><br><span class="line"><span class="comment"># data should be considered as appropriate for **non-commercial** personal use only.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> scipy</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="comment">## Download MIR RIR data</span></span><br><span class="line"></span><br><span class="line">output_dir = <span class="string">&quot;./mit_rirs&quot;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(output_dir):</span><br><span class="line">    os.mkdir(output_dir)</span><br><span class="line">    rir_dataset = datasets.load_dataset(<span class="string">&quot;davidscripka/MIT_environmental_impulse_responses&quot;</span>, split=<span class="string">&quot;train&quot;</span>, streaming=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># Save clips to 16-bit PCM wav files</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> tqdm(rir_dataset):</span><br><span class="line">        name = row[<span class="string">&#x27;audio&#x27;</span>][<span class="string">&#x27;path&#x27;</span>].split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>]</span><br><span class="line">        scipy.io.wavfile.write(os.path.join(output_dir, name), <span class="number">16000</span>, (row[<span class="string">&#x27;audio&#x27;</span>][<span class="string">&#x27;array&#x27;</span>]*<span class="number">32767</span>).astype(np.int16))</span><br><span class="line">        </span><br><span class="line"><span class="comment">## Download noise and background audio</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Audioset Dataset (https://research.google.com/audioset/dataset/index.html)</span></span><br><span class="line"><span class="comment"># Download one part of the audioset .tar files, extract, and convert to 16khz</span></span><br><span class="line"><span class="comment"># For full-scale training, it&#x27;s recommended to download the entire dataset from</span></span><br><span class="line"><span class="comment"># https://huggingface.co/datasets/agkphysics/AudioSet, and</span></span><br><span class="line"><span class="comment"># even potentially combine it with other background noise datasets (e.g., FSD50k, Freesound, etc.)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&quot;audioset&quot;</span>):</span><br><span class="line">    os.mkdir(<span class="string">&quot;audioset&quot;</span>)</span><br><span class="line"></span><br><span class="line">    fname = <span class="string">&quot;bal_train09.tar&quot;</span></span><br><span class="line">    out_dir = <span class="string">f&quot;audioset/<span class="subst">&#123;fname&#125;</span>&quot;</span></span><br><span class="line">    link = <span class="string">&quot;https://huggingface.co/datasets/agkphysics/AudioSet/resolve/main/data/&quot;</span> + fname</span><br><span class="line">    !wget -O &#123;out_dir&#125; &#123;link&#125;</span><br><span class="line">    !cd audioset &amp;&amp; tar -xf bal_train09.tar</span><br><span class="line"></span><br><span class="line">    output_dir = <span class="string">&quot;./audioset_16k&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(output_dir):</span><br><span class="line">        os.mkdir(output_dir)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Save clips to 16-bit PCM wav files</span></span><br><span class="line">    audioset_dataset = datasets.Dataset.from_dict(&#123;<span class="string">&quot;audio&quot;</span>: [<span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> Path(<span class="string">&quot;audioset/audio&quot;</span>).glob(<span class="string">&quot;**/*.flac&quot;</span>)]&#125;)</span><br><span class="line">    audioset_dataset = audioset_dataset.cast_column(<span class="string">&quot;audio&quot;</span>, datasets.Audio(sampling_rate=<span class="number">16000</span>))</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> tqdm(audioset_dataset):</span><br><span class="line">        name = row[<span class="string">&#x27;audio&#x27;</span>][<span class="string">&#x27;path&#x27;</span>].split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>].replace(<span class="string">&quot;.flac&quot;</span>, <span class="string">&quot;.wav&quot;</span>)</span><br><span class="line">        scipy.io.wavfile.write(os.path.join(output_dir, name), <span class="number">16000</span>, (row[<span class="string">&#x27;audio&#x27;</span>][<span class="string">&#x27;array&#x27;</span>]*<span class="number">32767</span>).astype(np.int16))</span><br><span class="line">        </span><br><span class="line"><span class="comment"># Free Music Archive dataset</span></span><br><span class="line"><span class="comment"># https://github.com/mdeff/fma</span></span><br><span class="line"><span class="comment"># (Third-party mchl914 extra small set)</span></span><br><span class="line"></span><br><span class="line">output_dir = <span class="string">&quot;./fma&quot;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(output_dir):</span><br><span class="line">    os.mkdir(output_dir)</span><br><span class="line">    fname = <span class="string">&quot;fma_xs.zip&quot;</span></span><br><span class="line">    link = <span class="string">&quot;https://huggingface.co/datasets/mchl914/fma_xsmall/resolve/main/&quot;</span> + fname</span><br><span class="line">    out_dir = <span class="string">f&quot;fma/<span class="subst">&#123;fname&#125;</span>&quot;</span></span><br><span class="line">    !wget -O &#123;out_dir&#125; &#123;link&#125;</span><br><span class="line">    !cd &#123;output_dir&#125; &amp;&amp; unzip -q &#123;fname&#125;</span><br><span class="line"></span><br><span class="line">    output_dir = <span class="string">&quot;./fma_16k&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(output_dir):</span><br><span class="line">        os.mkdir(output_dir)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Save clips to 16-bit PCM wav files</span></span><br><span class="line">    fma_dataset = datasets.Dataset.from_dict(&#123;<span class="string">&quot;audio&quot;</span>: [<span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> Path(<span class="string">&quot;fma/fma_small&quot;</span>).glob(<span class="string">&quot;**/*.mp3&quot;</span>)]&#125;)</span><br><span class="line">    fma_dataset = fma_dataset.cast_column(<span class="string">&quot;audio&quot;</span>, datasets.Audio(sampling_rate=<span class="number">16000</span>))</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> tqdm(fma_dataset):</span><br><span class="line">        name = row[<span class="string">&#x27;audio&#x27;</span>][<span class="string">&#x27;path&#x27;</span>].split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>].replace(<span class="string">&quot;.mp3&quot;</span>, <span class="string">&quot;.wav&quot;</span>)</span><br><span class="line">        scipy.io.wavfile.write(os.path.join(output_dir, name), <span class="number">16000</span>, (row[<span class="string">&#x27;audio&#x27;</span>][<span class="string">&#x27;array&#x27;</span>]*<span class="number">32767</span>).astype(np.int16))</span><br></pre></td></tr></table></figure>

<p>此代码段用于 <strong>下载、解压、转换</strong> 不同来源的音频数据，包括 <strong>混响响应 (RIR) 数据、背景噪声</strong>，用于 <strong>数据增强</strong>，提高唤醒词模型的鲁棒性。</p>
<p>下载并处理 MIT 环境脉冲响应（RIR）数据，<strong>用于模拟不同的房间环境</strong>（混响），<strong>转换为 16-bit PCM <code>.wav</code> 文件</strong>，以匹配训练数据格式</p>
<p>下载 Audioset（Google research的噪声数据集）,<strong>包含各种背景噪声</strong>，如城市噪声、自然环境声音，<strong>解压并转换为 16kHz WAV 格式</strong></p>
<p>下载 Free Music Archive（FMA）数据集，<strong>用于背景音乐增强</strong>，帮助模型学习在有音乐的环境中触发，<strong>解压并转换 MP3 到 WAV</strong></p>
<p><strong>第五块</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Sets up the augmentations.</span></span><br><span class="line"><span class="comment"># To improve your model, experiment with these settings and use more sources of</span></span><br><span class="line"><span class="comment"># background clips.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> microwakeword.audio.augmentation <span class="keyword">import</span> Augmentation</span><br><span class="line"><span class="keyword">from</span> microwakeword.audio.clips <span class="keyword">import</span> Clips</span><br><span class="line"><span class="keyword">from</span> microwakeword.audio.spectrograms <span class="keyword">import</span> SpectrogramGeneration</span><br><span class="line"></span><br><span class="line">clips = Clips(input_directory=<span class="string">&#x27;generated_samples&#x27;</span>,</span><br><span class="line">              file_pattern=<span class="string">&#x27;*.wav&#x27;</span>,</span><br><span class="line">              max_clip_duration_s=<span class="literal">None</span>,</span><br><span class="line">              remove_silence=<span class="literal">False</span>,</span><br><span class="line">              random_split_seed=<span class="number">10</span>,</span><br><span class="line">              split_count=<span class="number">0.1</span>,</span><br><span class="line">              )</span><br><span class="line">augmenter = Augmentation(augmentation_duration_s=<span class="number">3.2</span>,</span><br><span class="line">                         augmentation_probabilities = &#123;</span><br><span class="line">                                <span class="string">&quot;SevenBandParametricEQ&quot;</span>: <span class="number">0.1</span>,</span><br><span class="line">                                <span class="string">&quot;TanhDistortion&quot;</span>: <span class="number">0.1</span>,</span><br><span class="line">                                <span class="string">&quot;PitchShift&quot;</span>: <span class="number">0.1</span>,</span><br><span class="line">                                <span class="string">&quot;BandStopFilter&quot;</span>: <span class="number">0.1</span>,</span><br><span class="line">                                <span class="string">&quot;AddColorNoise&quot;</span>: <span class="number">0.1</span>,</span><br><span class="line">                                <span class="string">&quot;AddBackgroundNoise&quot;</span>: <span class="number">0.75</span>,</span><br><span class="line">                                <span class="string">&quot;Gain&quot;</span>: <span class="number">1.0</span>,</span><br><span class="line">                                <span class="string">&quot;RIR&quot;</span>: <span class="number">0.5</span>,</span><br><span class="line">                            &#125;,</span><br><span class="line">                         impulse_paths = [<span class="string">&#x27;mit_rirs&#x27;</span>],</span><br><span class="line">                         background_paths = [<span class="string">&#x27;fma_16k&#x27;</span>, <span class="string">&#x27;audioset_16k&#x27;</span>],</span><br><span class="line">                         background_min_snr_db = -<span class="number">5</span>,</span><br><span class="line">                         background_max_snr_db = <span class="number">10</span>,</span><br><span class="line">                         min_jitter_s = <span class="number">0.195</span>,</span><br><span class="line">                         max_jitter_s = <span class="number">0.205</span>,</span><br><span class="line">                         )</span><br></pre></td></tr></table></figure>

<p>设置数据增强配置。要改进您的模型，请试验这些设置并使用更多的背景噪声切片。</p>
<p>这段代码用于 <strong>设置和执行音频增强</strong>，以提高模型的鲁棒性和泛化能力。增强的主要目的是通过添加不同类型的噪声和变换来模拟不同的环境和设备条件，使得模型能够适应更多实际场景。</p>
<ul>
<li>初始化音频剪辑（Clips）<ul>
<li>从 <code>generated_samples</code> 目录中读取 <code>.wav</code> 文件。</li>
<li>通过随机拆分和去除静音部分，提高样本的多样性。</li>
</ul>
</li>
<li>设置增强方法（Augmentation），通过指定不同的增强方法和它们的概率来增强音频数据。常见的增强方法包括：<ul>
<li><strong>SevenBandParametricEQ</strong>：调整音频的频带</li>
<li><strong>PitchShift</strong>：改变音高</li>
<li><strong>BandStopFilter</strong>：使用带阻滤波器去除特定频段的声音</li>
<li><strong>AddColorNoise</strong>：添加颜色噪声。</li>
<li><strong>AddBackgroundNoise</strong>：将背景噪声添加到音频中（最常用）。</li>
<li><strong>Gain</strong>：调整音量增益。</li>
<li><strong>RIR（Room Impulse Response）</strong>：模拟房间混响效果。</li>
</ul>
</li>
</ul>
<p><strong>参数解析</strong>：</p>
<ul>
<li><strong><code>augmentation_duration_s=3.2</code></strong>: 设置每个增强音频的持续时间为 3.2 秒。</li>
<li><strong><code>augmentation_probabilities</code></strong>: 每种增强方法的应用概率。例如，背景噪声的应用概率为 75%。</li>
<li><strong><code>impulse_paths</code></strong>: 环境混响（RIR）的路径。使用 <code>mit_rirs</code> 数据集来模拟不同的房间混响效果。</li>
<li><strong><code>background_paths</code></strong>: 背景噪声数据的路径，包括 FMA 和 Audioset 数据集。</li>
<li><strong><code>background_min_snr_db</code> 和 <code>background_max_snr_db</code></strong>: 控制背景噪声的信噪比（SNR）。</li>
<li><strong><code>min_jitter_s</code> 和 <code>max_jitter_s</code></strong>: 控制音频抖动（随机偏移）。</li>
</ul>
<blockquote>
<p>随机偏移，简单理解：比如是0.2，那么音频前0.2 s就没了，现数据从原数据的0.2 s开始。说是这样可以增加训练数据的多样性，并且帮助模型学习到音频时间的变化，提升模型对实际场景中不同设备和延迟的适应能力（同一个音频使用一次以上才有意义吧）。</p>
</blockquote>
<p><strong>第六块：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Augment a random clip and play it back to verify it works well</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Audio</span><br><span class="line"><span class="keyword">from</span> microwakeword.audio.audio_utils <span class="keyword">import</span> save_clip</span><br><span class="line"></span><br><span class="line">random_clip = clips.get_random_clip()</span><br><span class="line">augmented_clip = augmenter.augment_clip(random_clip)</span><br><span class="line">save_clip(augmented_clip, <span class="string">&#x27;augmented_clip.wav&#x27;</span>)</span><br><span class="line"></span><br><span class="line">Audio(<span class="string">&quot;augmented_clip.wav&quot;</span>, autoplay=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p><strong>对一个随机音频样本进行数据增强，并播放增强后的音频</strong>，以便人工验证增强效果是否合理。</p>
<ul>
<li>从 <code>clips</code>（即 <code>Clips</code> 类的实例）中随机选取一个音频样本。</li>
<li>通过 <code>Augmentation</code> 类的 <code>augment_clip()</code> 方法对选中的音频进行数据增强</li>
<li>之前定义的 <code>augmenter</code> 已经设定了一系列增强方式，<code>augment_clip()</code> 会对音频进行这些随机变换，使得训练数据更加丰富。</li>
</ul>
<p><strong>第七块：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Augment samples and save the training, validation, and testing sets.</span></span><br><span class="line"><span class="comment"># Validating and testing samples generated the same way can make the model</span></span><br><span class="line"><span class="comment"># benchmark better than it performs in real-word use. Use real samples or TTS</span></span><br><span class="line"><span class="comment"># samples generated with a different TTS engine to potentially get more accurate</span></span><br><span class="line"><span class="comment"># benchmarks.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> mmap_ninja.ragged <span class="keyword">import</span> RaggedMmap</span><br><span class="line"></span><br><span class="line">output_dir = <span class="string">&#x27;generated_augmented_features&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(output_dir):</span><br><span class="line">    os.mkdir(output_dir)</span><br><span class="line"></span><br><span class="line">splits = [<span class="string">&quot;training&quot;</span>, <span class="string">&quot;validation&quot;</span>, <span class="string">&quot;testing&quot;</span>]</span><br><span class="line"><span class="keyword">for</span> split <span class="keyword">in</span> splits:</span><br><span class="line">  out_dir = os.path.join(output_dir, split)</span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(out_dir):</span><br><span class="line">      os.mkdir(out_dir)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  split_name = <span class="string">&quot;train&quot;</span></span><br><span class="line">  repetition = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">  spectrograms = SpectrogramGeneration(clips=clips,</span><br><span class="line">                                     augmenter=augmenter,</span><br><span class="line">                                     slide_frames=<span class="number">10</span>,    <span class="comment"># Uses the same spectrogram repeatedly, just shifted over by one frame. This simulates the streaming inferences while training/validating in nonstreaming mode.</span></span><br><span class="line">                                     step_ms=<span class="number">10</span>,</span><br><span class="line">                                     )</span><br><span class="line">  <span class="keyword">if</span> split == <span class="string">&quot;validation&quot;</span>:</span><br><span class="line">    split_name = <span class="string">&quot;validation&quot;</span></span><br><span class="line">    repetition = <span class="number">1</span></span><br><span class="line">  <span class="keyword">elif</span> split == <span class="string">&quot;testing&quot;</span>:</span><br><span class="line">    split_name = <span class="string">&quot;test&quot;</span></span><br><span class="line">    repetition = <span class="number">1</span></span><br><span class="line">    spectrograms = SpectrogramGeneration(clips=clips,</span><br><span class="line">                                     augmenter=augmenter,</span><br><span class="line">                                     slide_frames=<span class="number">1</span>,    <span class="comment"># The testing set uses the streaming version of the model, so no artificial repetition is necessary</span></span><br><span class="line">                                     step_ms=<span class="number">10</span>,</span><br><span class="line">                                     )</span><br><span class="line">    </span><br><span class="line"> RaggedMmap.from_generator(</span><br><span class="line">      out_dir=os.path.join(out_dir, <span class="string">&#x27;wakeword_mmap&#x27;</span>),</span><br><span class="line">      sample_generator=spectrograms.spectrogram_generator(split=split_name, repeat=repetition),</span><br><span class="line">      batch_size=<span class="number">100</span>,</span><br><span class="line">      verbose=<span class="literal">True</span>,</span><br><span class="line">  )</span><br></pre></td></tr></table></figure>

<p>增强样本并保存训练、验证和测试集。以相同方式生成的验证和测试样本可能会使模型的基准测试结果优于其在真实世界中的实际表现。建议使用真实样本或由不同 TTS 引擎生成的 TTS 样本，以获得更准确的基准测试结果<br><strong>对唤醒词数据集进行数据增强，并将其转换为训练、验证和测试集的特征数据</strong>。</p>
<ul>
<li><code>generated_augmented_features</code> 目录用于存储增强后的训练、验证和测试数据</li>
<li>在 <code>generated_augmented_features</code> 目录下分别创建 <code>training</code>、<code>validation</code> 和 <code>testing</code> 三个子文件夹</li>
<li>初始化 <code>SpectrogramGeneration</code> 处理音频，<strong><code>SpectrogramGeneration</code> 作用</strong>：<ul>
<li>从 <code>clips</code> 读取音频片段。</li>
<li>通过 <code>augmenter</code> 进行数据增强。</li>
<li>生成频谱图特征（spectrogram）</li>
</ul>
</li>
<li><code>slide_frames=10</code>：通过在频谱图上滑动 10 帧，使相同的音频片段在训练时以不同时间偏移输入，模拟流式推理。<code>step_ms=10</code>：每 10ms 计算一个新的帧特征。</li>
<li>生成数据并保存为 <code>RaggedMmap</code> 文件，<ul>
<li>处理 <code>spectrogram_generator()</code> 生成的频谱数据。</li>
<li>将特征数据存储为 <code>wakeword_mmap</code> 文件，提高后续训练速度。</li>
<li><code>batch_size=100</code>，意味着每次处理 100 个样本，提高效率。</li>
<li><code>verbose=True</code>，显示详细进度信息。</li>
</ul>
</li>
</ul>
<p><strong>第八块：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Save a yaml config that controls the training process</span></span><br><span class="line"><span class="comment"># These hyperparamters can make a huge different in model quality.</span></span><br><span class="line"><span class="comment"># Experiment with sampling and penalty weights and increasing the number of</span></span><br><span class="line"><span class="comment"># training steps.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> yaml</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">config = &#123;&#125;</span><br><span class="line"></span><br><span class="line">config[<span class="string">&quot;window_step_ms&quot;</span>] = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">config[<span class="string">&quot;train_dir&quot;</span>] = (</span><br><span class="line">    <span class="string">&quot;trained_models/wakeword&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Each feature_dir should have at least one of the following folders with this structure:</span></span><br><span class="line"><span class="comment">#  training/</span></span><br><span class="line"><span class="comment">#    ragged_mmap_folders_ending_in_mmap</span></span><br><span class="line"><span class="comment">#  testing/</span></span><br><span class="line"><span class="comment">#    ragged_mmap_folders_ending_in_mmap</span></span><br><span class="line"><span class="comment">#  testing_ambient/</span></span><br><span class="line"><span class="comment">#    ragged_mmap_folders_ending_in_mmap</span></span><br><span class="line"><span class="comment">#  validation/</span></span><br><span class="line"><span class="comment">#    ragged_mmap_folders_ending_in_mmap</span></span><br><span class="line"><span class="comment">#  validation_ambient/</span></span><br><span class="line"><span class="comment">#    ragged_mmap_folders_ending_in_mmap</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#  sampling_weight: Weight for choosing a spectrogram from this set in the batch</span></span><br><span class="line"><span class="comment">#  penalty_weight: Penalizing weight for incorrect predictions from this set</span></span><br><span class="line"><span class="comment">#  truth: Boolean whether this set has positive samples or negative samples</span></span><br><span class="line"><span class="comment">#  truncation_strategy = If spectrograms in the set are longer than necessary for training, how are they truncated</span></span><br><span class="line"><span class="comment">#       - random: choose a random portion of the entire spectrogram - useful for long negative samples</span></span><br><span class="line"><span class="comment">#       - truncate_start: remove the start of the spectrogram</span></span><br><span class="line"><span class="comment">#       - truncate_end: remove the end of the spectrogram</span></span><br><span class="line"><span class="comment">#       - split: Split the longer spectrogram into separate spectrograms offset by 100 ms. Only for ambient sets</span></span><br><span class="line"></span><br><span class="line">config[<span class="string">&quot;features&quot;</span>] = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;features_dir&quot;</span>: <span class="string">&quot;generated_augmented_features&quot;</span>,</span><br><span class="line">        <span class="string">&quot;sampling_weight&quot;</span>: <span class="number">2.0</span>,</span><br><span class="line">        <span class="string">&quot;penalty_weight&quot;</span>: <span class="number">1.0</span>,</span><br><span class="line">        <span class="string">&quot;truth&quot;</span>: <span class="literal">True</span>,</span><br><span class="line">        <span class="string">&quot;truncation_strategy&quot;</span>: <span class="string">&quot;truncate_start&quot;</span>,</span><br><span class="line">        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;mmap&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;features_dir&quot;</span>: <span class="string">&quot;negative_datasets/speech&quot;</span>,</span><br><span class="line">        <span class="string">&quot;sampling_weight&quot;</span>: <span class="number">10.0</span>,</span><br><span class="line">        <span class="string">&quot;penalty_weight&quot;</span>: <span class="number">1.0</span>,</span><br><span class="line">        <span class="string">&quot;truth&quot;</span>: <span class="literal">False</span>,</span><br><span class="line">        <span class="string">&quot;truncation_strategy&quot;</span>: <span class="string">&quot;random&quot;</span>,</span><br><span class="line">        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;mmap&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;features_dir&quot;</span>: <span class="string">&quot;negative_datasets/dinner_party&quot;</span>,</span><br><span class="line">        <span class="string">&quot;sampling_weight&quot;</span>: <span class="number">10.0</span>,</span><br><span class="line">        <span class="string">&quot;penalty_weight&quot;</span>: <span class="number">1.0</span>,</span><br><span class="line">        <span class="string">&quot;truth&quot;</span>: <span class="literal">False</span>,</span><br><span class="line">        <span class="string">&quot;truncation_strategy&quot;</span>: <span class="string">&quot;random&quot;</span>,</span><br><span class="line">        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;mmap&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;features_dir&quot;</span>: <span class="string">&quot;negative_datasets/no_speech&quot;</span>,</span><br><span class="line">        <span class="string">&quot;sampling_weight&quot;</span>: <span class="number">5.0</span>,</span><br><span class="line">        <span class="string">&quot;penalty_weight&quot;</span>: <span class="number">1.0</span>,</span><br><span class="line">        <span class="string">&quot;truth&quot;</span>: <span class="literal">False</span>,</span><br><span class="line">        <span class="string">&quot;truncation_strategy&quot;</span>: <span class="string">&quot;random&quot;</span>,</span><br><span class="line">        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;mmap&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123; <span class="comment"># Only used for validation and testing</span></span><br><span class="line">        <span class="string">&quot;features_dir&quot;</span>: <span class="string">&quot;negative_datasets/dinner_party_eval&quot;</span>,</span><br><span class="line">        <span class="string">&quot;sampling_weight&quot;</span>: <span class="number">0.0</span>,</span><br><span class="line">        <span class="string">&quot;penalty_weight&quot;</span>: <span class="number">1.0</span>,</span><br><span class="line">        <span class="string">&quot;truth&quot;</span>: <span class="literal">False</span>,</span><br><span class="line">        <span class="string">&quot;truncation_strategy&quot;</span>: <span class="string">&quot;split&quot;</span>,</span><br><span class="line">        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;mmap&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Number of training steps in each iteration - various other settings are configured as lists that corresponds to different steps</span></span><br><span class="line">config[<span class="string">&quot;training_steps&quot;</span>] = [<span class="number">10000</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Penalizing weight for incorrect class predictions - lists that correspond to training steps</span></span><br><span class="line">config[<span class="string">&quot;positive_class_weight&quot;</span>] = [<span class="number">1</span>]</span><br><span class="line">config[<span class="string">&quot;negative_class_weight&quot;</span>] = [<span class="number">20</span>]</span><br><span class="line"></span><br><span class="line">config[<span class="string">&quot;learning_rates&quot;</span>] = [</span><br><span class="line">    <span class="number">0.001</span>,</span><br><span class="line">]  <span class="comment"># Learning rates for Adam optimizer - list that corresponds to training steps</span></span><br><span class="line">config[<span class="string">&quot;batch_size&quot;</span>] = <span class="number">128</span></span><br><span class="line"></span><br><span class="line">config[<span class="string">&quot;time_mask_max_size&quot;</span>] = [</span><br><span class="line">    <span class="number">0</span></span><br><span class="line">]  <span class="comment"># SpecAugment - list that corresponds to training steps</span></span><br><span class="line">config[<span class="string">&quot;time_mask_count&quot;</span>] = [<span class="number">0</span>]  <span class="comment"># SpecAugment - list that corresponds to training steps</span></span><br><span class="line">config[<span class="string">&quot;freq_mask_max_size&quot;</span>] = [</span><br><span class="line">    <span class="number">0</span></span><br><span class="line">]  <span class="comment"># SpecAugment - list that corresponds to training steps</span></span><br><span class="line">config[<span class="string">&quot;freq_mask_count&quot;</span>] = [<span class="number">0</span>]  <span class="comment"># SpecAugment - list that corresponds to training steps</span></span><br><span class="line"></span><br><span class="line">config[<span class="string">&quot;eval_step_interval&quot;</span>] = (</span><br><span class="line">    <span class="number">500</span>  <span class="comment"># Test the validation sets after every this many steps</span></span><br><span class="line">)</span><br><span class="line">config[<span class="string">&quot;clip_duration_ms&quot;</span>] = (</span><br><span class="line">    <span class="number">1500</span>  <span class="comment"># Maximum length of wake word that the streaming model will accept</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># The best model weights are chosen first by minimizing the specified minimization metric below the specified target_minimization</span></span><br><span class="line"><span class="comment"># Once the target has been met, it chooses the maximum of the maximization metric. Set &#x27;minimization_metric&#x27; to None to only maximize</span></span><br><span class="line"><span class="comment"># Available metrics:</span></span><br><span class="line"><span class="comment">#   - &quot;loss&quot; - cross entropy error on validation set</span></span><br><span class="line"><span class="comment">#   - &quot;accuracy&quot; - accuracy of validation set</span></span><br><span class="line"><span class="comment">#   - &quot;recall&quot; - recall of validation set</span></span><br><span class="line"><span class="comment">#   - &quot;precision&quot; - precision of validation set</span></span><br><span class="line"><span class="comment">#   - &quot;false_positive_rate&quot; - false positive rate of validation set</span></span><br><span class="line"><span class="comment">#   - &quot;false_negative_rate&quot; - false negative rate of validation set</span></span><br><span class="line"><span class="comment">#   - &quot;ambient_false_positives&quot; - count of false positives from the split validation_ambient set</span></span><br><span class="line"><span class="comment">#   - &quot;ambient_false_positives_per_hour&quot; - estimated number of false positives per hour on the split validation_ambient set</span></span><br><span class="line">config[<span class="string">&quot;target_minimization&quot;</span>] = <span class="number">0.9</span></span><br><span class="line">config[<span class="string">&quot;minimization_metric&quot;</span>] = <span class="literal">None</span>  <span class="comment"># Set to None to disable</span></span><br><span class="line"></span><br><span class="line">config[<span class="string">&quot;maximization_metric&quot;</span>] = <span class="string">&quot;average_viable_recall&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(<span class="string">&quot;training_parameters.yaml&quot;</span>), <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    documents = yaml.dump(config, file)</span><br></pre></td></tr></table></figure>

<p>这段代码的目的是生成一个 YAML 配置文件 (<code>training_parameters.yaml</code>)，该文件用于控制训练过程中的一些重要超参数（hyperparameters），这些超参数可以显著影响模型的质量。</p>
<ul>
<li><code>yaml</code>：用于生成和读取 YAML 文件的库。YAML 格式常用于保存配置文件</li>
<li>创建了一个空字典 <code>config</code>，后续会将训练相关的配置项添加到该字典中</li>
<li>设置一些基本参数，<code>window_step_ms</code>: 设置窗口步长（时间步长），单位是毫秒，表示每步滑动的时间长度。<code>train_dir</code>: 设置训练模型存储的目录路径。</li>
<li>设置特征数据集配置，<code>features</code>: 一个列表，包含多个字典，每个字典描述一个特征数据集。<ul>
<li><code>features_dir</code>: 存储特征数据集的目录。</li>
<li><code>sampling_weight</code>: 设置该数据集的采样权重，表示在训练过程中该数据集的重要性（权重越大，模型训练时选择该数据集的概率越大，即每个样本使用几次）。</li>
<li><code>penalty_weight</code>: 错误预测的惩罚权重。预测错误时该数据集的影响会根据该权重增加。</li>
<li><code>truth</code>: 布尔值，表示该数据集是否包含正样本（<code>True</code>）还是负样本（<code>False</code>）。</li>
<li><code>truncation_strategy</code>: 对超长的频谱图进行截断的策略，具体值包括：<ul>
<li><code>random</code>: 随机选择频谱图的一部分。</li>
<li><code>truncate_start</code>: 从频谱图的开始位置去掉一部分。</li>
<li><code>truncate_end</code>: 从频谱图的结尾去掉一部分。</li>
<li><code>split</code>: 将长频谱图切分为多个小频谱图。</li>
</ul>
</li>
<li><code>type</code>: 数据集的类型，通常是 <code>mmap</code>，表示存储为 <code>mmap</code> 格式的文件。</li>
</ul>
</li>
<li><code>training_steps</code>: 设置训练的步骤数，这里设定为 10000 步。<code>positive_class_weight</code> 和 <code>negative_class_weight</code>: 设置正负类的权重。比如，负类的权重大于正类的权重（20 vs 1），意味着训练过程中负样本的影响更大。</li>
<li><code>learning_rates</code>: 设置 Adam 优化器的学习率。<code>batch_size</code>: 每次训练的批次大小，表示每次训练所用的样本数。</li>
<li><code>time_mask_max_size</code> 和 <code>freq_mask_max_size</code>: 控制时域和频域掩码的最大大小。时间掩码和频率掩码是 SpecAugment 数据增强的一部分，用于扰动频谱图。<code>time_mask_count</code> 和 <code>freq_mask_count</code>: 控制时间和频率掩码的应用数量。设置为 <code>0</code> 表示不使用 SpecAugment。</li>
<li><code>eval_step_interval</code>: 每训练多少步进行一次评估，这里设定为每 500 步进行一次评估。<code>clip_duration_ms</code>: 流式模型接受的最大语音片段长度，单位是毫秒。</li>
<li><code>target_minimization</code>: 目标最小化指标的阈值，模型需要尽量将该指标降到这个值以下。<code>minimization_metric</code>: 用于最小化的指标，常见的指标有 <code>loss</code>, <code>accuracy</code>, <code>recall</code> 等。设置为 <code>None</code> 表示不使用最小化指标。<code>maximization_metric</code>: 用于最大化的指标，这里设置为 <code>average_viable_recall</code>，表示希望最大化可行召回率。</li>
<li>最后，使用 <code>yaml.dump()</code> 将 <code>config</code> 字典保存为一个 YAML 配置文件，文件名为 <code>training_parameters.yaml</code>。</li>
</ul>
<p><strong>第九块：</strong></p>
<figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Trains a model. When finished, it will quantize and convert the model to a</span></span><br><span class="line"><span class="comment"># streaming version suitable for on-device detection.</span></span><br><span class="line"><span class="comment"># It will resume if stopped, but it will start over at the configured training</span></span><br><span class="line"><span class="comment"># steps in the yaml file.</span></span><br><span class="line"><span class="comment"># Change --train 0 to only convert and test the best-weighted model.</span></span><br><span class="line"><span class="comment"># On Google colab, it doesn&#x27;t print the mini-batch results, so it may appear</span></span><br><span class="line"><span class="comment"># stuck for several minutes! Additionally, it is very slow compared to training</span></span><br><span class="line"><span class="comment"># on a local GPU.</span></span><br><span class="line"></span><br><span class="line">!python -m microwakeword.model_train_eval <span class="string">\</span></span><br><span class="line">--training_config=<span class="string">&#x27;training_parameters.yaml&#x27;</span> <span class="string">\</span></span><br><span class="line">--train <span class="number">1</span> <span class="string">\</span></span><br><span class="line">--restore_checkpoint <span class="number">1</span> <span class="string">\</span></span><br><span class="line">--test_tf_nonstreaming <span class="number">0</span> <span class="string">\</span></span><br><span class="line">--test_tflite_nonstreaming <span class="number">0</span> <span class="string">\</span></span><br><span class="line">--test_tflite_nonstreaming_quantized <span class="number">0</span> <span class="string">\</span></span><br><span class="line">--test_tflite_streaming <span class="number">0</span> <span class="string">\</span></span><br><span class="line">--test_tflite_streaming_quantized <span class="number">1</span> <span class="string">\</span></span><br><span class="line">--use_weights <span class="string">&quot;best_weights&quot;</span> <span class="string">\</span></span><br><span class="line">mixednet <span class="string">\</span></span><br><span class="line">--pointwise_filters <span class="string">&quot;64,64,64,64&quot;</span> <span class="string">\</span></span><br><span class="line">--repeat_in_block  <span class="string">&quot;1, 1, 1, 1&quot;</span> <span class="string">\</span></span><br><span class="line">--mixconv_kernel_sizes <span class="string">&#x27;[5], [7,11], [9,15], [23]&#x27;</span> <span class="string">\</span></span><br><span class="line">--residual_connection <span class="string">&quot;0,0,0,0&quot;</span> <span class="string">\</span></span><br><span class="line">--first_conv_filters <span class="number">32</span> <span class="string">\</span></span><br><span class="line">--first_conv_kernel_size <span class="number">5</span> <span class="string">\</span></span><br><span class="line">--stride <span class="number">3</span></span><br></pre></td></tr></table></figure>

<p>这段代码是用来训练一个模型，并根据训练的结果对模型进行量化和转换，使其适用于设备端的流式检测。代码的关键部分是通过命令行调用 Python 模块 <code>microwakeword.model_train_eval</code> 来执行训练过程。</p>
<p>命令行参数解析：</p>
<ol>
<li><strong><code>--training_config=&#39;training_parameters.yaml&#39;</code></strong><ul>
<li>指定训练配置文件 <code>training_parameters.yaml</code>，其中包含了模型训练所需的超参数，如学习率、训练步骤、数据集配置等。</li>
</ul>
</li>
<li><strong><code>--train 1</code></strong><ul>
<li>设置 <code>--train</code> 参数为 <code>1</code>，表示执行训练过程。如果设置为 <code>0</code>，则仅会转换和测试最佳权重的模型。</li>
</ul>
</li>
<li><strong><code>--restore_checkpoint 1</code></strong><ul>
<li>设置 <code>--restore_checkpoint</code> 为 <code>1</code>，表示从最近的检查点恢复训练。如果之前的训练已经中断，可以通过此选项从中断的位置继续训练。</li>
</ul>
</li>
<li><strong><code>--test_tf_nonstreaming 0</code></strong><ul>
<li>设置 <code>--test_tf_nonstreaming</code> 为 <code>0</code>，表示不在非流模式下测试 TensorFlow 模型。</li>
</ul>
</li>
<li><strong><code>--test_tflite_nonstreaming 0</code></strong><ul>
<li>设置 <code>--test_tflite_nonstreaming</code> 为 <code>0</code>，表示不在非流模式下测试 TensorFlow Lite 模型。</li>
</ul>
</li>
<li><strong><code>--test_tflite_nonstreaming_quantized 0</code></strong><ul>
<li>设置 <code>--test_tflite_nonstreaming_quantized</code> 为 <code>0</code>，表示不在非流模式下测试已量化的 TensorFlow Lite 模型。</li>
</ul>
</li>
<li><strong><code>--test_tflite_streaming 0</code></strong><ul>
<li>设置 <code>--test_tflite_streaming</code> 为 <code>0</code>，表示不在流模式下测试 TensorFlow Lite 模型。</li>
</ul>
</li>
<li><strong><code>--test_tflite_streaming_quantized 1</code></strong><ul>
<li>设置 <code>--test_tflite_streaming_quantized</code> 为 <code>1</code>，表示在流模式下测试已量化的 TensorFlow Lite 模型。</li>
</ul>
</li>
<li><strong><code>--use_weights &quot;best_weights&quot;</code></strong><ul>
<li>使用最佳权重来训练模型，这个参数会选择在验证过程中表现最好的权重来进行训练或测试。</li>
</ul>
</li>
<li><strong><code>mixednet</code></strong><ul>
<li>这是模型的类型，可能是指一个混合网络架构（例如，结合卷积和其他层的网络）。</li>
</ul>
</li>
<li><strong><code>--pointwise_filters &quot;64,64,64,64&quot;</code></strong><ul>
<li>这是指定每个网络块的卷积过滤器数量，表示该网络架构中使用了 4 个卷积层，每个卷积层有 64 个过滤器。</li>
</ul>
</li>
<li><strong><code>--repeat_in_block &quot;1, 1, 1, 1&quot;</code></strong><ul>
<li>指定在每个卷积块中重复的次数，意味着每个卷积块只重复一次。</li>
</ul>
</li>
<li><strong><code>--mixconv_kernel_sizes &#39;[5], [7,11], [9,15], [23]&#39;</code></strong><ul>
<li>设置混合卷积层的卷积核尺寸，分别为 <code>[5]</code>，<code>[7,11]</code>，<code>[9,15]</code>，<code>[23]</code>。这些不同的卷积核大小用于处理不同大小的局部特征。</li>
</ul>
</li>
<li><strong><code>--residual_connection &quot;0,0,0,0&quot;</code></strong><ul>
<li>设置残差连接的配置，<code>0</code> 表示不使用残差连接，<code>1</code> 表示使用。</li>
</ul>
</li>
<li><strong><code>--first_conv_filters 32</code></strong><ul>
<li>设置第一个卷积层的过滤器数量为 32。</li>
</ul>
</li>
<li><strong><code>--first_conv_kernel_size 5</code></strong><ul>
<li>设置第一个卷积层的卷积核大小为 5。</li>
</ul>
</li>
<li><strong><code>--stride 3</code></strong><ul>
<li>设置卷积层的步长为 3，表示每次滑动的步长为 3。</li>
</ul>
</li>
</ol>
<p><strong>第十块：</strong></p>
<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Downloads the tflite model file. To use on the device, you need to write a</span></span><br><span class="line"><span class="comment"># Model JSON file. See https://esphome.io/components/micro_wake_word for the</span></span><br><span class="line"><span class="comment"># documentation and</span></span><br><span class="line"><span class="comment"># https://github.com/esphome/micro-wake-word-models/tree/main/models/v2 for</span></span><br><span class="line"><span class="comment"># examples. Adjust the probability threshold based on the test results obtained</span></span><br><span class="line"><span class="comment"># after training is finished. You may also need to increase the Tensor arena</span></span><br><span class="line"><span class="comment"># model size if the model fails to load.</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">from</span> google.colab import <span class="built_in">files</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">files</span>.download(f<span class="string">&quot;trained_models/wakeword/tflite_stream_state_internal_quant/stream_state_internal_quant.tflite&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>下载训练好的量化模型到本机。</p>
<p>okok，开炮！</p>
<p>缺什么库就pip install什么库，我在运行第九块进行训练时，出现一个问题（节选）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">E0000 00:00:1743592764.006021  298082 cuda_dnn.cc:522] Loaded runtime CuDNN library: 9.1.0 but <span class="built_in">source</span> was compiled with: 9.3.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.</span><br></pre></td></tr></table></figure>

<p>经查，是用了base环境下的cudnn库了，把base环境下的cudnn库卸载就好了（试了八百种方法，折磨了一整天😒）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python uninstall nvidia-cudnn-cu12</span><br></pre></td></tr></table></figure>

<h3 id="训练与测试"><a href="#训练与测试" class="headerlink" title="训练与测试"></a>训练与测试</h3><p>okok，那咱们直接开炮（训练），依次运行<code>notebook</code>中的代码块进行资源下载和数据集制作以及训练参数配置，训练结束后，会在<code>microWakeWord/notebooks/trained_models/wakeword/tflite_stream_state_internal_quant</code>文件夹下看到<code>stream_state_internal_quant.tflite</code>这个模型文件：</p>
<img src="/2025/04/03/KWS%E4%B9%8BmicroWakeWord%E5%AE%89%E8%A3%85%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95/9eecfa2b857a8bb9b05aa71619546346.png" class="" title="9eecfa2b857a8bb9b05aa71619546346">

<p>我们需要再去克隆一个库<a target="_blank" rel="noopener" href="https://github.com/OHF-Voice/pymicro-wakeword/tree/master">pymicro-wakeword</a>：</p>
<p>直接<code>pip install pymicro-wakeword</code>应该也行（作者介绍的就是这个方法），但我使用的是下面这种方式：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/OHF-Voice/pymicro-wakeword.git</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> pymicro-wakeword</span><br><span class="line"></span><br><span class="line">conda create -n pymicro_wakeword python=3.10</span><br><span class="line"></span><br><span class="line">conda activate pymicro_wakeword</span><br><span class="line"></span><br><span class="line">pip install -r requirements.txt</span><br><span class="line"></span><br><span class="line">(可选，我没运行) pip install -e .</span><br></pre></td></tr></table></figure>

<p>将<code>stream_state_internal_quant.tflite</code>复制到<code>pymicro-wakeword/pymicro-wakeword/model</code>下，并重命名为<code>hey_bubu.tflite</code>，需要注意的是，还需要创建同名的json文件，如果没有这个文件：</p>
<img src="/2025/04/03/KWS%E4%B9%8BmicroWakeWord%E5%AE%89%E8%A3%85%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95/3bef79d612d7f6d664fc2cc1cfd97743.png" class="" title="3bef79d612d7f6d664fc2cc1cfd97743">

<p><strong>同名<code>json</code>文件如下：</strong></p>
<img src="/2025/04/03/KWS%E4%B9%8BmicroWakeWord%E5%AE%89%E8%A3%85%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95/90c149772bb0c8a0da6b0688b51979af.png" class="" title="90c149772bb0c8a0da6b0688b51979af">

<p><strong>即：</strong></p>
<figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;type&quot;: &quot;micro&quot;,</span><br><span class="line">  &quot;wake<span class="built_in">_</span>word&quot;: &quot;hey bubu&quot;,</span><br><span class="line">  &quot;author&quot;: &quot;chr&quot;,</span><br><span class="line">  &quot;website&quot;: &quot;https://caihaoran-00.github.io/&quot;,</span><br><span class="line">  &quot;model&quot;: &quot;hey<span class="built_in">_</span>bubu.tflite&quot;,</span><br><span class="line">  &quot;trained<span class="built_in">_</span>languages&quot;: [&quot;en&quot;],</span><br><span class="line">  &quot;version&quot;: 2,</span><br><span class="line">  &quot;micro&quot;: &#123;</span><br><span class="line">    &quot;probability<span class="built_in">_</span>cutoff&quot;: 0.97,</span><br><span class="line">    &quot;feature<span class="built_in">_</span>step<span class="built_in">_</span>size&quot;: 10,</span><br><span class="line">    &quot;sliding<span class="built_in">_</span>window<span class="built_in">_</span>size&quot;: 5,</span><br><span class="line">    &quot;tensor<span class="built_in">_</span>arena<span class="built_in">_</span>size&quot;: 26080,</span><br><span class="line">    &quot;minimum<span class="built_in">_</span>esphome<span class="built_in">_</span>version&quot;: &quot;2024.7.0&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>再次运行：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arecord -r <span class="number">16000</span> -c <span class="number">1</span> -f S16_LE -t raw |   python3 -m pymicro_wakeword --model <span class="string">&#x27;hey_bubu&#x27;</span></span><br></pre></td></tr></table></figure>

<p>对着麦克风说：<code>hey,bubu</code>，将会得到如下的打印。</p>
<img src="/2025/04/03/KWS%E4%B9%8BmicroWakeWord%E5%AE%89%E8%A3%85%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95/a213cd73c57519b6aac53485bed42d71.png" class="" title="a213cd73c57519b6aac53485bed42d71">

<p>okok，让同事也说了两句，感觉基本可用，先部署起来，再花精力优化吧。</p>
<hr>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/kahrendt/microWakeWord">https://github.com/kahrendt/microWakeWord</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/kahrendt/microWakeWord/blob/main/notebooks/basic_training_notebook.ipynb">https://github.com/kahrendt/microWakeWord/blob/main/notebooks/basic_training_notebook.ipynb</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/OHF-Voice/pymicro-wakeword/tree/master">https://github.com/OHF-Voice/pymicro-wakeword/tree/master</a></li>
</ol>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/KWS/" rel="tag"># KWS</a>
              <a href="/tags/microWakeWord/" rel="tag"># microWakeWord</a>
              <a href="/tags/tensorflow/" rel="tag"># tensorflow</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/04/02/Ubuntu22-04%E6%9B%B4%E6%96%B0NVIDIA%E9%A9%B1%E5%8A%A8/" rel="prev" title="Ubuntu22.04更新NVIDIA驱动">
                  <i class="fa fa-angle-left"></i> Ubuntu22.04更新NVIDIA驱动
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/04/08/llama-cpp%E5%AE%89%E8%A3%85%E4%B8%8E%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8%EF%BC%88convert-hf-to-gguf-py/" rel="next" title="llama.cpp安装与简单使用（convert-hf-to-gguf.py)">
                  llama.cpp安装与简单使用（convert-hf-to-gguf.py) <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Chr</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">358k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">21:43</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"ams","src":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.min.js","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
