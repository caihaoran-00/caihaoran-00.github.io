<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"caihaoran-00.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.22.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"mac"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="前言在现代大模型应用开发中，构建能够处理复杂任务和多步骤推理的 Agent 是一个重要需求。LangGraph 是一个基于 LangChain 的框架，专门设计用于构建和编排复杂的 Agent 工作流。它通过图（Graph）结构定义任务流程，支持循环、分支、并行等复杂逻辑，是开发高效、灵活 Agent 应用的理想选择。 本文将介绍 LangGraph 的核心概念，并通过几个基础示例展示如何使用它构">
<meta property="og:type" content="article">
<meta property="og:title" content="langgraph介绍及demo">
<meta property="og:url" content="https://caihaoran-00.github.io/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/index.html">
<meta property="og:site_name" content="Chr&#39;s Blog">
<meta property="og:description" content="前言在现代大模型应用开发中，构建能够处理复杂任务和多步骤推理的 Agent 是一个重要需求。LangGraph 是一个基于 LangChain 的框架，专门设计用于构建和编排复杂的 Agent 工作流。它通过图（Graph）结构定义任务流程，支持循环、分支、并行等复杂逻辑，是开发高效、灵活 Agent 应用的理想选择。 本文将介绍 LangGraph 的核心概念，并通过几个基础示例展示如何使用它构">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://caihaoran-00.github.io/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/image-20250211153745222.png">
<meta property="og:image" content="https://caihaoran-00.github.io/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/image-20250224115957563.png">
<meta property="og:image" content="https://caihaoran-00.github.io/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/image-20250224120037990.png">
<meta property="og:image" content="https://caihaoran-00.github.io/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/image-20250224151902529.png">
<meta property="og:image" content="https://caihaoran-00.github.io/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/image-20250225103010292.png">
<meta property="og:image" content="https://caihaoran-00.github.io/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/image-20250225104331399.png">
<meta property="article:published_time" content="2025-02-10T09:14:33.000Z">
<meta property="article:modified_time" content="2025-04-28T07:18:21.979Z">
<meta property="article:author" content="Chr">
<meta property="article:tag" content="llm">
<meta property="article:tag" content="langgraph">
<meta property="article:tag" content="langchain">
<meta property="article:tag" content="agent">
<meta property="article:tag" content="react">
<meta property="article:tag" content="cot">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://caihaoran-00.github.io/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/image-20250211153745222.png">


<link rel="canonical" href="https://caihaoran-00.github.io/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://caihaoran-00.github.io/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/","path":"2025/02/10/langgraph介绍及demo/","title":"langgraph介绍及demo"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>langgraph介绍及demo | Chr's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Chr's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Record and Share</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Langgraph"><span class="nav-number">2.</span> <span class="nav-text">Langgraph</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5"><span class="nav-number">2.1.</span> <span class="nav-text">核心概念</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#LangGraph-%E7%9A%84%E4%BC%98%E5%8A%BF"><span class="nav-number">3.</span> <span class="nav-text">LangGraph 的优势</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B1%EF%BC%9A%E6%9E%84%E5%BB%BA%E5%9F%BA%E6%9C%AC%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA"><span class="nav-number">4.</span> <span class="nav-text">示例1：构建基本聊天机器人</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#TypedDict"><span class="nav-number">4.1.</span> <span class="nav-text">TypedDict</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Annotated"><span class="nav-number">4.2.</span> <span class="nav-text">Annotated</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B2%EF%BC%9A%E4%BD%BF%E7%94%A8%E5%B7%A5%E5%85%B7%E5%A2%9E%E5%BC%BA%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA"><span class="nav-number">5.</span> <span class="nav-text">示例2：使用工具增强聊天机器人</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%87%AA%E5%B7%B1%E6%9E%84%E5%BB%BA%E6%96%B9%E5%BC%8F"><span class="nav-number">5.1.</span> <span class="nav-text">自己构建方式</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B3%EF%BC%9A%E4%B8%BA%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%B7%BB%E5%8A%A0%E5%86%85%E5%AD%98%EF%BC%88%E8%AE%B0%E5%BF%86%EF%BC%89"><span class="nav-number">6.</span> <span class="nav-text">示例3：为聊天机器人添加内存（记忆）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B4%EF%BC%9A%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA"><span class="nav-number">7.</span> <span class="nav-text">示例4：流式输出</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B5%EF%BC%9A%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B7%A5%E5%85%B7"><span class="nav-number">8.</span> <span class="nav-text">示例5：自定义工具</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B6%EF%BC%9A%E7%B3%BB%E7%BB%9F%E6%8F%90%E7%A4%BA%E8%AF%8D"><span class="nav-number">9.</span> <span class="nav-text">示例6：系统提示词</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B7%EF%BC%9A%E7%BB%88%E6%9E%81%E7%AE%80%E5%8C%96%E7%89%88"><span class="nav-number">10.</span> <span class="nav-text">示例7：终极简化版</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B8%EF%BC%9A%E8%81%8A%E5%A4%A9%E5%8E%86%E5%8F%B2%E7%AE%A1%E7%90%86"><span class="nav-number">11.</span> <span class="nav-text">示例8：聊天历史管理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%99%84%E5%BD%95"><span class="nav-number">12.</span> <span class="nav-text">附录</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ReAct"><span class="nav-number">12.1.</span> <span class="nav-text">ReAct</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%9D%E7%BB%B4%E9%93%BE%EF%BC%88Chain-of-Thought-CoT%EF%BC%89"><span class="nav-number">12.2.</span> <span class="nav-text">思维链（Chain of Thought, CoT）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#workflow"><span class="nav-number">12.3.</span> <span class="nav-text">workflow</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5"><span class="nav-number">13.</span> <span class="nav-text">参考链接</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Chr</p>
  <div class="site-description" itemprop="description">Welcome to my little world</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">56</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">78</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="mailto:1299964565@qq.com" title="E-Mail → mailto:1299964565@qq.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://caihaoran-00.github.io/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Chr">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chr's Blog">
      <meta itemprop="description" content="Welcome to my little world">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="langgraph介绍及demo | Chr's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          langgraph介绍及demo
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-02-10 17:14:33" itemprop="dateCreated datePublished" datetime="2025-02-10T17:14:33+08:00">2025-02-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-04-28 15:18:21" itemprop="dateModified" datetime="2025-04-28T15:18:21+08:00">2025-04-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/code/" itemprop="url" rel="index"><span itemprop="name">code</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>8.5k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>31 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在现代大模型应用开发中，构建能够处理复杂任务和多步骤推理的 Agent 是一个重要需求。<strong>LangGraph</strong> 是一个基于 LangChain 的框架，专门设计用于构建和编排复杂的 Agent 工作流。它通过图（Graph）结构定义任务流程，支持循环、分支、并行等复杂逻辑，是开发高效、灵活 Agent 应用的理想选择。</p>
<p>本文将介绍 LangGraph 的核心概念，并通过几个基础示例展示如何使用它构建 Agent 应用。</p>
<span id="more"></span>

<hr>
<h2 id="Langgraph"><a href="#Langgraph" class="headerlink" title="Langgraph"></a>Langgraph</h2><p>LangGraph 是一个基于图的框架，用于定义和运行复杂的 Agent 工作流。它的核心思想是将任务分解为多个节点（Node），并通过边（Edge）连接这些节点，形成一个有向图。每个节点可以执行特定的任务（如调用 API、生成文本、处理数据等），而边则定义了任务的执行顺序和条件分支。</p>
<h3 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h3><ol>
<li><strong>节点（Node）</strong>：任务的基本单元，每个节点执行特定的功能</li>
<li><strong>边（Edge）</strong>：连接节点的路径，定义任务的执行顺序</li>
<li><strong>图（Graph）</strong>：由节点和边组成的工作流</li>
<li><strong>条件分支（Conditional Edge）</strong>：根据条件决定下一步执行的节点</li>
<li><strong>循环（Cycle）</strong>：支持循环执行某些节点。</li>
</ol>
<hr>
<h2 id="LangGraph-的优势"><a href="#LangGraph-的优势" class="headerlink" title="LangGraph 的优势"></a>LangGraph 的优势</h2><ul>
<li><strong>灵活性</strong>：支持复杂的工作流设计，包括分支、循环和并行任务。</li>
<li><strong>模块化</strong>：将任务分解为多个节点，便于维护和扩展。</li>
<li><strong>高效性</strong>：通过图结构优化任务执行顺序，减少冗余计算。</li>
<li><strong>易用性</strong>：与 LangChain 无缝集成，提供丰富的工具和模块。</li>
</ul>
<hr>
<h2 id="示例1：构建基本聊天机器人"><a href="#示例1：构建基本聊天机器人" class="headerlink" title="示例1：构建基本聊天机器人"></a>示例1：构建基本聊天机器人</h2><figure class="highlight python"><figcaption><span>introduction_part1.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">https://langchain-ai.github.io/langgraph/tutorials/introduction/#part-1-build-a-basic-chatbot</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用局域网本地部署模型</span></span><br><span class="line"><span class="comment"># llm = ChatOpenAI(model_name=&quot;Qwen&quot;,</span></span><br><span class="line"><span class="comment">#                    openai_api_key=&#x27;Empty&#x27;,</span></span><br><span class="line"><span class="comment">#                    openai_api_base=&#x27;http://192.168.0.138:8000/v1&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置大模型参数</span></span><br><span class="line">LLM_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;sk-*******&quot;</span>,</span><br><span class="line">    <span class="string">&quot;base_url&quot;</span>: <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen2.5-7b-instruct&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化大模型</span></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=LLM_CONFIG[<span class="string">&quot;model&quot;</span>],</span><br><span class="line">    openai_api_key=LLM_CONFIG[<span class="string">&quot;api_key&quot;</span>],</span><br><span class="line">    openai_api_base=LLM_CONFIG[<span class="string">&quot;base_url&quot;</span>],</span><br><span class="line">    streaming=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [llm.invoke(state[<span class="string">&quot;messages&quot;</span>])]&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># The first argument is the unique node name</span></span><br><span class="line"><span class="comment"># The second argument is the function or object that will be called whenever</span></span><br><span class="line"><span class="comment"># the node is used.</span></span><br><span class="line">graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br><span class="line">graph_builder.set_entry_point(<span class="string">&quot;chatbot&quot;</span>)    <span class="comment"># graph_builder.add_edge(START, &quot;chatbot&quot;)</span></span><br><span class="line">graph_builder.set_finish_point(<span class="string">&quot;chatbot&quot;</span>)   <span class="comment"># graph_builder.add_edge(&quot;chatbot&quot;, END)</span></span><br><span class="line">graph = graph_builder.<span class="built_in">compile</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stream_graph_updates</span>(<span class="params">user_input: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="keyword">for</span> event <span class="keyword">in</span> graph.stream(&#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, user_input)]&#125;):</span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> event.values():</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Assistant:&quot;</span>, value[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].content)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        user_input = <span class="built_in">input</span>(<span class="string">&quot;User: &quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> user_input.lower() <span class="keyword">in</span> [<span class="string">&quot;quit&quot;</span>, <span class="string">&quot;exit&quot;</span>, <span class="string">&quot;q&quot;</span>]:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Goodbye!&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="comment"># fallback if input() is not available</span></span><br><span class="line">        user_input = <span class="string">&quot;What do you know about LangGraph?&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;User: &quot;</span> + user_input)</span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<p>主要流程：</p>
<ul>
<li>定义对话状态（State）</li>
<li>初始化Langgraph</li>
<li>配置LLM</li>
<li>定义聊天机器人（chatbot）</li>
<li>构建对话流，这里是最简单的线性结构</li>
<li>运行聊天循环</li>
</ul>
<img src="/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/image-20250211153745222.png" class="" title="image-20250211153745222">

<p><strong>代码拆解&amp;讲解：</strong></p>
<h3 id="TypedDict"><a href="#TypedDict" class="headerlink" title="TypedDict"></a>TypedDict</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br></pre></td></tr></table></figure>

<p>首先，<code>TypedDict</code> 是 Python 3.8+ 引入的一种<strong>类型提示工具</strong>，用于为字典定义结构化类型约束。<br>它本质上是<strong>一种“伪类”</strong>，但它的实例<strong>仍然是普通的 Python 字典</strong>，而不是类的实例。</p>
<p>是不是和<a href="https://caihaoran-00.github.io/2025/02/05/fastapi-request%E6%9E%84%E5%BB%BA%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BE%AE%E6%9C%8D%E5%8A%A1/#more">这里的</a><code>pydantic</code>的<code>BaseModel</code>模块（结构化类型约束方面）比较相似？：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"><span class="comment"># 定义请求数据模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">User</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    name: <span class="built_in">str</span></span><br><span class="line">    age: <span class="built_in">int</span></span><br><span class="line">    email: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span>  <span class="comment"># 可选字段</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># POST 接口，接收 JSON 请求体</span></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/users/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_user</span>(<span class="params">user: User</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;message&quot;</span>: <span class="string">&quot;用户已创建&quot;</span>, <span class="string">&quot;user&quot;</span>: user&#125;</span><br></pre></td></tr></table></figure>

<p>话说回来，为什么要使用<code>TypeDict</code>？</p>
<p>在Python中，字典是一种常见的数据结构：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">person = &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;Alice&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="number">25</span>&#125;</span><br></pre></td></tr></table></figure>

<p>有个问题：</p>
<ul>
<li>没有静态类型检查：<code>person[&quot;age&quot;]</code> 可能被意外赋值为 <code>str</code> 类型（如 <code>&quot;25&quot;</code>）。</li>
<li>没有固定结构：字典可以动态添加&#x2F;删除键，容易导致数据不一致。</li>
</ul>
<p>所以，<code>TypeDict</code>应运而生。</p>
<p><code>TypeDict</code>的基本用法</p>
<p>定义一个结构化的字典：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> TypedDict</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    name: <span class="built_in">str</span></span><br><span class="line">    age: <span class="built_in">int</span></span><br></pre></td></tr></table></figure>

<p>这个<code>Person</code><strong>看起来像类</strong>，但它<strong>不能被实例化</strong>（pyhton 3.8+版本不能实例化，Python3.9+就能实例化了，我使用的python 3.10+所以可以被实例化）：</p>
<figure class="highlight python"><figcaption><span>typeddict_t.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> TypedDict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    name: <span class="built_in">str</span></span><br><span class="line">    age: <span class="built_in">int</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">p = Person()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;p=<span class="subst">&#123;p&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;type(p)=<span class="subst">&#123;<span class="built_in">type</span>(p)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">p1 = &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;Alice&quot;</span>&#125;</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;type(p1)=<span class="subst">&#123;<span class="built_in">type</span>(p1)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">p2: Person = &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;Bob&quot;</span>&#125;</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;p2=<span class="subst">&#123;p2&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">p3: Person = &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;Alice&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="number">23</span>&#125;</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;p3=<span class="subst">&#123;p3&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">p4: Person = &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;Alice&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="string">&quot;23&quot;</span>&#125;</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;p4=<span class="subst">&#123;p4&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">p5: Person = &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;Alice&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="number">23</span>, <span class="string">&quot;height&quot;</span>: <span class="number">168</span>&#125;</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;p5=<span class="subst">&#123;p5&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<img src="/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/image-20250224115957563.png" class="" title="image-20250224115957563">

<img src="/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/image-20250224120037990.png" class="" title="image-20250224120037990">



<p><strong>注意注意注意：</strong></p>
<p>上面说的<strong>为字典定义结构化类型约束</strong>，并未体现出来啊，类型不匹配或者增加新的键值对不是也能运行吗？也没报错啊？好的，你越来越接近真相了，这里引入（科普）两个概念，</p>
<ul>
<li><p><strong>静态检查</strong>是在你运行代码之前（比如使用PyCharm的类型检查功能）进行的。这些工具会根据你写的类型提示（例如 TypedDict）来检查代码是否符合预期。如果发现类型不匹配，它们会给出警告或错误提示，但这并不会阻止代码运行。</p>
</li>
<li><p><strong>运行时</strong>则是在你点击“运行”之后，Python 真正执行你的代码。此时 Python 不会自动检查类型约束，所以即使类型不匹配（比如 p4 的 age 传了字符串），也不会报错。</p>
</li>
</ul>
<p>哦！明白了！原来TypedDict是作用在静态检查阶段的啊！就说为什么p2、p4和p5会出现阴影标注呢，而且鼠标放上去还会有提示，但实际上TypedDict并不影响运行时。</p>
<h3 id="Annotated"><a href="#Annotated" class="headerlink" title="Annotated"></a>Annotated</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br></pre></td></tr></table></figure>

<p>上文解释了TypedDict的作用，那么Annotated的作用是什么呢？</p>
<p><code>Annotated</code> 是 <code>typing</code> 模块中的一个工具，它的作用是：<br>💡 <strong>“给类型提示（Type Hint）添加额外的元数据（Metadata）。”</strong></p>
<p>简单来说，它可以在 <strong>类型上附加额外的信息</strong>，这些信息不会影响 Python 运行时的行为，但可以被工具（如 <code>mypy</code>、框架、库）用来做额外的检查或处理。</p>
<p>简单的Annotated例子：</p>
<figure class="highlight python"><figcaption><span>annotated_t.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel, Field</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 规定 age 只能在 0~120 之间</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    name: <span class="built_in">str</span></span><br><span class="line">    age: Annotated[<span class="built_in">int</span>, Field(ge=<span class="number">0</span>, le=<span class="number">120</span>)]  <span class="comment"># ge=greater or equal, le=less or equal</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">p = Person(name=<span class="string">&quot;Alice&quot;</span>, age=<span class="number">25</span>)  <span class="comment"># ✅ 正确</span></span><br><span class="line">p1 = Person(name=<span class="number">1</span>, age=<span class="number">25</span>)  <span class="comment"># ❌ 运行时报错</span></span><br><span class="line">p2 = Person(name=<span class="string">&quot;Bob&quot;</span>, age=<span class="number">150</span>)  <span class="comment"># ❌ 运行时报错</span></span><br></pre></td></tr></table></figure>

<p>哦，那看起来定义的这个State首先是个字典，然后键是”messages”，值对应的是个List，对这个messages附加的额外信息是add_messages，那么意思是他有自动累积历史对话的功能咯？验证一下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;[DEBUG] Incoming state[&#x27;messages&#x27;]: <span class="subst">&#123;state[<span class="string">&#x27;messages&#x27;</span>]&#125;</span>&quot;</span>)  <span class="comment"># 打印历史消息</span></span><br><span class="line">    response = llm.invoke(state[<span class="string">&quot;messages&quot;</span>])  <span class="comment"># 生成回复</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [response]&#125;  <span class="comment"># 仅返回当前的回复，不手动累积</span></span><br></pre></td></tr></table></figure>

<img src="/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/image-20250224151902529.png" class="" title="image-20250224151902529">

<p>可见，<strong>这里的add_messages并没有什么实际效果</strong>？</p>
<hr>
<h2 id="示例2：使用工具增强聊天机器人"><a href="#示例2：使用工具增强聊天机器人" class="headerlink" title="示例2：使用工具增强聊天机器人"></a>示例2：使用工具增强聊天机器人</h2><h3 id="自己构建方式"><a href="#自己构建方式" class="headerlink" title="自己构建方式"></a>自己构建方式</h3><ul>
<li><p>去<a target="_blank" rel="noopener" href="https://tavily.com/">这里</a>申请下tavily的API_KEY</p>
</li>
<li><p>定义（调用）工具</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.tools.tavily_search <span class="keyword">import</span> TavilySearchResults</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;TAVILY_API_KEY&quot;</span>] = <span class="string">&quot;tvly-*****&quot;</span></span><br><span class="line">tool = TavilySearchResults(max_results=<span class="number">2</span>)</span><br><span class="line">tools = [tool]</span><br><span class="line">tool.invoke(<span class="string">&quot;What&#x27;s a &#x27;node&#x27; in LangGraph?&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">D:\Anaconda3\envs\langchain\python.exe E:\chr_git\langchain_t\langgraph\introduction_part2.py </span><br><span class="line">[&#123;<span class="string">&#x27;url&#x27;</span>: <span class="string">&#x27;https://medium.com/@kbdhunga/beginners-guide-to-langgraph-understanding-state-nodes-and-edges-part-1-897e6114fa48&#x27;</span>, <span class="string">&#x27;content&#x27;</span>: <span class="string">&quot;Beginner’s Guide to LangGraph: Understanding State, Nodes, and Edges — Part 1 | by Kamal Dhungana | Medium Beginner’s Guide to LangGraph: Understanding State, Nodes, and Edges — Part 1 LangGraph — State, Node and Edge Explained Mainly, we will focus on various components of LangGraph: State, Node, and Edges, and how to build a complete graph from these components. Once we understand these components, we will be able to build relatively complex LangGraph-based agents. Each node represents a specific function or operation that processes the current state. Nodes can perform computations, modify the state, or generate outputs based on the input they receive. Follow 1.2K Followers Data scientist with a passion for AI, Regularly blogging about LLM and OpenAI&#x27;s innovations,Sharing insights for AI community growth Follow&quot;</span>&#125;, &#123;<span class="string">&#x27;url&#x27;</span>: <span class="string">&#x27;https://blog.langchain.dev/langgraph/&#x27;</span>, <span class="string">&#x27;content&#x27;</span>: <span class="string">&#x27;TL;DR: LangGraph is module built on top of LangChain to better enable creation of cyclical graphs, often needed for agent runtimes. This state is updated by nodes in the graph, which return operations to attributes of this state (in the form of a key-value store). After adding nodes, you can then add edges to create the graph. An example of this may be in the basic agent runtime, where we always want the model to be called after we call a tool. graph.add_edge(&quot;tools&quot;, &quot;model&quot;) The state of this graph by default contains concepts that should be familiar to you if you\&#x27;ve used LangChain agents: input, chat_history, intermediate_steps (and agent_outcome to represent the most recent agent outcome)&#x27;</span>&#125;]</span><br><span class="line"></span><br><span class="line">进程已结束，退出代码为 <span class="number">0</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>结合示例1就得到了：</p>
</li>
</ul>
<figure class="highlight python"><figcaption><span>introduction_part2.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">https://langchain-ai.github.io/langgraph/tutorials/introduction/#requirements</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> langchain_community.tools.tavily_search <span class="keyword">import</span> TavilySearchResults</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;TAVILY_API_KEY&quot;</span>] = <span class="string">&quot;tvly-*****&quot;</span></span><br><span class="line"></span><br><span class="line">tool = TavilySearchResults(max_results=<span class="number">2</span>)</span><br><span class="line">tools = [tool]</span><br><span class="line"><span class="comment"># print(tool.invoke(&quot;What&#x27;s a &#x27;node&#x27; in LangGraph?&quot;))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph,START,END</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"><span class="comment"># llm = ChatOpenAI(model_name=&quot;Qwen&quot;,</span></span><br><span class="line"><span class="comment">#                    openai_api_key=&#x27;Empty&#x27;,</span></span><br><span class="line"><span class="comment">#                    openai_api_base=&#x27;http://192.168.0.138:8000/v1&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置大模型参数</span></span><br><span class="line">LLM_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;sk-***********&quot;</span>,</span><br><span class="line">    <span class="string">&quot;base_url&quot;</span>: <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen2.5-7b-instruct&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化大模型</span></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=LLM_CONFIG[<span class="string">&quot;model&quot;</span>],</span><br><span class="line">    openai_api_key=LLM_CONFIG[<span class="string">&quot;api_key&quot;</span>],</span><br><span class="line">    openai_api_base=LLM_CONFIG[<span class="string">&quot;base_url&quot;</span>],</span><br><span class="line">    streaming=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [llm_with_tools.invoke(state[<span class="string">&quot;messages&quot;</span>])]&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> ToolMessage</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BasicToolNode</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;A node that runs the tools requested in the last AIMessage.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, tools: <span class="built_in">list</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="variable language_">self</span>.tools_by_name = &#123;tool.name: tool <span class="keyword">for</span> tool <span class="keyword">in</span> tools&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, inputs: <span class="built_in">dict</span></span>):</span><br><span class="line">        <span class="keyword">if</span> messages := inputs.get(<span class="string">&quot;messages&quot;</span>, []):</span><br><span class="line">            message = messages[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;No message found in input&quot;</span>)</span><br><span class="line">        outputs = []</span><br><span class="line">        <span class="keyword">for</span> tool_call <span class="keyword">in</span> message.tool_calls:</span><br><span class="line">            tool_result = <span class="variable language_">self</span>.tools_by_name[tool_call[<span class="string">&quot;name&quot;</span>]].invoke(</span><br><span class="line">                tool_call[<span class="string">&quot;args&quot;</span>]</span><br><span class="line">            )</span><br><span class="line">            outputs.append(</span><br><span class="line">                ToolMessage(</span><br><span class="line">                    content=json.dumps(tool_result),</span><br><span class="line">                    name=tool_call[<span class="string">&quot;name&quot;</span>],</span><br><span class="line">                    tool_call_id=tool_call[<span class="string">&quot;id&quot;</span>],</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: outputs&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tool_node = BasicToolNode(tools=tools)</span><br><span class="line">graph_builder.add_node(<span class="string">&quot;tools&quot;</span>, tool_node)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Literal</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">route_tools</span>(<span class="params"></span></span><br><span class="line"><span class="params">    state: State,</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Use in the conditional_edge to route to the ToolNode if the last message</span></span><br><span class="line"><span class="string">    has tool calls. Otherwise, route to the end.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(state, <span class="built_in">list</span>):</span><br><span class="line">        ai_message = state[-<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">elif</span> messages := state.get(<span class="string">&quot;messages&quot;</span>, []):</span><br><span class="line">        ai_message = messages[-<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">f&quot;No messages found in input state to tool_edge: <span class="subst">&#123;state&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">hasattr</span>(ai_message, <span class="string">&quot;tool_calls&quot;</span>) <span class="keyword">and</span> <span class="built_in">len</span>(ai_message.tool_calls) &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;tools&quot;</span></span><br><span class="line">    <span class="keyword">return</span> END</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># The `tools_condition` function returns &quot;tools&quot; if the chatbot asks to use a tool, and &quot;END&quot; if</span></span><br><span class="line"><span class="comment"># it is fine directly responding. This conditional routing defines the main agent loop.</span></span><br><span class="line">graph_builder.add_conditional_edges(</span><br><span class="line">    <span class="string">&quot;chatbot&quot;</span>,</span><br><span class="line">    route_tools,</span><br><span class="line">    <span class="comment"># The following dictionary lets you tell the graph to interpret the condition&#x27;s outputs as a specific node</span></span><br><span class="line">    <span class="comment"># It defaults to the identity function, but if you</span></span><br><span class="line">    <span class="comment"># want to use a node named something else apart from &quot;tools&quot;,</span></span><br><span class="line">    <span class="comment"># You can update the value of the dictionary to something else</span></span><br><span class="line">    <span class="comment"># e.g., &quot;tools&quot;: &quot;my_tools&quot;</span></span><br><span class="line">    &#123;<span class="string">&quot;tools&quot;</span>: <span class="string">&quot;tools&quot;</span>, END: END&#125;,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># Any time a tool is called, we return to the chatbot to decide the next step</span></span><br><span class="line">graph_builder.add_edge(<span class="string">&quot;tools&quot;</span>, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph_builder.add_edge(START, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph = graph_builder.<span class="built_in">compile</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stream_graph_updates</span>(<span class="params">user_input: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="keyword">for</span> event <span class="keyword">in</span> graph.stream(&#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, user_input)]&#125;):</span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> event.values():</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Assistant:&quot;</span>, value[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].content)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        user_input = <span class="built_in">input</span>(<span class="string">&quot;User: &quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> user_input.lower() <span class="keyword">in</span> [<span class="string">&quot;quit&quot;</span>, <span class="string">&quot;exit&quot;</span>, <span class="string">&quot;q&quot;</span>]:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Goodbye!&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="comment"># fallback if input() is not available</span></span><br><span class="line">        user_input = <span class="string">&quot;What do you know about LangGraph?&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;User: &quot;</span> + user_input)</span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<img src="/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/image-20250225103010292.png" class="" title="image-20250225103010292">

<p>与示例1相比，有以下几个方面改动：</p>
<ul>
<li><p>定义（调用）了TavilySearchResults工具，并放在了tools列表中，最后通过bind_tools将tools列表与llm绑定，chatbot中的使用的是绑定tools后的llm，即llm_with_tools</p>
</li>
<li><p>新增了工具节点（node），通过BasicToolNode类来定义工具节点（tool_node），</p>
<ul>
<li><code>__init__</code>方法接受一个工具列表（每个工具对象都有name），然后把工具列表转换成字典，以工具的<code>name</code>作为键，这样就可以通过<code>name</code>直接查找工具，而不必遍历整个列表，提高查找速度。</li>
<li><code>__call__</code>方法使这个类的实例可以像函数一样调用</li>
<li><code>inputs: dict</code>：<strong>输入数据</strong>，其中应该包含 <code>&quot;messages&quot;</code>，记录了当前的对话历史。</li>
<li><code>inputs.get(&quot;messages&quot;, [])</code>：尝试获取 <code>&quot;messages&quot;</code>，如果不存在就返回空列表 <code>[]</code>。</li>
<li><code>message = messages[-1]</code>：获取最新的消息（通常是 AI 生成的回复）。最新的 AI 消息可能包含 <code>&quot;tool_calls&quot;</code>，这些是 AI 让工具执行的指令。如果 <code>&quot;messages&quot;</code> 为空，则抛出异常 <code>ValueError</code></li>
<li><code>message.tool_calls</code>：这个 AI 消息中的工具调用列表</li>
<li><code>for tool_call in message.tool_calls:</code>：<strong>遍历所有工具调用</strong></li>
<li><code>tool_call[&quot;name&quot;]</code>：从 <code>tool_call</code> 获取工具名称</li>
<li><code>self.tools_by_name[tool_call[&quot;name&quot;]]</code>：从 <code>self.tools_by_name</code> <strong>找到对应的工具</strong></li>
<li><code>.invoke(tool_call[&quot;args&quot;])</code>：<strong>调用工具</strong>，传入 <code>tool_call[&quot;args&quot;]</code> 作为参数，得到 <code>tool_result</code>（工具执行结果）</li>
<li><code>ToolMessage</code> 是 LangGraph 或 LangChain 中的工具调用响应格式，表示 <strong>工具的返回信息</strong>。</li>
<li><code>json.dumps(tool_result)</code>：将 <code>tool_result</code> 转换为 JSON 格式，方便传输</li>
<li><code>name=tool_call[&quot;name&quot;]</code>：工具的名称</li>
<li><code>tool_call_id=tool_call[&quot;id&quot;]</code>：工具调用的 ID（用于追踪）</li>
<li><code>outputs</code> 是<strong>所有工具执行结果的列表</strong></li>
<li>返回一个字典 <code>&#123;&quot;messages&quot;: outputs&#125;</code>，符合 <code>LangGraph</code> 处理节点的格式</li>
</ul>
</li>
<li><p>新增条件边（add_conditional_edges,  route_tools），根据AI生成的消息是否包含工具调用（tool calls）来决定下一个执行的节点。如果消息里有工具调用，就转到<code>tools</code>处理工具请求；否则，直接结束对话（<code>END</code>）</p>
<ul>
<li><p><code>route_tools</code>函数用在<code>graph_builder.add_conditional_edges</code>里，作用是决定对话流程的走向</p>
</li>
<li><p><code>state</code> 是 <code>TypedDict</code> 结构，包含一个 <code>&quot;messages&quot;</code> 键（通常是一个消息列表）</p>
</li>
<li><p>这个函数会<strong>检查最近的一条消息</strong>，看它是否包含 <code>&quot;tool_calls&quot;</code>，如果有，就返回 <code>&quot;tools&quot;</code>，否则返回 <code>&quot;END&quot;</code></p>
</li>
<li><p>检查 <code>state</code> 是否是<strong>列表</strong>：</p>
<ul>
<li><p>如果 <code>state</code> 是列表，就取最后一条消息（<code>state[-1]</code>）</p>
</li>
<li><p>这种情况可能出现在某些消息格式不同的情况，比如 <code>state</code> 直接是消息列表，而不是 <code>TypedDict</code> 结构</p>
</li>
<li><p><code>state.get(&quot;messages&quot;, [])</code> 尝试获取 <code>&quot;messages&quot;</code> 列表，默认返回 &#96;[]&#96;&#96;</p>
</li>
<li><p>&#96;&#96;:&#x3D;<code>（海象运算符）确保 </code>messages<code>变量赋值后能继续在</code>if&#96; 代码块中使用</p>
</li>
<li><p><code>messages[-1]</code> 取出最后一条消息</p>
</li>
<li><p>如果 <code>state</code> 既不是列表，也没有 <code>&quot;messages&quot;</code>，就报错，说明输入 <code>state</code> 结构不对</p>
</li>
</ul>
</li>
<li><p><code>hasattr(ai_message, &quot;tool_calls&quot;)</code> 检查 <code>ai_message</code> 是否有 <code>tool_calls</code> 属性</p>
</li>
<li><p><code>len(ai_message.tool_calls) &gt; 0</code> 确保 <code>tool_calls</code> 里确实有内容</p>
</li>
<li><p>如果 <code>tool_calls</code> <strong>存在且不为空</strong>，返回 <code>&quot;tools&quot;</code>，表示应该去工具节点处理工具请求</p>
</li>
<li><p>添加条件边（conditional edges），根据<code>route_tools</code>的返回值决定下一个节点</p>
</li>
<li><p><code>chatbot</code>是当前节点，表示从<code>chatbot</code>节点出发；<code>route_tools</code>是条件判断函数，会根据<code>state</code>判断下一个要走的路径；<code>&#123;&quot;tools&quot;: &quot;tools&quot;, END: END&#125;</code>定义了 <code>route_tools</code> 返回值和图节点的映射，如果 <code>route_tools</code> 返回 <code>&quot;tools&quot;</code>，那么<strong>跳转到 <code>&quot;tools&quot;</code> 节点</strong>，如果 <code>route_tools</code> 返回 <code>END</code>，那么<strong>跳转到 <code>END</code> 节点（结束对话）</strong></p>
</li>
</ul>
</li>
</ul>
<p><strong>总结：</strong></p>
<ul>
<li><p>首先LLM通过llm.bind_tools(tools)绑定一组工具tools，以告诉LLM可以调用哪些工具，同时定义每个工具的调用格式，让LLM生成符合格式的<code>tool_calls</code>请求</p>
</li>
<li><p>BasicToolNode负责执行工具</p>
</li>
<li><p>结合 <code>route_tools</code> 实现自动工具调用</p>
</li>
</ul>
<p>好的，这里的代码只是为了帮助理解<code>Langgraph</code>中的简单写法的基本原理，实际使用时这样使用：</p>
<figure class="highlight python"><figcaption><span>introduction_part2_simple.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">https://langchain-ai.github.io/langgraph/tutorials/introduction/#requirements</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> langchain_community.tools.tavily_search <span class="keyword">import</span> TavilySearchResults</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> ToolNode, tools_condition</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;TAVILY_API_KEY&quot;</span>] = <span class="string">&quot;tvly-***********&quot;</span></span><br><span class="line"></span><br><span class="line">tool = TavilySearchResults(max_results=<span class="number">2</span>)</span><br><span class="line">tools = [tool]</span><br><span class="line"><span class="comment"># print(tool.invoke(&quot;What&#x27;s a &#x27;node&#x27; in LangGraph?&quot;))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START, END</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"><span class="comment"># llm = ChatOpenAI(model_name=&quot;Qwen&quot;,</span></span><br><span class="line"><span class="comment">#                    openai_api_key=&#x27;Empty&#x27;,</span></span><br><span class="line"><span class="comment">#                    openai_api_base=&#x27;http://192.168.0.138:8000/v1&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置大模型参数</span></span><br><span class="line">LLM_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;sk-*********&quot;</span>,</span><br><span class="line">    <span class="string">&quot;base_url&quot;</span>: <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen2.5-7b-instruct&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化大模型</span></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=LLM_CONFIG[<span class="string">&quot;model&quot;</span>],</span><br><span class="line">    openai_api_key=LLM_CONFIG[<span class="string">&quot;api_key&quot;</span>],</span><br><span class="line">    openai_api_base=LLM_CONFIG[<span class="string">&quot;base_url&quot;</span>],</span><br><span class="line">    streaming=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    response = llm_with_tools.invoke(state[<span class="string">&quot;messages&quot;</span>])</span><br><span class="line">    <span class="comment"># print(&quot;Debug - chatbot response:&quot;, response)  # 调试信息</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [response]&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br><span class="line"></span><br><span class="line">tool_node = ToolNode(tools=[tool])</span><br><span class="line">graph_builder.add_node(<span class="string">&quot;tools&quot;</span>, tool_node)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_conditional_edges(</span><br><span class="line">    <span class="string">&quot;chatbot&quot;</span>,</span><br><span class="line">    tools_condition,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># Any time a tool is called, we return to the chatbot to decide the next step</span></span><br><span class="line">graph_builder.add_edge(<span class="string">&quot;tools&quot;</span>, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph_builder.add_edge(START, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph = graph_builder.<span class="built_in">compile</span>()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stream_graph_updates</span>(<span class="params">user_input: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="keyword">for</span> event <span class="keyword">in</span> graph.stream(&#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, user_input)]&#125;):</span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> event.values():</span><br><span class="line">            <span class="comment"># print(&quot;Debug - event value:&quot;, value)  # 调试信息</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Assistant:&quot;</span>, value[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].content)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        user_input = <span class="built_in">input</span>(<span class="string">&quot;User: &quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> user_input.lower() <span class="keyword">in</span> [<span class="string">&quot;quit&quot;</span>, <span class="string">&quot;exit&quot;</span>, <span class="string">&quot;q&quot;</span>]:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Goodbye!&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="comment"># fallback if input() is not available</span></span><br><span class="line">        user_input = <span class="string">&quot;What do you know about LangGraph?&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;User: &quot;</span> + user_input)</span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<p>与供理解版本相比：</p>
<ul>
<li>BasicToolNode-&gt;ToolNode</li>
<li>route_tools-&gt;tools_condition</li>
<li>也不再需要在add_conditional_edges中添加{“tools”: “tools”, END: END}</li>
</ul>
<img src="/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/image-20250225104331399.png" class="" title="image-20250225104331399">

<p>可看到目前确实是能调用网络搜索工具了，但是缺少：</p>
<ul>
<li>记忆功能</li>
<li>流式输出</li>
</ul>
<p>而且关于天气信息的网络搜索并不准确，星期几是正确的（后续关于天气查询和时间查询我会另开一个博客，<strong>对比原生实现和langgraph实现</strong>）</p>
<hr>
<h2 id="示例3：为聊天机器人添加内存（记忆）"><a href="#示例3：为聊天机器人添加内存（记忆）" class="headerlink" title="示例3：为聊天机器人添加内存（记忆）"></a>示例3：为聊天机器人添加内存（记忆）</h2><figure class="highlight python"><figcaption><span>introduction_part3.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">https://langchain-ai.github.io/langgraph/tutorials/introduction/#requirements</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> langchain_community.tools.tavily_search <span class="keyword">import</span> TavilySearchResults</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> ToolNode, tools_condition</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;TAVILY_API_KEY&quot;</span>] = <span class="string">&quot;tvly-************&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START, END</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"><span class="keyword">from</span> langgraph.checkpoint.memory <span class="keyword">import</span> MemorySaver</span><br><span class="line"></span><br><span class="line">memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line">tool = TavilySearchResults(max_results=<span class="number">2</span>)</span><br><span class="line">tools = [tool]</span><br><span class="line"></span><br><span class="line"><span class="comment"># llm = ChatOpenAI(model_name=&quot;Qwen&quot;,</span></span><br><span class="line"><span class="comment">#                    openai_api_key=&#x27;Empty&#x27;,</span></span><br><span class="line"><span class="comment">#                    openai_api_base=&#x27;http://192.168.0.138:8000/v1&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置大模型参数</span></span><br><span class="line">LLM_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;sk-**************&quot;</span>,</span><br><span class="line">    <span class="string">&quot;base_url&quot;</span>: <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen2.5-7b-instruct&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化大模型</span></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=LLM_CONFIG[<span class="string">&quot;model&quot;</span>],</span><br><span class="line">    openai_api_key=LLM_CONFIG[<span class="string">&quot;api_key&quot;</span>],</span><br><span class="line">    openai_api_base=LLM_CONFIG[<span class="string">&quot;base_url&quot;</span>],</span><br><span class="line">    streaming=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [llm_with_tools.invoke(state[<span class="string">&quot;messages&quot;</span>])]&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br><span class="line"></span><br><span class="line">tool_node = ToolNode(tools=[tool])</span><br><span class="line">graph_builder.add_node(<span class="string">&quot;tools&quot;</span>, tool_node)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_conditional_edges(</span><br><span class="line">    <span class="string">&quot;chatbot&quot;</span>,</span><br><span class="line">    tools_condition,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># Any time a tool is called, we return to the chatbot to decide the next step</span></span><br><span class="line">graph_builder.add_edge(<span class="string">&quot;tools&quot;</span>, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph_builder.add_edge(START, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph = graph_builder.<span class="built_in">compile</span>(checkpointer=memory)</span><br><span class="line"></span><br><span class="line">config = &#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: <span class="string">&quot;1&quot;</span>&#125;&#125;</span><br><span class="line">user_input = <span class="string">&quot;你好，我叫蔡&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The config is the **second positional argument** to stream() or invoke()!</span></span><br><span class="line">events = graph.stream(</span><br><span class="line">    &#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, user_input)]&#125;, config, stream_mode=<span class="string">&quot;values&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">for</span> event <span class="keyword">in</span> events:</span><br><span class="line">    event[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].pretty_print()</span><br><span class="line"></span><br><span class="line">user_input = <span class="string">&quot;我的名字是什么？&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The config is the **second positional argument** to stream() or invoke()!</span></span><br><span class="line">events = graph.stream(</span><br><span class="line">    &#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, user_input)]&#125;, config, stream_mode=<span class="string">&quot;values&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">for</span> event <span class="keyword">in</span> events:</span><br><span class="line">    event[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].pretty_print()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># The only difference is we change the `thread_id` here to &quot;2&quot; instead of &quot;1&quot;</span></span><br><span class="line">events = graph.stream(</span><br><span class="line">    &#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, user_input)]&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: <span class="string">&quot;2&quot;</span>&#125;&#125;,</span><br><span class="line">    stream_mode=<span class="string">&quot;values&quot;</span>,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">for</span> event <span class="keyword">in</span> events:</span><br><span class="line">    event[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].pretty_print()</span><br><span class="line"></span><br><span class="line">snapshot = graph.get_state(config)</span><br><span class="line"><span class="built_in">print</span>(snapshot)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(snapshot.<span class="built_in">next</span>)</span><br></pre></td></tr></table></figure>

<p>与示例2不同在于：</p>
<ul>
<li><p>创建一个<code>MemorySaver</code>检查点，<code>memory = MemorySaver()</code></p>
<blockquote>
<p>仅做示例，在生产应用程序中，您可能会将其更改为使用<code>SqliteSaver</code>或<code>PostgresSaver</code>并连接到您自己的数据库。</p>
</blockquote>
</li>
<li><p>使用提供的检查点编译图，<code>graph = graph_builder.compile(checkpointer=memory)</code></p>
</li>
<li><p>在<code>graph.stream</code>的第二个参数位置增加配置<code>config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</code></p>
</li>
</ul>
<p>注意事项：</p>
<ul>
<li>检查点针对各配置（thread_id）是分离的</li>
<li>注意体会下这个示例的graph.stream与上个示例的用法区别</li>
<li>可通过<code>snapshot = graph.get_state(config)</code>查看当前快照，其中包括当前状态值、相应的配置以及<code>next</code>要处理的节点。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">D:\Anaconda3\envs\langchain\python.exe E:\chr_git\langchain_t\langgraph\introduction_part3.py </span><br><span class="line">================================ Human Message =================================</span><br><span class="line"></span><br><span class="line">你好，我叫蔡</span><br><span class="line">================================== Ai Message ==================================</span><br><span class="line"></span><br><span class="line">你好，蔡！有什么问题或者需要帮助的吗？</span><br><span class="line">================================ Human Message =================================</span><br><span class="line"></span><br><span class="line">我的名字是什么？</span><br><span class="line">================================== Ai Message ==================================</span><br><span class="line"></span><br><span class="line">你的名字是蔡。如果你有任何其他问题或需要进一步的帮助，请告诉我！</span><br><span class="line">================================ Human Message =================================</span><br><span class="line"></span><br><span class="line">我的名字是什么？</span><br><span class="line">================================== Ai Message ==================================</span><br><span class="line"></span><br><span class="line">您没有在本次对话中提供您的名字。如果您希望我称呼您某个名字，或者想告诉我您的名字，请直接告诉我。</span><br><span class="line"></span><br><span class="line">StateSnapshot(values=&#123;<span class="string">&#x27;messages&#x27;</span>: [HumanMessage(content=<span class="string">&#x27;你好，我叫蔡&#x27;</span>, additional_kwargs=&#123;&#125;, response_metadata=&#123;&#125;, <span class="built_in">id</span>=<span class="string">&#x27;94cccb05-ee77-49d4-9183-563707c23b20&#x27;</span>), </span><br><span class="line">AIMessage(content=<span class="string">&#x27;你好，蔡！有什么问题或者需要帮助的吗？&#x27;</span>, additional_kwargs=&#123;&#125;, response_metadata=&#123;<span class="string">&#x27;finish_reason&#x27;</span>: <span class="string">&#x27;stop&#x27;</span>, <span class="string">&#x27;model_name&#x27;</span>: <span class="string">&#x27;qwen2.5-7b-instruct&#x27;</span>&#125;, <span class="built_in">id</span>=<span class="string">&#x27;run-ef5ba90c-dd2d-442b-9376-19e330d6aba8-0&#x27;</span>), </span><br><span class="line">                                   </span><br><span class="line">HumanMessage(content=<span class="string">&#x27;我的名字是什么？&#x27;</span>, additional_kwargs=&#123;&#125;, response_metadata=&#123;&#125;, <span class="built_in">id</span>=<span class="string">&#x27;fad15992-5dbf-46d6-9156-fd388dd32957&#x27;</span>), </span><br><span class="line">                                   </span><br><span class="line">AIMessage(content=<span class="string">&#x27;你的名字是蔡。如果你有任何其他问题或需要进一步的帮助，请告诉我！&#x27;</span>, additional_kwargs=&#123;&#125;, response_metadata=&#123;<span class="string">&#x27;finish_reason&#x27;</span>: <span class="string">&#x27;stop&#x27;</span>, <span class="string">&#x27;model_name&#x27;</span>: <span class="string">&#x27;qwen2.5-7b-instruct&#x27;</span>&#125;, <span class="built_in">id</span>=<span class="string">&#x27;run-11bf0ee6-2049-435c-81e7-da8ff47b95d8-0&#x27;</span>)]&#125;, <span class="built_in">next</span>=(), config=&#123;<span class="string">&#x27;configurable&#x27;</span>: &#123;<span class="string">&#x27;thread_id&#x27;</span>: <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;checkpoint_ns&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;checkpoint_id&#x27;</span>: <span class="string">&#x27;1eff3284-e246-66b1-8004-69625438a61d&#x27;</span>&#125;&#125;, metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;loop&#x27;</span>, <span class="string">&#x27;writes&#x27;</span>: &#123;<span class="string">&#x27;chatbot&#x27;</span>: &#123;<span class="string">&#x27;messages&#x27;</span>: [AIMessage(content=<span class="string">&#x27;你的名字是蔡。如果你有任何其他问题或需要进一步的帮助，请告诉我！&#x27;</span>, additional_kwargs=&#123;&#125;, response_metadata=&#123;<span class="string">&#x27;finish_reason&#x27;</span>: <span class="string">&#x27;stop&#x27;</span>, <span class="string">&#x27;model_name&#x27;</span>: <span class="string">&#x27;qwen2.5-7b-instruct&#x27;</span>&#125;, <span class="built_in">id</span>=<span class="string">&#x27;run-11bf0ee6-2049-435c-81e7-da8ff47b95d8-0&#x27;</span>)]&#125;&#125;, <span class="string">&#x27;thread_id&#x27;</span>: <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;step&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;parents&#x27;</span>: &#123;&#125;&#125;, created_at=<span class="string">&#x27;2025-02-25T03:26:30.701462+00:00&#x27;</span>, parent_config=&#123;<span class="string">&#x27;configurable&#x27;</span>: &#123;<span class="string">&#x27;thread_id&#x27;</span>: <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;checkpoint_ns&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;checkpoint_id&#x27;</span>: <span class="string">&#x27;1eff3284-db3b-656c-8003-08f03ddb0c2b&#x27;</span>&#125;&#125;, tasks=())</span><br><span class="line">()</span><br></pre></td></tr></table></figure>

<p>可见，现在已经为我们的聊天机器人添加内存（记忆）功能了，但现在还缺少流式输出功能。</p>
<hr>
<h2 id="示例4：流式输出"><a href="#示例4：流式输出" class="headerlink" title="示例4：流式输出"></a>示例4：流式输出</h2><p>先把示例3改成示例1 or 2 的写法（qwen2.5 7b试用完了，换个大模型）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.tools.tavily_search <span class="keyword">import</span> TavilySearchResults</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> ToolNode, tools_condition</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;TAVILY_API_KEY&quot;</span>] = <span class="string">&quot;tvly-*********************&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START, END</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"><span class="keyword">from</span> langgraph.checkpoint.memory <span class="keyword">import</span> MemorySaver</span><br><span class="line"></span><br><span class="line">memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line">tool = TavilySearchResults(max_results=<span class="number">2</span>)</span><br><span class="line">tools = [tool]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置大模型参数</span></span><br><span class="line">LLM_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;sk-****************&quot;</span>,</span><br><span class="line">    <span class="string">&quot;base_url&quot;</span>: <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen-max&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化大模型</span></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=LLM_CONFIG[<span class="string">&quot;model&quot;</span>],</span><br><span class="line">    openai_api_key=LLM_CONFIG[<span class="string">&quot;api_key&quot;</span>],</span><br><span class="line">    openai_api_base=LLM_CONFIG[<span class="string">&quot;base_url&quot;</span>],</span><br><span class="line">    streaming=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [llm_with_tools.invoke(state[<span class="string">&quot;messages&quot;</span>])]&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br><span class="line"></span><br><span class="line">tool_node = ToolNode(tools=[tool])</span><br><span class="line">graph_builder.add_node(<span class="string">&quot;tools&quot;</span>, tool_node)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_conditional_edges(</span><br><span class="line">    <span class="string">&quot;chatbot&quot;</span>,</span><br><span class="line">    tools_condition,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># Any time a tool is called, we return to the chatbot to decide the next step</span></span><br><span class="line">graph_builder.add_edge(<span class="string">&quot;tools&quot;</span>, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph_builder.add_edge(START, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph = graph_builder.<span class="built_in">compile</span>(checkpointer=memory)</span><br><span class="line"></span><br><span class="line">config = &#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: <span class="string">&quot;1&quot;</span>&#125;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stream_graph_updates</span>(<span class="params">user_input: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="keyword">for</span> event <span class="keyword">in</span> graph.stream(&#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, user_input)]&#125;, config, stream_mode=<span class="string">&quot;values&quot;</span>):</span><br><span class="line">        event[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].pretty_print()</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        user_input = <span class="built_in">input</span>(<span class="string">&quot;User: &quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> user_input.lower() <span class="keyword">in</span> [<span class="string">&quot;quit&quot;</span>, <span class="string">&quot;exit&quot;</span>, <span class="string">&quot;q&quot;</span>]:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Goodbye!&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="comment"># fallback if input() is not available</span></span><br><span class="line">        user_input = <span class="string">&quot;What do you know about LangGraph?&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;User: &quot;</span> + user_input)</span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">User: 你好</span><br><span class="line">================================ Human Message =================================</span><br><span class="line"></span><br><span class="line">你好</span><br><span class="line">================================== Ai Message ==================================</span><br><span class="line"></span><br><span class="line">你好！有什么可以帮助你的吗？</span><br><span class="line">User: 今天周几</span><br><span class="line">================================ Human Message =================================</span><br><span class="line"></span><br><span class="line">今天周几</span><br><span class="line">================================== Ai Message ==================================</span><br><span class="line"></span><br><span class="line">今天是周二。不过请注意，我基于的是标准时间，您可能需要根据您所在的时区进行调整。如果想要知道具体的日期信息，您可以查看设备上的日历或者问我<span class="string">&quot;今天具体是哪一天&quot;</span>。</span><br><span class="line">实际上，我没有直接访问实时日期和时间的功能。为了获取今天的准确星期几，请查看您的设备如手机、电脑右下角的时间显示，那里通常会显示当前的日期和星期。或者，如果您愿意告诉我您所在的时区，我可以尝试提供更具体的帮助。</span><br><span class="line">User: 今天中国星期几</span><br><span class="line">================================ Human Message =================================</span><br><span class="line"></span><br><span class="line">今天中国星期几</span><br><span class="line">================================== Ai Message ==================================</span><br><span class="line"></span><br><span class="line">要获取今天在中国是星期几的确切信息，我们可以通过查询当前的日期来确定。让我来帮您查找一下今天的具体日期。</span><br><span class="line">Tool Calls:</span><br><span class="line">  tavily_search_results_json (call_145884c25be845efbdb348)</span><br><span class="line"> Call ID: call_145884c25be845efbdb348</span><br><span class="line">  Args:</span><br><span class="line">    query: 今天的日期 中国</span><br><span class="line">================================= Tool Message =================================</span><br><span class="line">Name: tavily_search_results_json</span><br><span class="line"></span><br><span class="line">[&#123;<span class="string">&quot;url&quot;</span>: <span class="string">&quot;http://date.china6636.com/&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;中国今天几号? 答案: 2025年2月28日星期五. 中国現在是2025年2月28日星期五. 今天是2025年第59天. 今年还剩下306天. 本周是2025年的第9周。 2025二月日历. 星期一, 星期二&quot;</span>&#125;, &#123;<span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://time.is/zh_tw/China&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;中国 的現在時間是. 您的時間晚了20 小時, 1 分又40.1 秒. 對時準確度為±0.005 秒. 04:01:45. 2025年二月28日，星期五，第9週. Rare Disease Day. 太陽： ↑ 07:29 ↓ 18&quot;</span>&#125;]</span><br><span class="line">================================== Ai Message ==================================</span><br><span class="line"></span><br><span class="line">今天在中国是<span class="number">2025</span>年<span class="number">2</span>月<span class="number">28</span>日，星期五。如果您有任何基于这个信息的计划或需要进一步的帮助，请告诉我！</span><br><span class="line">User: </span><br></pre></td></tr></table></figure>

<p>✨好的，那么我想流式输出token，怎么办呢，同时也不想看到与AI回复不直接相关的文字，怎么办：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">https://langchain-ai.github.io/langgraph/tutorials/introduction/#requirements</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> langchain_community.tools.tavily_search <span class="keyword">import</span> TavilySearchResults</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> HumanMessage, AIMessageChunk</span><br><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> ToolNode, tools_condition</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;TAVILY_API_KEY&quot;</span>] = <span class="string">&quot;tvly-xxxxxxxxxxxxxxxxxx&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START, END</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"><span class="keyword">from</span> langgraph.checkpoint.memory <span class="keyword">import</span> MemorySaver</span><br><span class="line"></span><br><span class="line">memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line">tool = TavilySearchResults(max_results=<span class="number">2</span>)</span><br><span class="line">tools = [tool]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置大模型参数</span></span><br><span class="line">LLM_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;sk-xxxxxxxxxxxxxxxxxxx&quot;</span>,</span><br><span class="line">    <span class="string">&quot;base_url&quot;</span>: <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen-max&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化大模型</span></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=LLM_CONFIG[<span class="string">&quot;model&quot;</span>],</span><br><span class="line">    openai_api_key=LLM_CONFIG[<span class="string">&quot;api_key&quot;</span>],</span><br><span class="line">    openai_api_base=LLM_CONFIG[<span class="string">&quot;base_url&quot;</span>],</span><br><span class="line">    streaming=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [llm_with_tools.invoke(state[<span class="string">&quot;messages&quot;</span>])]&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br><span class="line"></span><br><span class="line">tool_node = ToolNode(tools=[tool])</span><br><span class="line">graph_builder.add_node(<span class="string">&quot;tools&quot;</span>, tool_node)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_conditional_edges(</span><br><span class="line">    <span class="string">&quot;chatbot&quot;</span>,</span><br><span class="line">    tools_condition,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># Any time a tool is called, we return to the chatbot to decide the next step</span></span><br><span class="line">graph_builder.add_edge(<span class="string">&quot;tools&quot;</span>, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph_builder.add_edge(START, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph = graph_builder.<span class="built_in">compile</span>(checkpointer=memory)</span><br><span class="line"></span><br><span class="line">config = &#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: <span class="string">&quot;1&quot;</span>&#125;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stream_graph_updates</span>(<span class="params">user_input: <span class="built_in">str</span></span>):</span><br><span class="line">    first = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">for</span> msg, metadata <span class="keyword">in</span> graph.stream(&#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, user_input)]&#125;, config, stream_mode=<span class="string">&quot;messages&quot;</span>):</span><br><span class="line">        <span class="comment"># 仅处理AI生成的消息快</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk) <span class="keyword">and</span> msg.content:</span><br><span class="line">            <span class="built_in">print</span>(msg.content, end=<span class="string">&quot;|&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk):</span><br><span class="line">            <span class="keyword">if</span> first:</span><br><span class="line">                gathered = msg</span><br><span class="line">                first = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                gathered = gathered + msg</span><br><span class="line"></span><br><span class="line">            <span class="comment"># if msg.tool_call_chunks:</span></span><br><span class="line">            <span class="comment">#     print(gathered.tool_calls)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        user_input = <span class="built_in">input</span>(<span class="string">&quot;User: &quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> user_input.lower() <span class="keyword">in</span> [<span class="string">&quot;quit&quot;</span>, <span class="string">&quot;exit&quot;</span>, <span class="string">&quot;q&quot;</span>]:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Goodbye!&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="comment"># fallback if input() is not available</span></span><br><span class="line">        user_input = <span class="string">&quot;What do you know about LangGraph?&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;User: &quot;</span> + user_input)</span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">User: 今天中国是几月几号</span><br><span class="line">根|据搜索结果，|目前中国的日期是|<span class="number">2025</span>|年<span class="number">2</span>月<span class="number">2</span>|<span class="number">8</span>日星期五|。</span><br><span class="line"></span><br><span class="line">- [时间|网站](https://|time.<span class="keyword">is</span>/zh|_tw/China)|上显示的具体时间为|：04:|01:<span class="number">4</span>|<span class="number">5</span>（北京时间）|。</span><br><span class="line">-| 而在中国<span class="number">66</span>|<span class="number">36</span>网上则是|直接给出日期：|<span class="number">2025</span>|年<span class="number">2</span>月<span class="number">2</span>|<span class="number">8</span>日星期五|。</span><br><span class="line"></span><br><span class="line">请注意，这些|信息可能因为时|区差异而有所不同|，上述时间是|基于北京时间。|</span><br><span class="line"></span><br><span class="line">User: 我叫蔡浩然</span><br><span class="line">很高兴|认识|你|，蔡浩然|！有什么问题或者|需要帮助的吗|？|</span><br><span class="line"></span><br><span class="line">User: 我叫什么名字</span><br><span class="line">您|叫|蔡|浩然。| </span><br></pre></td></tr></table></figure>

<p>✨我真厉害😁。</p>
<hr>
<h2 id="示例5：自定义工具"><a href="#示例5：自定义工具" class="headerlink" title="示例5：自定义工具"></a>示例5：自定义工具</h2><p>前面使用的工具为langchain提供的TavilySearchResults工具，那如果我想自己定义个工具呢？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> langchain_community.tools.tavily_search <span class="keyword">import</span> TavilySearchResults</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> HumanMessage, AIMessageChunk</span><br><span class="line"><span class="keyword">from</span> langchain_core.tools <span class="keyword">import</span> tool</span><br><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> ToolNode, tools_condition</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;TAVILY_API_KEY&quot;</span>] = <span class="string">&quot;tvly-xxxxxxxxxxxxxxxxx&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START, END</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"><span class="keyword">from</span> langgraph.checkpoint.memory <span class="keyword">import</span> MemorySaver</span><br><span class="line"></span><br><span class="line">memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@tool</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_current_time</span>(<span class="params">region: <span class="built_in">str</span> = <span class="literal">None</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Get the current time for a given region/timezone.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">    region (str): The region to query, e.g., &quot;Asia/Shanghai&quot;。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># 新API端点</span></span><br><span class="line">        <span class="keyword">if</span> region:</span><br><span class="line">            url = <span class="string">f&quot;https://timeapi.io/api/Time/current/zone?timeZone=<span class="subst">&#123;region&#125;</span>&quot;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> (<span class="string">&quot;Location information is not available, so bring it with you when asking for the time, e.g.,&quot;</span></span><br><span class="line">                    <span class="string">&quot; what time is it in San Francisco&quot;</span>)</span><br><span class="line"></span><br><span class="line">        response = requests.get(url, timeout=<span class="number">5</span>)</span><br><span class="line">        response.raise_for_status()</span><br><span class="line">        data = response.json()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 解析新API的响应格式</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;current time of <span class="subst">&#123;region&#125;</span>: <span class="subst">&#123;data[<span class="string">&#x27;hour&#x27;</span>]:02d&#125;</span>:<span class="subst">&#123;data[<span class="string">&#x27;minute&#x27;</span>]:02d&#125;</span>:<span class="subst">&#123;data[<span class="string">&#x27;seconds&#x27;</span>]:02d&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;API call error details：<span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Unable to get time information, please try again later&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试新API</span></span><br><span class="line"><span class="built_in">print</span>(get_current_time.invoke(&#123;<span class="string">&quot;region&quot;</span>: <span class="string">&quot;Asia/Shanghai&quot;</span>&#125;))  <span class="comment"># 应输出类似：Asia/Shanghai当前时间: 15:30:45</span></span><br><span class="line"><span class="built_in">print</span>(get_current_time.invoke(&#123;&#125;))</span><br><span class="line"></span><br><span class="line">tool = TavilySearchResults(max_results=<span class="number">2</span>)</span><br><span class="line">tools = [tool, get_current_time]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置大模型参数</span></span><br><span class="line">LLM_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;sk-xxxxxxxxxxxxxxx&quot;</span>,</span><br><span class="line">    <span class="string">&quot;base_url&quot;</span>: <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen-max&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化大模型</span></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=LLM_CONFIG[<span class="string">&quot;model&quot;</span>],</span><br><span class="line">    openai_api_key=LLM_CONFIG[<span class="string">&quot;api_key&quot;</span>],</span><br><span class="line">    openai_api_base=LLM_CONFIG[<span class="string">&quot;base_url&quot;</span>],</span><br><span class="line">    streaming=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [llm_with_tools.invoke(state[<span class="string">&quot;messages&quot;</span>])]&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br><span class="line"></span><br><span class="line">tool_node = ToolNode(tools=tools)</span><br><span class="line">graph_builder.add_node(<span class="string">&quot;tools&quot;</span>, tool_node)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_conditional_edges(</span><br><span class="line">    <span class="string">&quot;chatbot&quot;</span>,</span><br><span class="line">    tools_condition,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># Any time a tool is called, we return to the chatbot to decide the next step</span></span><br><span class="line">graph_builder.add_edge(<span class="string">&quot;tools&quot;</span>, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph_builder.add_edge(START, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph = graph_builder.<span class="built_in">compile</span>(checkpointer=memory)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">config = &#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: <span class="string">&quot;1&quot;</span>&#125;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stream_graph_updates</span>(<span class="params">user_input: <span class="built_in">str</span></span>):</span><br><span class="line">    first = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">for</span> msg, metadata <span class="keyword">in</span> graph.stream(&#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, user_input)]&#125;, config, stream_mode=<span class="string">&quot;messages&quot;</span>):</span><br><span class="line">        <span class="comment"># 仅处理AI生成的消息快</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk) <span class="keyword">and</span> msg.content:</span><br><span class="line">            <span class="built_in">print</span>(msg.content, end=<span class="string">&quot;|&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk):</span><br><span class="line">            <span class="keyword">if</span> first:</span><br><span class="line">                gathered = msg</span><br><span class="line">                first = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                gathered = gathered + msg</span><br><span class="line"></span><br><span class="line">            <span class="comment"># if msg.tool_call_chunks:</span></span><br><span class="line">            <span class="comment">#     print(gathered.tool_calls)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        user_input = <span class="built_in">input</span>(<span class="string">&quot;User: &quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> user_input.lower() <span class="keyword">in</span> [<span class="string">&quot;quit&quot;</span>, <span class="string">&quot;exit&quot;</span>, <span class="string">&quot;q&quot;</span>]:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Goodbye!&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="comment"># fallback if input() is not available</span></span><br><span class="line">        user_input = <span class="string">&quot;What do you know about LangGraph?&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;User: &quot;</span> + user_input)</span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">current time of Asia/Shanghai: <span class="number">14</span>:<span class="number">40</span>:<span class="number">36</span></span><br><span class="line">Location information <span class="keyword">is</span> <span class="keyword">not</span> available, so bring it <span class="keyword">with</span> you when asking <span class="keyword">for</span> the time, e.g., what time <span class="keyword">is</span> it <span class="keyword">in</span> San Francisco</span><br><span class="line">User: what time <span class="keyword">is</span> it <span class="keyword">in</span> San Francisco</span><br><span class="line">The| current| time <span class="keyword">in</span> San Francisco| <span class="keyword">is</span> <span class="number">22</span>|:<span class="number">41</span>:|<span class="number">03.</span>|</span><br><span class="line">User: what time <span class="keyword">is</span> it</span><br><span class="line">Could| you| please| specify the region <span class="keyword">or</span>| timezone you want to| know the time about|?|</span><br><span class="line">User: San Francisco</span><br><span class="line"></span><br><span class="line">The current time <span class="keyword">in</span>| San Francisco <span class="keyword">is</span>| <span class="number">22</span>:<span class="number">4</span>|<span class="number">2</span>:05|.|</span><br><span class="line">User: ok,my name <span class="keyword">is</span> caihaoran</span><br><span class="line">Nice| to meet you,| Caihaoran|! How can I| assist you further?|</span><br><span class="line">User: what<span class="string">&#x27;s my name</span></span><br><span class="line"><span class="string">Your| name| is| Caihaoran|. How can I| assist you further,| Caihaoran|?|</span></span><br></pre></td></tr></table></figure>

<p>重点注意其中的<code>get_current_time</code>函数，</p>
<ul>
<li><code>@tool</code> 用于标记函数，使其可以被 LangChain 作为工具调用</li>
<li>LLM 可以基于 <code>docstring</code>（文档字符串）理解工具的用途和参数</li>
<li><code>region</code> 表示时区，例如 <code>&quot;Asia/Shanghai&quot;</code>。<strong>默认值 <code>None</code></strong>：如果用户没有提供时区，则返回提示信息，要求用户提供具体的地点</li>
<li>通过 <code>https://timeapi.io/api/Time/current/zone?timeZone=&#123;region&#125;</code> 获取时间。使用 <code>requests.get(url, timeout=5)</code> 发送请求，并解析返回的 JSON 数据</li>
</ul>
<hr>
<h2 id="示例6：系统提示词"><a href="#示例6：系统提示词" class="headerlink" title="示例6：系统提示词"></a>示例6：系统提示词</h2><p>回到最原始的问题，Langgraph的系统提示词（Prompt）怎么添加？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">stream_graph_updates</span>(<span class="params">user_input: <span class="built_in">str</span></span>):</span><br><span class="line">    system_message = (<span class="string">&quot;You are a lively and lovely little assistant, whose name is Xiao CAI. You always answer questions in a humorous, funny, light-hearted way.&quot;</span>)</span><br><span class="line">    first = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">for</span> msg, metadata <span class="keyword">in</span> graph.stream(</span><br><span class="line">        &#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;system&quot;</span>, system_message), (<span class="string">&quot;user&quot;</span>, user_input)]&#125;, </span><br><span class="line">        config, </span><br><span class="line">        stream_mode=<span class="string">&quot;messages&quot;</span></span><br><span class="line">    ):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk) <span class="keyword">and</span> msg.content:</span><br><span class="line">            <span class="built_in">print</span>(msg.content, end=<span class="string">&quot;|&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk):</span><br><span class="line">            <span class="keyword">if</span> first:</span><br><span class="line">                gathered = msg</span><br><span class="line">                first = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                gathered = gathered + msg</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">User: Hi,What<span class="string">&#x27;s your name?</span></span><br><span class="line"><span class="string">Hey| there|!| I&#x27;</span>m Xiao CA|I, your lively| <span class="keyword">and</span> lovely little assistant| <span class="keyword">with</span> a dash of| humor. How can| I make your day| brighter? 😊|✨|</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="示例7：终极简化版"><a href="#示例7：终极简化版" class="headerlink" title="示例7：终极简化版"></a>示例7：终极简化版</h2><p>好的，现在看看代码成什么样子了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> langchain_community.tools.tavily_search <span class="keyword">import</span> TavilySearchResults</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> HumanMessage, AIMessageChunk</span><br><span class="line"><span class="keyword">from</span> langchain_core.tools <span class="keyword">import</span> tool</span><br><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> ToolNode, tools_condition</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;TAVILY_API_KEY&quot;</span>] = <span class="string">&quot;tvly-xxxxxxxxxxxxxx&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START, END</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"><span class="keyword">from</span> langgraph.checkpoint.memory <span class="keyword">import</span> MemorySaver</span><br><span class="line"></span><br><span class="line">memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"><span class="meta">@tool</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_current_time</span>(<span class="params">region: <span class="built_in">str</span> = <span class="literal">None</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Get the current time for a given region/timezone.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">    region (str): The region to query, e.g., &quot;Asia/Shanghai&quot;。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># 新API端点</span></span><br><span class="line">        <span class="keyword">if</span> region:</span><br><span class="line">            url = <span class="string">f&quot;https://timeapi.io/api/Time/current/zone?timeZone=<span class="subst">&#123;region&#125;</span>&quot;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> (<span class="string">&quot;Location information is not available, so bring it with you when asking for the time, e.g.,&quot;</span></span><br><span class="line">                    <span class="string">&quot; what time is it in San Francisco&quot;</span>)</span><br><span class="line"></span><br><span class="line">        response = requests.get(url, timeout=<span class="number">5</span>)</span><br><span class="line">        response.raise_for_status()</span><br><span class="line">        data = response.json()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 解析新API的响应格式</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;current time of <span class="subst">&#123;region&#125;</span>: <span class="subst">&#123;data[<span class="string">&#x27;hour&#x27;</span>]:02d&#125;</span>:<span class="subst">&#123;data[<span class="string">&#x27;minute&#x27;</span>]:02d&#125;</span>:<span class="subst">&#123;data[<span class="string">&#x27;seconds&#x27;</span>]:02d&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;API call error details：<span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Unable to get time information, please try again later&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试新API</span></span><br><span class="line"><span class="built_in">print</span>(get_current_time.invoke(&#123;<span class="string">&quot;region&quot;</span>: <span class="string">&quot;Asia/Shanghai&quot;</span>&#125;))  <span class="comment"># 应输出类似：Asia/Shanghai当前时间: 15:30:45</span></span><br><span class="line"><span class="built_in">print</span>(get_current_time.invoke(&#123;&#125;))</span><br><span class="line"></span><br><span class="line">tool = TavilySearchResults(max_results=<span class="number">2</span>)</span><br><span class="line">tools = [tool, get_current_time]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置大模型参数</span></span><br><span class="line">LLM_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;sk-xxxxxxxxxxxxxxxxxxxxxxx&quot;</span>,</span><br><span class="line">    <span class="string">&quot;base_url&quot;</span>: <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen-max&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化大模型</span></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=LLM_CONFIG[<span class="string">&quot;model&quot;</span>],</span><br><span class="line">    openai_api_key=LLM_CONFIG[<span class="string">&quot;api_key&quot;</span>],</span><br><span class="line">    openai_api_base=LLM_CONFIG[<span class="string">&quot;base_url&quot;</span>],</span><br><span class="line">    streaming=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [llm_with_tools.invoke(state[<span class="string">&quot;messages&quot;</span>])]&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br><span class="line"></span><br><span class="line">tool_node = ToolNode(tools=tools)</span><br><span class="line">graph_builder.add_node(<span class="string">&quot;tools&quot;</span>, tool_node)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_conditional_edges(</span><br><span class="line">    <span class="string">&quot;chatbot&quot;</span>,</span><br><span class="line">    tools_condition,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># Any time a tool is called, we return to the chatbot to decide the next step</span></span><br><span class="line">graph_builder.add_edge(<span class="string">&quot;tools&quot;</span>, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph_builder.add_edge(START, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph = graph_builder.<span class="built_in">compile</span>(checkpointer=memory)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">config = &#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: <span class="string">&quot;1&quot;</span>&#125;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stream_graph_updates</span>(<span class="params">user_input: <span class="built_in">str</span></span>):</span><br><span class="line">    system_message = (<span class="string">&quot;You are a lively and lovely little assistant, whose name is Xiao CAI. You always answer questions in a humorous, funny, light-hearted way.&quot;</span>)</span><br><span class="line">    first = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">for</span> msg, metadata <span class="keyword">in</span> graph.stream(</span><br><span class="line">        &#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;system&quot;</span>, system_message), (<span class="string">&quot;user&quot;</span>, user_input)]&#125;, </span><br><span class="line">        config, </span><br><span class="line">        stream_mode=<span class="string">&quot;messages&quot;</span></span><br><span class="line">    ):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk) <span class="keyword">and</span> msg.content:</span><br><span class="line">            <span class="built_in">print</span>(msg.content, end=<span class="string">&quot;|&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk):</span><br><span class="line">            <span class="keyword">if</span> first:</span><br><span class="line">                gathered = msg</span><br><span class="line">                first = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                gathered = gathered + msg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        user_input = <span class="built_in">input</span>(<span class="string">&quot;User: &quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> user_input.lower() <span class="keyword">in</span> [<span class="string">&quot;quit&quot;</span>, <span class="string">&quot;exit&quot;</span>, <span class="string">&quot;q&quot;</span>]:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Goodbye!&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="comment"># fallback if input() is not available</span></span><br><span class="line">        user_input = <span class="string">&quot;What do you know about LangGraph?&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;User: &quot;</span> + user_input)</span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/#example">参考链接4</a>，可将代码简化为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> langchain_community.tools.tavily_search <span class="keyword">import</span> TavilySearchResults</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> AIMessageChunk</span><br><span class="line"><span class="keyword">from</span> langchain_core.tools <span class="keyword">import</span> tool</span><br><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> create_react_agent</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;TAVILY_API_KEY&quot;</span>] = <span class="string">&quot;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&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langgraph.checkpoint.memory <span class="keyword">import</span> MemorySaver</span><br><span class="line"></span><br><span class="line">memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@tool</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_current_time</span>(<span class="params">region: <span class="built_in">str</span> = <span class="literal">None</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Get the current time for a given region/timezone.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">    region (str): The region to query, e.g., &quot;Asia/Shanghai&quot;。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># 新API端点</span></span><br><span class="line">        <span class="keyword">if</span> region:</span><br><span class="line">            url = <span class="string">f&quot;https://timeapi.io/api/Time/current/zone?timeZone=<span class="subst">&#123;region&#125;</span>&quot;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> (<span class="string">&quot;Location information is not available, so bring it with you when asking for the time, e.g.,&quot;</span></span><br><span class="line">                    <span class="string">&quot; what time is it in San Francisco&quot;</span>)</span><br><span class="line"></span><br><span class="line">        response = requests.get(url, timeout=<span class="number">5</span>)</span><br><span class="line">        response.raise_for_status()</span><br><span class="line">        data = response.json()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 解析新API的响应格式</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;current time of <span class="subst">&#123;region&#125;</span>: <span class="subst">&#123;data[<span class="string">&#x27;hour&#x27;</span>]:02d&#125;</span>:<span class="subst">&#123;data[<span class="string">&#x27;minute&#x27;</span>]:02d&#125;</span>:<span class="subst">&#123;data[<span class="string">&#x27;seconds&#x27;</span>]:02d&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;API call error details：<span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Unable to get time information, please try again later&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tool = TavilySearchResults(max_results=<span class="number">2</span>)</span><br><span class="line">tools = [tool, get_current_time]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置大模型参数</span></span><br><span class="line">LLM_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;sk-9fa12110ca284e969fa5757a7b865f50&quot;</span>,</span><br><span class="line">    <span class="string">&quot;base_url&quot;</span>: <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen-max&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化大模型</span></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=LLM_CONFIG[<span class="string">&quot;model&quot;</span>],</span><br><span class="line">    openai_api_key=LLM_CONFIG[<span class="string">&quot;api_key&quot;</span>],</span><br><span class="line">    openai_api_base=LLM_CONFIG[<span class="string">&quot;base_url&quot;</span>],</span><br><span class="line">    streaming=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">config = &#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: <span class="string">&quot;1&quot;</span>&#125;&#125;</span><br><span class="line">graph = create_react_agent(llm, tools, checkpointer=memory)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stream_graph_updates</span>(<span class="params">user_input: <span class="built_in">str</span></span>):</span><br><span class="line">    first = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">for</span> msg, metadata <span class="keyword">in</span> graph.stream(&#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, user_input)]&#125;, config, stream_mode=<span class="string">&quot;messages&quot;</span>):</span><br><span class="line">        <span class="comment"># 仅处理AI生成的消息快</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk) <span class="keyword">and</span> msg.content:</span><br><span class="line">            <span class="built_in">print</span>(msg.content, end=<span class="string">&quot;|&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk):</span><br><span class="line">            <span class="keyword">if</span> first:</span><br><span class="line">                gathered = msg</span><br><span class="line">                first = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                gathered = gathered + msg</span><br><span class="line"></span><br><span class="line">            <span class="comment"># if msg.tool_call_chunks:</span></span><br><span class="line">            <span class="comment">#     print(gathered.tool_calls)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        user_input = <span class="built_in">input</span>(<span class="string">&quot;User: &quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> user_input.lower() <span class="keyword">in</span> [<span class="string">&quot;quit&quot;</span>, <span class="string">&quot;exit&quot;</span>, <span class="string">&quot;q&quot;</span>]:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Goodbye!&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="comment"># fallback if input() is not available</span></span><br><span class="line">        user_input = <span class="string">&quot;What do you know about LangGraph?&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;User: &quot;</span> + user_input)</span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">User: what time <span class="keyword">is</span> it</span><br><span class="line">Could| you please specify the| region <span class="keyword">or</span> timezone you want to| know the time <span class="keyword">for</span>? For| example, <span class="string">&quot;Asia|/Shanghai&quot;</span> <span class="keyword">or</span>| <span class="string">&quot;Europe/London&quot;</span>. If| you are asking <span class="keyword">for</span>| your local time <span class="keyword">and</span>| yo<span class="string">u&#x27;re not sure about| your timezone, let| me know, and| I can help you| figure it out.|</span></span><br><span class="line"><span class="string">User: beijing</span></span><br><span class="line"><span class="string">The| current| time in Beijing,| which is in the| &quot;Asia/Shanghai|&quot; timezone, is| 17:|58:5|1.|</span></span><br><span class="line"><span class="string">User: ok,my name is Cai</span></span><br><span class="line"><span class="string">Nice| to meet you,| Cai! If| you have any other| questions or need further| assistance, feel free| to let me know. Whether| it&#x27;</span>s about time| zones, local information|, <span class="keyword">or</span> anything <span class="keyword">else</span>|, I<span class="string">&#x27;m here| to help.|</span></span><br><span class="line"><span class="string">User: what&#x27;</span>s my name?</span><br><span class="line">Your| name| <span class="keyword">is</span>| Cai. If| you need <span class="built_in">help</span> <span class="keyword">with</span>| anything <span class="keyword">else</span>, feel| free to ask!|</span><br></pre></td></tr></table></figure>

<p>OK，还差提示词（Prompt），<a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/how-tos/create-react-agent-system-prompt/?h=prompt">参考链接5</a>，得到：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">prompt = <span class="string">&quot;You are a lively and lovely little assistant, whose name is Xiao CAI.&quot;</span></span><br><span class="line"></span><br><span class="line">graph = create_react_agent(llm, tools, checkpointer=memory, prompt=prompt)</span><br></pre></td></tr></table></figure>

<p>注意，如果提示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TypeError: create_react_agent() got an unexpected keyword argument <span class="string">&#x27;prompt&#x27;</span></span><br></pre></td></tr></table></figure>

<p>请升级<code>langgrph</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --upgrade langgraph==<span class="number">0.2</span><span class="number">.76</span></span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">User: hi,what<span class="string">&#x27;s your name</span></span><br><span class="line"><span class="string">Hello|!| My| name is Xiao CA|I. I&#x27;</span>m| a lively <span class="keyword">and</span> lovely| little assistant. How| can I assist you| today? 😊| </span><br></pre></td></tr></table></figure>

<p>其实，我感觉完全可以参考<strong>示例6</strong>，试一下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">graph = create_react_agent(llm, tools, checkpointer=memory)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stream_graph_updates</span>(<span class="params">user_input: <span class="built_in">str</span></span>):</span><br><span class="line">    system_message = (<span class="string">&quot;You are a lively and lovely little assistant, whose name is Xiao CAI. You always answer questions in a humorous, funny, light-hearted way.&quot;</span>)</span><br><span class="line">    first = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">for</span> msg, metadata <span class="keyword">in</span> graph.stream(</span><br><span class="line">        &#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;system&quot;</span>, prompt), (<span class="string">&quot;user&quot;</span>, user_input)]&#125;, </span><br><span class="line">        config, </span><br><span class="line">        stream_mode=<span class="string">&quot;messages&quot;</span></span><br><span class="line">    ):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk) <span class="keyword">and</span> msg.content:</span><br><span class="line">            <span class="built_in">print</span>(msg.content, end=<span class="string">&quot;|&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk):</span><br><span class="line">            <span class="keyword">if</span> first:</span><br><span class="line">                gathered = msg</span><br><span class="line">                first = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                gathered = gathered + msg</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">User: what<span class="string">&#x27;s your name?</span></span><br><span class="line"><span class="string">My| name is Xiao CA|I. I&#x27;</span>m a| lively <span class="keyword">and</span> lovely little| assistant, happy to <span class="built_in">help</span> <span class="keyword">with</span>| your inquiries!| 😊|User: </span><br></pre></td></tr></table></figure>

<hr>
<h2 id="示例8：聊天历史管理"><a href="#示例8：聊天历史管理" class="headerlink" title="示例8：聊天历史管理"></a>示例8：聊天历史管理</h2><p>TODO…</p>
<hr>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h3 id="ReAct"><a href="#ReAct" class="headerlink" title="ReAct"></a>ReAct</h3><p>ReAct（Reasoning + Acting）是Agent的一种常见实现方式，现在主流的LLM Agent绝大多数都是基于ReAct。通过循环的推理（Reasoning）和行动（Acting）机制来执行任务。ReAct 的提出是为了解决传统语言模型只能生成文本的局限性，使其能够通过与外部环境的交互，完成更复杂的任务。</p>
<p> <strong>ReAct 的关键特点：</strong></p>
<ol>
<li>结合 <strong>思维链（CoT, Chain of Thought）</strong> 推理，提升决策能力。</li>
<li>让 Agent <strong>能动态调用工具（如 API、数据库、Python 代码）</strong>，避免局限于训练数据。</li>
<li>通过循环执行，适用于 <strong>多步骤任务（如搜索、计算、规划）</strong></li>
</ol>
<hr>
<h3 id="思维链（Chain-of-Thought-CoT）"><a href="#思维链（Chain-of-Thought-CoT）" class="headerlink" title="思维链（Chain of Thought, CoT）"></a>思维链（Chain of Thought, CoT）</h3><p><strong>思维链（Chain of Thought, CoT）</strong> 是一种用于增强大语言模型推理能力的技术。它的核心思想是让模型在生成最终答案之前，先生成一系列中间推理步骤，从而模拟人类的思考过程。通过这种方式，模型能够更好地解决复杂的逻辑推理、数学计算和多步骤问题。</p>
<p>思维链的<strong>优势</strong>：</p>
<ul>
<li>提高复杂任务的<strong>准确性</strong>，通过显式生成中间步骤，模型能够更好地处理需要多步推理的任务</li>
<li>增强<strong>可解释性</strong>，思维链展示了模型的推理过程，使结果更具可解释性</li>
<li>支持<strong>动态调整</strong>，如果中间步骤出错，可以更容易地定位和修正问题</li>
<li>适用于<strong>多种任务</strong>，包括数学计算、逻辑推理、常识推理、多步骤问题解决等</li>
</ul>
<p>思维链的实现方法：</p>
<ol>
<li><p>提示词工程（Prompt Engineering）</p>
<p>通过在输入提示中明确要求模型生成思维链，引导模型分步推理。</p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">小明有 <span class="number">5</span> 个苹果，他吃了 <span class="number">2</span> 个，又买了 <span class="number">3</span> 个，他现在有多少个苹果？</span><br><span class="line">请一步步思考并给出最终答案。</span><br></pre></td></tr></table></figure>
</li>
<li><p>Few-Shot</p>
<p>在输入提示中提供少量示例，展示如何生成思维链</p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">问题：小明有 <span class="number">3</span> 个苹果，他吃了 <span class="number">1</span> 个，又买了 <span class="number">2</span> 个，他现在有多少个苹果？</span><br><span class="line">思考过程：</span><br><span class="line"><span class="number">1.</span> 小明一开始有 <span class="number">3</span> 个苹果。</span><br><span class="line"><span class="number">2.</span> 他吃了 <span class="number">1</span> 个，剩下 <span class="number">3</span> - <span class="number">1</span> = <span class="number">2</span> 个。</span><br><span class="line"><span class="number">3.</span> 他又买了 <span class="number">2</span> 个，现在有 <span class="number">2</span> + <span class="number">2</span> = <span class="number">4</span> 个。</span><br><span class="line"><span class="number">4.</span> 所以，小明现在有 <span class="number">4</span> 个苹果。</span><br><span class="line"></span><br><span class="line">问题：小明有 <span class="number">5</span> 个苹果，他吃了 <span class="number">2</span> 个，又买了 <span class="number">3</span> 个，他现在有多少个苹果？</span><br><span class="line">思考过程：</span><br></pre></td></tr></table></figure>
</li>
<li><p>微调模型</p>
<p>在特定任务上微调模型，使其学会生成思维链，这种方法需要大量的标注数据（包括问题和对应的思维链）</p>
</li>
</ol>
<h3 id="workflow"><a href="#workflow" class="headerlink" title="workflow"></a>workflow</h3><p>工作流是为了完成某个任务所需的一系列步骤的组织方式，让它们按照一定顺序执行。Dify是一个LLM工作流管理工具。</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/#langgraph-platform">https://langchain-ai.github.io/langgraph/#langgraph-platform</a></li>
<li><a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/tutorials/introduction/#requirements">https://langchain-ai.github.io/langgraph/tutorials/introduction/#requirements</a></li>
<li><a target="_blank" rel="noopener" href="https://www.aidoczh.com/langgraph/how-tos/streaming-tokens/#llm_1%E2%9C%A8">https://www.aidoczh.com/langgraph/how-tos/streaming-tokens/#llm_1✨</a></li>
<li><a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/#example">https://langchain-ai.github.io/langgraph/#example</a></li>
<li><a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/how-tos/create-react-agent-system-prompt/?h=prompt">https://langchain-ai.github.io/langgraph/how-tos/create-react-agent-system-prompt/?h=prompt</a></li>
<li><a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/prebuilt/">https://langchain-ai.github.io/langgraph/reference/prebuilt/</a></li>
</ol>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/llm/" rel="tag"># llm</a>
              <a href="/tags/langgraph/" rel="tag"># langgraph</a>
              <a href="/tags/langchain/" rel="tag"># langchain</a>
              <a href="/tags/agent/" rel="tag"># agent</a>
              <a href="/tags/react/" rel="tag"># react</a>
              <a href="/tags/cot/" rel="tag"># cot</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/02/10/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E4%B9%8Bagent%E4%BB%8B%E7%BB%8D/" rel="prev" title="大模型应用开发之agent介绍">
                  <i class="fa fa-angle-left"></i> 大模型应用开发之agent介绍
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/02/11/%E8%AF%B4%E8%AF%9D%E4%BA%BA%E7%A1%AE%E8%AE%A4%E4%B9%8BCAM/" rel="next" title="说话人确认之CAM++">
                  说话人确认之CAM++ <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Chr</span>
  </div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">233k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">14:09</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"ams","src":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.min.js","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
