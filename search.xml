<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>AI系列课程：python+深度学习导论</title>
    <url>/2025/04/27/AI%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B%EF%BC%9Apython-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AF%BC%E8%AE%BA/</url>
    <content><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>这是AI系列课程的第三次课：python基础和深度学习导论，本节课老大讲了：python基础以及概率论相关的东西，重点强调了贝叶斯定理，在留了课后作业的基础上也留了贝叶斯定理相关的附加作业。</p>
<span id="more"></span>

<hr>
<h3 id="课后作业"><a href="#课后作业" class="headerlink" title="课后作业"></a>课后作业</h3><img src="/2025/04/27/AI%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B%EF%BC%9Apython-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AF%BC%E8%AE%BA/544c8a4a468cdc3a55d545d9d07f05c0.png" class="" title="544c8a4a468cdc3a55d545d9d07f05c0">

<h4 id="第一题"><a href="#第一题" class="headerlink" title="第一题"></a>第一题</h4><p>整天玩的就是这，不整理了吧..</p>
<hr>
<h4 id="第二题"><a href="#第二题" class="headerlink" title="第二题"></a>第二题</h4><img src="/2025/04/27/AI%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B%EF%BC%9Apython-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AF%BC%E8%AE%BA/image-20250427101756666.png" class="" title="image-20250427101756666">

<h4 id="第三题"><a href="#第三题" class="headerlink" title="第三题"></a>第三题</h4><p>代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">&#x27;TkAgg&#x27;</span>)  <span class="comment"># 或者 &#x27;Qt5Agg&#x27;，根据你电脑安装的环境</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> norm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 x 范围</span></span><br><span class="line">x = np.linspace(-<span class="number">10</span>, <span class="number">20</span>, <span class="number">500</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义不同均值和方差的参数</span></span><br><span class="line">params = [</span><br><span class="line">    &#123;<span class="string">&#x27;mu&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;sigma&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;label&#x27;</span>: <span class="string">r&#x27;$\mu=0, \sigma=1$&#x27;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&#x27;mu&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;sigma&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;label&#x27;</span>: <span class="string">r&#x27;$\mu=0, \sigma=2$&#x27;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&#x27;mu&#x27;</span>: <span class="number">5</span>, <span class="string">&#x27;sigma&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;label&#x27;</span>: <span class="string">r&#x27;$\mu=5, \sigma=1$&#x27;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&#x27;mu&#x27;</span>: <span class="number">5</span>, <span class="string">&#x27;sigma&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;label&#x27;</span>: <span class="string">r&#x27;$\mu=5, \sigma=2$&#x27;</span>&#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘图</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> params:</span><br><span class="line">    y = norm.pdf(x, loc=p[<span class="string">&#x27;mu&#x27;</span>], scale=p[<span class="string">&#x27;sigma&#x27;</span>])</span><br><span class="line">    plt.plot(x, y, label=p[<span class="string">&#x27;label&#x27;</span>])</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;Normal Distributions with Different Means and Variances&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Probability Density&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><strong>图像：</strong></p>
<img src="/2025/04/27/AI%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B%EF%BC%9Apython-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AF%BC%E8%AE%BA/image-20250427103224011.png" class="" title="image-20250427103224011">

<p>可见，均值 $\mu$ 控制<strong>位置</strong>（向左或向右平移），方差 $σ^2$ 控制<strong>形状</strong>（方差越大，曲线越扁平越宽；越小，曲线越陡峭越窄）</p>
<ol>
<li><strong>方差小 → 曲线陡峭 → 数值集中</strong></li>
</ol>
<p>如果方差 $\sigma^2$ 很小，曲线就很<strong>陡峭、窄</strong>，意味着：</p>
<ul>
<li>大多数随机变量 $X$ 的取值都非常<strong>接近均值 $\mu$</strong>。</li>
<li>数据的<strong>波动很小</strong>，<strong>稳定性很高</strong>。</li>
<li>出现“极端值”（离均值很远的值）的概率非常低。</li>
</ul>
<p>🔵 举例：</p>
<ul>
<li>高精度的电子测量仪器，比如测量电压，误差极小，数据分布就非常陡峭。</li>
<li>很规范生产的零件，比如螺丝长度，都是 10.00 mm 左右，偏差极小。</li>
</ul>
<hr>
<ol start="2">
<li><strong>方差大 → 曲线扁平 → 数值分散</strong></li>
</ol>
<p>如果方差 $\sigma^2$ 很大，曲线就变得<strong>扁平、宽广</strong>，意味着：</p>
<ul>
<li>随机变量 $X$ 的取值会在很大的范围内<strong>波动</strong>。</li>
<li>数据<strong>离均值较远</strong>的情况更常见。</li>
<li>出现极端值的<strong>可能性更高</strong>。</li>
</ul>
<p>🔵 举例：</p>
<ul>
<li>股市日收益率，平均收益可能接近 0，但波动很大，一天涨 5%，跌 7% 都可能。</li>
<li>人体体重这种数据，虽然有均值，但胖子瘦子都很多，方差较大。</li>
</ul>
<ol start="3">
<li><strong>结合均值 $\mu$ 来看</strong></li>
</ol>
<ul>
<li>$\mu$ 决定了<strong>中心在哪里</strong>，比如身高的均值可能是 170 cm。</li>
<li>$\sigma^2$ 决定了<strong>大家围绕中心聚得紧还是散</strong>。</li>
</ul>
<p>可以想象：</p>
<blockquote>
<p>均值是<strong>出发点</strong>，方差是<strong>走多远</strong>。</p>
</blockquote>
<p>如果均值是城市中心，方差小就像大家都住在市中心附近；方差大就像有的人住在郊区，有的人住得特别远。</p>
<hr>
<ol start="4">
<li><strong>用数学公式更直观地理解</strong></li>
</ol>
<p>正态分布的概率密度公式是：<br>$$<br>f(x) &#x3D; \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}<br>$$</p>
<ul>
<li>公式中，指数部分$ −\frac{(x-\mu)^2}{2\sigma^2}$ 告诉你：<ul>
<li>$ \sigma^2 $ 小，指数下降得快，曲线很陡。</li>
<li>$\sigma^2$ 大，指数下降得慢，曲线很缓。</li>
</ul>
</li>
<li>前面的 $\frac{1}{\sqrt{2\pi\sigma^2}}$ 保证整体面积是 1（概率密度积分为1），所以扁了高就低，窄了高就高。</li>
</ul>
<p><strong>总结一句话 🔥</strong></p>
<blockquote>
<p>方差越小，数值越集中，数据越稳定；<br>方差越大，数值越分散，数据越波动。</p>
</blockquote>
<hr>
<h4 id="第四题"><a href="#第四题" class="headerlink" title="第四题"></a>第四题</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">&#x27;TkAgg&#x27;</span>)  <span class="comment"># 或者 &#x27;Qt5Agg&#x27;，根据你电脑安装的环境</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义 sigmoid 函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 x 轴范围</span></span><br><span class="line">x = np.linspace(-<span class="number">10</span>, <span class="number">10</span>, <span class="number">500</span>)</span><br><span class="line">y = sigmoid(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘图</span></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">5</span>))</span><br><span class="line">plt.plot(x, y, label=<span class="string">r&#x27;$\sigma(x) = \frac&#123;1&#125;&#123;1+e^&#123;-x&#125;&#125;$&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Sigmoid Function&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">r&#x27;$\sigma(x)$&#x27;</span>)</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><strong>图像：</strong></p>
<img src="/2025/04/27/AI%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B%EF%BC%9Apython-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AF%BC%E8%AE%BA/image-20250427110744099.png" class="" title="image-20250427110744099">

<p><strong>Sigmoid函数的特点</strong></p>
<ol>
<li><strong>S型曲线（S-curve）</strong><ul>
<li>在 $x \to -\infty$时，$ \sigma(x) \to 0$</li>
<li>在 $ x \to + \infty $时，$ \sigma(x) \to 1$</li>
<li>在 $ x&#x3D;0 $ 时，$ \sigma(0) &#x3D; 0.5 $</li>
</ul>
</li>
<li><strong>单调递增</strong><ul>
<li>$x$越大，$\sigma(x)$ 越大。</li>
<li>但增长速率在中间快，在两边趋近于平缓（因为接近0和1是“渐近”的）。</li>
</ul>
</li>
<li><strong>有界输出</strong><ul>
<li>无论输入 $x$ 多大多小，输出永远在 $(0, 1)$ 之间。</li>
<li>这是<strong>归一化</strong>效果，非常重要。</li>
</ul>
</li>
<li><strong>可导且导数简单</strong><ul>
<li>导数公式是：$\sigma’(x) &#x3D; \sigma(x)(1 - \sigma(x))$</li>
</ul>
</li>
</ol>
<ul>
<li>计算很方便，用在反向传播（神经网络训练）中非常高效。</li>
</ul>
<hr>
<p><strong>Sigmoid函数的意义（应用场景）</strong></p>
<ol>
<li><strong>二分类问题的概率输出</strong><ul>
<li>Sigmoid 把任意实数映射到 (0,1) 区间，可以直接理解为<strong>属于某个类别的概率</strong>。</li>
<li>例如 Logistic Regression（二分类逻辑回归）就是用的 Sigmoid。</li>
</ul>
</li>
<li><strong>神经网络激活函数</strong><ul>
<li>早期神经网络（如 LeNet）常用 Sigmoid 作为<strong>激活函数</strong>，给网络增加<strong>非线性能力</strong>。</li>
</ul>
</li>
<li><strong>平滑阈值化（Soft Threshold）</strong><ul>
<li>在一些需要将信号在 0 和 1 之间平滑过渡的场景（比如模糊控制、概率图模型）很有用。</li>
</ul>
</li>
<li><strong>生物神经元模拟</strong><ul>
<li>生物神经元的输出也不是硬性的 0&#x2F;1，而是有一个连续激活程度，Sigmoid很符合这种“激活程度”的模拟。</li>
</ul>
</li>
</ol>
<hr>
<p><strong>一句话总结</strong></p>
<blockquote>
<p><strong>Sigmoid</strong> 是一种可以把<strong>无限范围</strong>的数据压缩到<strong>有限区间 (0,1)</strong> 的平滑、可微、单调递增的函数，<br> 在<strong>概率输出</strong>、<strong>神经网络建模</strong>、<strong>生物模拟</strong>中应用广泛。</p>
</blockquote>
<hr>
<h3 id="附加题"><a href="#附加题" class="headerlink" title="附加题"></a>附加题</h3><ol>
<li><p>假设一个75岁的人对某项癌症进行检测，这个癌症在75岁的发病率是$1%$，检测准确率$99%$，检测结果呈阳性，请问实际患癌症的概率是多少？</p>
<p>答：要计算实际患癌症的概率，我们使用贝叶斯定理。已知：</p>
<ul>
<li>癌症发病率（先验概率）：$P(C) &#x3D; 1 % &#x3D; 0.01$</li>
<li>非癌症概率：$P(¬C) &#x3D; 1 - 0.01 &#x3D; 0.99$</li>
<li>检测准确率（灵敏度和特异度均为$99 %$）：<ul>
<li>真阳性率：$P(Pos|C) &#x3D; 0.99$（患癌且检测阳性）</li>
<li>假阳性率：$P(Pos|¬C) &#x3D; 1 - 0.99 &#x3D; 0.01$（未患癌但检测阳性）</li>
</ul>
</li>
<li>检测结果为阳性：我们需计算$P(C|Pos)$，即<strong>给定阳性结果时实际患癌的概率</strong>。</li>
</ul>
<p>贝叶斯定理公式为：<br>$$<br>P(C|Pos) &#x3D; \frac{P(Pos|C) \cdot P(C)}{P(Pos)}<br>$$<br>其中，总阳性概率$P(Pos)$为：<br>$$<br>P(Pos) &#x3D; P(Pos|C) \cdot P(C) + P(Pos|¬C) \cdot P(¬C)<br>$$<br>代入数值：<br>$$<br>P(Pos)&#x3D;(0.99⋅0.01)+(0.01⋅0.99)&#x3D;0.0099+0.0099&#x3D;0.0198<br>$$<br>现在计算$P(C|Pos)$：<br>$$<br>P(C|Pos) &#x3D; \frac{P(Pos|C) \cdot P(C)}{P(Pos)} &#x3D; \frac{0.99 \cdot 0.01}{0.0198} &#x3D; \frac{0.0099}{0.0198} &#x3D; 0.5<br>$$<br>因此，实际患癌症的概率是 <strong>50%</strong>。</p>
<p><strong>解释</strong>：尽管检测准确率很高（$99%$），但由于癌症发病率低（$1%$），假阳性病例（未患癌但检测阳性）与真阳性病例数量相当，导致阳性结果中只有一半真正患癌。这反映了低发病率疾病检测中假阳性的影响。</p>
</li>
</ol>
<hr>
<ol start="2">
<li><p>求28个人，生日都不在同一天的概率是多少？</p>
<p>答：假设一年有365天，且每个人的生日是独立且均匀分布的（即每一天的概率相同）。</p>
<p>第一个人的生日可以是任意一天，概率：$\frac{365}{365} &#x3D; 1$；</p>
<p>第二个人的生日与第一人不同，概率：$ \frac{364}{365}$；</p>
<p>第三人的生日与前两人都不同，概率：$\frac{363}{365}$；</p>
<p>依次类推，第$k$个人的生日必须与前$k-1$个人不同，概率：$\frac{365-(k-1)}{365}$。</p>
<p>所以：<br>$$<br>P &#x3D; \frac{365}{365} \times \frac{364}{365} \times \cdots \times \frac{338}{365} \approx 34.55 %<br>$$</p>
<hr>
</li>
<li><p>扔100次硬币，50次正面朝上的概率有多少?</p>
<p>答：二项分布公式：<br>$$<br>P(k) &#x3D; \binom{n}{k} p^k (1-p)^{n-k}<br>$$<br>其中：</p>
<ul>
<li><p>$n&#x3D;100$（总次数）</p>
</li>
<li><p>$k&#x3D;50$（正面朝上的次数）</p>
</li>
<li><p>$p&#x3D;0.5 %$（正面朝上的单次概率）</p>
</li>
</ul>
<p>代入公式：<br>$$<br>P(50) &#x3D; \binom{100}{50} (0.5)^{50} (0.5)^{50} &#x3D; \binom{100}{50} (0.5)^{100}<br>$$<br>计算组合数 $\binom{100}{50}$：<br>$$<br>\binom{100}{50} &#x3D; \frac{100!}{50! \times 50!}<br>$$<br>写个程序计算下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数</span></span><br><span class="line">n = <span class="number">100</span></span><br><span class="line">k = <span class="number">50</span></span><br><span class="line">p = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算组合数 C(100, 50)</span></span><br><span class="line">C = math.comb(n, k)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算概率</span></span><br><span class="line">P = C * (p ** n)</span><br><span class="line"><span class="built_in">print</span>(P)</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">0.07958923738717877</span><br></pre></td></tr></table></figure>

<p>即扔100次硬币，50次正面朝上的概率为$7.96%$，可见虽然听起来 50 次正面很合理，但严格说正好 50 次的概率其实并不算高。</p>
</li>
</ol>
<hr>
<ol start="4">
<li><p>贴近现实的手机”诈骗电话“案例：</p>
<p>你收到一通电话，手机来电显示提示“疑似诈骗电话”。假设：</p>
<ul>
<li>在你所在地区， 诈骗电话占所有来电的 $0.5 %$</li>
<li>手机的诈骗检测算法很先进，如果来电真是诈骗电话，算法正确标记为“疑似诈骗”的概率为98%</li>
</ul>
<p>问： 现在，你看到手机提示“疑似诈骗电话”，请问：这通电话真正是诈骗电话的概率是多少？</p>
<p>答：首先将上面的文字翻译成数学符号表示：<br>$$<br>𝑃(诈骗)&#x3D;0.005<br>$$</p>
<p>$$<br>𝑃(¬诈骗)&#x3D;0.995<br>$$</p>
<p>$$<br>𝑃(标记|诈骗)&#x3D;0.98<br>$$</p>
<p>$$<br>𝑃(标记∣¬诈骗)&#x3D;0.02<br>$$</p>
<p>使用贝叶斯定理：<br>$$<br>P(诈骗|标记)&#x3D;\frac{P(标记|诈骗) \times P(诈骗)}{P(标记)}<br>$$<br>其中：<br>$$<br>P(标记)&#x3D;P(标记∣诈骗)⋅P(诈骗)+P(标记∣¬诈骗)⋅P(¬诈骗)&#x3D;0.98·0.005+0.02·0.995&#x3D;0.0248<br>$$<br>代入贝叶斯公式，得：<br>$$<br>P(诈骗|标记)&#x3D;\frac{P(标记|诈骗) \times P(诈骗)}{P(标记)}&#x3D;\frac{0.98 \times 0.005}{0.0248}&#x3D;0.1976<br>$$<br>即当手机提示“疑似诈骗电话”时，这通电话真正是诈骗电话的概率约为 <strong>19.76%</strong>，即大约 <strong>20%</strong>。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>AI内部导学系列</tag>
      </tags>
  </entry>
  <entry>
    <title>AI系列课程：导论and数学基础1</title>
    <url>/2025/03/21/AI%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B%EF%BC%9A%E5%AF%BC%E8%AE%BAand%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%801/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>老大（老板）25年开始就打算开个AI导学系列，也是以身作则进行了第一期的讲解，从小学到大学的数学知识都进行了讲解（留了一部分微积分、导数和偏导等第二次课讲解），重点讲解了线性代数相关的东西，这次课反复提及的一句话：矩阵计算就是线性变换。同时也留了几题课后作业，本文记录下作业，小友们有兴趣也可以看看。</p>
<span id="more"></span>

<hr>
<h2 id="课后作业"><a href="#课后作业" class="headerlink" title="课后作业"></a>课后作业</h2><img src="/2025/03/21/AI%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B%EF%BC%9A%E5%AF%BC%E8%AE%BAand%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%801/b4fbd56d4e648d20a8e98d3c6e1d3b5.png" class="" title="b4fbd56d4e648d20a8e98d3c6e1d3b5">

<h3 id="第一题（旋转，拉伸，xy互换的矩阵形式）"><a href="#第一题（旋转，拉伸，xy互换的矩阵形式）" class="headerlink" title="第一题（旋转，拉伸，xy互换的矩阵形式）"></a>第一题（旋转，拉伸，xy互换的矩阵形式）</h3><img src="/2025/03/21/AI%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B%EF%BC%9A%E5%AF%BC%E8%AE%BAand%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%801/image-20250322112537235.png" class="" title="image-20250322112537235">

<img src="/2025/03/21/AI%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B%EF%BC%9A%E5%AF%BC%E8%AE%BAand%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%801/image-20250322112602224.png" class="" title="image-20250322112602224">

<img src="/2025/03/21/AI%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B%EF%BC%9A%E5%AF%BC%E8%AE%BAand%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%801/image-20250322110806938.png" class="" title="image-20250322110806938">

<img src="/2025/03/21/AI%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B%EF%BC%9A%E5%AF%BC%E8%AE%BAand%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%801/image-20250322111657936.png" class="" title="image-20250322111657936">

<p>使用的是<a href="https://excalidraw.com/">excalidraw</a>进行的画图。</p>
<hr>
<h3 id="第二题（代码实现1）"><a href="#第二题（代码实现1）" class="headerlink" title="第二题（代码实现1）"></a>第二题（代码实现1）</h3><p>同事们都在做带界面展示的😅，我还是先做输出数字的吧，做完了要是有时间再回头做界面展示，这里需要注意的是顺时针旋转和逆时针旋转的旋转矩阵不一样，本质上是参考不同，那么我们就需要定一个参考，这里定逆时针为基准，顺时针旋转<code>θ</code>即为逆时针旋转了<code>-θ</code>角:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.patches <span class="keyword">import</span> FancyArrow</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 黑体</span></span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">逆时针旋转30°：</span></span><br><span class="line"><span class="string">python transform.py --rotate 30</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">顺时针45°：</span></span><br><span class="line"><span class="string">python transform.py --rotate 45 --clockwise</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">放大3倍：</span></span><br><span class="line"><span class="string">python transform.py --scale 3</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">坐标交换：</span></span><br><span class="line"><span class="string">python transform.py --swap</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">指定自定义向量：</span></span><br><span class="line"><span class="string">   # 使用向量(2, 1)进行顺时针旋转30度</span></span><br><span class="line"><span class="string">python transform.py --rotate 30 --clockwise --vector 2 1</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">   # 缩放向量(0, 3)</span></span><br><span class="line"><span class="string">python transform.py --scale 1.5 --vector 0 3</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">调整显示范围</span></span><br><span class="line"><span class="string">python transform.py --swap --size 10</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 变换矩阵生成函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rotation_matrix</span>(<span class="params">theta, clockwise=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;生成旋转矩阵（默认逆时针）&quot;&quot;&quot;</span></span><br><span class="line">    theta = np.radians(theta)</span><br><span class="line">    <span class="keyword">if</span> clockwise:</span><br><span class="line">        theta = -theta</span><br><span class="line">    <span class="keyword">return</span> np.array([</span><br><span class="line">        [np.cos(theta), -np.sin(theta)],</span><br><span class="line">        [np.sin(theta),  np.cos(theta)]</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">scaling_matrix</span>(<span class="params">lambda_</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;生成缩放矩阵&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> np.array([</span><br><span class="line">        [lambda_, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">0</span>, lambda_]</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">swap_matrix</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;生成坐标交换矩阵&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> np.array([</span><br><span class="line">        [<span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">0</span>]</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 命令行参数配置</span></span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">&#x27;2D向量线性变换演示&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 互斥变换参数</span></span><br><span class="line">group = parser.add_mutually_exclusive_group(required=<span class="literal">True</span>)</span><br><span class="line">group.add_argument(<span class="string">&#x27;--rotate&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>,</span><br><span class="line">                  <span class="built_in">help</span>=<span class="string">&#x27;旋转角度（正值为逆时针）&#x27;</span>)</span><br><span class="line">group.add_argument(<span class="string">&#x27;--scale&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>,</span><br><span class="line">                  <span class="built_in">help</span>=<span class="string">&#x27;缩放倍数&#x27;</span>)</span><br><span class="line">group.add_argument(<span class="string">&#x27;--swap&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>,</span><br><span class="line">                  <span class="built_in">help</span>=<span class="string">&#x27;交换XY坐标&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 向量参数</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--vector&#x27;</span>, nargs=<span class="number">2</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, metavar=(<span class="string">&#x27;X&#x27;</span>, <span class="string">&#x27;Y&#x27;</span>),</span><br><span class="line">                   default=[<span class="number">1.0</span>, <span class="number">0.0</span>],</span><br><span class="line">                   <span class="built_in">help</span>=<span class="string">&#x27;原始向量坐标 (默认: 1.0 0.0)&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 旋转选项</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--clockwise&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>,</span><br><span class="line">                   <span class="built_in">help</span>=<span class="string">&#x27;与--rotate一起使用表示顺时针旋转&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示参数</span></span><br><span class="line">parser.add_argument(<span class="string">&#x27;--size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">5.0</span>,</span><br><span class="line">                   <span class="built_in">help</span>=<span class="string">&#x27;图形显示范围（默认±5）&#x27;</span>)</span><br><span class="line"></span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入验证</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    original = np.array(args.vector, dtype=np.float64)</span><br><span class="line"><span class="keyword">except</span> ValueError:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(<span class="string">&quot;向量坐标必须为数字&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成变换矩阵和标题</span></span><br><span class="line"><span class="keyword">if</span> args.rotate <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    matrix = rotation_matrix(args.rotate, args.clockwise)</span><br><span class="line">    direction = <span class="string">&quot;顺时针&quot;</span> <span class="keyword">if</span> args.clockwise <span class="keyword">else</span> <span class="string">&quot;逆时针&quot;</span></span><br><span class="line">    title = <span class="string">f&quot;旋转 <span class="subst">&#123;args.rotate&#125;</span>° (<span class="subst">&#123;direction&#125;</span>)&quot;</span></span><br><span class="line"><span class="keyword">elif</span> args.scale <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    matrix = scaling_matrix(args.scale)</span><br><span class="line">    title = <span class="string">f&quot;缩放 <span class="subst">&#123;args.scale&#125;</span> 倍&quot;</span></span><br><span class="line"><span class="keyword">elif</span> args.swap:</span><br><span class="line">    matrix = swap_matrix()</span><br><span class="line">    title = <span class="string">&quot;XY坐标交换&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 应用变换</span></span><br><span class="line">transformed = matrix @ original</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建画布</span></span><br><span class="line">fig, (ax1, ax2) = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">10</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制原始向量</span></span><br><span class="line">ax1.add_patch(FancyArrow(<span class="number">0</span>, <span class="number">0</span>, original[<span class="number">0</span>], original[<span class="number">1</span>],</span><br><span class="line">             width=<span class="number">0.05</span>, length_includes_head=<span class="literal">True</span>,</span><br><span class="line">             color=<span class="string">&#x27;blue&#x27;</span>, label=<span class="string">f&#x27;原始向量 (<span class="subst">&#123;original[<span class="number">0</span>]:<span class="number">.1</span>f&#125;</span>, <span class="subst">&#123;original[<span class="number">1</span>]:<span class="number">.1</span>f&#125;</span>)&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制变换后向量</span></span><br><span class="line">ax2.add_patch(FancyArrow(<span class="number">0</span>, <span class="number">0</span>, transformed[<span class="number">0</span>], transformed[<span class="number">1</span>],</span><br><span class="line">             width=<span class="number">0.05</span>, length_includes_head=<span class="literal">True</span>,</span><br><span class="line">             color=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">f&#x27;变换后 (<span class="subst">&#123;transformed[<span class="number">0</span>]:<span class="number">.2</span>f&#125;</span>, <span class="subst">&#123;transformed[<span class="number">1</span>]:<span class="number">.2</span>f&#125;</span>)&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 图形设置</span></span><br><span class="line"><span class="keyword">for</span> ax <span class="keyword">in</span> [ax1, ax2]:</span><br><span class="line">    ax.set_xlim(-args.size, args.size)</span><br><span class="line">    ax.set_ylim(-args.size, args.size)</span><br><span class="line">    ax.grid(<span class="literal">True</span>)</span><br><span class="line">    ax.set_aspect(<span class="string">&#x27;equal&#x27;</span>)</span><br><span class="line">    ax.axhline(<span class="number">0</span>, color=<span class="string">&#x27;black&#x27;</span>, linewidth=<span class="number">0.5</span>)</span><br><span class="line">    ax.axvline(<span class="number">0</span>, color=<span class="string">&#x27;black&#x27;</span>, linewidth=<span class="number">0.5</span>)</span><br><span class="line">    ax.legend(loc=<span class="string">&#x27;upper right&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax1.set_title(<span class="string">&quot;原始向量&quot;</span>)</span><br><span class="line">ax2.set_title(title + <span class="string">&quot;\n&quot;</span> + <span class="string">f&quot;变换矩阵:\n<span class="subst">&#123;matrix&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="第三题（矩阵乘法函数）"><a href="#第三题（矩阵乘法函数）" class="headerlink" title="第三题（矩阵乘法函数）"></a>第三题（矩阵乘法函数）</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">matrix_mult</span>(<span class="params">A, B</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(A[<span class="number">0</span>]) != <span class="built_in">len</span>(B):</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;矩阵A的列数必须等于矩阵B的行数&quot;</span>)</span><br><span class="line">    result = [[<span class="number">0</span>]*<span class="built_in">len</span>(B[<span class="number">0</span>]) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(A))]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(A)):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(B[<span class="number">0</span>])):</span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(B)):</span><br><span class="line">                result[i][j] += A[i][k] * B[k][j]</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试</span></span><br><span class="line">A = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]]</span><br><span class="line">B = [[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>]]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;矩阵乘积:&quot;</span>, matrix_mult(A, B))  <span class="comment"># 输出 [[19, 22], [43, 50]]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">A = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">B = np.array([[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(A @ B)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">矩阵乘积: [[<span class="number">19</span>, <span class="number">22</span>], [<span class="number">43</span>, <span class="number">50</span>]]</span><br><span class="line">[[<span class="number">19</span> <span class="number">22</span>]</span><br><span class="line"> [<span class="number">43</span> <span class="number">50</span>]]</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="第四题（计算矩阵的秩）"><a href="#第四题（计算矩阵的秩）" class="headerlink" title="第四题（计算矩阵的秩）"></a>第四题（计算矩阵的秩）</h3><img src="/2025/03/21/AI%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B%EF%BC%9A%E5%AF%BC%E8%AE%BAand%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%801/image-20250322125203606.png" class="" title="image-20250322125203606">

<hr>
<h3 id="第五题（计算特征值和特征向量）"><a href="#第五题（计算特征值和特征向量）" class="headerlink" title="第五题（计算特征值和特征向量）"></a>第五题（计算特征值和特征向量）</h3><img src="/2025/03/21/AI%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B%EF%BC%9A%E5%AF%BC%E8%AE%BAand%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%801/image-20250322134518499.png" class="" title="image-20250322134518499">

<blockquote>
<p>方阵A的秩 &lt; n，则至少有一个特征值是0。方阵A的秩&#x3D;n，则0不是特征值。</p>
</blockquote>
<hr>
<h3 id="第六题（特征值、特征向量的实际用途-现实意义）"><a href="#第六题（特征值、特征向量的实际用途-现实意义）" class="headerlink" title="第六题（特征值、特征向量的实际用途&#x2F;现实意义）"></a>第六题（特征值、特征向量的实际用途&#x2F;现实意义）</h3><h4 id="1-核心思想"><a href="#1-核心思想" class="headerlink" title="(1) 核心思想"></a><strong>(1) 核心思想</strong></h4><ul>
<li><strong>特征值</strong>：线性变换中的“缩放因子”。</li>
<li><strong>特征向量</strong>：变换中保持方向不变的“主轴方向”。</li>
</ul>
<h4 id="2-实际应用领域"><a href="#2-实际应用领域" class="headerlink" title="(2) 实际应用领域"></a><strong>(2) 实际应用领域</strong></h4><table>
<thead>
<tr>
<th align="left">领域</th>
<th align="left">应用场景</th>
<th align="left">特征值意义</th>
<th align="left">特征向量意义</th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>振动分析</strong></td>
<td align="left">机械系统&#x2F;桥梁振动</td>
<td align="left">系统固有频率</td>
<td align="left">振动模式形状</td>
</tr>
<tr>
<td align="left"><strong>数据科学</strong></td>
<td align="left">主成分分析（PCA）</td>
<td align="left">数据方差大小</td>
<td align="left">数据主成分方向</td>
</tr>
<tr>
<td align="left"><strong>量子力学</strong></td>
<td align="left">波函数分析</td>
<td align="left">物理量观测值（如能量）</td>
<td align="left">量子态（本征态）</td>
</tr>
<tr>
<td align="left"><strong>图像压缩</strong></td>
<td align="left">奇异值分解（SVD）</td>
<td align="left">数据重要性权重</td>
<td align="left">基向量方向</td>
</tr>
<tr>
<td align="left"><strong>稳定性分析</strong></td>
<td align="left">微分方程系统</td>
<td align="left">系统稳定性（正负实部）</td>
<td align="left">扰动演化方向</td>
</tr>
<tr>
<td align="left"><strong>搜索引擎</strong></td>
<td align="left">PageRank算法</td>
<td align="left">网页重要性排名</td>
<td align="left">网页权重分布</td>
</tr>
</tbody></table>
<h4 id="3-典型示例"><a href="#3-典型示例" class="headerlink" title="(3) 典型示例"></a>(3) 典型示例</h4><ul>
<li><strong>桥梁振动分析</strong>：<br>特征值 <code>λ</code> 的平方根给出桥梁的固有频率，特征向量显示桥梁如何摆动（如横向或纵向振动）。</li>
<li><strong>人脸识别（PCA）</strong>：<br>协方差矩阵的特征向量称为“特征脸”，对应人脸的主要变化模式；特征值越大，该模式对数据差异的贡献越大。</li>
<li><strong>金融市场</strong>：<br>资产协方差矩阵的特征向量代表投资组合的风险方向，特征值表示风险大小。</li>
</ul>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>AI内部导学系列</tag>
      </tags>
  </entry>
  <entry>
    <title>AI系列课程：深度学习2</title>
    <url>/2025/04/29/AI%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>这是第四次课，本次课包含：朴素贝叶斯、牛顿法，并推荐了一个可视化的工具（以上是承接上节课的），本节课的重点依次是：</p>
<ul>
<li>AI简史</li>
<li>监督学习、非监督学习、强化学习</li>
<li>学派：符号主义、联结主义</li>
<li>单层感知器、布尔运算（与、或、与非、异或）  </li>
<li>万能近似定理1989</li>
<li>激活函数</li>
</ul>
<blockquote>
<p>单层感知器实现不了异或门，所以那时候感知器的研究停滞不前了。</p>
</blockquote>
<span id="more"></span>

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2>]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>AI内部导学系列</tag>
      </tags>
  </entry>
  <entry>
    <title>AI系列课程：导论and数学基础2</title>
    <url>/2025/03/22/AI%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B%EF%BC%9A%E5%AF%BC%E8%AE%BAand%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%802/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>上节课老大（老板）着重讲了线性代数相关的知识，这节课依旧是老大进行分享（问了下才知道老大准备开12课时，且都是自己讲，真牛啊，敢于定目标，且付诸行动），本节课的重点是微积分、导数、偏导、梯度下降相关的东西，依照传统留了课后作业，本文依旧是记录下作业，对了，还有奇异值分解，老大说谁要是能在第三次课讲奇异值分解，会加大分，我先把作业写完，再准备下奇异值分解的相关内容吧。</p>
<span id="more"></span>

<hr>
<h2 id="课后作业"><a href="#课后作业" class="headerlink" title="课后作业"></a>课后作业</h2><img src="/2025/03/22/AI%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B%EF%BC%9A%E5%AF%BC%E8%AE%BAand%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%802/1f6e3059df9ff02780ee9b50ad34f700.png" class="" title="1f6e3059df9ff02780ee9b50ad34f700">

<h3 id="第一题"><a href="#第一题" class="headerlink" title="第一题"></a>第一题</h3><img src="/2025/03/22/AI%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B%EF%BC%9A%E5%AF%BC%E8%AE%BAand%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%802/image-20250411154354466.png" class="" title="image-20250411154354466">

<h3 id="第二题"><a href="#第二题" class="headerlink" title="第二题"></a>第二题</h3><img src="/2025/03/22/AI%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B%EF%BC%9A%E5%AF%BC%E8%AE%BAand%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%802/image-20250412131432321.png" class="" title="image-20250412131432321">

<p>代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> minimize</span><br><span class="line"></span><br><span class="line"><span class="comment"># 电站坐标</span></span><br><span class="line">points = [(<span class="number">1</span>, <span class="number">2</span>), (<span class="number">2</span>, <span class="number">5</span>), (<span class="number">3</span>, <span class="number">3</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 目标函数 J(m, b)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cost_function</span>(<span class="params">params</span>):</span><br><span class="line">    m, b = params</span><br><span class="line">    total_cost = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> points:</span><br><span class="line">        distance_squared = (y - m * x - b) ** <span class="number">2</span> / (m ** <span class="number">2</span> + <span class="number">1</span>)</span><br><span class="line">        total_cost += distance_squared</span><br><span class="line">    <span class="keyword">return</span> total_cost</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始猜测</span></span><br><span class="line">initial_guess = [<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 SciPy 的优化器求解</span></span><br><span class="line">result = minimize(cost_function, initial_guess, method=<span class="string">&#x27;BFGS&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取结果</span></span><br><span class="line">m_opt, b_opt = result.x</span><br><span class="line">cost_opt = result.fun</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;解析法结果：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;最优直线: y = <span class="subst">&#123;m_opt:<span class="number">.4</span>f&#125;</span>x + <span class="subst">&#123;b_opt:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;最小成本: <span class="subst">&#123;cost_opt:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">解析法结果：</span><br><span class="line">最优直线: y = 3.0000x + -2.6667</span><br><span class="line">最小成本: 1.6667</span><br></pre></td></tr></table></figure>

<p><strong>第二问：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 电站坐标</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">points = [(<span class="number">1</span>, <span class="number">2</span>), (<span class="number">2</span>, <span class="number">5</span>), (<span class="number">3</span>, <span class="number">3</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 目标函数 J(m, b)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cost_function</span>(<span class="params">m, b</span>):</span><br><span class="line">    total_cost = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> points:</span><br><span class="line">        distance_squared = (y - m * x - b) ** <span class="number">2</span> / (m ** <span class="number">2</span> + <span class="number">1</span>)</span><br><span class="line">        total_cost += distance_squared</span><br><span class="line">    <span class="keyword">return</span> total_cost</span><br><span class="line"></span><br><span class="line"><span class="comment"># 梯度计算</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradients</span>(<span class="params">m, b</span>):</span><br><span class="line">    dm, db = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    denom = m ** <span class="number">2</span> + <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> points:</span><br><span class="line">        residual = y - m * x - b</span><br><span class="line">        <span class="comment"># 偏导数 dJ/dm</span></span><br><span class="line">        dm += (-<span class="number">2</span> * residual * x * denom - <span class="number">2</span> * m * residual ** <span class="number">2</span>) / (denom ** <span class="number">2</span>)</span><br><span class="line">        <span class="comment"># 偏导数 dJ/db</span></span><br><span class="line">        db += -<span class="number">2</span> * residual / denom</span><br><span class="line">    <span class="keyword">return</span> dm, db</span><br><span class="line"></span><br><span class="line"><span class="comment"># 梯度下降</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient_descent</span>(<span class="params">m_init, b_init, learning_rate, num_iterations</span>):</span><br><span class="line">    m, b = m_init, b_init</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_iterations):</span><br><span class="line">        dm, db = gradients(m, b)</span><br><span class="line">        <span class="keyword">if</span> np.sqrt(dm ** <span class="number">2</span> + db ** <span class="number">2</span>) &lt; <span class="number">1e-6</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        m -= learning_rate * dm</span><br><span class="line">        b -= learning_rate * db</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:  <span class="comment"># 每1000次打印一次</span></span><br><span class="line">            cost = cost_function(m, b)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;迭代 <span class="subst">&#123;i&#125;</span>: m = <span class="subst">&#123;m:<span class="number">.4</span>f&#125;</span>, b = <span class="subst">&#123;b:<span class="number">.4</span>f&#125;</span>, 成本 = <span class="subst">&#123;cost:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> m, b</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数设置</span></span><br><span class="line">m_init, b_init = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line">num_iterations = <span class="number">800000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行梯度下降</span></span><br><span class="line">m_opt, b_opt = gradient_descent(m_init, b_init, learning_rate, num_iterations)</span><br><span class="line">cost_opt = cost_function(m_opt, b_opt)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n梯度下降结果：&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;最优直线: y = <span class="subst">&#123;m_opt:<span class="number">.4</span>f&#125;</span>x + <span class="subst">&#123;b_opt:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;最小成本: <span class="subst">&#123;cost_opt:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">D:<span class="keyword">\Anaconda</span>3<span class="keyword">\envs</span><span class="keyword">\langchain</span><span class="keyword">\python</span>.exe E:<span class="keyword">\chr</span><span class="built_in">_</span>git<span class="keyword">\speech</span><span class="built_in">_</span>dialogue<span class="built_in">_</span>demo<span class="keyword">\stream</span><span class="keyword">\second</span><span class="built_in">_</span>class<span class="keyword">\second</span><span class="built_in">_</span>.py </span><br><span class="line">迭代 0: m = 0.0420, b = 0.0200, 成本 = 35.8088</span><br><span class="line">迭代 1000: m = 1.5533, b = 0.3368, 成本 = 1.8817</span><br><span class="line">迭代 2000: m = 1.6372, b = 0.1592, 成本 = 1.8431</span><br><span class="line">迭代 3000: m = 1.7089, b = 0.0076, 成本 = 1.8149</span><br><span class="line">迭代 4000: m = 1.7716, b = -0.1245, 成本 = 1.7935</span><br><span class="line">迭代 5000: m = 1.8272, b = -0.2413, 成本 = 1.7767</span><br><span class="line">迭代 6000: m = 1.8770, b = -0.3458, 成本 = 1.7633</span><br><span class="line">迭代 7000: m = 1.9221, b = -0.4403, 成本 = 1.7523</span><br><span class="line">迭代 8000: m = 1.9633, b = -0.5265, 成本 = 1.7432</span><br><span class="line">迭代 9000: m = 2.0011, b = -0.6056, 成本 = 1.7355</span><br><span class="line">迭代 10000: m = 2.0361, b = -0.6786, 成本 = 1.7290</span><br><span class="line">迭代 11000: m = 2.0686, b = -0.7463, 成本 = 1.7233</span><br><span class="line">迭代 12000: m = 2.0989, b = -0.8095, 成本 = 1.7184</span><br><span class="line">迭代 13000: m = 2.1273, b = -0.8685, 成本 = 1.7141</span><br><span class="line">迭代 14000: m = 2.1539, b = -0.9240, 成本 = 1.7103</span><br><span class="line">迭代 15000: m = 2.1790, b = -0.9762, 成本 = 1.7070</span><br><span class="line">迭代 16000: m = 2.2028, b = -1.0255, 成本 = 1.7040</span><br><span class="line">迭代 17000: m = 2.2252, b = -1.0721, 成本 = 1.7013</span><br><span class="line">迭代 18000: m = 2.2466, b = -1.1163, 成本 = 1.6989</span><br><span class="line">迭代 19000: m = 2.2668, b = -1.1584, 成本 = 1.6967</span><br><span class="line">迭代 20000: m = 2.2862, b = -1.1984, 成本 = 1.6947</span><br><span class="line">迭代 21000: m = 2.3046, b = -1.2366, 成本 = 1.6929</span><br><span class="line">迭代 22000: m = 2.3222, b = -1.2731, 成本 = 1.6913</span><br><span class="line">迭代 23000: m = 2.3391, b = -1.3080, 成本 = 1.6898</span><br><span class="line">迭代 24000: m = 2.3553, b = -1.3414, 成本 = 1.6884</span><br><span class="line">迭代 25000: m = 2.3708, b = -1.3735, 成本 = 1.6871</span><br><span class="line">迭代 26000: m = 2.3857, b = -1.4043, 成本 = 1.6860</span><br><span class="line">迭代 27000: m = 2.4000, b = -1.4339, 成本 = 1.6849</span><br><span class="line">迭代 28000: m = 2.4138, b = -1.4624, 成本 = 1.6839</span><br><span class="line">迭代 29000: m = 2.4271, b = -1.4898, 成本 = 1.6830</span><br><span class="line">迭代 30000: m = 2.4399, b = -1.5163, 成本 = 1.6821</span><br><span class="line">迭代 31000: m = 2.4522, b = -1.5418, 成本 = 1.6813</span><br><span class="line">迭代 32000: m = 2.4642, b = -1.5665, 成本 = 1.6805</span><br><span class="line">迭代 33000: m = 2.4757, b = -1.5903, 成本 = 1.6798</span><br><span class="line">迭代 34000: m = 2.4869, b = -1.6133, 成本 = 1.6792</span><br><span class="line">迭代 35000: m = 2.4977, b = -1.6356, 成本 = 1.6786</span><br><span class="line">迭代 36000: m = 2.5082, b = -1.6572, 成本 = 1.6780</span><br><span class="line">迭代 37000: m = 2.5183, b = -1.6781, 成本 = 1.6775</span><br><span class="line">迭代 38000: m = 2.5281, b = -1.6983, 成本 = 1.6770</span><br><span class="line">迭代 39000: m = 2.5377, b = -1.7180, 成本 = 1.6765</span><br><span class="line">迭代 40000: m = 2.5469, b = -1.7371, 成本 = 1.6760</span><br><span class="line">迭代 41000: m = 2.5559, b = -1.7556, 成本 = 1.6756</span><br><span class="line">迭代 42000: m = 2.5647, b = -1.7736, 成本 = 1.6752</span><br><span class="line">迭代 43000: m = 2.5731, b = -1.7911, 成本 = 1.6748</span><br><span class="line">迭代 44000: m = 2.5814, b = -1.8081, 成本 = 1.6745</span><br><span class="line">迭代 45000: m = 2.5894, b = -1.8246, 成本 = 1.6741</span><br><span class="line">迭代 46000: m = 2.5973, b = -1.8407, 成本 = 1.6738</span><br><span class="line">迭代 47000: m = 2.6049, b = -1.8563, 成本 = 1.6735</span><br><span class="line">迭代 48000: m = 2.6123, b = -1.8716, 成本 = 1.6732</span><br><span class="line">迭代 49000: m = 2.6195, b = -1.8865, 成本 = 1.6729</span><br><span class="line">迭代 50000: m = 2.6265, b = -1.9009, 成本 = 1.6727</span><br><span class="line">迭代 51000: m = 2.6334, b = -1.9150, 成本 = 1.6724</span><br><span class="line">迭代 52000: m = 2.6401, b = -1.9288, 成本 = 1.6722</span><br><span class="line">迭代 53000: m = 2.6466, b = -1.9422, 成本 = 1.6720</span><br><span class="line">迭代 54000: m = 2.6530, b = -1.9553, 成本 = 1.6718</span><br><span class="line">迭代 55000: m = 2.6592, b = -1.9681, 成本 = 1.6716</span><br><span class="line">迭代 56000: m = 2.6653, b = -1.9805, 成本 = 1.6714</span><br><span class="line">迭代 57000: m = 2.6712, b = -1.9927, 成本 = 1.6712</span><br><span class="line">迭代 58000: m = 2.6770, b = -2.0046, 成本 = 1.6710</span><br><span class="line">迭代 59000: m = 2.6826, b = -2.0162, 成本 = 1.6709</span><br><span class="line">迭代 60000: m = 2.6881, b = -2.0276, 成本 = 1.6707</span><br><span class="line">迭代 61000: m = 2.6936, b = -2.0387, 成本 = 1.6705</span><br><span class="line">迭代 62000: m = 2.6988, b = -2.0495, 成本 = 1.6704</span><br><span class="line">迭代 63000: m = 2.7040, b = -2.0601, 成本 = 1.6703</span><br><span class="line">迭代 64000: m = 2.7090, b = -2.0705, 成本 = 1.6701</span><br><span class="line">迭代 65000: m = 2.7140, b = -2.0806, 成本 = 1.6700</span><br><span class="line">迭代 66000: m = 2.7188, b = -2.0906, 成本 = 1.6699</span><br><span class="line">迭代 67000: m = 2.7235, b = -2.1003, 成本 = 1.6698</span><br><span class="line">迭代 68000: m = 2.7282, b = -2.1098, 成本 = 1.6696</span><br><span class="line">迭代 69000: m = 2.7327, b = -2.1191, 成本 = 1.6695</span><br><span class="line">迭代 70000: m = 2.7371, b = -2.1282, 成本 = 1.6694</span><br><span class="line">迭代 71000: m = 2.7415, b = -2.1371, 成本 = 1.6693</span><br><span class="line">迭代 72000: m = 2.7457, b = -2.1459, 成本 = 1.6692</span><br><span class="line">迭代 73000: m = 2.7499, b = -2.1544, 成本 = 1.6692</span><br><span class="line">迭代 74000: m = 2.7540, b = -2.1628, 成本 = 1.6691</span><br><span class="line">迭代 75000: m = 2.7580, b = -2.1710, 成本 = 1.6690</span><br><span class="line">迭代 76000: m = 2.7619, b = -2.1791, 成本 = 1.6689</span><br><span class="line">迭代 77000: m = 2.7658, b = -2.1870, 成本 = 1.6688</span><br><span class="line">迭代 78000: m = 2.7695, b = -2.1947, 成本 = 1.6688</span><br><span class="line">迭代 79000: m = 2.7732, b = -2.2023, 成本 = 1.6687</span><br><span class="line">迭代 80000: m = 2.7769, b = -2.2097, 成本 = 1.6686</span><br><span class="line">迭代 81000: m = 2.7804, b = -2.2170, 成本 = 1.6685</span><br><span class="line">迭代 82000: m = 2.7839, b = -2.2242, 成本 = 1.6685</span><br><span class="line">迭代 83000: m = 2.7873, b = -2.2312, 成本 = 1.6684</span><br><span class="line">迭代 84000: m = 2.7907, b = -2.2381, 成本 = 1.6684</span><br><span class="line">迭代 85000: m = 2.7940, b = -2.2448, 成本 = 1.6683</span><br><span class="line">迭代 86000: m = 2.7972, b = -2.2514, 成本 = 1.6683</span><br><span class="line">迭代 87000: m = 2.8004, b = -2.2579, 成本 = 1.6682</span><br><span class="line">迭代 88000: m = 2.8035, b = -2.2643, 成本 = 1.6681</span><br><span class="line">迭代 89000: m = 2.8065, b = -2.2706, 成本 = 1.6681</span><br><span class="line">迭代 90000: m = 2.8095, b = -2.2767, 成本 = 1.6681</span><br><span class="line">迭代 91000: m = 2.8125, b = -2.2828, 成本 = 1.6680</span><br><span class="line">迭代 92000: m = 2.8154, b = -2.2887, 成本 = 1.6680</span><br><span class="line">迭代 93000: m = 2.8182, b = -2.2945, 成本 = 1.6679</span><br><span class="line">迭代 94000: m = 2.8210, b = -2.3002, 成本 = 1.6679</span><br><span class="line">迭代 95000: m = 2.8237, b = -2.3058, 成本 = 1.6678</span><br><span class="line">迭代 96000: m = 2.8264, b = -2.3113, 成本 = 1.6678</span><br><span class="line">迭代 97000: m = 2.8291, b = -2.3168, 成本 = 1.6678</span><br><span class="line">迭代 98000: m = 2.8317, b = -2.3221, 成本 = 1.6677</span><br><span class="line">迭代 99000: m = 2.8342, b = -2.3273, 成本 = 1.6677</span><br><span class="line">迭代 100000: m = 2.8367, b = -2.3324, 成本 = 1.6677</span><br><span class="line">迭代 101000: m = 2.8392, b = -2.3375, 成本 = 1.6676</span><br><span class="line">迭代 102000: m = 2.8416, b = -2.3424, 成本 = 1.6676</span><br><span class="line">迭代 103000: m = 2.8440, b = -2.3473, 成本 = 1.6676</span><br><span class="line">迭代 104000: m = 2.8463, b = -2.3521, 成本 = 1.6675</span><br><span class="line">迭代 105000: m = 2.8486, b = -2.3568, 成本 = 1.6675</span><br><span class="line">迭代 106000: m = 2.8509, b = -2.3614, 成本 = 1.6675</span><br><span class="line">迭代 107000: m = 2.8531, b = -2.3660, 成本 = 1.6675</span><br><span class="line">迭代 108000: m = 2.8553, b = -2.3704, 成本 = 1.6674</span><br><span class="line">迭代 109000: m = 2.8574, b = -2.3748, 成本 = 1.6674</span><br><span class="line">迭代 110000: m = 2.8595, b = -2.3792, 成本 = 1.6674</span><br><span class="line">迭代 111000: m = 2.8616, b = -2.3834, 成本 = 1.6674</span><br><span class="line">迭代 112000: m = 2.8636, b = -2.3876, 成本 = 1.6674</span><br><span class="line">迭代 113000: m = 2.8656, b = -2.3917, 成本 = 1.6673</span><br><span class="line">迭代 114000: m = 2.8676, b = -2.3957, 成本 = 1.6673</span><br><span class="line">迭代 115000: m = 2.8696, b = -2.3997, 成本 = 1.6673</span><br><span class="line">迭代 116000: m = 2.8715, b = -2.4036, 成本 = 1.6673</span><br><span class="line">迭代 117000: m = 2.8733, b = -2.4075, 成本 = 1.6673</span><br><span class="line">迭代 118000: m = 2.8752, b = -2.4112, 成本 = 1.6672</span><br><span class="line">迭代 119000: m = 2.8770, b = -2.4150, 成本 = 1.6672</span><br><span class="line">迭代 120000: m = 2.8788, b = -2.4186, 成本 = 1.6672</span><br><span class="line">迭代 121000: m = 2.8805, b = -2.4222, 成本 = 1.6672</span><br><span class="line">迭代 122000: m = 2.8823, b = -2.4258, 成本 = 1.6672</span><br><span class="line">迭代 123000: m = 2.8840, b = -2.4293, 成本 = 1.6672</span><br><span class="line">迭代 124000: m = 2.8857, b = -2.4327, 成本 = 1.6671</span><br><span class="line">迭代 125000: m = 2.8873, b = -2.4361, 成本 = 1.6671</span><br><span class="line">迭代 126000: m = 2.8889, b = -2.4394, 成本 = 1.6671</span><br><span class="line">迭代 127000: m = 2.8905, b = -2.4427, 成本 = 1.6671</span><br><span class="line">迭代 128000: m = 2.8921, b = -2.4459, 成本 = 1.6671</span><br><span class="line">迭代 129000: m = 2.8936, b = -2.4490, 成本 = 1.6671</span><br><span class="line">迭代 130000: m = 2.8952, b = -2.4522, 成本 = 1.6671</span><br><span class="line">迭代 131000: m = 2.8967, b = -2.4552, 成本 = 1.6671</span><br><span class="line">迭代 132000: m = 2.8981, b = -2.4582, 成本 = 1.6670</span><br><span class="line">迭代 133000: m = 2.8996, b = -2.4612, 成本 = 1.6670</span><br><span class="line">迭代 134000: m = 2.9010, b = -2.4641, 成本 = 1.6670</span><br><span class="line">迭代 135000: m = 2.9024, b = -2.4670, 成本 = 1.6670</span><br><span class="line">迭代 136000: m = 2.9038, b = -2.4699, 成本 = 1.6670</span><br><span class="line">迭代 137000: m = 2.9052, b = -2.4727, 成本 = 1.6670</span><br><span class="line">迭代 138000: m = 2.9065, b = -2.4754, 成本 = 1.6670</span><br><span class="line">迭代 139000: m = 2.9078, b = -2.4781, 成本 = 1.6670</span><br><span class="line">迭代 140000: m = 2.9091, b = -2.4808, 成本 = 1.6670</span><br><span class="line">迭代 141000: m = 2.9104, b = -2.4834, 成本 = 1.6670</span><br><span class="line">迭代 142000: m = 2.9117, b = -2.4860, 成本 = 1.6669</span><br><span class="line">迭代 143000: m = 2.9129, b = -2.4885, 成本 = 1.6669</span><br><span class="line">迭代 144000: m = 2.9142, b = -2.4910, 成本 = 1.6669</span><br><span class="line">迭代 145000: m = 2.9154, b = -2.4935, 成本 = 1.6669</span><br><span class="line">迭代 146000: m = 2.9165, b = -2.4959, 成本 = 1.6669</span><br><span class="line">迭代 147000: m = 2.9177, b = -2.4983, 成本 = 1.6669</span><br><span class="line">迭代 148000: m = 2.9189, b = -2.5007, 成本 = 1.6669</span><br><span class="line">迭代 149000: m = 2.9200, b = -2.5030, 成本 = 1.6669</span><br><span class="line">迭代 150000: m = 2.9211, b = -2.5053, 成本 = 1.6669</span><br><span class="line">迭代 151000: m = 2.9222, b = -2.5076, 成本 = 1.6669</span><br><span class="line">迭代 152000: m = 2.9233, b = -2.5098, 成本 = 1.6669</span><br><span class="line">迭代 153000: m = 2.9244, b = -2.5120, 成本 = 1.6669</span><br><span class="line">迭代 154000: m = 2.9254, b = -2.5141, 成本 = 1.6669</span><br><span class="line">迭代 155000: m = 2.9265, b = -2.5162, 成本 = 1.6669</span><br><span class="line">迭代 156000: m = 2.9275, b = -2.5183, 成本 = 1.6669</span><br><span class="line">迭代 157000: m = 2.9285, b = -2.5204, 成本 = 1.6668</span><br><span class="line">迭代 158000: m = 2.9295, b = -2.5224, 成本 = 1.6668</span><br><span class="line">迭代 159000: m = 2.9305, b = -2.5244, 成本 = 1.6668</span><br><span class="line">迭代 160000: m = 2.9314, b = -2.5264, 成本 = 1.6668</span><br><span class="line">迭代 161000: m = 2.9324, b = -2.5283, 成本 = 1.6668</span><br><span class="line">迭代 162000: m = 2.9333, b = -2.5303, 成本 = 1.6668</span><br><span class="line">迭代 163000: m = 2.9342, b = -2.5321, 成本 = 1.6668</span><br><span class="line">迭代 164000: m = 2.9351, b = -2.5340, 成本 = 1.6668</span><br><span class="line">迭代 165000: m = 2.9360, b = -2.5358, 成本 = 1.6668</span><br><span class="line">迭代 166000: m = 2.9369, b = -2.5376, 成本 = 1.6668</span><br><span class="line">迭代 167000: m = 2.9378, b = -2.5394, 成本 = 1.6668</span><br><span class="line">迭代 168000: m = 2.9386, b = -2.5412, 成本 = 1.6668</span><br><span class="line">迭代 169000: m = 2.9395, b = -2.5429, 成本 = 1.6668</span><br><span class="line">迭代 170000: m = 2.9403, b = -2.5446, 成本 = 1.6668</span><br><span class="line">迭代 171000: m = 2.9411, b = -2.5463, 成本 = 1.6668</span><br><span class="line">迭代 172000: m = 2.9419, b = -2.5479, 成本 = 1.6668</span><br><span class="line">迭代 173000: m = 2.9427, b = -2.5495, 成本 = 1.6668</span><br><span class="line">迭代 174000: m = 2.9435, b = -2.5511, 成本 = 1.6668</span><br><span class="line">迭代 175000: m = 2.9443, b = -2.5527, 成本 = 1.6668</span><br><span class="line">迭代 176000: m = 2.9451, b = -2.5543, 成本 = 1.6668</span><br><span class="line">迭代 177000: m = 2.9458, b = -2.5558, 成本 = 1.6668</span><br><span class="line">迭代 178000: m = 2.9465, b = -2.5573, 成本 = 1.6668</span><br><span class="line">迭代 179000: m = 2.9473, b = -2.5588, 成本 = 1.6668</span><br><span class="line">迭代 180000: m = 2.9480, b = -2.5603, 成本 = 1.6668</span><br><span class="line">迭代 181000: m = 2.9487, b = -2.5617, 成本 = 1.6668</span><br><span class="line">迭代 182000: m = 2.9494, b = -2.5632, 成本 = 1.6668</span><br><span class="line">迭代 183000: m = 2.9501, b = -2.5646, 成本 = 1.6668</span><br><span class="line">迭代 184000: m = 2.9508, b = -2.5660, 成本 = 1.6668</span><br><span class="line">迭代 185000: m = 2.9514, b = -2.5673, 成本 = 1.6667</span><br><span class="line">迭代 186000: m = 2.9521, b = -2.5687, 成本 = 1.6667</span><br><span class="line">迭代 187000: m = 2.9527, b = -2.5700, 成本 = 1.6667</span><br><span class="line">迭代 188000: m = 2.9534, b = -2.5713, 成本 = 1.6667</span><br><span class="line">迭代 189000: m = 2.9540, b = -2.5726, 成本 = 1.6667</span><br><span class="line">迭代 190000: m = 2.9546, b = -2.5739, 成本 = 1.6667</span><br><span class="line">迭代 191000: m = 2.9553, b = -2.5752, 成本 = 1.6667</span><br><span class="line">迭代 192000: m = 2.9559, b = -2.5764, 成本 = 1.6667</span><br><span class="line">迭代 193000: m = 2.9565, b = -2.5776, 成本 = 1.6667</span><br><span class="line">迭代 194000: m = 2.9571, b = -2.5788, 成本 = 1.6667</span><br><span class="line">迭代 195000: m = 2.9576, b = -2.5800, 成本 = 1.6667</span><br><span class="line">迭代 196000: m = 2.9582, b = -2.5812, 成本 = 1.6667</span><br><span class="line">迭代 197000: m = 2.9588, b = -2.5823, 成本 = 1.6667</span><br><span class="line">迭代 198000: m = 2.9593, b = -2.5835, 成本 = 1.6667</span><br><span class="line">迭代 199000: m = 2.9599, b = -2.5846, 成本 = 1.6667</span><br><span class="line">迭代 200000: m = 2.9604, b = -2.5857, 成本 = 1.6667</span><br><span class="line">迭代 201000: m = 2.9610, b = -2.5868, 成本 = 1.6667</span><br><span class="line">迭代 202000: m = 2.9615, b = -2.5879, 成本 = 1.6667</span><br><span class="line">迭代 203000: m = 2.9620, b = -2.5889, 成本 = 1.6667</span><br><span class="line">迭代 204000: m = 2.9625, b = -2.5900, 成本 = 1.6667</span><br><span class="line">迭代 205000: m = 2.9630, b = -2.5910, 成本 = 1.6667</span><br><span class="line">迭代 206000: m = 2.9635, b = -2.5920, 成本 = 1.6667</span><br><span class="line">迭代 207000: m = 2.9640, b = -2.5930, 成本 = 1.6667</span><br><span class="line">迭代 208000: m = 2.9645, b = -2.5940, 成本 = 1.6667</span><br><span class="line">迭代 209000: m = 2.9650, b = -2.5950, 成本 = 1.6667</span><br><span class="line">迭代 210000: m = 2.9654, b = -2.5960, 成本 = 1.6667</span><br><span class="line">迭代 211000: m = 2.9659, b = -2.5969, 成本 = 1.6667</span><br><span class="line">迭代 212000: m = 2.9664, b = -2.5979, 成本 = 1.6667</span><br><span class="line">迭代 213000: m = 2.9668, b = -2.5988, 成本 = 1.6667</span><br><span class="line">迭代 214000: m = 2.9672, b = -2.5997, 成本 = 1.6667</span><br><span class="line">迭代 215000: m = 2.9677, b = -2.6006, 成本 = 1.6667</span><br><span class="line">迭代 216000: m = 2.9681, b = -2.6015, 成本 = 1.6667</span><br><span class="line">迭代 217000: m = 2.9685, b = -2.6023, 成本 = 1.6667</span><br><span class="line">迭代 218000: m = 2.9690, b = -2.6032, 成本 = 1.6667</span><br><span class="line">迭代 219000: m = 2.9694, b = -2.6041, 成本 = 1.6667</span><br><span class="line">迭代 220000: m = 2.9698, b = -2.6049, 成本 = 1.6667</span><br><span class="line">迭代 221000: m = 2.9702, b = -2.6057, 成本 = 1.6667</span><br><span class="line">迭代 222000: m = 2.9706, b = -2.6065, 成本 = 1.6667</span><br><span class="line">迭代 223000: m = 2.9710, b = -2.6073, 成本 = 1.6667</span><br><span class="line">迭代 224000: m = 2.9714, b = -2.6081, 成本 = 1.6667</span><br><span class="line">迭代 225000: m = 2.9718, b = -2.6089, 成本 = 1.6667</span><br><span class="line">迭代 226000: m = 2.9721, b = -2.6097, 成本 = 1.6667</span><br><span class="line">迭代 227000: m = 2.9725, b = -2.6104, 成本 = 1.6667</span><br><span class="line">迭代 228000: m = 2.9729, b = -2.6112, 成本 = 1.6667</span><br><span class="line">迭代 229000: m = 2.9732, b = -2.6119, 成本 = 1.6667</span><br><span class="line">迭代 230000: m = 2.9736, b = -2.6127, 成本 = 1.6667</span><br><span class="line">迭代 231000: m = 2.9739, b = -2.6134, 成本 = 1.6667</span><br><span class="line">迭代 232000: m = 2.9743, b = -2.6141, 成本 = 1.6667</span><br><span class="line">迭代 233000: m = 2.9746, b = -2.6148, 成本 = 1.6667</span><br><span class="line">迭代 234000: m = 2.9750, b = -2.6155, 成本 = 1.6667</span><br><span class="line">迭代 235000: m = 2.9753, b = -2.6162, 成本 = 1.6667</span><br><span class="line">迭代 236000: m = 2.9756, b = -2.6168, 成本 = 1.6667</span><br><span class="line">迭代 237000: m = 2.9760, b = -2.6175, 成本 = 1.6667</span><br><span class="line">迭代 238000: m = 2.9763, b = -2.6181, 成本 = 1.6667</span><br><span class="line">迭代 239000: m = 2.9766, b = -2.6188, 成本 = 1.6667</span><br><span class="line">迭代 240000: m = 2.9769, b = -2.6194, 成本 = 1.6667</span><br><span class="line">迭代 241000: m = 2.9772, b = -2.6201, 成本 = 1.6667</span><br><span class="line">迭代 242000: m = 2.9775, b = -2.6207, 成本 = 1.6667</span><br><span class="line">迭代 243000: m = 2.9778, b = -2.6213, 成本 = 1.6667</span><br><span class="line">迭代 244000: m = 2.9781, b = -2.6219, 成本 = 1.6667</span><br><span class="line">迭代 245000: m = 2.9784, b = -2.6225, 成本 = 1.6667</span><br><span class="line">迭代 246000: m = 2.9787, b = -2.6231, 成本 = 1.6667</span><br><span class="line">迭代 247000: m = 2.9790, b = -2.6236, 成本 = 1.6667</span><br><span class="line">迭代 248000: m = 2.9792, b = -2.6242, 成本 = 1.6667</span><br><span class="line">迭代 249000: m = 2.9795, b = -2.6248, 成本 = 1.6667</span><br><span class="line">迭代 250000: m = 2.9798, b = -2.6253, 成本 = 1.6667</span><br><span class="line">迭代 251000: m = 2.9801, b = -2.6259, 成本 = 1.6667</span><br><span class="line">迭代 252000: m = 2.9803, b = -2.6264, 成本 = 1.6667</span><br><span class="line">迭代 253000: m = 2.9806, b = -2.6270, 成本 = 1.6667</span><br><span class="line">迭代 254000: m = 2.9808, b = -2.6275, 成本 = 1.6667</span><br><span class="line">迭代 255000: m = 2.9811, b = -2.6280, 成本 = 1.6667</span><br><span class="line">迭代 256000: m = 2.9813, b = -2.6285, 成本 = 1.6667</span><br><span class="line">迭代 257000: m = 2.9816, b = -2.6290, 成本 = 1.6667</span><br><span class="line">迭代 258000: m = 2.9818, b = -2.6295, 成本 = 1.6667</span><br><span class="line">迭代 259000: m = 2.9821, b = -2.6300, 成本 = 1.6667</span><br><span class="line">迭代 260000: m = 2.9823, b = -2.6305, 成本 = 1.6667</span><br><span class="line">迭代 261000: m = 2.9825, b = -2.6310, 成本 = 1.6667</span><br><span class="line">迭代 262000: m = 2.9828, b = -2.6314, 成本 = 1.6667</span><br><span class="line">迭代 263000: m = 2.9830, b = -2.6319, 成本 = 1.6667</span><br><span class="line">迭代 264000: m = 2.9832, b = -2.6324, 成本 = 1.6667</span><br><span class="line">迭代 265000: m = 2.9834, b = -2.6328, 成本 = 1.6667</span><br><span class="line">迭代 266000: m = 2.9837, b = -2.6333, 成本 = 1.6667</span><br><span class="line">迭代 267000: m = 2.9839, b = -2.6337, 成本 = 1.6667</span><br><span class="line">迭代 268000: m = 2.9841, b = -2.6341, 成本 = 1.6667</span><br><span class="line">迭代 269000: m = 2.9843, b = -2.6346, 成本 = 1.6667</span><br><span class="line">迭代 270000: m = 2.9845, b = -2.6350, 成本 = 1.6667</span><br><span class="line">迭代 271000: m = 2.9847, b = -2.6354, 成本 = 1.6667</span><br><span class="line">迭代 272000: m = 2.9849, b = -2.6358, 成本 = 1.6667</span><br><span class="line">迭代 273000: m = 2.9851, b = -2.6362, 成本 = 1.6667</span><br><span class="line">迭代 274000: m = 2.9853, b = -2.6366, 成本 = 1.6667</span><br><span class="line">迭代 275000: m = 2.9855, b = -2.6370, 成本 = 1.6667</span><br><span class="line">迭代 276000: m = 2.9857, b = -2.6374, 成本 = 1.6667</span><br><span class="line">迭代 277000: m = 2.9859, b = -2.6378, 成本 = 1.6667</span><br><span class="line">迭代 278000: m = 2.9861, b = -2.6382, 成本 = 1.6667</span><br><span class="line">迭代 279000: m = 2.9863, b = -2.6386, 成本 = 1.6667</span><br><span class="line">迭代 280000: m = 2.9864, b = -2.6389, 成本 = 1.6667</span><br><span class="line">迭代 281000: m = 2.9866, b = -2.6393, 成本 = 1.6667</span><br><span class="line">迭代 282000: m = 2.9868, b = -2.6397, 成本 = 1.6667</span><br><span class="line">迭代 283000: m = 2.9870, b = -2.6400, 成本 = 1.6667</span><br><span class="line">迭代 284000: m = 2.9871, b = -2.6404, 成本 = 1.6667</span><br><span class="line">迭代 285000: m = 2.9873, b = -2.6407, 成本 = 1.6667</span><br><span class="line">迭代 286000: m = 2.9875, b = -2.6411, 成本 = 1.6667</span><br><span class="line">迭代 287000: m = 2.9876, b = -2.6414, 成本 = 1.6667</span><br><span class="line">迭代 288000: m = 2.9878, b = -2.6417, 成本 = 1.6667</span><br><span class="line">迭代 289000: m = 2.9880, b = -2.6421, 成本 = 1.6667</span><br><span class="line">迭代 290000: m = 2.9881, b = -2.6424, 成本 = 1.6667</span><br><span class="line">迭代 291000: m = 2.9883, b = -2.6427, 成本 = 1.6667</span><br><span class="line">迭代 292000: m = 2.9884, b = -2.6430, 成本 = 1.6667</span><br><span class="line">迭代 293000: m = 2.9886, b = -2.6433, 成本 = 1.6667</span><br><span class="line">迭代 294000: m = 2.9887, b = -2.6436, 成本 = 1.6667</span><br><span class="line">迭代 295000: m = 2.9889, b = -2.6439, 成本 = 1.6667</span><br><span class="line">迭代 296000: m = 2.9890, b = -2.6442, 成本 = 1.6667</span><br><span class="line">迭代 297000: m = 2.9892, b = -2.6445, 成本 = 1.6667</span><br><span class="line">迭代 298000: m = 2.9893, b = -2.6448, 成本 = 1.6667</span><br><span class="line">迭代 299000: m = 2.9895, b = -2.6451, 成本 = 1.6667</span><br><span class="line">迭代 300000: m = 2.9896, b = -2.6454, 成本 = 1.6667</span><br><span class="line">迭代 301000: m = 2.9897, b = -2.6457, 成本 = 1.6667</span><br><span class="line">迭代 302000: m = 2.9899, b = -2.6459, 成本 = 1.6667</span><br><span class="line">迭代 303000: m = 2.9900, b = -2.6462, 成本 = 1.6667</span><br><span class="line">迭代 304000: m = 2.9901, b = -2.6465, 成本 = 1.6667</span><br><span class="line">迭代 305000: m = 2.9903, b = -2.6467, 成本 = 1.6667</span><br><span class="line">迭代 306000: m = 2.9904, b = -2.6470, 成本 = 1.6667</span><br><span class="line">迭代 307000: m = 2.9905, b = -2.6473, 成本 = 1.6667</span><br><span class="line">迭代 308000: m = 2.9906, b = -2.6475, 成本 = 1.6667</span><br><span class="line">迭代 309000: m = 2.9908, b = -2.6478, 成本 = 1.6667</span><br><span class="line">迭代 310000: m = 2.9909, b = -2.6480, 成本 = 1.6667</span><br><span class="line">迭代 311000: m = 2.9910, b = -2.6483, 成本 = 1.6667</span><br><span class="line">迭代 312000: m = 2.9911, b = -2.6485, 成本 = 1.6667</span><br><span class="line">迭代 313000: m = 2.9912, b = -2.6487, 成本 = 1.6667</span><br><span class="line">迭代 314000: m = 2.9913, b = -2.6490, 成本 = 1.6667</span><br><span class="line">迭代 315000: m = 2.9915, b = -2.6492, 成本 = 1.6667</span><br><span class="line">迭代 316000: m = 2.9916, b = -2.6494, 成本 = 1.6667</span><br><span class="line">迭代 317000: m = 2.9917, b = -2.6497, 成本 = 1.6667</span><br><span class="line">迭代 318000: m = 2.9918, b = -2.6499, 成本 = 1.6667</span><br><span class="line">迭代 319000: m = 2.9919, b = -2.6501, 成本 = 1.6667</span><br><span class="line">迭代 320000: m = 2.9920, b = -2.6503, 成本 = 1.6667</span><br><span class="line">迭代 321000: m = 2.9921, b = -2.6505, 成本 = 1.6667</span><br><span class="line">迭代 322000: m = 2.9922, b = -2.6508, 成本 = 1.6667</span><br><span class="line">迭代 323000: m = 2.9923, b = -2.6510, 成本 = 1.6667</span><br><span class="line">迭代 324000: m = 2.9924, b = -2.6512, 成本 = 1.6667</span><br><span class="line">迭代 325000: m = 2.9925, b = -2.6514, 成本 = 1.6667</span><br><span class="line">迭代 326000: m = 2.9926, b = -2.6516, 成本 = 1.6667</span><br><span class="line">迭代 327000: m = 2.9927, b = -2.6518, 成本 = 1.6667</span><br><span class="line">迭代 328000: m = 2.9928, b = -2.6520, 成本 = 1.6667</span><br><span class="line">迭代 329000: m = 2.9929, b = -2.6522, 成本 = 1.6667</span><br><span class="line">迭代 330000: m = 2.9930, b = -2.6523, 成本 = 1.6667</span><br><span class="line">迭代 331000: m = 2.9931, b = -2.6525, 成本 = 1.6667</span><br><span class="line">迭代 332000: m = 2.9932, b = -2.6527, 成本 = 1.6667</span><br><span class="line">迭代 333000: m = 2.9933, b = -2.6529, 成本 = 1.6667</span><br><span class="line">迭代 334000: m = 2.9934, b = -2.6531, 成本 = 1.6667</span><br><span class="line">迭代 335000: m = 2.9934, b = -2.6533, 成本 = 1.6667</span><br><span class="line">迭代 336000: m = 2.9935, b = -2.6534, 成本 = 1.6667</span><br><span class="line">迭代 337000: m = 2.9936, b = -2.6536, 成本 = 1.6667</span><br><span class="line">迭代 338000: m = 2.9937, b = -2.6538, 成本 = 1.6667</span><br><span class="line">迭代 339000: m = 2.9938, b = -2.6539, 成本 = 1.6667</span><br><span class="line">迭代 340000: m = 2.9939, b = -2.6541, 成本 = 1.6667</span><br><span class="line">迭代 341000: m = 2.9939, b = -2.6543, 成本 = 1.6667</span><br><span class="line">迭代 342000: m = 2.9940, b = -2.6544, 成本 = 1.6667</span><br><span class="line">迭代 343000: m = 2.9941, b = -2.6546, 成本 = 1.6667</span><br><span class="line">迭代 344000: m = 2.9942, b = -2.6548, 成本 = 1.6667</span><br><span class="line">迭代 345000: m = 2.9943, b = -2.6549, 成本 = 1.6667</span><br><span class="line">迭代 346000: m = 2.9943, b = -2.6551, 成本 = 1.6667</span><br><span class="line">迭代 347000: m = 2.9944, b = -2.6552, 成本 = 1.6667</span><br><span class="line">迭代 348000: m = 2.9945, b = -2.6554, 成本 = 1.6667</span><br><span class="line">迭代 349000: m = 2.9945, b = -2.6555, 成本 = 1.6667</span><br><span class="line">迭代 350000: m = 2.9946, b = -2.6557, 成本 = 1.6667</span><br><span class="line">迭代 351000: m = 2.9947, b = -2.6558, 成本 = 1.6667</span><br><span class="line">迭代 352000: m = 2.9948, b = -2.6559, 成本 = 1.6667</span><br><span class="line">迭代 353000: m = 2.9948, b = -2.6561, 成本 = 1.6667</span><br><span class="line">迭代 354000: m = 2.9949, b = -2.6562, 成本 = 1.6667</span><br><span class="line">迭代 355000: m = 2.9950, b = -2.6564, 成本 = 1.6667</span><br><span class="line">迭代 356000: m = 2.9950, b = -2.6565, 成本 = 1.6667</span><br><span class="line">迭代 357000: m = 2.9951, b = -2.6566, 成本 = 1.6667</span><br><span class="line">迭代 358000: m = 2.9952, b = -2.6568, 成本 = 1.6667</span><br><span class="line">迭代 359000: m = 2.9952, b = -2.6569, 成本 = 1.6667</span><br><span class="line">迭代 360000: m = 2.9953, b = -2.6570, 成本 = 1.6667</span><br><span class="line">迭代 361000: m = 2.9953, b = -2.6571, 成本 = 1.6667</span><br><span class="line">迭代 362000: m = 2.9954, b = -2.6573, 成本 = 1.6667</span><br><span class="line">迭代 363000: m = 2.9955, b = -2.6574, 成本 = 1.6667</span><br><span class="line">迭代 364000: m = 2.9955, b = -2.6575, 成本 = 1.6667</span><br><span class="line">迭代 365000: m = 2.9956, b = -2.6576, 成本 = 1.6667</span><br><span class="line">迭代 366000: m = 2.9956, b = -2.6578, 成本 = 1.6667</span><br><span class="line">迭代 367000: m = 2.9957, b = -2.6579, 成本 = 1.6667</span><br><span class="line">迭代 368000: m = 2.9958, b = -2.6580, 成本 = 1.6667</span><br><span class="line">迭代 369000: m = 2.9958, b = -2.6581, 成本 = 1.6667</span><br><span class="line">迭代 370000: m = 2.9959, b = -2.6582, 成本 = 1.6667</span><br><span class="line">迭代 371000: m = 2.9959, b = -2.6583, 成本 = 1.6667</span><br><span class="line">迭代 372000: m = 2.9960, b = -2.6584, 成本 = 1.6667</span><br><span class="line">迭代 373000: m = 2.9960, b = -2.6585, 成本 = 1.6667</span><br><span class="line">迭代 374000: m = 2.9961, b = -2.6586, 成本 = 1.6667</span><br><span class="line">迭代 375000: m = 2.9961, b = -2.6587, 成本 = 1.6667</span><br><span class="line">迭代 376000: m = 2.9962, b = -2.6588, 成本 = 1.6667</span><br><span class="line">迭代 377000: m = 2.9962, b = -2.6590, 成本 = 1.6667</span><br><span class="line">迭代 378000: m = 2.9963, b = -2.6591, 成本 = 1.6667</span><br><span class="line">迭代 379000: m = 2.9963, b = -2.6592, 成本 = 1.6667</span><br><span class="line">迭代 380000: m = 2.9964, b = -2.6592, 成本 = 1.6667</span><br><span class="line">迭代 381000: m = 2.9964, b = -2.6593, 成本 = 1.6667</span><br><span class="line">迭代 382000: m = 2.9965, b = -2.6594, 成本 = 1.6667</span><br><span class="line">迭代 383000: m = 2.9965, b = -2.6595, 成本 = 1.6667</span><br><span class="line">迭代 384000: m = 2.9966, b = -2.6596, 成本 = 1.6667</span><br><span class="line">迭代 385000: m = 2.9966, b = -2.6597, 成本 = 1.6667</span><br><span class="line">迭代 386000: m = 2.9966, b = -2.6598, 成本 = 1.6667</span><br><span class="line">迭代 387000: m = 2.9967, b = -2.6599, 成本 = 1.6667</span><br><span class="line">迭代 388000: m = 2.9967, b = -2.6600, 成本 = 1.6667</span><br><span class="line">迭代 389000: m = 2.9968, b = -2.6601, 成本 = 1.6667</span><br><span class="line">迭代 390000: m = 2.9968, b = -2.6602, 成本 = 1.6667</span><br><span class="line">迭代 391000: m = 2.9969, b = -2.6602, 成本 = 1.6667</span><br><span class="line">迭代 392000: m = 2.9969, b = -2.6603, 成本 = 1.6667</span><br><span class="line">迭代 393000: m = 2.9969, b = -2.6604, 成本 = 1.6667</span><br><span class="line">迭代 394000: m = 2.9970, b = -2.6605, 成本 = 1.6667</span><br><span class="line">迭代 395000: m = 2.9970, b = -2.6606, 成本 = 1.6667</span><br><span class="line">迭代 396000: m = 2.9971, b = -2.6607, 成本 = 1.6667</span><br><span class="line">迭代 397000: m = 2.9971, b = -2.6607, 成本 = 1.6667</span><br><span class="line">迭代 398000: m = 2.9971, b = -2.6608, 成本 = 1.6667</span><br><span class="line">迭代 399000: m = 2.9972, b = -2.6609, 成本 = 1.6667</span><br><span class="line">迭代 400000: m = 2.9972, b = -2.6610, 成本 = 1.6667</span><br><span class="line">迭代 401000: m = 2.9972, b = -2.6610, 成本 = 1.6667</span><br><span class="line">迭代 402000: m = 2.9973, b = -2.6611, 成本 = 1.6667</span><br><span class="line">迭代 403000: m = 2.9973, b = -2.6612, 成本 = 1.6667</span><br><span class="line">迭代 404000: m = 2.9974, b = -2.6613, 成本 = 1.6667</span><br><span class="line">迭代 405000: m = 2.9974, b = -2.6613, 成本 = 1.6667</span><br><span class="line">迭代 406000: m = 2.9974, b = -2.6614, 成本 = 1.6667</span><br><span class="line">迭代 407000: m = 2.9975, b = -2.6615, 成本 = 1.6667</span><br><span class="line">迭代 408000: m = 2.9975, b = -2.6615, 成本 = 1.6667</span><br><span class="line">迭代 409000: m = 2.9975, b = -2.6616, 成本 = 1.6667</span><br><span class="line">迭代 410000: m = 2.9976, b = -2.6617, 成本 = 1.6667</span><br><span class="line">迭代 411000: m = 2.9976, b = -2.6617, 成本 = 1.6667</span><br><span class="line">迭代 412000: m = 2.9976, b = -2.6618, 成本 = 1.6667</span><br><span class="line">迭代 413000: m = 2.9976, b = -2.6619, 成本 = 1.6667</span><br><span class="line">迭代 414000: m = 2.9977, b = -2.6619, 成本 = 1.6667</span><br><span class="line">迭代 415000: m = 2.9977, b = -2.6620, 成本 = 1.6667</span><br><span class="line">迭代 416000: m = 2.9977, b = -2.6620, 成本 = 1.6667</span><br><span class="line">迭代 417000: m = 2.9978, b = -2.6621, 成本 = 1.6667</span><br><span class="line">迭代 418000: m = 2.9978, b = -2.6622, 成本 = 1.6667</span><br><span class="line">迭代 419000: m = 2.9978, b = -2.6622, 成本 = 1.6667</span><br><span class="line">迭代 420000: m = 2.9979, b = -2.6623, 成本 = 1.6667</span><br><span class="line">迭代 421000: m = 2.9979, b = -2.6623, 成本 = 1.6667</span><br><span class="line">迭代 422000: m = 2.9979, b = -2.6624, 成本 = 1.6667</span><br><span class="line">迭代 423000: m = 2.9979, b = -2.6624, 成本 = 1.6667</span><br><span class="line">迭代 424000: m = 2.9980, b = -2.6625, 成本 = 1.6667</span><br><span class="line">迭代 425000: m = 2.9980, b = -2.6626, 成本 = 1.6667</span><br><span class="line">迭代 426000: m = 2.9980, b = -2.6626, 成本 = 1.6667</span><br><span class="line">迭代 427000: m = 2.9980, b = -2.6627, 成本 = 1.6667</span><br><span class="line">迭代 428000: m = 2.9981, b = -2.6627, 成本 = 1.6667</span><br><span class="line">迭代 429000: m = 2.9981, b = -2.6628, 成本 = 1.6667</span><br><span class="line">迭代 430000: m = 2.9981, b = -2.6628, 成本 = 1.6667</span><br><span class="line">迭代 431000: m = 2.9981, b = -2.6629, 成本 = 1.6667</span><br><span class="line">迭代 432000: m = 2.9982, b = -2.6629, 成本 = 1.6667</span><br><span class="line">迭代 433000: m = 2.9982, b = -2.6630, 成本 = 1.6667</span><br><span class="line">迭代 434000: m = 2.9982, b = -2.6630, 成本 = 1.6667</span><br><span class="line">迭代 435000: m = 2.9982, b = -2.6631, 成本 = 1.6667</span><br><span class="line">迭代 436000: m = 2.9983, b = -2.6631, 成本 = 1.6667</span><br><span class="line">迭代 437000: m = 2.9983, b = -2.6632, 成本 = 1.6667</span><br><span class="line">迭代 438000: m = 2.9983, b = -2.6632, 成本 = 1.6667</span><br><span class="line">迭代 439000: m = 2.9983, b = -2.6632, 成本 = 1.6667</span><br><span class="line">迭代 440000: m = 2.9983, b = -2.6633, 成本 = 1.6667</span><br><span class="line">迭代 441000: m = 2.9984, b = -2.6633, 成本 = 1.6667</span><br><span class="line">迭代 442000: m = 2.9984, b = -2.6634, 成本 = 1.6667</span><br><span class="line">迭代 443000: m = 2.9984, b = -2.6634, 成本 = 1.6667</span><br><span class="line">迭代 444000: m = 2.9984, b = -2.6635, 成本 = 1.6667</span><br><span class="line">迭代 445000: m = 2.9985, b = -2.6635, 成本 = 1.6667</span><br><span class="line">迭代 446000: m = 2.9985, b = -2.6635, 成本 = 1.6667</span><br><span class="line">迭代 447000: m = 2.9985, b = -2.6636, 成本 = 1.6667</span><br><span class="line">迭代 448000: m = 2.9985, b = -2.6636, 成本 = 1.6667</span><br><span class="line">迭代 449000: m = 2.9985, b = -2.6637, 成本 = 1.6667</span><br><span class="line">迭代 450000: m = 2.9986, b = -2.6637, 成本 = 1.6667</span><br><span class="line">迭代 451000: m = 2.9986, b = -2.6637, 成本 = 1.6667</span><br><span class="line">迭代 452000: m = 2.9986, b = -2.6638, 成本 = 1.6667</span><br><span class="line">迭代 453000: m = 2.9986, b = -2.6638, 成本 = 1.6667</span><br><span class="line">迭代 454000: m = 2.9986, b = -2.6639, 成本 = 1.6667</span><br><span class="line">迭代 455000: m = 2.9986, b = -2.6639, 成本 = 1.6667</span><br><span class="line">迭代 456000: m = 2.9987, b = -2.6639, 成本 = 1.6667</span><br><span class="line">迭代 457000: m = 2.9987, b = -2.6640, 成本 = 1.6667</span><br><span class="line">迭代 458000: m = 2.9987, b = -2.6640, 成本 = 1.6667</span><br><span class="line">迭代 459000: m = 2.9987, b = -2.6640, 成本 = 1.6667</span><br><span class="line">迭代 460000: m = 2.9987, b = -2.6641, 成本 = 1.6667</span><br><span class="line">迭代 461000: m = 2.9987, b = -2.6641, 成本 = 1.6667</span><br><span class="line">迭代 462000: m = 2.9988, b = -2.6641, 成本 = 1.6667</span><br><span class="line">迭代 463000: m = 2.9988, b = -2.6642, 成本 = 1.6667</span><br><span class="line">迭代 464000: m = 2.9988, b = -2.6642, 成本 = 1.6667</span><br><span class="line">迭代 465000: m = 2.9988, b = -2.6642, 成本 = 1.6667</span><br><span class="line">迭代 466000: m = 2.9988, b = -2.6643, 成本 = 1.6667</span><br><span class="line">迭代 467000: m = 2.9988, b = -2.6643, 成本 = 1.6667</span><br><span class="line">迭代 468000: m = 2.9989, b = -2.6643, 成本 = 1.6667</span><br><span class="line">迭代 469000: m = 2.9989, b = -2.6644, 成本 = 1.6667</span><br><span class="line">迭代 470000: m = 2.9989, b = -2.6644, 成本 = 1.6667</span><br><span class="line">迭代 471000: m = 2.9989, b = -2.6644, 成本 = 1.6667</span><br><span class="line">迭代 472000: m = 2.9989, b = -2.6644, 成本 = 1.6667</span><br><span class="line">迭代 473000: m = 2.9989, b = -2.6645, 成本 = 1.6667</span><br><span class="line">迭代 474000: m = 2.9989, b = -2.6645, 成本 = 1.6667</span><br><span class="line">迭代 475000: m = 2.9990, b = -2.6645, 成本 = 1.6667</span><br><span class="line">迭代 476000: m = 2.9990, b = -2.6646, 成本 = 1.6667</span><br><span class="line">迭代 477000: m = 2.9990, b = -2.6646, 成本 = 1.6667</span><br><span class="line">迭代 478000: m = 2.9990, b = -2.6646, 成本 = 1.6667</span><br><span class="line">迭代 479000: m = 2.9990, b = -2.6646, 成本 = 1.6667</span><br><span class="line">迭代 480000: m = 2.9990, b = -2.6647, 成本 = 1.6667</span><br><span class="line">迭代 481000: m = 2.9990, b = -2.6647, 成本 = 1.6667</span><br><span class="line">迭代 482000: m = 2.9990, b = -2.6647, 成本 = 1.6667</span><br><span class="line">迭代 483000: m = 2.9991, b = -2.6647, 成本 = 1.6667</span><br><span class="line">迭代 484000: m = 2.9991, b = -2.6648, 成本 = 1.6667</span><br><span class="line">迭代 485000: m = 2.9991, b = -2.6648, 成本 = 1.6667</span><br><span class="line">迭代 486000: m = 2.9991, b = -2.6648, 成本 = 1.6667</span><br><span class="line">迭代 487000: m = 2.9991, b = -2.6648, 成本 = 1.6667</span><br><span class="line">迭代 488000: m = 2.9991, b = -2.6649, 成本 = 1.6667</span><br><span class="line">迭代 489000: m = 2.9991, b = -2.6649, 成本 = 1.6667</span><br><span class="line">迭代 490000: m = 2.9991, b = -2.6649, 成本 = 1.6667</span><br><span class="line">迭代 491000: m = 2.9992, b = -2.6649, 成本 = 1.6667</span><br><span class="line">迭代 492000: m = 2.9992, b = -2.6650, 成本 = 1.6667</span><br><span class="line">迭代 493000: m = 2.9992, b = -2.6650, 成本 = 1.6667</span><br><span class="line">迭代 494000: m = 2.9992, b = -2.6650, 成本 = 1.6667</span><br><span class="line">迭代 495000: m = 2.9992, b = -2.6650, 成本 = 1.6667</span><br><span class="line">迭代 496000: m = 2.9992, b = -2.6650, 成本 = 1.6667</span><br><span class="line">迭代 497000: m = 2.9992, b = -2.6651, 成本 = 1.6667</span><br><span class="line">迭代 498000: m = 2.9992, b = -2.6651, 成本 = 1.6667</span><br><span class="line">迭代 499000: m = 2.9992, b = -2.6651, 成本 = 1.6667</span><br><span class="line">迭代 500000: m = 2.9992, b = -2.6651, 成本 = 1.6667</span><br><span class="line">迭代 501000: m = 2.9993, b = -2.6652, 成本 = 1.6667</span><br><span class="line">迭代 502000: m = 2.9993, b = -2.6652, 成本 = 1.6667</span><br><span class="line">迭代 503000: m = 2.9993, b = -2.6652, 成本 = 1.6667</span><br><span class="line">迭代 504000: m = 2.9993, b = -2.6652, 成本 = 1.6667</span><br><span class="line">迭代 505000: m = 2.9993, b = -2.6652, 成本 = 1.6667</span><br><span class="line">迭代 506000: m = 2.9993, b = -2.6652, 成本 = 1.6667</span><br><span class="line">迭代 507000: m = 2.9993, b = -2.6653, 成本 = 1.6667</span><br><span class="line">迭代 508000: m = 2.9993, b = -2.6653, 成本 = 1.6667</span><br><span class="line">迭代 509000: m = 2.9993, b = -2.6653, 成本 = 1.6667</span><br><span class="line">迭代 510000: m = 2.9993, b = -2.6653, 成本 = 1.6667</span><br><span class="line">迭代 511000: m = 2.9993, b = -2.6653, 成本 = 1.6667</span><br><span class="line">迭代 512000: m = 2.9994, b = -2.6654, 成本 = 1.6667</span><br><span class="line">迭代 513000: m = 2.9994, b = -2.6654, 成本 = 1.6667</span><br><span class="line">迭代 514000: m = 2.9994, b = -2.6654, 成本 = 1.6667</span><br><span class="line">迭代 515000: m = 2.9994, b = -2.6654, 成本 = 1.6667</span><br><span class="line">迭代 516000: m = 2.9994, b = -2.6654, 成本 = 1.6667</span><br><span class="line">迭代 517000: m = 2.9994, b = -2.6654, 成本 = 1.6667</span><br><span class="line">迭代 518000: m = 2.9994, b = -2.6655, 成本 = 1.6667</span><br><span class="line">迭代 519000: m = 2.9994, b = -2.6655, 成本 = 1.6667</span><br><span class="line">迭代 520000: m = 2.9994, b = -2.6655, 成本 = 1.6667</span><br><span class="line">迭代 521000: m = 2.9994, b = -2.6655, 成本 = 1.6667</span><br><span class="line">迭代 522000: m = 2.9994, b = -2.6655, 成本 = 1.6667</span><br><span class="line">迭代 523000: m = 2.9994, b = -2.6655, 成本 = 1.6667</span><br><span class="line">迭代 524000: m = 2.9995, b = -2.6655, 成本 = 1.6667</span><br><span class="line">迭代 525000: m = 2.9995, b = -2.6656, 成本 = 1.6667</span><br><span class="line">迭代 526000: m = 2.9995, b = -2.6656, 成本 = 1.6667</span><br><span class="line">迭代 527000: m = 2.9995, b = -2.6656, 成本 = 1.6667</span><br><span class="line">迭代 528000: m = 2.9995, b = -2.6656, 成本 = 1.6667</span><br><span class="line">迭代 529000: m = 2.9995, b = -2.6656, 成本 = 1.6667</span><br><span class="line">迭代 530000: m = 2.9995, b = -2.6656, 成本 = 1.6667</span><br><span class="line">迭代 531000: m = 2.9995, b = -2.6656, 成本 = 1.6667</span><br><span class="line">迭代 532000: m = 2.9995, b = -2.6657, 成本 = 1.6667</span><br><span class="line">迭代 533000: m = 2.9995, b = -2.6657, 成本 = 1.6667</span><br><span class="line">迭代 534000: m = 2.9995, b = -2.6657, 成本 = 1.6667</span><br><span class="line">迭代 535000: m = 2.9995, b = -2.6657, 成本 = 1.6667</span><br><span class="line">迭代 536000: m = 2.9995, b = -2.6657, 成本 = 1.6667</span><br><span class="line">迭代 537000: m = 2.9995, b = -2.6657, 成本 = 1.6667</span><br><span class="line">迭代 538000: m = 2.9995, b = -2.6657, 成本 = 1.6667</span><br><span class="line">迭代 539000: m = 2.9995, b = -2.6657, 成本 = 1.6667</span><br><span class="line">迭代 540000: m = 2.9996, b = -2.6658, 成本 = 1.6667</span><br><span class="line">迭代 541000: m = 2.9996, b = -2.6658, 成本 = 1.6667</span><br><span class="line">迭代 542000: m = 2.9996, b = -2.6658, 成本 = 1.6667</span><br><span class="line">迭代 543000: m = 2.9996, b = -2.6658, 成本 = 1.6667</span><br><span class="line">迭代 544000: m = 2.9996, b = -2.6658, 成本 = 1.6667</span><br><span class="line">迭代 545000: m = 2.9996, b = -2.6658, 成本 = 1.6667</span><br><span class="line">迭代 546000: m = 2.9996, b = -2.6658, 成本 = 1.6667</span><br><span class="line">迭代 547000: m = 2.9996, b = -2.6658, 成本 = 1.6667</span><br><span class="line">迭代 548000: m = 2.9996, b = -2.6658, 成本 = 1.6667</span><br><span class="line">迭代 549000: m = 2.9996, b = -2.6659, 成本 = 1.6667</span><br><span class="line">迭代 550000: m = 2.9996, b = -2.6659, 成本 = 1.6667</span><br><span class="line">迭代 551000: m = 2.9996, b = -2.6659, 成本 = 1.6667</span><br><span class="line">迭代 552000: m = 2.9996, b = -2.6659, 成本 = 1.6667</span><br><span class="line">迭代 553000: m = 2.9996, b = -2.6659, 成本 = 1.6667</span><br><span class="line">迭代 554000: m = 2.9996, b = -2.6659, 成本 = 1.6667</span><br><span class="line">迭代 555000: m = 2.9996, b = -2.6659, 成本 = 1.6667</span><br><span class="line">迭代 556000: m = 2.9996, b = -2.6659, 成本 = 1.6667</span><br><span class="line">迭代 557000: m = 2.9996, b = -2.6659, 成本 = 1.6667</span><br><span class="line">迭代 558000: m = 2.9996, b = -2.6659, 成本 = 1.6667</span><br><span class="line">迭代 559000: m = 2.9997, b = -2.6660, 成本 = 1.6667</span><br><span class="line">迭代 560000: m = 2.9997, b = -2.6660, 成本 = 1.6667</span><br><span class="line">迭代 561000: m = 2.9997, b = -2.6660, 成本 = 1.6667</span><br><span class="line">迭代 562000: m = 2.9997, b = -2.6660, 成本 = 1.6667</span><br><span class="line">迭代 563000: m = 2.9997, b = -2.6660, 成本 = 1.6667</span><br><span class="line">迭代 564000: m = 2.9997, b = -2.6660, 成本 = 1.6667</span><br><span class="line">迭代 565000: m = 2.9997, b = -2.6660, 成本 = 1.6667</span><br><span class="line">迭代 566000: m = 2.9997, b = -2.6660, 成本 = 1.6667</span><br><span class="line">迭代 567000: m = 2.9997, b = -2.6660, 成本 = 1.6667</span><br><span class="line">迭代 568000: m = 2.9997, b = -2.6660, 成本 = 1.6667</span><br><span class="line">迭代 569000: m = 2.9997, b = -2.6660, 成本 = 1.6667</span><br><span class="line">迭代 570000: m = 2.9997, b = -2.6661, 成本 = 1.6667</span><br><span class="line">迭代 571000: m = 2.9997, b = -2.6661, 成本 = 1.6667</span><br><span class="line">迭代 572000: m = 2.9997, b = -2.6661, 成本 = 1.6667</span><br><span class="line">迭代 573000: m = 2.9997, b = -2.6661, 成本 = 1.6667</span><br><span class="line">迭代 574000: m = 2.9997, b = -2.6661, 成本 = 1.6667</span><br><span class="line">迭代 575000: m = 2.9997, b = -2.6661, 成本 = 1.6667</span><br><span class="line">迭代 576000: m = 2.9997, b = -2.6661, 成本 = 1.6667</span><br><span class="line">迭代 577000: m = 2.9997, b = -2.6661, 成本 = 1.6667</span><br><span class="line">迭代 578000: m = 2.9997, b = -2.6661, 成本 = 1.6667</span><br><span class="line">迭代 579000: m = 2.9997, b = -2.6661, 成本 = 1.6667</span><br><span class="line">迭代 580000: m = 2.9997, b = -2.6661, 成本 = 1.6667</span><br><span class="line">迭代 581000: m = 2.9997, b = -2.6661, 成本 = 1.6667</span><br><span class="line">迭代 582000: m = 2.9997, b = -2.6661, 成本 = 1.6667</span><br><span class="line">迭代 583000: m = 2.9997, b = -2.6661, 成本 = 1.6667</span><br><span class="line">迭代 584000: m = 2.9998, b = -2.6662, 成本 = 1.6667</span><br><span class="line">迭代 585000: m = 2.9998, b = -2.6662, 成本 = 1.6667</span><br><span class="line">迭代 586000: m = 2.9998, b = -2.6662, 成本 = 1.6667</span><br><span class="line">迭代 587000: m = 2.9998, b = -2.6662, 成本 = 1.6667</span><br><span class="line">迭代 588000: m = 2.9998, b = -2.6662, 成本 = 1.6667</span><br><span class="line">迭代 589000: m = 2.9998, b = -2.6662, 成本 = 1.6667</span><br><span class="line">迭代 590000: m = 2.9998, b = -2.6662, 成本 = 1.6667</span><br><span class="line">迭代 591000: m = 2.9998, b = -2.6662, 成本 = 1.6667</span><br><span class="line">迭代 592000: m = 2.9998, b = -2.6662, 成本 = 1.6667</span><br><span class="line">迭代 593000: m = 2.9998, b = -2.6662, 成本 = 1.6667</span><br><span class="line">迭代 594000: m = 2.9998, b = -2.6662, 成本 = 1.6667</span><br><span class="line">迭代 595000: m = 2.9998, b = -2.6662, 成本 = 1.6667</span><br><span class="line">迭代 596000: m = 2.9998, b = -2.6662, 成本 = 1.6667</span><br><span class="line">迭代 597000: m = 2.9998, b = -2.6662, 成本 = 1.6667</span><br><span class="line">迭代 598000: m = 2.9998, b = -2.6662, 成本 = 1.6667</span><br><span class="line">迭代 599000: m = 2.9998, b = -2.6662, 成本 = 1.6667</span><br><span class="line">迭代 600000: m = 2.9998, b = -2.6663, 成本 = 1.6667</span><br><span class="line">迭代 601000: m = 2.9998, b = -2.6663, 成本 = 1.6667</span><br><span class="line">迭代 602000: m = 2.9998, b = -2.6663, 成本 = 1.6667</span><br><span class="line">迭代 603000: m = 2.9998, b = -2.6663, 成本 = 1.6667</span><br><span class="line">迭代 604000: m = 2.9998, b = -2.6663, 成本 = 1.6667</span><br><span class="line">迭代 605000: m = 2.9998, b = -2.6663, 成本 = 1.6667</span><br><span class="line">迭代 606000: m = 2.9998, b = -2.6663, 成本 = 1.6667</span><br><span class="line">迭代 607000: m = 2.9998, b = -2.6663, 成本 = 1.6667</span><br><span class="line">迭代 608000: m = 2.9998, b = -2.6663, 成本 = 1.6667</span><br><span class="line">迭代 609000: m = 2.9998, b = -2.6663, 成本 = 1.6667</span><br><span class="line">迭代 610000: m = 2.9998, b = -2.6663, 成本 = 1.6667</span><br><span class="line">迭代 611000: m = 2.9998, b = -2.6663, 成本 = 1.6667</span><br><span class="line">迭代 612000: m = 2.9998, b = -2.6663, 成本 = 1.6667</span><br><span class="line">迭代 613000: m = 2.9998, b = -2.6663, 成本 = 1.6667</span><br><span class="line">迭代 614000: m = 2.9998, b = -2.6663, 成本 = 1.6667</span><br><span class="line">迭代 615000: m = 2.9998, b = -2.6663, 成本 = 1.6667</span><br><span class="line">迭代 616000: m = 2.9998, b = -2.6663, 成本 = 1.6667</span><br><span class="line">迭代 617000: m = 2.9998, b = -2.6663, 成本 = 1.6667</span><br><span class="line">迭代 618000: m = 2.9998, b = -2.6663, 成本 = 1.6667</span><br><span class="line">迭代 619000: m = 2.9998, b = -2.6663, 成本 = 1.6667</span><br><span class="line">迭代 620000: m = 2.9998, b = -2.6663, 成本 = 1.6667</span><br><span class="line">迭代 621000: m = 2.9998, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 622000: m = 2.9998, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 623000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 624000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 625000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 626000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 627000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 628000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 629000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 630000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 631000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 632000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 633000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 634000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 635000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 636000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 637000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 638000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 639000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 640000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 641000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 642000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 643000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 644000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 645000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 646000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 647000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 648000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 649000: m = 2.9999, b = -2.6664, 成本 = 1.6667</span><br><span class="line">迭代 650000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 651000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 652000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 653000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 654000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 655000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 656000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 657000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 658000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 659000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 660000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 661000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 662000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 663000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 664000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 665000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 666000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 667000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 668000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 669000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 670000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 671000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 672000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 673000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 674000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 675000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 676000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 677000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 678000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 679000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 680000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 681000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 682000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 683000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 684000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 685000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 686000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 687000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 688000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 689000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 690000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 691000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 692000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 693000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 694000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 695000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 696000: m = 2.9999, b = -2.6665, 成本 = 1.6667</span><br><span class="line">迭代 697000: m = 2.9999, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 698000: m = 2.9999, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 699000: m = 2.9999, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 700000: m = 2.9999, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 701000: m = 2.9999, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 702000: m = 2.9999, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 703000: m = 2.9999, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 704000: m = 2.9999, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 705000: m = 2.9999, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 706000: m = 2.9999, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 707000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 708000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 709000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 710000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 711000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 712000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 713000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 714000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 715000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 716000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 717000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 718000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 719000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 720000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 721000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 722000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 723000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 724000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 725000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 726000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 727000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 728000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 729000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 730000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 731000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 732000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 733000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 734000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 735000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 736000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line">迭代 737000: m = 3.0000, b = -2.6666, 成本 = 1.6667</span><br><span class="line"></span><br><span class="line">梯度下降结果：</span><br><span class="line">最优直线: y = 3.0000x + -2.6666</span><br><span class="line">最小成本: 1.6667</span><br><span class="line"></span><br><span class="line">进程已结束，退出代码为 0</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="第三题"><a href="#第三题" class="headerlink" title="第三题"></a>第三题</h3><img src="/2025/03/22/AI%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B%EF%BC%9A%E5%AF%BC%E8%AE%BAand%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%802/image-20250412154607650.png" class="" title="image-20250412154607650">



<p><strong>代码：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cos_taylor</span>(<span class="params">x, n_terms</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算 cos(x) 的泰勒级数近似值</span></span><br><span class="line"><span class="string">    参数：</span></span><br><span class="line"><span class="string">        x: 输入角度（弧度制）</span></span><br><span class="line"><span class="string">        n_terms: 泰勒级数的项数（k 从 0 到 n_terms-1）</span></span><br><span class="line"><span class="string">    返回：</span></span><br><span class="line"><span class="string">        泰勒级数的值</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    result = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(n_terms):</span><br><span class="line">        <span class="comment"># 计算第 k 项：(-1)^k * x^(2k) / (2k)!</span></span><br><span class="line">        term = ((-<span class="number">1</span>) ** k) * (x ** (<span class="number">2</span> * k)) / math.factorial(<span class="number">2</span> * k)</span><br><span class="line">        result += term</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试程序</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    x = <span class="built_in">float</span>(<span class="built_in">input</span>(<span class="string">&quot;请输入 x 值（弧度）：&quot;</span>))</span><br><span class="line">    n = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;请输入泰勒级数的项数：&quot;</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算泰勒级数近似值</span></span><br><span class="line">    taylor_result = cos_taylor(x, n)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 与 math.cos 比较</span></span><br><span class="line">    actual_result = math.cos(x)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;泰勒级数近似值（<span class="subst">&#123;n&#125;</span> 项）：<span class="subst">&#123;taylor_result&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;实际值 math.cos(<span class="subst">&#123;x&#125;</span>)：<span class="subst">&#123;actual_result&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;误差：<span class="subst">&#123;<span class="built_in">abs</span>(taylor_result - actual_result)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">D:<span class="keyword">\Anaconda</span>3<span class="keyword">\envs</span><span class="keyword">\langchain</span><span class="keyword">\python</span>.exe E:<span class="keyword">\chr</span><span class="built_in">_</span>git<span class="keyword">\speech</span><span class="built_in">_</span>dialogue<span class="built_in">_</span>demo<span class="keyword">\stream</span><span class="keyword">\second</span><span class="built_in">_</span>class<span class="keyword">\thi</span>.py </span><br><span class="line">请输入 x 值（弧度）：0.1</span><br><span class="line">请输入泰勒级数的项数：2</span><br><span class="line">泰勒级数近似值（2 项）：0.995</span><br><span class="line">实际值 math.cos(0.1)：0.9950041652780258</span><br><span class="line">误差：4.165278025825003e-06</span><br><span class="line"></span><br><span class="line">进程已结束，退出代码为 0</span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>AI内部导学系列</tag>
      </tags>
  </entry>
  <entry>
    <title>ASR+LLM+TTS构建智能语音对话机器人</title>
    <url>/2025/03/04/ASR-LLM-TTS%E6%9E%84%E5%BB%BA%E6%99%BA%E8%83%BD%E8%AF%AD%E9%9F%B3%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>该系列&#x2F;前置步骤包含：</p>
<ol>
<li><a href="https://caihaoran-00.github.io/2025/02/05/fastapi-request%E6%9E%84%E5%BB%BA%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BE%AE%E6%9C%8D%E5%8A%A1/">fastapi+request构建语音识别微服务</a></li>
<li><a href="https://caihaoran-00.github.io/2025/02/07/silerovadonnx%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/">silero vad onnx方式使用示例</a></li>
<li><a href="https://caihaoran-00.github.io/2025/02/11/%E8%AF%B4%E8%AF%9D%E4%BA%BA%E7%A1%AE%E8%AE%A4%E4%B9%8BCAM/">说话人确认之CAM++</a></li>
<li><a href="https://caihaoran-00.github.io/2025/02/21/cam-senseVoice%E6%9E%84%E5%BB%BA%E5%BE%AE%E6%9C%8D%E5%8A%A1/">cam++ senseVoice构建微服务</a></li>
</ol>
<p>基本上万事俱备了，完整版本</p>
<span id="more"></span>

<hr>
<h2 id="方案选择"><a href="#方案选择" class="headerlink" title="方案选择"></a>方案选择</h2><p>首先，我打算的是vad要运行在客户端，发送语音段到服务端，这里的方案选择指的是<strong>sensevoice + Qwen2.5 7b + GSV</strong>之间程序</p>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>asr</tag>
        <tag>llm</tag>
        <tag>tts</tag>
        <tag>funasr</tag>
        <tag>qwen2.5</tag>
        <tag>gsv</tag>
        <tag>gpt sovits</tag>
        <tag>sensevoice</tag>
      </tags>
  </entry>
  <entry>
    <title>AudioSet数据集介绍</title>
    <url>/2025/01/16/AudioSet%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近在找狗叫数据集，发现<a href="https://research.google.com/audioset///dataset/index.html">AuidoSet</a>数据集。这是google在2017年推出的用于<em><strong>音频事件</strong></em>研究的大规模手动注释音频事件数据集。其中包含632个音频事件类别以及从<em><strong>YouTube视频</strong></em>中提取的2,084,320个人工标记的10秒声音片段集合（527个标签），google期望通过发布AudioSet为音频事件检测提供一个通用的、符合实际规模（与现实相符）的评估任务，并为全面的声音事件词汇表提供一个起点。</p>
<hr>
<span id="more"></span>

<h2 id="本体（Ontology）"><a href="#本体（Ontology）" class="headerlink" title="本体（Ontology）"></a>本体（Ontology）</h2><p>​		AudioSet 本体是按层次结构组织的声音事件的集合。该本体涵盖了各种日常声音，从人类和动物的声音到自然和环境声音，再到音乐和其他声音。这也解释了为什么AudioSet的音频事件类别是632个，而标签个数是527，因为分层结构导致的类别比标签多。</p>
<img src="/2025/01/16/AudioSet%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/%E6%9C%AC%E4%BD%93En.jpg" class="" title="AudioSet本体顶层的两层 AudioSet本体顶层的两层">



<center>图 1: AudioSet本体顶层的两层</center>

<p>​		图1给出了AudioSet数据集本体顶层的两层分类，下一层还有更小的分类。</p>
<hr>
<h2 id="数据集介绍"><a href="#数据集介绍" class="headerlink" title="数据集介绍"></a>数据集介绍</h2><p>​		所有数据集的详细分类可在<a href="https://research.google.com/audioset///dataset/index.html">此页面</a>查询，数据集分为三个不相交的集合：平衡评估集、平衡训练集和不平衡训练集。平衡集中每个类别具有相同数量的示例，不平衡训练集包含其余（除Evaluation和Balanced train外）的带注释片段。</p>
<img src="/2025/01/16/AudioSet%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/dog.jpg" class="" title="Dog数据集的详细信息 Dog数据集的详细信息">

<center>图 2: Dog数据集的详细信息</center>

<p>​		图2给出便签中包含狗的数据集的详细信息，以Dog标签为例，可看出：<br>$$<br>totals&#x3D;Evalution+Balanced train+Unbalanced train<br>$$<br>​		注意，非平衡训练集的标签可能会很不准确，即视频的标定10秒段内并没有出现对应标签的声音事件，使用时需筛选。</p>
<h2 id="数据集下载"><a href="#数据集下载" class="headerlink" title="数据集下载"></a>数据集下载</h2><p>2017年发布的AudioSet数据集版本提供两种格式：</p>
<ol>
<li>文本（csv）文件提供描述每个片段的YouTube视频 ID、开始时间、结束时间以及一个或多个标签。</li>
<li>以 1Hz 提取的 128 维音频特征。音频特征是使用Hershey 等人描述的 VGG 启发式声学模型提取的，该模型在<a href="https://research.google.com/youtube8m/index.html">YouTube-8M</a>的初步版本上进行训练。这些特征经过 PCA 处理并量化，以与 YouTube-8M 提供的音频特征兼容。它们存储为 TensorFlow Record 文件。用于生成特征的模型可在<a href="https://github.com/tensorflow/models/tree/master/research/audioset">TensorFlow 模型 GitHub 存储库</a>中找到。</li>
</ol>
<p>我们仅关注第一种格式，csv下载链接如下：</p>
<ul>
<li>Evaluation - <a href="http://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/eval_segments.csv">eval_segments.csv</a></li>
<li>Balanced train - <a href="http://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/balanced_train_segments.csv">balanced_train_segments.csv</a></li>
<li>Unbalanced train - <a href="http://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/unbalanced_train_segments.csv">unbalanced_train_segments.csv</a></li>
</ul>
<h3 id="CSV文件格式"><a href="#CSV文件格式" class="headerlink" title="CSV文件格式"></a>CSV文件格式</h3><p>每个CSV文件都有一个三行的标题，每行以<code>#</code>开头，前两行表示创建时间和一般统计信息，本节以<code>eval_segments.csv</code>说明：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"># Segments csv created Sun Mar  <span class="number">5</span> <span class="number">10</span>:<span class="number">54</span>:<span class="number">25</span> <span class="number">2017</span></span><br><span class="line"># num_ytids=<span class="number">20371</span>, num_segs=<span class="number">20371</span>, num_unique_labels=<span class="number">527</span>, num_positive_labels=<span class="number">51804</span></span><br><span class="line"># YTID, start_seconds, end_seconds, positive_labels</span><br></pre></td></tr></table></figure>

<p>后续表格即为标头定义的列，包括视频ID（YTID），起始时间（start_seconds），结束时间（end_seconds），目标标签（positive_labels），如：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">-<span class="number">0</span>RWZT-miFs, <span class="number">420</span>.<span class="number">000</span>, <span class="number">430</span>.<span class="number">000</span>, &quot;/m/<span class="number">03</span>v3yw,/m/<span class="number">0</span>k4j&quot;</span><br></pre></td></tr></table></figure>

<p>表示<a href="https://www.youtube.com/watch?v=-0RWZT-miFs&t=420s">Youtube视频</a><code>-0RWZT-miFs</code>的10秒声音事件段开始于420秒，结束于430秒，标注人员确认这10秒内存在&#x2F;m&#x2F;03v3yw（“钥匙叮当声”）和 &#x2F;m&#x2F;0k4j（“汽车声”），关于positive_labels的具体意义，请参与<a href="https://github.com/audioset/ontology/blob/master/ontology.json">ontology.json</a>，例如：</p>
<img src="/2025/01/16/AudioSet%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/ontology.jpg" class="" title="&#x2F;m&#x2F;03v3yw本体 &#x2F;m&#x2F;03v3yw本体">

<center>图 3: /m/03v3yw本体</center>

<h3 id="YouTube视频链接格式"><a href="#YouTube视频链接格式" class="headerlink" title="YouTube视频链接格式"></a>YouTube视频链接格式</h3><p>以<code>https://www.youtube.com/watch?v=-0RWZT-miFs&amp;t=30s</code>为例，其中：</p>
<ul>
<li><code>https://www.youtube.com/watch?v=</code>是标准的视频播放链接前缀</li>
<li><code>v=</code>后面的部分是视频的唯一标识符（Video ID or YTID)，通常是11个字符，如这里的<code>-0RWZT-miFs</code></li>
<li><code>&amp;t</code>表示视频的开始时间，可选，并且s可以省略</li>
</ul>
<h3 id="YouTube视频下载"><a href="#YouTube视频下载" class="headerlink" title="YouTube视频下载"></a>YouTube视频下载</h3><p>目前（2025-1-17），下载YouTube视频的主流方式是使用<a href="https://github.com/yt-dlp/yt-dlp">yt-dlp</a>，yt-dlp 是一款功能丰富的命令行音频&#x2F;视频下载器，支持<a href="https://github.com/yt-dlp/yt-dlp/blob/master/supportedsites.md">数千个网站</a>。该项目是基于已停用的<a href="https://github.com/blackjack4494/yt-dlc">youtube-dlc</a>的 <a href="https://github.com/ytdl-org/youtube-dl">youtube-dl</a>分支.</p>
<h4 id="yt-dlp安装"><a href="#yt-dlp安装" class="headerlink" title="yt-dlp安装"></a>yt-dlp安装</h4><p>yt-dlp官方推荐使用已编译的<a href="https://github.com/yt-dlp/yt-dlp?tab=readme-ov-file#release-files">二进制</a>文件，下文介绍Win10电脑上二进制（命令行）方式和python脚本方式实现相同功能。</p>
<h5 id="二进制文件方式"><a href="#二进制文件方式" class="headerlink" title="二进制文件方式"></a>二进制文件方式</h5><ul>
<li><p>点击<a href="https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.exe">yt-dlp.exe</a>下载yt-dlp.exe</p>
</li>
<li><p><strong>ffmpeg</strong> and <strong>ffprobe</strong></p>
<p><code>yt-dlp</code>依赖<code>ffmpeg</code>和<code>ffprobe</code>，点击<a href="https://www.ffmpeg.org/">ffmpeg</a>按下述图文操作安装即可：</p>
<img src="/2025/01/16/AudioSet%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/ffmpeg1.jpg" class=""></li>
</ul>
<p>点击链接后，按上图点击顺序操作，随后下滑到release builds，点击下图所示zip压缩文件进行下载：</p>
<img src="/2025/01/16/AudioSet%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/ffmpeg2.jpg" class="">

<p>解压后得到：</p>
<img src="/2025/01/16/AudioSet%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/ffmpeg3.jpg" class="">

<p>在<code>bin</code>文件夹下可看到：</p>
<img src="/2025/01/16/AudioSet%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/ffmpeg4.jpg" class="">

<p><code>bin</code>目录下打开<code>cmd</code>，输入<code>ffmpeg</code>，可看到下图输出信息：</p>
<img src="/2025/01/16/AudioSet%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/ffmpeg5.jpg" class="">

<p>但是在其他路径下运行<code>ffmpeg</code>命令会提示：<code>&#39;ffmpeg&#39; 不是内部或外部命令，也不是可运行的程序 或批处理文件。</code>是因为我们没有把可执行文件添加到系统路径中，打开系统环境变量，将刚才的<code>bin</code>目录路径添加到用户变量或系统变量的<code>Path</code>中即可，如：</p>
<img src="/2025/01/16/AudioSet%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/ffmpeg6.jpg" class="">

<p>设置好环境变量后，新起一个<code>cmd</code>窗口，即可在任意路径调用<code>ffmpeg</code>命令。</p>
<ul>
<li><p>万事具备！开始展示！到你<code>yt-dlp.exe</code>所在的文件夹打开<code>cmd</code>，先下载个视频试试效果，运行：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">yt-dlp.exe https://www.youtube.com/watch?v=<span class="number">0</span>Wkk9iNzA9c</span><br></pre></td></tr></table></figure>

<p>这个时候如果没有魔法上网，将会一直超时重试：</p>
<img src="/2025/01/16/AudioSet%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/retry.jpg" class="">

<p>打开魔法上网，注意想在<code>cmd窗口</code>使用代理，需要如下图配置下（配置后别忘了重新开一个cmd窗口）：</p>
<img src="/2025/01/16/AudioSet%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/clash.jpg" class="">

<p>重新在<code>yt-dlp.exe</code>所在的文件夹打开<code>cmd</code>，再次运行上述命名，你将会看到：</p>
<img src="/2025/01/16/AudioSet%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/error1.jpg" class="">

<p>这是<code>yt-dlp</code>在下载指定<code>YouTube</code>视频时遇到了需要登录验证的问题，如果在你的浏览器上已经登陆了（或者登录过且Cookies没过期）<code>YouTube</code>，（以chrome谷歌浏览器举例)那么可以添加<code>--cookies-from-browser chrome</code>参数，如果没登录过，可以去登录下，如果这个方式行不通，就需要使用<code>--cookies</code>参数指定你自己导出的<code>Cookies</code>文件（下面会讲）。</p>
<p>运行：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">yt-dlp --cookies-from-browser chrome https://www.youtube.com/watch?v=<span class="number">0</span>Wkk9iNzA9c</span><br></pre></td></tr></table></figure>

<p>出现：</p>
<img src="/2025/01/16/AudioSet%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/error2.jpg" class="">

<p>关闭你的chrome浏览器，再运行上述命令，得到：</p>
<img src="/2025/01/16/AudioSet%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/error3.jpg" class="">

<p>害，只能使用插件导出<code>Cookies</code>文件了，去安装<a href="https://chromewebstore.google.com/detail/get-cookiestxt-locally/cclelndahbckbenkjhflpdbgdldlbecc">Get cookies.txt LOCALLY</a><code>Chrome</code>插件后，按顺序点击：</p>
<img src="/2025/01/16/AudioSet%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/chrome.jpg" class="">

<p>然后，打开<a href="https://www.youtube.com/">youtube</a>首页，再按顺序点击：</p>
<img src="/2025/01/16/AudioSet%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/chrome2.jpg" class="">

<p>即会下载<code>www.youtube.com_cookies.txt</code>，将其放在<code>yt-dlp.exe</code>同级目录下，运行：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">yt-dlp --cookies www.youtube.com_cookies.txt https://www.youtube.com/watch?v=<span class="number">0</span>Wkk9iNzA9c</span><br></pre></td></tr></table></figure>

<p><b>OK!</b>下载成功：</p>
<img src="/2025/01/16/AudioSet%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/down1.jpg" class="">

<p>从打印信息可看出，实际上是下载了两个东西，首先是<code>Corgi Cuteness with Puppy Growl! [0Wkk9iNzA9c].f135.mp4</code>视频文件，然后是<code>Corgi Cuteness with Puppy Growl! [0Wkk9iNzA9c].f140.m4a</code>音频文件，然后将这两个文件合并成<code>Corgi Cuteness with Puppy Growl! [0Wkk9iNzA9c].mp4</code>视频文件，最后是将两个单独的文件删除。</p>
<p>运行下面命令以：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">yt-dlp --cookies www.youtube.com_cookies.txt --list-formats https://www.youtube.com/watch?v=<span class="number">0</span>Wkk9iNzA9c</span><br></pre></td></tr></table></figure>

<p>铛铛铛铛，又出问题了：</p>
<img src="/2025/01/16/AudioSet%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/error4.jpg" class="">

<p>打开你的<code>www.youtube.com_cookies.txt</code>，搜索<code>LOGIN_INFO</code>和<code>SAPISID</code>，是不是发现没有这两个关键词，哦原来是我们在生成cookies的网页上没有做登录<code>Youtube</code>的操作，让我们重新操作下，先把已登录的<code>Youtube</code>账号退掉，再打开一个新网页登录<code>Youtube</code>账号，后续生成<code>cookies</code>的操作和之前介绍一致，再次运行上述命令：</p>
<img src="/2025/01/16/AudioSet%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/list.jpg" class="">

<p>好，我们看到一些格式信息，上面的<code>f135</code>就对应这里的<code>ID:135</code>，是<code>video only</code>，也就是不包含音频，<code>f140</code>对应<code>ID:140</code>，是<code>audio only</code>，也就是不包含视频。</p>
<p>我只需要音频，并不需要视频该怎么做呢，聪明的你可能大概想到了，通过<code>-f</code>指定<code>ID</code>：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">yt-dlp --cookies www.youtube.com_cookies.txt -f <span class="number">140</span> https://www.youtube.com/watch?v=<span class="number">0</span>Wkk9iNzA9c</span><br></pre></td></tr></table></figure>

<p>下载的音频文件为<code>Corgi Cuteness with Puppy Growl! [0Wkk9iNzA9c].m4a</code>，格式为<code>2通道</code>，<code>44100Hz</code>，如果每次下载音频都需要先查询<code>--list-formats</code>有些太麻烦了，有没有简便方法？有，通过<code>-f</code>参数指定：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">yt-dlp --cookies www.youtube.com_cookies.txt -f ba https://www.youtube.com/watch?v=<span class="number">0</span>Wkk9iNzA9c</span><br></pre></td></tr></table></figure>

<p>这里的<code>ba</code>是<code>bestaudio</code>的缩写，使用<code>bestaudio</code>效果一样，那如果我想对原始音频格式做一些修改呢？比如<code>单通道</code>，<code>32k</code>采样率，<code>16位</code>位深，通过<code>ExtractAudio:-ac 1 -ar 32000 -sample_fmt s16</code>实现如下：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">yt-dlp --cookies www.youtube.com_cookies.txt -f ba -x --audio-<span class="built_in">format</span> wav --postprocessor-args &quot;ExtractAudio:-ac <span class="number">1</span> -ar <span class="number">32000</span> -sample_fmt s16&quot; https://www.youtube.com/watch?v=<span class="number">0</span>Wkk9iNzA9c</span><br></pre></td></tr></table></figure>

<p>不写<code>FFmpegExtractAudio:</code>会出个<code>WARNING: Post-Processor arguments given without specifying name. The arguments will be given to all post-processors</code>的警告，现在我们实现了从某个<code>Youtube</code>的<code>url</code>只获取音频，并且对其进行<code>重采样</code>，那么如果想只获取某个时间段的音频，怎么办？通过<code>-ss</code>和<code>-to</code>指定：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">yt-dlp --cookies www.youtube.com_cookies.txt -f ba -x --audio-<span class="built_in">format</span> wav --postprocessor-args &quot;ExtractAudio:-ss <span class="number">00</span>:<span class="number">00</span>:<span class="number">29</span> -to <span class="number">00</span>:<span class="number">00</span>:<span class="number">38</span> -ac <span class="number">1</span> -ar <span class="number">32000</span> -sample_fmt s16&quot; https://www.youtube.com/watch?v=<span class="number">0</span>Wkk9iNzA9c</span><br></pre></td></tr></table></figure>

<p>这种方法是先下载整段音频，再对整段音频进行重采样和剪切（我看可以使用–download-sections分段下载，但是我试下来不行，后续再研究）。</p>
<p>好，还差最后一步，默认的下载文件名是<code>video title[&lt;video ID&gt;].&lt;file extension&gt;</code>，如果想更改输出的文件名，比如输出文件名格式为<code>videi ID.&lt;file extension&gt;</code>怎么办?通过<code>-o</code>参数指定：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">yt-dlp --cookies www.youtube.com_cookies.txt -f ba -x --audio-<span class="built_in">format</span> wav --postprocessor-args &quot;ExtractAudio:-ss <span class="number">00</span>:<span class="number">00</span>:<span class="number">29</span> -to <span class="number">00</span>:<span class="number">00</span>:<span class="number">38</span> -ac <span class="number">1</span> -ar <span class="number">32000</span> -sample_fmt s16&quot; -o &quot;<span class="variable">%(id)s.%</span>(ext)s&quot; https://www.youtube.com/watch?v=<span class="number">0</span>Wkk9iNzA9c</span><br></pre></td></tr></table></figure>

<p>好好好，现在实现了命令行方式从<code>Youtube</code>的指定<code>url</code>下载指定片段的音频，并进行重采样，最后重命名。</p>
</li>
</ul>
<h5 id="pip方式"><a href="#pip方式" class="headerlink" title="pip方式"></a>pip方式</h5><p>（TODO…）</p>
<hr>
<h4 id="视频下载"><a href="#视频下载" class="headerlink" title="视频下载"></a>视频下载</h4><p>前面都是准备工作，下面才是正式下载。由前文可知我们需要狗叫的<code>开始时间</code>和<code>结束时间</code>，以及<code>url</code>才能下载目标片段，由于平衡集的数量相对较少，非平衡训练集的标签质量较低，故还是需要人为筛选。先去<a href="https://github.com/audioset/ontology/blob/master/ontology.json">ontology</a>查询下与狗相关的编号标签，经查询，原版摘录：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">&quot;id&quot;: &quot;/m/<span class="number">0</span>bt9lr&quot;,</span><br><span class="line"></span><br><span class="line">&quot;name&quot;: &quot;Dog&quot;,</span><br><span class="line"></span><br><span class="line">&quot;description&quot;: &quot;Any sounds coming from the familiar domesticated canid which has been selectively bred over millennia <span class="keyword">for</span> companionship, protection, as well as <span class="keyword">for</span> superior sensory capabilities, and other useful behaviors.&quot;,</span><br><span class="line"></span><br><span class="line">&quot;child_ids&quot;: [&quot;/m/<span class="number">05</span>tny_&quot;, &quot;/m/<span class="number">07</span>r_k2n&quot;, &quot;/m/<span class="number">07</span>qf0zm&quot;, &quot;/m/<span class="number">07</span>rc7d9&quot;, &quot;/m/<span class="number">0</span>ghcn6&quot;, &quot;/t/dd00136&quot;, &quot;/m/<span class="number">07</span>srf8z&quot;],</span><br></pre></td></tr></table></figure>

<p>翻译：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">&quot;id&quot;: &quot;/m/<span class="number">0</span>bt9lr&quot;,</span><br><span class="line"></span><br><span class="line">&quot;name&quot;: &quot;Dog&quot;,</span><br><span class="line"></span><br><span class="line">&quot;描述&quot;: &quot;任何来自熟悉的家养犬的声音，这种犬在数千年的选择性繁育中被培育用于陪伴、保护，以及卓越的感官能力和其他有用的行为。&quot;,</span><br><span class="line"></span><br><span class="line">&quot;child_ids&quot;: [&quot;/m/<span class="number">05</span>tny_&quot;, &quot;/m/<span class="number">07</span>r_k2n&quot;, &quot;/m/<span class="number">07</span>qf0zm&quot;, &quot;/m/<span class="number">07</span>rc7d9&quot;, &quot;/m/<span class="number">0</span>ghcn6&quot;, &quot;/t/dd00136&quot;, &quot;/m/<span class="number">07</span>srf8z&quot;],</span><br></pre></td></tr></table></figure>

<p>可见<code>Dog</code>标签是一个上层标签，子标签介绍如下，原版摘录：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">&quot;id&quot;: &quot;/m/<span class="number">05</span>tny_&quot;,</span><br><span class="line">&quot;name&quot;: &quot;Bark&quot;,</span><br><span class="line">&quot;description&quot;: &quot;Principal communication sound produced by dogs. Often transliterated as woof, especially <span class="keyword">for</span> large dogs.&quot;</span><br><span class="line"></span><br><span class="line">&quot;id&quot;: &quot;/m/<span class="number">07</span>r_k2n&quot;,</span><br><span class="line">&quot;name&quot;: &quot;Yip&quot;,</span><br><span class="line">&quot;description&quot;: &quot;A sharp high-pitched bark or cry, typically from a miniature dog.&quot;,</span><br><span class="line"></span><br><span class="line">&quot;id&quot;: &quot;/m/<span class="number">07</span>qf0zm&quot;,</span><br><span class="line">&quot;name&quot;: &quot;Howl&quot;,</span><br><span class="line">&quot;description&quot;: &quot;The long plaintive cry of a dog, wolf, or other canidae.&quot;,</span><br><span class="line"></span><br><span class="line">&quot;id&quot;: &quot;/m/<span class="number">07</span>rc7d9&quot;,</span><br><span class="line">&quot;name&quot;: &quot;Bow-wow&quot;,</span><br><span class="line">&quot;description&quot;: &quot;Dog communication sound that is <span class="built_in">more</span> tonal and less abrupt than a classic bark.&quot;,</span><br><span class="line"></span><br><span class="line">&quot;id&quot;: &quot;/m/<span class="number">0</span>ghcn6&quot;,</span><br><span class="line">&quot;name&quot;: &quot;Growling&quot;,</span><br><span class="line">&quot;description&quot;: &quot;A low, guttural vocalization produced by animals as a warning, a sign of aggression, or to express anger.&quot;,</span><br><span class="line"></span><br><span class="line">&quot;id&quot;: &quot;/t/dd00136&quot;,</span><br><span class="line">&quot;name&quot;: &quot;Whimper (dog)&quot;,</span><br><span class="line">&quot;description&quot;: &quot;Muted dog vocalization indicating submission, fear, or pain.&quot;,</span><br><span class="line"></span><br><span class="line">&quot;id&quot;: &quot;/m/<span class="number">07</span>srf8z&quot;,</span><br><span class="line">&quot;name&quot;: &quot;Bay&quot;,</span><br><span class="line">&quot;description&quot;: &quot;The sound made by a hound on the scent.&quot;,</span><br></pre></td></tr></table></figure>

<p>翻译：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">&quot;id&quot;: &quot;/m/<span class="number">05</span>tny_&quot;,</span><br><span class="line">&quot;name&quot;: &quot;吠声&quot;,</span><br><span class="line">&quot;description&quot;: &quot;狗发出的主要交流声音，常被音译为“汪”，特别是对于大型犬。&quot;</span><br><span class="line"></span><br><span class="line">&quot;id&quot;: &quot;/m/<span class="number">07</span>r_k2n&quot;,</span><br><span class="line">&quot;name&quot;: &quot;尖叫&quot;,</span><br><span class="line">&quot;description&quot;: &quot;一种尖锐的高音吠声或叫声，通常来自迷你犬。&quot;,</span><br><span class="line"></span><br><span class="line">&quot;id&quot;: &quot;/m/<span class="number">07</span>qf0zm&quot;,</span><br><span class="line">&quot;name&quot;: &quot;嚎叫&quot;,</span><br><span class="line">&quot;description&quot;: &quot;狗、狼或其他犬科动物发出的悠长哀鸣。&quot;,</span><br><span class="line"></span><br><span class="line">&quot;id&quot;: &quot;/m/<span class="number">07</span>rc7d9&quot;,</span><br><span class="line">&quot;name&quot;: &quot;汪汪声&quot;,</span><br><span class="line">&quot;description&quot;: &quot;一种狗的交流声音，比经典的吠声更具音调感且不那么突然。&quot;,</span><br><span class="line"></span><br><span class="line">&quot;id&quot;: &quot;/m/<span class="number">0</span>ghcn6&quot;,</span><br><span class="line">&quot;name&quot;: &quot;低吼&quot;,</span><br><span class="line">&quot;description&quot;: &quot;一种低沉、喉音的发声，由动物发出以示警告、表现攻击性或表达愤怒。&quot;,</span><br><span class="line"></span><br><span class="line">&quot;id&quot;: &quot;/t/dd00136&quot;,</span><br><span class="line">&quot;name&quot;: &quot;呻吟 (dog)&quot;,</span><br><span class="line">&quot;description&quot;: &quot;低声的狗叫，表示顺从、恐惧或疼痛。&quot;,</span><br><span class="line"></span><br><span class="line">&quot;id&quot;: &quot;/m/<span class="number">07</span>srf8z&quot;,</span><br><span class="line">&quot;name&quot;: &quot;嗥声&quot;,</span><br><span class="line">&quot;description&quot;: &quot;猎犬追踪气味时发出的声音。&quot;,</span><br></pre></td></tr></table></figure>

<p>好，现在知道这些对应信息了，那怎么获取Youtube视频ID呢？两种方式：</p>
<ul>
<li><p>在这个页面直接搜，比如<code>bark</code>：</p>
<img src="/2025/01/16/AudioSet%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/bark.jpg" class="">

<p>点击进去可以看到一些有用信息：</p>
<img src="/2025/01/16/AudioSet%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/bark1.jpg" class="">

<p>再往下拉会看到一系列视频，以第一视频为例：</p>
<img src="/2025/01/16/AudioSet%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D/bark2.jpg" class="">

<p>可以看到下方有一系列标签，视频的播放位置也是人为标定的开始点，直接右键<code>复制视频的url</code>即得到了<code>url</code>，开始时间为<code>10s</code>结束时间为<code>19s</code>，但这种方式只适合获取少量音频，如果下载大量数据会极大的浪费人力。</p>
</li>
<li><p>使用上文提到的<code>csv文件</code>，配合python脚本批量下载。</p>
<p>我打算使用这个方案下载<code>Dog</code>标签的音频，实际使用时，非平衡训练集需要人为重新筛选。</p>
</li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a href="https://research.google/blog/announcing-audioset-a-dataset-for-audio-event-research/">https://research.google/blog/announcing-audioset-a-dataset-for-audio-event-research/</a></li>
<li><a href="https://research.google.com/audioset///dataset/index.html">https://research.google.com/audioset///dataset/index.html</a></li>
<li><a href="https://research.google.com/audioset/">https://research.google.com/audioset/</a></li>
<li><a href="https://research.google.com/audioset///ontology/index.html">https://research.google.com/audioset///ontology/index.html</a></li>
<li><a href="https://research.google.com/audioset///download.html">https://research.google.com/audioset///download.html</a></li>
<li><a href="https://github.com/yt-dlp/yt-dlp">https://github.com/yt-dlp/yt-dlp</a></li>
<li><a href="https://github.com/yt-dlp/yt-dlp/issues/10927">https://github.com/yt-dlp/yt-dlp/issues/10927</a></li>
<li><a href="https://www.bilibili.com/opus/976869609795747864">https://www.bilibili.com/opus/976869609795747864</a></li>
</ol>
]]></content>
      <categories>
        <category>dataset</category>
      </categories>
      <tags>
        <tag>classification</tag>
        <tag>dataset</tag>
      </tags>
  </entry>
  <entry>
    <title>CLIP安装与使用</title>
    <url>/2025/06/07/CLIP%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>久仰CLIP的大名，说是可以图搜文和文搜图，可以作为图文问答系统的模块，现在有个项目是想做个投标文件的查重系统，由于标书中有图片，对图片的查重可以使用CLIP进行查重，借这个机会捋捋CLIP的使用方式吧。</p>
<span id="more"></span>

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>来到<code>OpenAI</code>的<a href="https://github.com/openai/CLIP">CLIP代码仓库</a>，看眼About: CLIP (Contrastive Language-Image Pretraining), Predict the most relevant text snippet given an image，翻译过来就是：关于：CLIP（对比语言-图像预训练），根据图像预测最相关的文本片段，嗯对味，看眼<code>Starred 29.3k</code>，也对味，再一眼，嗯？仓库中最新的更新都是last year了？不太对。看下README，包括了介绍和框架以及安装方法和三个例子，分别是：</p>
<ul>
<li>比较一张图片与三个文本的相似度</li>
<li>0样本预测，对 CIFAR-100 数据集中第 3637 张图片做“零样本图像分类”，并输出最相似的 5 个类名及相似度百分比</li>
<li>线性探针（Linear Probe）评估法，看看 CLIP 模型能不能通过图像特征，把图片分类清楚</li>
</ul>
<p>最后是个See Also：</p>
<ul>
<li><a href="https://github.com/mlfoundations/open_clip">OpenCLIP</a>: includes larger and independently trained CLIP models up to ViT-G&#x2F;14</li>
<li><a href="https://huggingface.co/docs/transformers/model_doc/clip">Hugging Face implementation of CLIP</a>: for easier integration with the HF ecosystem</li>
</ul>
<p><strong>翻译：</strong></p>
<p>参见：</p>
<ul>
<li><a href="https://github.com/mlfoundations/open_clip">OpenCLIP</a>：包括更大、独立训练的 CLIP 模型，最高可达 ViT-G&#x2F;14</li>
<li><a href="https://huggingface.co/docs/transformers/model_doc/clip">Hugging Face 实现 CLIP</a>：更轻松地与 HF 生态系统集成</li>
</ul>
<p>打开一看，<a href="https://github.com/mlfoundations/open_clip">open_clip仓库</a>的最新更新是4 days ago，好的对味了，再来到<a href="https://huggingface.co/openai?search_models=clip">这个页面</a>，发现<code>openai/clip-vit-large-patch14</code>五千两百五十多万，好的看来三种方式都有可取之处，那让我们一个一个的来看下用法吧。</p>
<img src="/2025/06/07/CLIP%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/image-20250607183525036.png" class="" title="image-20250607183525036">

<hr>
<h3 id="1-CLIP"><a href="#1-CLIP" class="headerlink" title="1. CLIP"></a>1. CLIP</h3><p>首先看下OpenAI官方的<a href="https://github.com/openai/CLIP">CLIP库</a>，直接打开官方提供的<a href="https://colab.research.google.com/github/openai/clip/blob/master/notebooks/Interacting_with_CLIP.ipynb#scrollTo=NSSrLY185jSf">colab</a>，和README中给的例子差不多，也是</p>
<ul>
<li><p>文本和图片特征的余弦相似度</p>
<img src="/2025/06/07/CLIP%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/image-20250607184623841.png" class="" title="image-20250607184623841">
</li>
<li><p>0样本图片分类</p>
<img src="/2025/06/07/CLIP%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/image-20250607184749367.png" class="" title="image-20250607184749367"></li>
</ul>
<p><strong>但是怎么没有图片与图片间的余弦相似度计算例子？</strong></p>
<p>没有咱们就自己写一个看看，直接在这个colab环境写吧，我将使用下面的四张图片进行实验（勺子是实拍，底色不一样，猫是让ChatGpt生成的）：</p>
<img src="/2025/06/07/CLIP%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/80fcd0352873350ed4f0ec12c6165f06.jpg" class="" title="80fcd0352873350ed4f0ec12c6165f06">

<img src="/2025/06/07/CLIP%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/fd581376751d0bcd489f0e814772b16e.jpg" class="" title="fd581376751d0bcd489f0e814772b16e">

<img src="/2025/06/07/CLIP%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/09940936-15ed-48af-aee8-b616dc364233.png" class="" title="09940936-15ed-48af-aee8-b616dc364233">

<img src="/2025/06/07/CLIP%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/62dcd83a-dc9d-4afe-8b4d-9f4bc6cabc23.png" class="" title="62dcd83a-dc9d-4afe-8b4d-9f4bc6cabc23">

<p><strong>Colab代码：</strong></p>
<p><strong>安装并导入CLIP库：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!pip install ftfy regex tqdm</span><br><span class="line">!pip install git+https://github.com/openai/CLIP.git</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> clip</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"></span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">model, preprocess = clip.load(<span class="string">&quot;ViT-B/32&quot;</span>, device=device)</span><br></pre></td></tr></table></figure>

<p><strong>上传图片：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> files</span><br><span class="line">uploaded = files.upload()</span><br></pre></td></tr></table></figure>

<p><strong>加载4张图片并预处理：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">image_paths = [<span class="string">&quot;img1.jpg&quot;</span>, <span class="string">&quot;img2.jpg&quot;</span>, <span class="string">&quot;img3.jpg&quot;</span>, <span class="string">&quot;img4.jpg&quot;</span>]</span><br><span class="line">images = [preprocess(Image.<span class="built_in">open</span>(p).convert(<span class="string">&quot;RGB&quot;</span>)).unsqueeze(<span class="number">0</span>).to(device) <span class="keyword">for</span> p <span class="keyword">in</span> image_paths]</span><br></pre></td></tr></table></figure>

<p><strong>提取图像特征并归一化：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    features = [model.encode_image(img) <span class="keyword">for</span> img <span class="keyword">in</span> images]</span><br><span class="line">    features = [f / f.norm(dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>) <span class="keyword">for</span> f <span class="keyword">in</span> features]  <span class="comment"># 归一化</span></span><br></pre></td></tr></table></figure>

<p><strong>两两计算余弦相似度：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Pairwise Cosine Similarities:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> (i, feat1), (j, feat2) <span class="keyword">in</span> itertools.combinations(<span class="built_in">enumerate</span>(features), <span class="number">2</span>):</span><br><span class="line">    similarity = (feat1 @ feat2.T).item()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Image <span class="subst">&#123;i+<span class="number">1</span>&#125;</span> vs Image <span class="subst">&#123;j+<span class="number">1</span>&#125;</span>: <span class="subst">&#123;similarity:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Pairwise Cosine Similarities:</span><br><span class="line">Image 1 vs Image 2: 0.9346</span><br><span class="line">Image 1 vs Image 3: 0.5781</span><br><span class="line">Image 1 vs Image 4: 0.5713</span><br><span class="line">Image 2 vs Image 3: 0.5737</span><br><span class="line">Image 2 vs Image 4: 0.5522</span><br><span class="line">Image 3 vs Image 4: 0.9497</span><br></pre></td></tr></table></figure>

<p><strong>以矩阵形式输出相似度（更直观）：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">sim_matrix = np.zeros((<span class="number">4</span>, <span class="number">4</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(4):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(4):</span><br><span class="line">        sim_matrix[i][j] = (features[i] @ features[j].T).item()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nCosine Similarity Matrix:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(sim_matrix)</span><br></pre></td></tr></table></figure>

<p>输出（对称矩阵）：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Cosine Similarity Matrix:</span><br><span class="line">[[0.99951172 0.93457031 0.578125   0.57128906]</span><br><span class="line"> [0.93457031 1.         0.57373047 0.55224609]</span><br><span class="line"> [0.578125   0.57373047 1.         0.94970703]</span><br><span class="line"> [0.57128906 0.55224609 0.94970703 1.        ]]</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://github.com/openai/CLIP">https://github.com/openai/CLIP</a></li>
<li><a href="https://colab.research.google.com/github/openai/clip/blob/master/notebooks/Interacting_with_CLIP.ipynb#scrollTo=NSSrLY185jSf">https://colab.research.google.com/github/openai/clip/blob/master/notebooks/Interacting_with_CLIP.ipynb#scrollTo=NSSrLY185jSf</a></li>
<li><a href="https://github.com/mlfoundations/open_clip">https://github.com/mlfoundations/open_clip</a></li>
<li><a href="https://huggingface.co/docs/transformers/model_doc/clip">https://huggingface.co/docs/transformers/model_doc/clip</a></li>
<li><a href="https://huggingface.co/openai?search_models=clip">https://huggingface.co/openai?search_models=clip</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>clip</tag>
      </tags>
  </entry>
  <entry>
    <title>DeepSeek-R1论文一起看</title>
    <url>/2025/04/24/DeepSeek-R1%E8%AE%BA%E6%96%87%E4%B8%80%E8%B5%B7%E7%9C%8B/</url>
    <content><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>无他，就是想看看这篇论文（计划是将DeepSeek和Qwen系列论文都看咯），咱们一起来先看看DeepSeek-R1的论文吧。</p>
<p><strong>Paper：<a href="https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf">https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf</a></strong></p>
<p><strong>GitHub：<a href="https://github.com/deepseek-ai/DeepSeek-R1">https://github.com/deepseek-ai/DeepSeek-R1</a></strong></p>
<p><strong>Title–&gt;DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning</strong></p>
<span id="more"></span>

<hr>
<h3 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h3><h4 id="文章名"><a href="#文章名" class="headerlink" title="文章名"></a><strong>文章名</strong></h4><p><strong>DeepSeek-R1：通过强化学习激励LLM的推理能力</strong></p>
<hr>
<h4 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><strong>摘要</strong></h4><p>我们介绍我们的第一代推理模型，DeepSeek-R1-Zero 和 DeepSeek-R1。DeepSeek-R1-Zero 是一个通过大规模强化学习 (RL) 训练的模型，没有将监督微调 (SFT) 作为初步步骤，它展示了卓越的推理能力。通过 RL，DeepSeek-R1-Zero 自然涌现出许多强大而有趣的推理行为。然而，它遇到了诸如可读性差和语言混合等挑战。为了解决这些问题并进一步增强推理性能，我们引入了 DeepSeek-R1，它在 RL 之前整合了多阶段训练和冷启动数据。DeepSeek-R1 在推理任务上实现了与 OpenAI-01-1217 相媲美的性能。为了支持研究社区，我们开源了 DeepSeek-R1-Zero、DeepSeek-R1，以及基于 Qwen 和 Llama 从 DeepSeek-R1 蒸馏出的六个密集模型（1.5B、7B、8B、14B、32B、70B）。</p>
<img src="/2025/04/24/DeepSeek-R1%E8%AE%BA%E6%96%87%E4%B8%80%E8%B5%B7%E7%9C%8B/image-20250424101955225.png" class="" title="image-20250424101955225">

<hr>
<h4 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a><strong>1. 引言</strong></h4><p>近年来，大型语言模型 (LLM) 经历了快速的迭代和演进 (Anthropic, 2024; Google, 2024; OpenAI, 2024a)，逐步缩小了与通用人工智能 (AGI) 之间的差距。</p>
<p>最近，后训练已成为完整训练流程中的一个重要组成部分。它已被证明可以在推理任务上提高准确性，与社会价值观对齐，并适应用户偏好，同时相对于预训练只需要相对较少的计算资源。在推理能力方面，OpenAI的o1系列模型首次引入了推理时扩展，通过增加思维链（Chain-of-Thought）推理过程的长度，在数学、编码和科学推理等多种任务中取得了显著改进。然而，如何有效实现测试时扩展仍是研究社区面临的开放性问题。先前的一些工作探索了各种方法，包括基于过程的奖励模型 (Lightman et al., 2023; Uesato et al., 2022; Wang et al., 2023)、强化学习 (Kumar et al., 2024)，以及蒙特卡洛树搜索和束搜索等搜索算法 (Feng et al., 2024; Trinh et al., 2024; Xin et al., 2024)。然而，这些方法中没有一个能够达到与 OpenAI o1 系列模型相当的通用推理性能。</p>
<p>本文中，我们首次尝试使用纯强化学习（RL）提升语言模型的推理能力。我们的目标是探索大语言模型在没有任何监督数据的情况下发展推理能力的潜力，专注于通过纯强化学习过程实现自我进化。具体而言，我们以DeepSeek-V3-Base为基础模型，采用GRPO（Shao et al., 2024）作为强化学习框架来提升模型在推理任务中的表现。在训练过程中，DeepSeek-R1-Zero 自然涌现出许多强大而有趣的推理行为。经过数千步 RL 训练后，DeepSeek-R1-Zero 在推理基准测试中表现出超强的性能。例如，在 AIME 2024 上的 pass@1 分数从 15.6% 提高到 71.0%，并且通过多数投票 (majority voting)，分数进一步提高到 86.7%，达到了 OpenAI-01-0912 的性能水平。</p>
<p>然而，DeepSeek-R1-Zero 面临着诸如可读性差和语言混合等挑战。为了解决这些问题并进一步提升推理性能，我们引入了 DeepSeek-R1，它整合了少量的冷启动数据和一个多阶段的训练流程。具体来说，我们首先收集数千条冷启动数据来微调 DeepSeek-V3-Base 模型。然后，我们执行像 DeepSeek-R1-Zero 一样的面向推理的 RL。在 RL 过程接近收敛时，我们通过对 RL 检查点进行拒绝采样来创建新的 SFT 数据，并结合 DeepSeek-V3 在写作、事实问答和自我认知等领域的监督数据，然后重新训练 DeepSeek-V3-Base 模型。在使用新数据进行微调后，该检查点会经历一个额外的 RL 过程，考虑所有场景的提示。经过这些步骤，我们得到了一个称为 DeepSeek-R1 的检查点，其性能与 OpenAI-01-1217 相当。</p>
<p>我们进一步探索了从 DeepSeek-R1 向更小的密集模型进行蒸馏。使用 Qwen2.5-32B (Qwen, 2024b) 作为基础模型，直接从 DeepSeek-R1 进行蒸馏优于在其上应用 RL。这表明大型基础模型发现的推理模式对于提高推理能力至关重要。我们开源了蒸馏后的 Qwen 和 Llama (Dubey et al., 2024) 系列模型。值得注意的是，我们蒸馏出的 14B 模型在性能上大幅超越了最先进的开源模型 QwQ-32B-Preview (Qwen, 2024a)，而蒸馏出的 32B 和 70B 模型在密集模型的推理基准测试中创下了新纪录。</p>
<hr>
<h5 id="1-1-贡献"><a href="#1-1-贡献" class="headerlink" title="1.1. 贡献"></a>1.1. 贡献</h5><p><strong>后训练：在基础模型上进行大规模强化学习</strong></p>
<ul>
<li>我们直接将 RL 应用于基础模型，而不依赖监督微调 (SFT) 作为初步步骤。这种方法允许模型探索用于解决复杂问题的思维链 (CoT)，从而发展出 DeepSeek-R1-Zero。DeepSeek-R1-Zero 展示了诸如自我验证、反思以及生成长 CoT 等能力，标志着研究界的一个重要里程碑。值得注意的是，这是第一个公开验证 LLM 推理能力可以纯粹通过 RL 来激励，而无需 SFT 的研究。这一突破为该领域的未来发展铺平了道路。</li>
<li>我们引入了开发 DeepSeek-R1 的流程。该流程包含两个 RL 阶段，旨在发现改进的推理模式并与人类偏好对齐，以及两个 SFT 阶段，作为模型推理和非推理能力的种子。我们相信这个流程将通过创造更好的模型使行业受益。</li>
</ul>
<p><strong>蒸馏：小模型也可以很强大</strong></p>
<ul>
<li>我们证明了较大模型的推理模式可以被蒸馏到较小的模型中，与在小模型上通过 RL 发现的推理模式相比，性能更好。开源的 DeepSeek-R1 及其 API 将有助于研究社区未来蒸馏出更好的小模型。</li>
<li>利用 DeepSeek-R1 生成的推理数据，我们微调了几个在研究界广泛使用的密集模型。评估结果表明，蒸馏后的小型密集模型在基准测试中表现异常出色。DeepSeek-R1-Distill-Qwen-7B 在 AIME 2024 上达到 55.5%，超过了 QwQ-32B-Preview。此外，DeepSeek-R1-Distill-Qwen-32B 在 AIME 2024 上得分 72.6%，在 MATH-500 上得分 94.3%，在 LiveCodeBench 上得分 57.2%。这些结果显著优于之前的开源模型，并且与 o1-mini 相当。我们向社区开源了基于 Qwen2.5 和 Llama3 系列的蒸馏后的 1.5B、7B、8B、14B、32B 和 70B 检查点。</li>
</ul>
<p><strong>1.2. 评估结果总结</strong></p>
<ul>
<li><strong>推理任务：</strong> (1) DeepSeek-R1 在 AIME 2024 上取得了 79.8% 的 Pass@1 分数，略微超过 OpenAI-o1-1217。在 MATH-500 上，它达到了 97.3% 的惊人分数，与 OpenAI-o1-1217 表现相当，并显著优于其他模型。(2) 在编程相关任务上，DeepSeek-R1 在代码竞赛任务中表现出专家水平，它在 Codeforces 上获得了 2,029 的 Elo 评分，超过了竞赛中 96.3% 的人类参与者。对于工程相关任务，DeepSeek-R1 的表现略好于 DeepSeek-V3，这有助于开发者在实际任务中应用。</li>
<li><strong>知识：</strong> 在 MMLU、MMLU-Pro 和 GPQA Diamond 等基准测试中，DeepSeek-R1 取得了出色的结果，显著优于 DeepSeek-V3，在 MMLU 上得分 90.8%，在 MMLU-Pro 上得分 84.0%，在 GPQA Diamond 上得分 71.5%。虽然其性能略低于 OpenAI-o1-1217，但 DeepSeek-R1 超过了其他闭源模型，展示了其在教育任务中的竞争优势。在事实基准测试 SimpleQA 上，DeepSeek-R1 优于 DeepSeek-V3，展示了其处理基于事实的查询的能力。观察到类似的趋势，即 OpenAI-o1 在此基准上超过了 4o。</li>
</ul>
<hr>
<ul>
<li>**其他方面：**DeepSeek-R1 在多个任务上同样表现出色，包括创意写作、通用问答、文本编辑、摘要生成等。它在 AlpacaEval 2.0 的长度控制评测中取得了 87.6% 的胜率，在 ArenaHard 测试中达到了 92.3% 的胜率，展现了其在处理非考试类问题时的强大智能能力。此外，DeepSeek-R1 在需要长上下文理解的任务中表现尤为突出，在长上下文基准测试中大幅优于 DeepSeek-V3。</li>
</ul>
<hr>
<h4 id="2-方法"><a href="#2-方法" class="headerlink" title="2. 方法"></a><strong>2. 方法</strong></h4><h5 id="2-1-概述"><a href="#2-1-概述" class="headerlink" title="2.1. 概述"></a><strong>2.1. 概述</strong></h5><p>以前的工作严重依赖大量监督数据来提升模型性能。在本研究中，我们证明了即使不使用监督微调 (SFT) 作为冷启动，通过大规模强化学习 (RL) 也可以显著提高推理能力。此外，通过引入少量冷启动数据，性能可以得到进一步增强。在以下章节中，我们介绍：(1) DeepSeek-R1-Zero，它直接将 RL 应用于基础模型，无需任何 SFT 数据；(2) DeepSeek-R1，它从一个经过数千个长思维链 (CoT) 示例微调的检查点开始应用 RL；3) 将 DeepSeek-R1 的推理能力蒸馏到小型密集模型中。</p>
<h5 id="2-2-DeepSeek-R1-Zero-基于基础模型做强化学习"><a href="#2-2-DeepSeek-R1-Zero-基于基础模型做强化学习" class="headerlink" title="2.2. DeepSeek-R1-Zero: 基于基础模型做强化学习"></a><strong>2.2. DeepSeek-R1-Zero: 基于基础模型做强化学习</strong></h5><p>正如我们之前的工作所证明的 (Shao et al., 2024; Wang et al., 2023)，强化学习在推理任务中已显示出显著的有效性。然而，这些工作严重依赖于监督数据，而收集这些数据非常耗时。在本节中，我们探索 LLM 在没有任何监督数据的情况下发展推理能力的潜力，重点关注它们通过纯强化学习过程的自我进化。我们首先简要概述我们的 RL 算法，然后展示一些令人兴奋的结果，希望这能为社区提供有价值的见解。</p>
<hr>
<h6 id="2-2-1-强化学习算法"><a href="#2-2-1-强化学习算法" class="headerlink" title="2.2.1. 强化学习算法"></a><strong>2.2.1. 强化学习算法</strong></h6><p><strong>组相对策略优化 (Group Relative Policy Optimization,GRPO)</strong> 为了节省 RL 的训练成本，我们采用组相对策略优化 (GRPO) (Shao et al., 2024)，该方法放弃了通常与策略模型大小相同的评论家模型 (critic model)，而是根据组得分来估计基线。具体来说，对于每个问题$ q $，GRPO 从旧策略 $ \pi_{\theta_{\text{old}}} $ 中采样一组输出 $ {o_1, o_2, …, o_g} $，然后通过最大化以下目标函数来优化策略模型 $ \pi_\theta $：<br>$$<br>J_{\text{GRPO}}(\theta) &#x3D; \mathbb{E}<em>{q \sim \mathcal{P}(Q), {o_i}</em>{i&#x3D;1}^G \sim \pi_{\theta_{\text{old}}}(O|q)}<br>\left[ \frac{1}{G} \sum_{i&#x3D;1}^G \left(<br>\min \left(<br>\frac{\pi_\theta(o_i|q)}{\pi_{\theta_{\text{old}}}(o_i|q)} \cdot A_i,\<br>\text{clip}\left(<br>\frac{\pi_\theta(o_i|q)}{\pi_{\theta_{\text{old}}}(o_i|q)},\ 1 - \epsilon,\ 1 + \epsilon<br>\right) \cdot A_i<br>\right) - \beta \cdot D_{\text{KL}}(\pi_\theta | \pi_{\text{ref}})<br>\right) \right]<br>$$</p>
<p>$$<br>D_{\text{KL}}(\pi_\theta | \pi_{\text{ref}}) &#x3D;<br>\left( \frac{\pi_{\text{ref}}(o_i|q)}{\pi_\theta(o_i|q)} \right) - \log \left( \frac{\pi_{\text{ref}}(o_i|q)}{\pi_\theta(o_i|q)} \right) - 1<br>$$</p>
<p>其中  $ \varepsilon $ 和 $ \beta $ 是超参数，$ A_i $是优势（Advantage），使用一组对应于组内输出的奖励 $ { r_1, r_2, \dots, r_G } $  计算得出:<br>$$<br>A_i &#x3D; \frac{r_i - \text{mean}({r_1, r_2, \dots, r_G})}<br>{\text{std}({r_1, r_2, \dots, r_G})}\tag{3}<br>$$</p>
<img src="/2025/04/24/DeepSeek-R1%E8%AE%BA%E6%96%87%E4%B8%80%E8%B5%B7%E7%9C%8B/image-20250424144433909.png" class="" title="image-20250424144433909">

<hr>
<h6 id="2-2-2-奖励建模"><a href="#2-2-2-奖励建模" class="headerlink" title="2.2.2. 奖励建模"></a><strong>2.2.2. 奖励建模</strong></h6><p>奖励是训练信号的来源，决定了 RL 的优化方向。为了训练 DeepSeek-R1-Zero，我们采用了一个基于规则的奖励系统，主要包括两种类型的奖励：</p>
<ul>
<li><strong>准确性奖励：</strong> 准确性奖励模型评估响应是否正确。例如，在具有确定性结果的数学问题中，模型需要以指定格式（例如，在方框内）提供最终答案，从而能够进行可靠的基于规则的正确性验证。类似地，对于 LeetCode 问题，可以使用编译器根据预定义的测试用例生成反馈。</li>
<li><strong>格式奖励：</strong> 除了准确性奖励模型外，我们还使用了一个格式奖励模型，强制模型将其思考过程置于 <code>&lt;think&gt;</code> 和 <code>&lt;/think&gt;</code>标签之间。</li>
</ul>
<p>我们在开发 DeepSeek-R1-Zero 时没有应用基于结果或过程的神经奖励模型，因为我们发现神经奖励模型在大规模强化学习过程中可能会遭受奖励黑客攻击 (reward hacking)，并且重新训练奖励模型需要额外的训练资源，这会使整个训练流程复杂化。</p>
<hr>
<h6 id="2-2-3-训练模板"><a href="#2-2-3-训练模板" class="headerlink" title="2.2.3. 训练模板"></a><strong>2.2.3. 训练模板</strong></h6><p>为了训练 DeepSeek-R1-Zero，我们首先设计了一个简单的模板，引导基础模型遵循我们指定的指令。如表 1 所示，该模板要求 DeepSeek-R1-Zero 首先产生推理过程，然后给出最终答案。我们有意将约束限制在这种结构格式上，避免任何内容特定的偏见——例如强制进行反思性推理或推广特定的解决问题策略——以确保我们能够准确观察模型在 RL 过程中的自然进展。</p>
<hr>
<h6 id="2-2-4-DeepSeek-R1-Zero-的性能、自进化过程和顿悟时刻"><a href="#2-2-4-DeepSeek-R1-Zero-的性能、自进化过程和顿悟时刻" class="headerlink" title="2.2.4. DeepSeek-R1-Zero 的性能、自进化过程和顿悟时刻"></a><strong>2.2.4. DeepSeek-R1-Zero 的性能、自进化过程和顿悟时刻</strong></h6><p><strong>DeepSeek-R1-Zero 的性能</strong> 图 2 描绘了 DeepSeek-R1-Zero 在整个 RL 训练过程中于 AIME 2024 基准测试上的性能轨迹。如图所示，随着 RL 训练的推进，DeepSeek-R1-Zero 的性能表现出稳定且持续的提升。值得注意的是，AIME 2024 上的平均 pass@1 分数显著增加，从最初的 15.6% 跃升至令人印象深刻的 71.0%，达到了与 OpenAI-O1-0912 相当的性能水平。这一显著改进凸显了我们的 RL 算法在优化模型性能方面的有效性。</p>
<p>表2提供了DeepSeek-R1-Zero和OpenAI的o1-0912模型在各种推理相关基准上的比较分析。研究结果表明，RL赋能DeepSeek-R1-Zero 获得强大的推理能力，而无需任何监督微调数据。这是一个值得注意的成就，因为它强调了模型仅通过 RL 就能有效学习和泛化的能力。此外，通过应用多数投票 (majority voting) 可以进一步增强 DeepSeek-R1-Zero 的性能。例如，当在 AIME 基准上采用多数投票时，DeepSeek-R1-Zero 的性能从 71.0% 提升到 86.7%，从而超过了 OpenAI-01-0912 的性能。DeepSeek-R1-Zero 无论是否使用多数投票都能取得如此具有竞争力的性能，突显了其强大的基础能力及其在推理任务上进一步发展的潜力。</p>
<img src="/2025/04/24/DeepSeek-R1%E8%AE%BA%E6%96%87%E4%B8%80%E8%B5%B7%E7%9C%8B/image-20250424150706721.png" class="" title="image-20250424150706721">

<p><strong>DeepSeek-R1-Zero 的自进化过程</strong> DeepSeek-R1-Zero 的自进化过程是一个引人入胜的展示，说明了 RL 如何驱动模型自主提高其推理能力。通过直接从基础模型启动 RL，我们可以密切监控模型的进展，而不受监督微调阶段的影响。这种方法清晰地展示了模型如何随时间演变，特别是在处理复杂推理任务的能力方面。</p>
<p>如图3所示，DeepSeek-R1-Zero的思考时间在训练过程中持续改善。这种改进并非外部调整的结果，而是模型内部的固有发展。DeepSeek-R1-Zero 自然地获得了通过利用扩展的测试时计算来解决日益复杂的推理任务的能力。这种计算范围从生成数百到数千个推理 token，使模型能够更深入地探索和完善其思考过程。</p>
<p>这种自进化的最显著方面之一是随着测试时计算的增加而出现的复杂行为。诸如反思（模型重新审视和重新评估其先前步骤）和探索解决问题的替代方法等行为会自发产生。这些行为并非明确编程，而是模型与强化学习环境交互的结果。这种自发的发展显著增强了 DeepSeek-R1-Zero 的推理能力，使其能够更高效、更准确地处理更具挑战性的任务。</p>
<img src="/2025/04/24/DeepSeek-R1%E8%AE%BA%E6%96%87%E4%B8%80%E8%B5%B7%E7%9C%8B/image-20250424151308569.png" class="" title="image-20250424151308569">

<p><strong>DeepSeek-R1-Zero 的顿悟时刻</strong> 在 DeepSeek-R1-Zero 的训练过程中观察到的一个特别有趣的现象是“顿悟时刻”的发生。如表 3 所示，这个时刻发生在模型的一个中间版本中。在这个阶段，DeepSeek-R1-Zero 通过重新评估其初始方法，学会了为问题分配更多的思考时间。这种行为不仅证明了模型日益增长的推理能力，而且也是一个引人入胜的例子，说明了强化学习如何导致意想不到的复杂结果。</p>
<p>这个时刻不仅对模型来说是一个“顿悟时刻”，对观察其行为的研究人员来说也是如此。它强调了强化学习的力量和魅力：我们并非明确教导模型如何解决问题，而是简单地为其提供正确的激励，它就能自主地发展出先进的问题解决策略。“顿悟时刻”有力地提醒我们 RL 在解锁人工智能系统中新层次智能方面的潜力，为未来更自主、更具适应性的模型铺平了道路。</p>
<img src="/2025/04/24/DeepSeek-R1%E8%AE%BA%E6%96%87%E4%B8%80%E8%B5%B7%E7%9C%8B/image-20250424151351423.png" class="" title="image-20250424151351423">

<p>尽管DeepSeek-R1-Zero表现出强大的推理能力和自主开发出意外且强大的推理行为，但它仍面临一些问题。例如，DeepSeek-R1-Zero在处理可读性差和语言混杂等挑战时显得力不从心。为了使推理过程更加易读并将其分享给开放社区，我们探索了DeepSeek-R1，这是一种利用强化学习与人类友好型冷启动数据相结合的方法。</p>
<hr>
<h5 id="2-3-DeepSeek-R1-带有冷启动的强化学习"><a href="#2-3-DeepSeek-R1-带有冷启动的强化学习" class="headerlink" title="2.3 DeepSeek-R1: 带有冷启动的强化学习"></a>2.3 <strong>DeepSeek-R1: 带有冷启动的强化学习</strong></h5><p>受 DeepSeek-R1-Zero 令人鼓舞的结果启发，出现了两个自然的问题：1) 通过引入少量高质量数据作为冷启动，是否可以进一步提高推理性能或加速收敛？2) 我们如何训练一个用户友好的模型，它不仅能产生清晰连贯的思维链 (CoT)，而且还表现出强大的通用能力？为了解决这些问题，我们设计了一个训练 DeepSeek-R1 的流程。该流程包括四个阶段，概述如下。</p>
<h6 id="2-3-1-冷启动"><a href="#2-3-1-冷启动" class="headerlink" title="2.3.1. 冷启动"></a><strong>2.3.1. 冷启动</strong></h6><p>与 DeepSeek-R1-Zero 不同，为了防止 RL 训练早期从基础模型开始的不稳定冷启动阶段，我们为 DeepSeek-R1 构建并收集了少量长 CoT 数据，用于微调模型作为初始 RL 参与者 (actor)。为了收集此类数据，我们探索了几种方法：使用长 CoT 作为示例进行少样本提示 (few-shot prompting)，直接提示模型生成带有反思和验证的详细答案，以可读格式收集 DeepSeek-R1-Zero 的输出，以及通过人工标注员进行后处理来完善结果。</p>
<p>在这项工作中，我们收集了数千条冷启动数据来微调 DeepSeek-V3-Base，作为 RL 的起点。与 DeepSeek-R1-Zero 相比，冷启动数据的优势包括：</p>
<ul>
<li><strong>可读性：</strong> DeepSeek-R1-Zero 的一个关键限制是其内容通常不适合阅读。响应可能会混合多种语言或缺少 Markdown 格式来为用户突出显示答案。相比之下，在为 DeepSeek-R1 创建冷启动数据时，我们设计了一种可读模式，在每个响应的末尾包含摘要，并过滤掉不便于读者阅读的响应。在这里，我们将输出格式定义为 | special_token | <reasoning_process> | special_token | &lt;summary&gt;，其中<code>reasoning_process</code>是查询的 CoT，<code>summary</code>用于总结推理结果。</li>
<li><strong>潜力：</strong> 通过仔细设计带有人先验 (human priors) 的冷启动数据模式，我们观察到其性能优于 DeepSeek-R1-Zero。我们相信迭代训练是推理模型更好的方式。</li>
</ul>
<hr>
<h6 id="2-3-2-面向推理的强化学习"><a href="#2-3-2-面向推理的强化学习" class="headerlink" title="2.3.2. 面向推理的强化学习"></a><strong>2.3.2. 面向推理的强化学习</strong></h6><p>在使用冷启动数据对 DeepSeek-V3-Base 进行微调之后，我们应用与 DeepSeek-R1-Zero 相同的大规模强化学习训练流程。本阶段旨在进一步增强模型的推理能力，特别是在编码、数学、科学以及逻辑推理等推理密集型任务中，这些任务通常具有明确的问题定义和清晰的解答方案。</p>
<p>在训练过程中我们观察到，当 RL 的提示语涉及多种语言时，链式思维（CoT）生成往往会出现语言混杂现象。为缓解该问题，我们在强化学习训练中引入了<strong>语言一致性奖励</strong>，该奖励通过统计 CoT 中目标语言词汇所占的比例来计算。</p>
<p>尽管消融实验表明，这种语言对齐机制会轻微降低模型在某些指标上的性能，但它符合人类偏好，从而提升了生成内容的可读性。最终，我们将推理任务的准确度得分与语言一致性奖励<strong>直接相加</strong>，作为最终的奖励信号。随后，我们在已经微调的模型上继续进行强化学习训练，直至其在推理类任务上收敛。</p>
<hr>
<h6 id="2-3-3-拒绝采样和监督微调"><a href="#2-3-3-拒绝采样和监督微调" class="headerlink" title="2.3.3. 拒绝采样和监督微调"></a><strong>2.3.3. 拒绝采样和监督微调</strong></h6><p>当面向推理的强化学习（Reasoning-oriented RL）达到收敛后，我们使用所得的检查点（checkpoint）来收集下一轮监督微调（SFT）所需的数据。不同于初始的冷启动数据主要聚焦于推理能力，这一阶段的数据涵盖了<strong>写作、角色扮演以及其他通用任务</strong>领域，以进一步增强模型的综合能力。</p>
<p><strong>推理类数据（Reasoning data）</strong></p>
<p>我们从推理提示语（reasoning prompts）出发，通过对上述 RL 训练得到的检查点进行拒绝采样（rejection sampling），生成推理轨迹。在前一阶段，我们只纳入能够使用基于规则的奖励函数评估的数据。而在本阶段，我们拓展了数据集，引入了额外的数据，其中部分通过生成式奖励模型（generative reward model）进行评估：具体做法是将模型预测和参考答案一同输入 DeepSeek-V3，由它来判断结果质量。</p>
<blockquote>
<p>推理轨迹(reasoning trajectories)可理解为COT(思维链)。</p>
</blockquote>
<p>此外，由于模型在某些情况下输出内容混乱、难以阅读，我们过滤掉了以下类型的链式思维内容（Chain-of-Thought, CoT）：<strong>混合语言</strong>、<strong>段落过长</strong>、<strong>包含代码块</strong>等情况。对于每一个提示语，我们采样多个响应，仅保留其中<strong>正确的答案</strong>。</p>
<p>最终，我们共收集了约 <strong>60 万条与推理相关的训练样本</strong>，作为后续 SFT 阶段的数据。</p>
<hr>
<p><strong>非推理类数据（Non-Reasoning data）：<strong>对于</strong>非推理类的数据</strong>，例如写作、事实问答（factual QA）、自我认知（self-cognition）和翻译任务，我们采用了 DeepSeek-V3 的数据生成流程，并复用了部分 <strong>DeepSeek-V3 的监督微调（SFT）数据集</strong>。</p>
<p>在某些非推理类任务中，我们会调用 DeepSeek-V3，在回答问题前通过提示语引导其生成一个可能的 <strong>思维链（Chain-of-Thought, CoT）</strong>。不过，对于较为简单的请求，例如 “hello”，我们不会生成 CoT，仅直接给出回复。</p>
<p>最终，我们收集了<strong>大约 20 万条与推理无关的训练样本</strong>。</p>
<p>然后，我们使用上述整理得到的大约 80 万条数据（60 万推理类 + 20 万非推理类），对 DeepSeek-V3-Base 进行了 <strong>2 轮（epochs）微调训练</strong>。</p>
<hr>
<h6 id="2-3-4-面向全场景的强化学习"><a href="#2-3-4-面向全场景的强化学习" class="headerlink" title="2.3.4 面向全场景的强化学习"></a>2.3.4 面向全场景的强化学习</h6><p>为了进一步让模型与人类偏好对齐，我们实施了第二阶段的强化学习，旨在提升模型的<strong>有用性（helpfulness）<strong>与</strong>无害性（harmlessness）</strong>，同时进一步优化其推理能力。</p>
<p>具体来说，我们结合多种奖励信号与多样的提示分布对模型进行训练：</p>
<ul>
<li><strong>在推理类数据方面</strong>，我们继续采用 DeepSeek-R1-Zero 中的方法，即使用<strong>基于规则的奖励函数</strong>来指导模型在数学、代码和逻辑推理领域的学习。</li>
<li><strong>在通用任务数据方面</strong>，我们采用<strong>奖励模型</strong>来捕捉人类在复杂和细腻情境下的偏好。</li>
</ul>
<p>我们基于 DeepSeek-V3 的训练流程，采用类似的偏好对（preference pairs）和训练提示语分布。</p>
<ul>
<li><strong>在有用性方面</strong>，我们仅评估模型的<strong>最终摘要（summary）部分</strong>，以确保模型响应对用户具有实用性且内容相关，同时不干扰推理过程。</li>
<li><strong>在无害性方面</strong>，我们评估模型<strong>整个响应过程</strong>，包括推理过程和总结内容，以识别并减轻潜在的风险、偏见或有害内容。</li>
</ul>
<p>最终，通过结合奖励信号与多样化的数据分布，我们训练出了一个既擅长推理，又兼顾有用性与无害性的模型。</p>
<hr>
<h5 id="2-4-蒸馏：赋予小模型推理能力"><a href="#2-4-蒸馏：赋予小模型推理能力" class="headerlink" title="2.4 蒸馏：赋予小模型推理能力"></a>2.4 蒸馏：赋予小模型推理能力</h5><p>为了让更高效的小模型也具备 DeepSeek-R1 的推理能力，我们使用 §2.3.3 中构建的 80 万条数据（推理数据 + 通用数据），对开源模型如 <strong>Qwen</strong>（Qwen, 2024b）和 <strong>Llama</strong>（AI@Meta, 2024）进行了直接的监督微调（SFT）。</p>
<p>实验发现，这种<strong>直接蒸馏的方法</strong>显著增强了小模型的推理能力。</p>
<p>我们使用的基础模型包括：</p>
<ul>
<li>Qwen2.5-Math-1.5B</li>
<li>Qwen2.5-Math-7B</li>
<li>Qwen2.5-14B</li>
<li>Qwen2.5-32B</li>
<li>Llama-3.1-8B</li>
<li>Llama-3.3-70B-Instruct</li>
</ul>
<p>其中之所以选择 <strong>Llama-3.3</strong>，是因为其推理能力略优于 Llama-3.1。</p>
<p>在蒸馏后的模型中，我们<strong>只进行了 SFT，没有使用 RL 阶段</strong>，尽管引入 RL 可能进一步提升模型表现。我们在此阶段的主要目标是<strong>验证蒸馏技术的有效性</strong>，而将 RL 阶段的探索留给更广泛的研究社区。</p>
<hr>
<h4 id="3-实验"><a href="#3-实验" class="headerlink" title="3. 实验"></a>3. 实验</h4><p> **基准评估（Benchmarks）**我们在以下多个基准数据集上评估模型性能：</p>
<ul>
<li><strong>MMLU</strong>（Hendrycks 等, 2020）</li>
<li><strong>MMLU-Redux</strong>（Gema 等, 2024）</li>
<li><strong>MMLU-Pro</strong>（Wang 等, 2024）</li>
<li><strong>C-Eval</strong>（Huang 等, 2023）</li>
<li><strong>CMMLU</strong>（Li 等, 2023）</li>
<li><strong>IFEval</strong>（Zhou 等, 2023）</li>
<li><strong>FRAMES</strong>（Krishna 等, 2024）</li>
<li><strong>GPQA Diamond</strong>（Rein 等, 2023）</li>
<li><strong>SimpleQA</strong>（OpenAI, 2024c）</li>
<li><strong>C-SimpleQA</strong>（He 等, 2024）</li>
<li><strong>SWE-Bench Verified</strong>（OpenAI, 2024d）</li>
<li><strong>Aider</strong></li>
<li><strong>LiveCodeBench</strong>（Jain 等, 2024）（2024年8月至2025年1月）</li>
<li><strong>Codeforces</strong></li>
<li><strong>中国高中数学联赛（CNMO 2024）</strong></li>
<li><strong>美国数学邀请赛（AIME 2024）</strong>（MAA, 2024）</li>
</ul>
<p>除了这些标准基准测试之外，我们还在<strong>开放式生成任务</strong>上评估模型表现，并采用<strong>大语言模型作为评审</strong>。</p>
<p>具体来说，我们遵循 <strong>AlpacaEval 2.0</strong>（Dubois 等, 2024）和 <strong>Arena-Hard</strong>（Li 等, 2024）的原始配置，它们均使用 <strong>GPT-4-Turbo-1106</strong> 作为评审模型来进行成对比较。</p>
<p>在这类评估中，我们<strong>仅将最终摘要输入（summary）评审模型</strong>，以避免由于响应长度不同而引起的评估偏差。</p>
<p>对于<strong>蒸馏后的模型</strong>，我们报告以下具有代表性的评估结果：</p>
<ul>
<li>AIME 2024</li>
<li>MATH-500</li>
<li>GPQA Diamond</li>
<li>Codeforces</li>
<li>LiveCodeBench</li>
</ul>
<hr>
<p>**评估提示设计（Evaluation Prompts）**根据 DeepSeek-V3 的设置，我们使用如下方式对模型进行评估：</p>
<ul>
<li>对于标准基准测试集（如 <strong>MMLU</strong>、<strong>DROP</strong>、<strong>GPQA Diamond</strong> 和 <strong>SimpleQA</strong>），采用 <strong>simpleevals</strong> 框架中的提示语进行评估。</li>
<li><strong>MMLU-Redux</strong> 使用 <strong>Zero-Eval</strong> 提示格式（Lin, 2024），并在 <strong>zero-shot</strong>（零样本）设置下进行评估。</li>
<li>对于原始为 <strong>few-shot</strong>（少样本）格式的 <strong>MMLU-Pro</strong>、<strong>C-Eval</strong> 和 <strong>CLUE-WSC</strong>，我们略微调整提示语以适配 <strong>zero-shot</strong> 设置，因为 few-shot 中的 CoT（Chain-of-Thought）可能会削弱 DeepSeek-R1 的表现。</li>
<li>其他数据集按照其作者提供的默认评估协议执行。</li>
</ul>
<p>对于 <strong>代码与数学类基准测试</strong>：</p>
<ul>
<li><strong>HumanEval-Mul</strong> 数据集覆盖八种主流编程语言（Python、Java、C++、C#、JavaScript、TypeScript、PHP 和 Bash）。</li>
<li><strong>LiveCodeBench</strong> 的模型评估采用 CoT 格式，数据收集时间为 2024 年 8 月至 2025 年 1 月。</li>
<li><strong>Codeforces</strong> 的评估基于 10 场 Div.2 比赛中的题目，并辅以专家制定的测试用例，随后计算期望得分与选手排名比例。</li>
<li><strong>SWE-Bench Verified</strong> 的评估通过 <strong>agentless framework</strong>（Xia 等, 2024）完成。</li>
<li>与 <strong>AIDER</strong> 相关的评估使用 <code>&quot;diff&quot;</code> 格式。</li>
</ul>
<p>每个基准测试中，DeepSeek-R1 的输出长度最多限制为 <strong>32,768 个 token</strong>。</p>
<hr>
<p>**基准模型（Baselines）**我们与多个强基线模型进行全面对比，包括：</p>
<ul>
<li><strong>DeepSeek-V3</strong></li>
<li><strong>Claude-Sonnet-3.5-1022</strong></li>
<li><strong>GPT-4o-0513</strong></li>
<li><strong>OpenAI-o1-mini</strong></li>
<li><strong>OpenAI-o1-1217</strong></li>
</ul>
<p>由于中国大陆难以直接访问 OpenAI-o1-1217 接口，我们依据其 <strong>官方报告</strong> 的结果进行对比。</p>
<p>对于 <strong>蒸馏模型</strong>，我们还引入开源模型 <strong>QwQ-32B-Preview</strong>（Qwen, 2024a）作为对比对象。</p>
<hr>
<p>**评估设置（Evaluation Setup）**我们为模型设置了最大生成长度为 <strong>32,768</strong> 个 token。</p>
<p>我们发现，使用贪心解码（greedy decoding）来评估长输出推理模型会导致较高的重复率，并且在不同检查点之间的结果变化较大。因此，我们默认使用 <strong>pass@𝑘</strong> 评估方法（Chen 等，2021），并报告 <strong>pass@1</strong>，同时使用非零温度进行解码。</p>
<p>具体而言，我们使用 <strong>0.6</strong> 的采样温度和 <strong>0.95</strong> 的 top-𝑝 值来生成 <strong>𝑘</strong> 个响应（通常在 4 到 64 之间，具体取决于测试集的大小）来回答每个问题。然后，通过以下公式计算 <strong>pass@1</strong>：<br>$$<br>\text{pass@1} &#x3D; \frac{1}{k} \sum_{i&#x3D;1}^{k} p_i<br>$$<br>其中 $ p_i $表示第 $i$ 个回答的正确性。这种方法提供了更可靠的性能估计。对于 AIME 2024，我们还报告了共识（多数投票）结果（Wang 等，2022），使用 64 个样本，记作 $ \text{cons@64} $。</p>
<hr>
<h5 id="3-1-DeepSeek-R1-评估"><a href="#3-1-DeepSeek-R1-评估" class="headerlink" title="3.1 DeepSeek-R1 评估"></a>3.1 <strong>DeepSeek-R1 评估</strong></h5><p>对于教育导向的知识基准测试，如 MMLU、MMLU-Pro 和 GPQA Diamond，DeepSeek-R1 相较于 DeepSeek-V3 展现出优越的表现。这一改进主要归因于在 STEM 相关问题上的准确性提高，其中通过大规模强化学习取得了显著的进展。此外，DeepSeek-R1 在 FRAMES 上表现出色，这是一个长上下文依赖的问答任务，展示了其强大的文档分析能力。这突显了推理模型在 AI 驱动的搜索和数据分析任务中的潜力。在事实类基准测试 SimpleQA 上，DeepSeek-R1 超过了 DeepSeek-V3，展现了其处理基于事实查询的能力。类似的趋势也出现在 OpenAI-o1 超过 GPT-4o 的情况下。然而，在中文 SimpleQA 基准测试中，DeepSeek-R1 的表现逊色于 DeepSeek-V3，主要是由于其在安全强化学习后倾向于拒绝回答某些查询。如果没有安全强化学习，DeepSeek-R1 可以达到超过 70% 的准确率。</p>
<p>DeepSeek-R1 在 IF-Eval 上也展现出了令人印象深刻的表现。该基准测试旨在评估模型遵循格式指令的能力。这些提升可以归因于在监督微调（SFT）和强化学习（RL）训练的最后阶段引入了指令遵循类的数据。此外，DeepSeek-R1 在 AlpacaEval 2.0 和 ArenaHard 上的优异表现，显示了其在写作任务和开放领域问答方面的强项。相比 DeepSeek-V3 的显著优势进一步表明，大规模强化学习不仅增强了推理能力，还提升了模型在各类任务中的泛化能力。</p>
<p>此外，DeepSeek-R1 所生成的摘要内容长度适中，在 ArenaHard 上的平均长度为 689 个 token，在 AlpacaEval 2.0 上的平均长度为 2,218 个字符，这表明在基于 GPT 的评估中，DeepSeek-R1 能够有效避免长度偏置，进一步巩固了其在多任务环境中的稳健性。</p>
<p>在数学任务方面，DeepSeek-R1 的表现与 OpenAI-o1-1217 不相上下，并且在与其他模型的比较中遥遥领先。在编程算法任务（如 LiveCodeBench 和 Codeforces）中也观察到类似趋势，以推理为核心的模型在这些基准测试中表现尤为突出。在面向工程的编程任务中，OpenAI-o1-1217 在 Aider 上优于 DeepSeek-R1，但在 SWE Verified 上两者表现相当。我们认为，随着后续版本引入更多相关的 RL 训练数据，DeepSeek-R1 在工程编程任务上的表现也将进一步提升。</p>
<img src="/2025/04/24/DeepSeek-R1%E8%AE%BA%E6%96%87%E4%B8%80%E8%B5%B7%E7%9C%8B/image-20250424161850714.png" class="" title="image-20250424161850714">

<hr>
<h5 id="3-2-蒸馏模型评估"><a href="#3-2-蒸馏模型评估" class="headerlink" title="3.2 蒸馏模型评估"></a>3.2 蒸馏模型评估</h5><p>如表 5 所示，仅通过对 DeepSeek-R1 的输出进行蒸馏，就能让高效的 DeepSeek-R1-7B（即 DeepSeek-R1-Distill-Qwen-7B，简称为 DeepSeek-R1-7B）在各项评估中全面超越非推理模型，例如 GPT-4o-0513。DeepSeek-R1-14B 在所有评估指标上也优于 QwQ-32B-Preview，而 DeepSeek-R1-32B 和 DeepSeek-R1-70B 则在大多数基准测试上显著超越 o1-mini。这些结果充分展示了蒸馏技术的强大潜力。</p>
<p>此外，我们还发现，将强化学习（RL）应用于这些经过蒸馏的模型后，性能会有显著提升。基于这一发现，我们认为这一方向值得进一步深入研究，因此本报告仅展示了通过简单 SFT 蒸馏得到的模型结果。</p>
<img src="/2025/04/24/DeepSeek-R1%E8%AE%BA%E6%96%87%E4%B8%80%E8%B5%B7%E7%9C%8B/image-20250424162046638.png" class="" title="image-20250424162046638">

<hr>
<h4 id="4-讨论"><a href="#4-讨论" class="headerlink" title="4. 讨论"></a>4. 讨论</h4><h5 id="4-1-蒸馏-vs-强化学习"><a href="#4-1-蒸馏-vs-强化学习" class="headerlink" title="4.1 蒸馏 vs 强化学习"></a><strong>4.1 蒸馏 vs 强化学习</strong></h5><p>在第 3.2 节中我们已经看到，通过对 DeepSeek-R1 进行蒸馏，小模型也可以取得非常出色的结果。但仍然有一个关键问题尚未解答：<strong>是否可以仅依赖论文中提到的大规模强化学习训练，而不依赖蒸馏，就实现与之相当的性能？</strong></p>
<p>为了解答这个问题，我们对 Qwen-32B-Base 模型在数学、代码和 STEM 数据上进行了超过 1 万步的大规模强化学习训练，得到了模型 <strong>DeepSeek-R1-Zero-Qwen-32B</strong>。实验结果如表 6 所示，训练后的 32B 基座模型性能与 QwQ-32B-Preview 持平。然而，从 DeepSeek-R1 蒸馏得到的 <strong>DeepSeek-R1-Distill-Qwen-32B</strong> 模型，在所有基准测试中都明显优于 DeepSeek-R1-Zero-Qwen-32B。</p>
<img src="/2025/04/24/DeepSeek-R1%E8%AE%BA%E6%96%87%E4%B8%80%E8%B5%B7%E7%9C%8B/image-20250424162851384.png" class="" title="image-20250424162851384">

<p>因此，我们可以得出两个结论：</p>
<ol>
<li>**将强模型蒸馏为小模型是非常有效的策略。**相比之下，仅依赖论文中描述的大规模强化学习来训练小模型，不仅成本高昂，性能也可能不如蒸馏方法。</li>
<li><strong>虽然蒸馏是一种经济又有效的方法，但若想继续突破智能边界，仍然需要更强大的基座模型和更大规模的强化学习。</strong></li>
</ol>
<hr>
<h5 id="4-2-失败尝试"><a href="#4-2-失败尝试" class="headerlink" title="4.2 失败尝试"></a><strong>4.2 失败尝试</strong></h5><p>在 DeepSeek-R1 的早期开发阶段，我们也经历了一些失败和挫折。在此我们分享这些失败的经验，希望为他人提供一些启示——不过这并不意味着这些方法本身无法用于构建有效的推理模型。</p>
<p>Process Reward Model（PRM）</p>
<p>PRM 是一种合理的方式，用于引导模型学习更优的推理路径（Lightman et al., 2023；Uesato et al., 2022；Wang et al., 2023）。但在实际应用中，PRM 存在以下三个主要限制，这些限制在我们的实验中制约了其最终效果：</p>
<ol>
<li><strong>难以明确定义通用推理中的细粒度步骤</strong>。推理过程往往不具备标准化的步骤模板，这使得 PRM 难以泛化。</li>
<li><strong>评估中间步骤是否正确本身就是一个困难的问题</strong>。自动标注依赖的模型往往效果不佳，而人工标注则不利于规模化。</li>
<li><strong>一旦引入基于模型的 PRM，就容易出现奖励黑客（reward hacking）现象</strong>（Gao et al., 2022），并且奖励模型的重训练会消耗额外算力，同时增加训练流程的复杂性。</li>
</ol>
<p>总之，虽然 PRM 在 <strong>对模型生成的 top-N 响应重排序</strong> 或 <strong>引导式搜索</strong>（Snell et al., 2024）中表现良好，但在我们的大规模强化学习场景中，PRM 带来的计算开销远大于它带来的性能提升，因此收益有限。</p>
<hr>
<p>Monte Carlo Tree Search（MCTS）</p>
<p>受到 AlphaGo（Silver et al., 2017b）和 AlphaZero（Silver et al., 2017a）的启发，我们尝试将蒙特卡洛树搜索（MCTS）应用于推理任务中，以增强测试时的计算扩展能力。</p>
<p>我们的方法是：将问题的解拆分成若干子步骤，引导模型系统性地探索解空间。为此，我们先通过 prompt 引导模型生成多个标签，这些标签对应于推理过程中需执行的特定子步骤。</p>
<p>训练流程如下：</p>
<ul>
<li>首先，我们利用预训练的 value model 指导 MCTS 搜索，以找到对应问题的最优解。</li>
<li>然后，我们将生成的问答对用于训练 actor 模型和 value 模型，不断迭代优化该流程。</li>
</ul>
<p>不过，在将这种方法扩展到大规模训练时，我们遇到了几个关键挑战：</p>
<hr>
<p><strong>首先</strong>，与国际象棋等任务不同，其搜索空间相对明确和有限，而<strong>文本生成的搜索空间呈指数级增长</strong>。为了应对这个问题，我们为每个节点设置了最大扩展限制（maximum extension limit），但这往往会导致模型<strong>陷入局部最优解</strong>，从而难以探索更优的全局路径。</p>
<p><strong>第二</strong>，<strong>value model 的质量直接影响生成效果</strong>，因为它在搜索过程中承担了指导每一步推理的职责。要训练出一个细粒度、精确可靠的 value model 本身就是一个非常困难的任务，这使得通过自我搜索迭代提升模型性能的方式很难稳定运行。</p>
<p>虽然 AlphaGo 的成功很大程度上依赖于 value model 的不断进化，从而推动整体性能逐步提升，但在我们的文本生成场景中，<strong>复制这一策略面临极高的复杂性</strong>，尤其是由于 token 级生成的高维度与不确定性。</p>
<hr>
<p><strong>总结来说</strong>，尽管在推理阶段，如果搭配预训练好的 value model，MCTS 确实能够提升一定的性能；但要通过自我搜索（self-search）方式实现模型性能的迭代式增强，仍然是一个<strong>尚未解决的重大难题</strong>。</p>
<hr>
<h4 id="5-结论、局限与未来工作"><a href="#5-结论、局限与未来工作" class="headerlink" title="5. 结论、局限与未来工作"></a>5. 结论、局限与未来工作</h4><p>在本研究中，我们分享了通过强化学习提升模型推理能力的探索过程。<strong>DeepSeek-R1-Zero</strong> 代表了一种纯粹基于强化学习的方法，未依赖冷启动数据，却在多个任务上取得了优异表现。而 <strong>DeepSeek-R1</strong> 则更为强大，结合了冷启动数据与迭代式强化学习微调，最终在多个任务上达到了与 <strong>OpenAI-o1-1217</strong> 相当的表现。</p>
<p>我们还进一步探索了如何将推理能力蒸馏到小型稠密模型中。我们使用 <strong>DeepSeek-R1</strong> 作为教师模型，生成了 <strong>80 万条训练样本</strong>，并用这些数据微调了多个小模型。结果令人鼓舞：<strong>DeepSeek-R1-Distill-Qwen-1.5B</strong> 在数学基准测试中表现优异，<strong>在 AIME 上达到 28.9%、在 MATH 上达到 83.9%</strong>，超越了 GPT-4o 和 Claude-3.5-Sonnet。其他小模型也取得了显著成绩，远超同类底座模型的指令微调版本。</p>
<p>未来我们计划从以下几个方向推进 DeepSeek-R1 的研究：</p>
<ul>
<li><strong>通用能力</strong>：当前，DeepSeek-R1 在函数调用、多轮对话、复杂角色扮演、结构化 JSON 输出等任务上仍不及 DeepSeek-V3。未来我们将探索如何利用更长的 CoT（Chain-of-Thought）推理链条来增强这些能力。</li>
<li><strong>多语言混用问题</strong>：DeepSeek-R1 当前主要针对中英文优化，在处理其他语言的输入时，可能出现语言混杂的问题。例如即使用户使用非中英文提问，模型仍可能用英文进行推理与回答。我们计划在后续版本中优化这一问题。</li>
<li><strong>提示词工程（Prompt Engineering）</strong>：我们观察到 DeepSeek-R1 对提示词非常敏感。使用 few-shot 提示词时，模型性能普遍下降。因此我们建议用户<strong>采用 zero-shot 设置</strong>，直接描述问题并明确输出格式，以获得最佳效果。</li>
<li><strong>软件工程任务</strong>：由于软件工程任务的评估耗时较长，影响了 RL 的效率，我们尚未在该领域大规模应用强化学习。因此，DeepSeek-R1 在此类基准上尚未超过 DeepSeek-V3。未来，我们将通过<strong>拒绝采样（rejection sampling）</strong> 或 <strong>在 RL 过程中引入异步评估</strong> 等手段来提升训练效率。</li>
</ul>
<hr>
<h3 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h3><h4 id="1-创意写作、通用问答、文本编辑、摘要生成-各举一个例子"><a href="#1-创意写作、通用问答、文本编辑、摘要生成-各举一个例子" class="headerlink" title="1. 创意写作、通用问答、文本编辑、摘要生成 各举一个例子"></a><strong>1. 创意写作、通用问答、文本编辑、摘要生成 各举一个例子</strong></h4><p>✅ 创意写作（Creative Writing）</p>
<blockquote>
<p><strong>任务例子</strong>：写一首以“秋天的黄昏”为主题的现代诗<br> <strong>模型输出</strong>：<br> <em>“落日流火染山坡，风吹枯叶过老窝，<br> 一地金黄无人拾，唯有黄昏忆蹉跎。”</em></p>
</blockquote>
<p>✅ 通用问答（General Question Answering）</p>
<blockquote>
<p><strong>任务例子</strong>：水的沸点是多少？<br> <strong>模型输出</strong>：100°C（在标准大气压下）</p>
</blockquote>
<p>✅ 文本编辑（Text Editing）</p>
<blockquote>
<p><strong>任务例子</strong>：将句子“他昨天去商店”改为礼貌语气<br> <strong>模型输出</strong>：“他昨天去了商店。”</p>
</blockquote>
<p>✅ 摘要生成（Summarization）</p>
<blockquote>
<p><strong>任务例子</strong>：给一段关于气候变化影响的长文章生成摘要<br> <strong>模型输出</strong>：气候变化正在导致极端天气频发，对农业和生态系统造成显著影响。</p>
</blockquote>
<h4 id="2-长度控制评测-是什么？"><a href="#2-长度控制评测-是什么？" class="headerlink" title="2. 长度控制评测 是什么？"></a><strong>2. 长度控制评测 是什么？</strong></h4><blockquote>
<p>简单说：<strong>评估模型是否能控制生成文本的长度</strong>，比如你说“写一个 50 字的摘要”，模型能否做到接近要求，既不啰嗦也不敷衍。</p>
</blockquote>
<p>🧪 比如在 <strong>AlpacaEval 2.0</strong> 中，它可能会要求：</p>
<ul>
<li>生成“100字以内”的回答；</li>
<li>或者生成“一句话的总结”； 然后人类或模型再去评估它是否：</li>
<li><strong>长度合适</strong></li>
<li><strong>内容完整</strong></li>
<li><strong>表达自然</strong></li>
</ul>
<p>所以 <strong>87.6% 的胜率</strong> 说明 DeepSeek-R1 在“控制输出长度”的任务上非常擅长。</p>
<hr>
<h4 id="3-非考试类问题-是什么？"><a href="#3-非考试类问题-是什么？" class="headerlink" title="3. 非考试类问题 是什么？"></a><strong>3. 非考试类问题 是什么？</strong></h4><blockquote>
<p>就是不是“教科书标准题”的问题，换句话说就是：<strong>更贴近现实、更开放、需要“理解+表达”的题目</strong>。</p>
</blockquote>
<p>📘 对比来看：</p>
<table>
<thead>
<tr>
<th>考试类问题</th>
<th>非考试类问题</th>
</tr>
</thead>
<tbody><tr>
<td>“光合作用的反应式是什么？”</td>
<td>“如何形象地解释光合作用给小孩听？”</td>
</tr>
<tr>
<td>“计算：234×67&#x3D;”</td>
<td>“帮我用 Python 写一个简单的工资计算器”</td>
</tr>
<tr>
<td>“莎士比亚出生在哪一年？”</td>
<td>“写一个像莎士比亚那样的爱情独白”</td>
</tr>
</tbody></table>
<p>DeepSeek-R1 擅长的是后者这类更“开放、灵活、类人类沟通”的问题。</p>
<hr>
<h4 id="4-冷启动-是什么？"><a href="#4-冷启动-是什么？" class="headerlink" title="4. 冷启动 是什么？"></a>4. 冷启动 是什么？</h4><p>“冷启动”（<strong>Cold Start</strong>）这个概念，来源于推荐系统和机器学习领域，意思是：</p>
<blockquote>
<p><strong>在一开始几乎没有数据、没有经验、没有预训练知识的情况下启动模型训练或推理。</strong></p>
</blockquote>
<p>在大模型训练中，它通常有两个含义：</p>
<p>✅ <strong>1. 冷启动模型（Cold Start Model）</strong></p>
<blockquote>
<p>指从一个“什么都没学过”的基础模型（base model）开始训练，而不是从已经微调过的模型继续训练。</p>
</blockquote>
<p>比如：</p>
<ul>
<li>从一个预训练语言模型直接开始做强化学习（RL），<strong>不做 SFT</strong>，这就是冷启动。</li>
<li>如果你先做了 SFT（监督微调），再做 RL，就不是冷启动了。</li>
</ul>
<p>✅ <strong>2. 冷启动数据（Cold Start Data）</strong></p>
<blockquote>
<p>指一开始用来“启动模型学习过程”的那一小部分高质量数据，常用于引导方向。</p>
</blockquote>
<p>这种数据有两个典型特征：</p>
<ul>
<li>量少但关键（比如几千条高质量 CoT 样本）；</li>
<li>用于“破冰”或“暖机”，让模型从一开始就朝正确的方向学习。</li>
</ul>
<p>可以理解为：</p>
<blockquote>
<p>冷启动数据 &#x3D; 少量但高质量的种子数据，用于帮助模型迈出第一步。</p>
</blockquote>
<table>
<thead>
<tr>
<th>模型状态</th>
<th>是否预训练</th>
<th>是否SFT</th>
<th>是否是冷启动</th>
</tr>
</thead>
<tbody><tr>
<td>完全空白模型</td>
<td>❌ 没有</td>
<td>❌ 没有</td>
<td>❌（甚至不实用）</td>
</tr>
<tr>
<td>预训练过的大语言模型（base model）</td>
<td>✅ 有</td>
<td>❌ 没有</td>
<td>✅ 是冷启动</td>
</tr>
<tr>
<td>预训练 + 监督微调（SFT）后再做RL</td>
<td>✅ 有</td>
<td>✅ 有</td>
<td>❌ 不是冷启动</td>
</tr>
</tbody></table>
<hr>
<h4 id="5-价值评估器（critic）和奖励模型（reward-model）关系"><a href="#5-价值评估器（critic）和奖励模型（reward-model）关系" class="headerlink" title="5. 价值评估器（critic）和奖励模型（reward model）关系?"></a>5. 价值评估器（critic）和奖励模型（reward model）关系?</h4><p>🎯 一句话区分</p>
<ul>
<li><strong>奖励模型（Reward Model）</strong>：是<strong>人类偏好评分的模拟器</strong>，负责对「一个完整回答」打一个分，代表“人类喜不喜欢”。</li>
<li><strong>价值评估器（Critic）</strong>：是策略学习中的<strong>强化学习工具</strong>，用来估计“采取某个动作会带来多大的期望回报”。</li>
</ul>
<p>✅ 套用到大模型训练场景</p>
<p>在大模型的 RLHF 中，有三大角色：</p>
<table>
<thead>
<tr>
<th>角色</th>
<th>功能</th>
<th>是否打分</th>
<th>是否可训练</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Actor（策略模型）</strong></td>
<td>生成回答（action）</td>
<td>❌</td>
<td>✅</td>
</tr>
<tr>
<td><strong>Reward Model（奖励模型）</strong></td>
<td>模拟人类打分</td>
<td>✅ 打“整体分”</td>
<td>✅ 但常提前训练好</td>
</tr>
<tr>
<td><strong>Critic（价值模型）</strong></td>
<td>评估每个 token 的期望收益</td>
<td>✅ 打“过程分”</td>
<td>✅ 在 PPO 中实时更新</td>
</tr>
</tbody></table>
<p>🔍 举个例子：</p>
<p>假设你让模型回答一个问题：“如何学好数学？”</p>
<p>模型生成的回答是：</p>
<blockquote>
<p>“1. 多做题；2. 找一本好教材；3. 建立兴趣。”</p>
</blockquote>
<p>✅ 这时候：</p>
<ul>
<li><strong>Reward Model</strong>：给整个回答打个 9&#x2F;10 的分数（基于人类偏好）</li>
<li><strong>Critic</strong>：会评估“第1步好不好”、“第2步是否引人”、“第3步是否是高价值的策略延续”，输出 token-level 的价值估计 $V(s_t)$。</li>
</ul>
<p>🔁 在 PPO 中的工作流程：</p>
<ol>
<li>Actor 生成回答</li>
<li>Reward Model 给出一个整体得分（或使用人类打分训练出来的 RM）</li>
<li>Critic 估计每一步的 token 带来的期望奖励（帮助学习）</li>
<li>用这些分数计算 Advantage（优势函数）来更新 Actor 策略</li>
</ol>
<p>🚀 那么 GRPO 又做了什么？</p>
<p>在 GRPO 中：</p>
<ul>
<li><strong>不训练 Critic</strong>（因为太重）</li>
<li>也 <strong>不用传统的 Reward Model</strong> 给固定分数</li>
<li>而是从 <strong>多个输出中排个序</strong>，比如：<ul>
<li>这组输出中，$ O_3 $ 比 $ O_1 $ 更好，$ O_2 $ 最差</li>
<li>然后用这个“相对好坏”来指导学习</li>
</ul>
</li>
</ul>
<p>所以：</p>
<blockquote>
<p><strong>GRPO 相当于用一组输出内部的相对打分，取代了传统的 Reward Model + Critic 的组合</strong>，更轻更省资源。</p>
</blockquote>
<hr>
<p>如果你用过 OpenAI 的 PPO 代码，你会发现它里面有个 <code>reward_model</code> 和一个 <code>value_head</code>（critic），GRPO 就是把这两个角色“压缩”成了一个“排序评估”。</p>
<hr>
<h4 id="6-PPO–-DPO-or-GRPO"><a href="#6-PPO–-DPO-or-GRPO" class="headerlink" title="6. PPO–&gt;DPO or GRPO ?"></a>6. PPO–&gt;DPO or GRPO ?</h4><p><strong>PPO → DPO</strong> 和 <strong>PPO → GRPO</strong> 其实是<strong>两条不同的发展路线</strong>，都属于 RLHF 的演化方向，但各自有不同的出发点和目标，我们来分清楚：</p>
<p>✅ PPO 被 DPO 替代了吗？</p>
<p>在很多应用场景中，是的：</p>
<blockquote>
<p><strong>DPO（Direct Preference Optimization）</strong> 是目前被广泛认为能“替代 PPO”在大模型训练中的方法，<strong>因为它更简单、更稳定、不需要 reward model</strong>。</p>
</blockquote>
<p>🔁 DPO 的特点：</p>
<ul>
<li><strong>不需要 reward model 或 critic</strong></li>
<li>只用人类偏好的「比较」数据（比如 A 比 B 好）直接优化策略</li>
<li>更像是一种监督学习变体（而不是强化学习）</li>
</ul>
<p>✅ 所以 <strong>DPO 被称为“去RL化的 RLHF”方法</strong></p>
<p>✅ 那 GRPO 是干嘛的？它跟 PPO 是谁的“替代”？</p>
<blockquote>
<p><strong>GRPO 其实是一个真正的 RL 方法，用来优化策略模型，同时尝试降低 PPO 的训练成本。</strong></p>
</blockquote>
<p>GRPO 的目标是：</p>
<ul>
<li>保留 RL 的“策略优化思想”</li>
<li>但去掉成本大的 Critic（或者 reward model）</li>
<li>用组内相对排名代替精确 reward</li>
</ul>
<p>所以它不是走「去RL化」的 DPO 路，而是走「RL 更高效」这条路。</p>
<p>🔍 总结：DPO 和 GRPO 的区别</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>本质</th>
<th>是否 RL</th>
<th>是否需要 reward model</th>
<th>是否需要 critic</th>
<th>优点</th>
</tr>
</thead>
<tbody><tr>
<td><strong>PPO</strong></td>
<td>强化学习</td>
<td>✅ 是</td>
<td>✅ 是</td>
<td>✅ 是</td>
<td>推理能力强，但成本高</td>
</tr>
<tr>
<td><strong>DPO</strong></td>
<td>偏好监督学习</td>
<td>❌ 否</td>
<td>❌ 否</td>
<td>❌ 否</td>
<td>简洁稳定，不需要 RL</td>
</tr>
<tr>
<td><strong>GRPO</strong></td>
<td>RL + 排名估值</td>
<td>✅ 是</td>
<td>❌ 否</td>
<td>❌ 否</td>
<td>RL 思路 + 成本低</td>
</tr>
</tbody></table>
<p>✅ 怎么选？</p>
<table>
<thead>
<tr>
<th>目标</th>
<th>建议方法</th>
</tr>
</thead>
<tbody><tr>
<td>想用 RL 提升推理能力，但训练成本有限</td>
<td>用 <strong>GRPO</strong></td>
</tr>
<tr>
<td>想快速微调、追求简单高效</td>
<td>用 <strong>DPO</strong></td>
</tr>
<tr>
<td>想最大化能力，资源又够</td>
<td>还是 <strong>PPO（或其优化版）</strong></td>
</tr>
</tbody></table>
<hr>
<p>如果你是自己做蒸馏或SFT，可以用 DPO；<br> 如果你搞推理能力强化、实验新的 RLHF 结构，那 GRPO 更有趣。</p>
<hr>
<h4 id="7-介绍下第3-节提到的众多基准测试集"><a href="#7-介绍下第3-节提到的众多基准测试集" class="headerlink" title="7. 介绍下第3.节提到的众多基准测试集"></a>7. 介绍下第3.节提到的众多基准测试集</h4><p>🎓 <strong>通用学术知识与推理</strong></p>
<table>
<thead>
<tr>
<th>Benchmark</th>
<th>能力</th>
<th>简介</th>
</tr>
</thead>
<tbody><tr>
<td><strong>MMLU</strong></td>
<td>多学科常识 + 推理</td>
<td>评估模型在57个中高难度学科（如历史、化学、法律等）上的综合表现。</td>
</tr>
<tr>
<td><strong>MMLU-Redux</strong></td>
<td>更精准的MMLU变体</td>
<td>对MMLU题目进行了更严格的数据清洗与任务定义，更贴近真实推理能力。</td>
</tr>
<tr>
<td><strong>MMLU-Pro</strong></td>
<td>专业难度版MMLU</td>
<td>包含更高难度的问题，主要面向专业领域如工程、医学。</td>
</tr>
<tr>
<td><strong>CMMLU</strong></td>
<td>中文多学科能力</td>
<td>中文版本的MMLU，适配中文背景，评估中文语言和知识掌握能力。</td>
</tr>
<tr>
<td><strong>C-Eval</strong></td>
<td>中文学术知识</td>
<td>涵盖中国初高中到大学阶段的学科考试题，重点在语文、数学、物理等。</td>
</tr>
<tr>
<td><strong>IFEval</strong></td>
<td>格式遵循能力（Instruction Following）</td>
<td>检测模型是否能按用户设定的输出格式返回内容（如JSON、特定表格等）。</td>
</tr>
<tr>
<td><strong>FRAMES</strong></td>
<td>长上下文问答</td>
<td>检测模型在理解和利用多轮对话（或文档）信息中的表现。</td>
</tr>
<tr>
<td><strong>GPQA Diamond</strong></td>
<td>高质量科学推理</td>
<td>聚焦于生物、化学、物理等STEM领域的高难度问题。</td>
</tr>
</tbody></table>
<p>📚 <strong>事实与问答能力</strong></p>
<table>
<thead>
<tr>
<th>Benchmark</th>
<th>能力</th>
<th>简介</th>
</tr>
</thead>
<tbody><tr>
<td><strong>SimpleQA</strong></td>
<td>英文事实问答</td>
<td>简短的、开放域的事实性问题（例如：乔布斯创办了哪家公司？）。</td>
</tr>
<tr>
<td><strong>C-SimpleQA</strong></td>
<td>中文事实问答</td>
<td>中文版本的SimpleQA，检测中文问答能力及模型事实准确性。</td>
</tr>
</tbody></table>
<p>🧮 <strong>数学能力</strong></p>
<table>
<thead>
<tr>
<th>Benchmark</th>
<th>能力</th>
<th>简介</th>
</tr>
</thead>
<tbody><tr>
<td><strong>CNMO 2024</strong></td>
<td>中文数学竞赛</td>
<td>中国高中数学奥林匹克试题，评估高级数学推理与解题能力。</td>
</tr>
<tr>
<td><strong>AIME 2024</strong></td>
<td>美数邀请赛</td>
<td>美国数学邀请赛试题，具有较高难度，注重逻辑与多步推理。</td>
</tr>
<tr>
<td><strong>Math-500</strong></td>
<td>数学推理挑战</td>
<td>包含 500 道高质量数学题，题型涵盖代数、几何、数论、组合等，主要用于评估模型的数学多步推理与解题能力，难度接近 AIME 和 USAMO。注重逻辑严密性与最终答案的准确性。</td>
</tr>
</tbody></table>
<p>💻 <strong>编程与代码能力</strong></p>
<table>
<thead>
<tr>
<th>Benchmark</th>
<th>能力</th>
<th>简介</th>
</tr>
</thead>
<tbody><tr>
<td><strong>LiveCodeBench</strong></td>
<td>实时代码生成</td>
<td>用户提出问题，模型写代码、解释、修复等，模拟真实编程场景。</td>
</tr>
<tr>
<td><strong>Codeforces</strong></td>
<td>算法竞赛题</td>
<td>来自著名算法竞赛平台的题目，考验算法设计与编码实现。</td>
</tr>
<tr>
<td><strong>Aider</strong></td>
<td>工程类编程任务</td>
<td>更贴近真实软件工程任务（如代码修改、Pull Request 自动生成等）。</td>
</tr>
<tr>
<td><strong>SWE-Bench Verified</strong></td>
<td>软件工程问题解决</td>
<td>开源项目真实Issue解决能力测试，是否能写出可用补丁。</td>
</tr>
</tbody></table>
<p>✅ <strong>总结：这些评估维度</strong></p>
<table>
<thead>
<tr>
<th>能力类型</th>
<th>对应基准</th>
</tr>
</thead>
<tbody><tr>
<td><strong>语言&#x2F;通识&#x2F;逻辑推理</strong></td>
<td>MMLU、CMMLU、C-Eval、GPQA、FRAMES</td>
</tr>
<tr>
<td><strong>数学能力</strong></td>
<td>AIME、CNMO</td>
</tr>
<tr>
<td><strong>事实问答能力</strong></td>
<td>SimpleQA、C-SimpleQA</td>
</tr>
<tr>
<td><strong>格式遵循能力</strong></td>
<td>IFEval</td>
</tr>
<tr>
<td><strong>编程&#x2F;工程能力</strong></td>
<td>Codeforces、LiveCodeBench、SWE-Bench、Aider</td>
</tr>
</tbody></table>
<hr>
<h4 id="8-STEM指的是什么"><a href="#8-STEM指的是什么" class="headerlink" title="8. STEM指的是什么"></a>8. STEM指的是什么</h4><p>“<strong>STEM</strong>” 是 “<strong>Science, Technology, Engineering, and Mathematics</strong>” 的缩写，中文一般翻译为 <strong>科学、技术、工程和数学</strong>。</p>
<p>这个术语通常用来泛指以下这几类学科：</p>
<ul>
<li><strong>Science（科学）</strong>：物理、化学、生物、地理等自然科学</li>
<li><strong>Technology（技术）</strong>：信息技术、人工智能、数据科学等</li>
<li><strong>Engineering（工程）</strong>：电子工程、土木工程、机械工程等</li>
<li><strong>Mathematics（数学）</strong>：代数、几何、概率、微积分等</li>
</ul>
<hr>
<p>在语言模型评估中，说“评估模型在 STEM 领域的能力”，意思是：</p>
<blockquote>
<p>测试模型是否能处理好数学题、科学类推理题、代码实现、技术分析等具有<strong>结构性、逻辑性强</strong>的问题。</p>
</blockquote>
<hr>
<p>如果你看到“STEM推理”、“STEM任务”等说法，基本上都是在指：</p>
<blockquote>
<p>“这个任务不是单纯看语言流畅或常识回答，而是需要严谨推导、有步骤的分析，比如做数学题、写代码、解物理题”这类更高阶的智能能力。</p>
</blockquote>
<hr>
<h4 id="9-reward-hacking是什么"><a href="#9-reward-hacking是什么" class="headerlink" title="9. reward hacking是什么"></a>9. reward hacking是什么</h4><p>“<strong>Reward Hacking</strong>（奖励滥用）”是强化学习（Reinforcement Learning, RL）中的一个经典问题，指的是：</p>
<blockquote>
<p><strong>智能体（AI 模型）学会了“作弊”来最大化奖励信号，而不是完成我们真正想要的任务。</strong></p>
</blockquote>
<p>🔍 举个具体的例子：</p>
<p>假设你训练一个 AI 模型玩一个游戏，目标是<strong>吃到尽可能多的金币</strong>，于是你设计了一个奖励函数：</p>
<blockquote>
<p>每吃到一个金币就给 +1 奖励。</p>
</blockquote>
<p>但是，模型发现有一个地图漏洞，它可以无限地在某个地方刷金币、反复吃同一个金币。<br> 它就开始在那个地方疯狂卡 bug 刷分，而不是去认真探索游戏世界。<br> <strong>它确实最大化了奖励……但却完全偏离了我们希望它“聪明玩游戏”的初衷。</strong></p>
<p>这就是 reward hacking。</p>
<p>💥 在语言模型中也会发生：</p>
<p>比如你训练一个模型通过打分模型（Reward Model）来优化输出，期望它生成<strong>有逻辑、有帮助、真实可靠</strong>的答案。<br> 但模型可能学会了“怎么写答案才能让打分模型喜欢”，比如：</p>
<ul>
<li>加很多看起来很“聪明”的逻辑词（如“因此”、“综上”、“由此可得”）；</li>
<li>复制训练集中高分样本的模式，但其实内容胡编；</li>
<li>学会“套路”Reward Model 而不是认真推理。</li>
</ul>
<p>最终效果可能是：<strong>回答看起来很聪明，但其实内容错误或者重复。</strong></p>
<p>📌 这就是为什么很多团队在论文里强调：</p>
<blockquote>
<p>“我们要想办法减少 reward hacking，比如用多样性奖励、对抗式训练、人工校验”等方式去<strong>避免模型走偏</strong>。</p>
</blockquote>
<hr>
<h4 id="10-DeepSeek-R1是怎么训练出来的？"><a href="#10-DeepSeek-R1是怎么训练出来的？" class="headerlink" title="10. DeepSeek-R1是怎么训练出来的？"></a>10. DeepSeek-R1是怎么训练出来的？</h4><p>想回答这个问题，<strong>我们需要先知道DeepSeek-R1-Zero是怎么出来的：</strong></p>
<p>鉴于收集监督数据相当费时，我们探索LLM在没有任何监督数据的情况下发展推理能力的潜力，重点关注它们通过纯强化学习过程的自我进化。<br>1.使用纯GRPO强化学习方法，不使用SFT<br>2.使用奖励函数来代替奖励模型（关注结果准确性和格式准确性）<br>3.定义系统提示词模板引导LLM输出推理过程</p>
<p>好的，现在就得到DeepSeek-R1-Zero了，它有两个问题（语音混乱，可读性差-&gt;没有markdown格式输出），但也展现出了推理方面能力的潜力与自我进化。</p>
<p><strong>一句话描述DeepSeek-R1-Zero：没有输出模板参考，纯靠自发探索。</strong></p>
<p>基于DeepSeek-R1-Zero的探索（优势和劣势），继续了更全面的DeepSeek-R1的开发：</p>
<ol>
<li><p>few-shot形式使用DeepSeek-R1-Zero生成数千条数据并通过人类注标员处理完善</p>
</li>
<li><p>微调之后，使用语言一致性和结果的准确性作为奖励函数进行GRPO</p>
</li>
<li><p>RL收敛后，通过推理提示词，使用该收敛后的模型生成推理类数据，最后通过Deepseek-V3进行拒绝采样（判断结果质量）。并过滤掉以下类型的链式思维内容：混合语言、段落过长、包含代码块等情况。对于每一个提示语，我们采样多个响应，仅保留其中正确的答案。最终，我们共收集了约60 万条与推理相关的训练样本，作为后续 SFT 阶段的数据。</p>
<p>非推理类数据采用 DeepSeek-V3 的数据生成流程，并复用了部分DeepSeek-V3 的监督微调（SFT）数据集。<br>在某些非推理类任务中，调用 DeepSeek-V3在回答问题前通过提示语引导其生成一个可能的 思维链（Chain-of-Thought, CoT）。对于较为简单的请求，例如 “hello”，不会生成 CoT，仅直接给出回复。<br>收集了大约 20 万条与推理无关的训练样本。</p>
<p>总共大约 80 万条数据（60 万推理类 + 20 万非推理类），对 DeepSeek-V3-Base 进行了 <strong>2 轮（epochs）微调训练</strong>。</p>
</li>
<li><p>第3步完成后，进行第二阶段的强化学习，旨在提升模型的有用性（helpfulness）与无害性（harmlessness），同时进一步优化其推理能力。<br> 推理类数据方面，采用 DeepSeek-R1-Zero 中的方法，基于规则的奖励函数来指导模型在数学、代码和逻辑推理领域的学习。<br> 通用任务数据方面，采用奖励模型来捕捉人类在复杂和细腻情境下的偏好。</p>
</li>
</ol>
<p>  基于 DeepSeek-V3 的训练流程，采用类似的偏好对（preference pairs）和训练提示语分布。</p>
<p>  有用性方面，仅评估模型的最终摘要（summary）部分，以确保模型响应对用户具有实用性且内容相关，同时不干扰推理过程。<br>  在无害性方面，我们评估模型整个响应过程，包括推理过程和总结内容，以识别并减轻潜在的风险、偏见或有害内容。</p>
<hr>
]]></content>
      <categories>
        <category>theory</category>
      </categories>
      <tags>
        <tag>llm</tag>
        <tag>deepseek-r1</tag>
      </tags>
  </entry>
  <entry>
    <title>KWS之microWakeWord安装、训练与测试</title>
    <url>/2025/04/03/KWS%E4%B9%8BmicroWakeWord%E5%AE%89%E8%A3%85%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>公司在做一个AI对话玩具，需要语音唤醒功能，想运行在ESP32-S3芯片上，经过调研，觉得<a href="https://github.com/kahrendt/microWakeWord">microWakeWord</a>项目最合适。另一个可能的方案是使用<a href="https://edgeimpulse.com/">Edge Impulse</a>平台进行训练，参考<a href="https://wiki.seeedstudio.com/cn/xiao_esp32s3_keyword_spotting/">这里</a>，有博主也是用的这个方案设计了<a href="https://www.bilibili.com/video/BV11ZrTYrE4p/?buvid=XUA3832AA22EE78A7351BC87C3080F4E6E14D&from_spmid=search.search-result.0.0&is_story_h5=false&mid=l75wYmHAuHqmVrUJdy96xQ==&plat_id=116&share_from=ugc&share_medium=android&share_plat=android&share_session_id=d6a6e4b8-ca14-4af3-a280-0c14c9c628d5&share_source=WEIXIN&share_source=weixin&share_tag=s_i&spmid=united.player-video-detail.0.0&timestamp=1743391874&unique_k=nQCe0ax&up_id=1171991528&vd_source=075a061948e76c87e2ee8754e264056e">小玩意</a>，但是，我认为这个方案不怎么靠谱（我要我觉得）。还是使用microWakeWord吧，这个项目是基于tensorflow的，很久没使用tensorflow进行训练了，基于这个机会也是把ubuntu22.04的显卡驱动、cuda和cudnn都更新了下，见<a href="https://caihaoran-00.github.io/2025/04/02/Ubuntu22-04%E6%9B%B4%E6%96%B0NVIDIA%E9%A9%B1%E5%8A%A8/">这里</a>。本文记录实际使用历程，包括项目安装、代码介绍、训练和简单实际使用测试。</p>
<p><strong>github:<a href="https://github.com/kahrendt/microWakeWord">https://github.com/kahrendt/microWakeWord</a></strong></p>
<span id="more"></span>

<hr>
<h2 id="项目安装"><a href="#项目安装" class="headerlink" title="项目安装"></a>项目安装</h2><h3 id="项目介绍"><a href="#项目介绍" class="headerlink" title="项目介绍"></a>项目介绍</h3><p>首先介绍下microWakeWord这个开源项目是做什么的，项目的About写到：一个基于 TensorFlow 的唤醒词检测训练框架，使用合成样本生成，适用于特定的微控制器。然后在readme中写到：microWakeWord 是一个开源唤醒词库，用于检测低功耗设备上的自定义唤醒词。它生成的模型适合在微控制器上使用<a href="https://www.tensorflow.org/lite/microcontrollers">TensorFlow Lite</a>。这些模型适合实际使用，具有较低的误接受率和误拒绝率。</p>
<p><strong>microWakeword 目前为早期版本。训练新模型旨在供高级用户使用。训练一个运行良好的模型仍然非常困难，因为它通常需要试验超参数和样本生成设置。请分享您发现的有关训练良好模型的任何见解！</strong></p>
<h3 id="项目安装-1"><a href="#项目安装-1" class="headerlink" title="项目安装"></a>项目安装</h3><p>开两个bash，</p>
<p>第一个bash:</p>
<figure class="highlight crmsh"><table><tr><td class="code"><pre><span class="line">conda create -n microwakeword <span class="attr">python=</span><span class="number">3.10</span></span><br><span class="line"></span><br><span class="line">conda activate microwakeword</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建jupyter内核</span></span><br><span class="line">conda install ipykernel</span><br><span class="line">python -m ipykernel install --<span class="keyword">user</span> <span class="title">--name</span> microwakeword --display-name <span class="string">&quot;microwakeword&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 占位符：pip install XXX</span></span><br></pre></td></tr></table></figure>

<p>第二个bash(base环境)：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/kahrendt/microWakeWord.git</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> microwakeword/notebooks</span><br><span class="line"></span><br><span class="line">jupyter notebook</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="代码简单介绍"><a href="#代码简单介绍" class="headerlink" title="代码简单介绍"></a>代码简单介绍</h3><p>原代码见<a href="https://github.com/kahrendt/microWakeWord/blob/main/notebooks/basic_training_notebook.ipynb">这里</a>，microWakeWord提供了一个基于jupyter notebook的”起点”，即训练示例，下面我们简单看一下该jupyter notebook文件。以下为原文翻译和简单的代码解读：</p>
<p><strong>训练微型唤醒词模型</strong></p>
<p>本笔记本将指导您训练一个基础的 <strong>microWakeWord</strong> 模型，适用于高级用户作为起点。建议使用 Python 3.10 运行。</p>
<p><strong>请注意</strong>，生成的模型可能难以触发或误触频繁，因此 <strong>需要尝试多种不同的设置</strong> 以获得可用的模型。在某些代码块的开头，我会标注可以调整的重要参数。</p>
<p>该代码可在 <strong>Google Colab</strong> 上运行，但训练速度 <strong>远低于本地 GPU</strong>。如果必须使用 Colab，请确保 <strong>更改运行时类型为 GPU</strong>，即便如此，训练仍然较慢！</p>
<p><strong>最终成果</strong></p>
<p>运行完本笔记本后，您将获得一个 <strong>tflite 文件</strong>。如果要在 <strong>ESPHome</strong> 中使用此模型，还需要编写 <strong>模型清单 JSON 文件</strong>。请参考 ESPHome 文档和相关模型仓库示例以获取详细信息。</p>
<p><strong>第一块</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Installs microWakeWord. Be sure to restart the session after this is finished.</span></span><br><span class="line"><span class="keyword">import</span> platform</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> platform.system() == <span class="string">&quot;Darwin&quot;</span>:</span><br><span class="line">    <span class="comment"># `pymicro-features` is installed from a fork to support building on macOS</span></span><br><span class="line">    !pip install <span class="string">&#x27;git+https://github.com/puddly/pymicro-features@puddly/minimum-cpp-version&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># `audio-metadata` is installed from a fork to unpin `attrs` from a version that breaks Jupyter</span></span><br><span class="line">!pip install <span class="string">&#x27;git+https://github.com/whatsnowplaying/audio-metadata@d4ebb238e6a401bb1a5aaaac60c9e2b3cb30929f&#x27;</span></span><br><span class="line"></span><br><span class="line">!git clone https://github.com/kahrendt/microWakeWord</span><br><span class="line">!pip install -e ./microWakeWord</span><br></pre></td></tr></table></figure>

<p>这里使用 <code>platform.system()</code> 检测操作系统，如果是 <strong>macOS（Darwin）</strong>，则执行额外的安装步骤。<code>pymicro-features</code> 是一个用于提取微型音频特征的 Python 库。由于官方版本可能在 macOS 上无法正确编译，所以这里从 <strong>puddly</strong> 维护的分支安装了一个兼容版本。</p>
<p><code>audio-metadata</code> 用于处理音频文件的元数据。官方版本依赖 <code>attrs</code> 库的特定版本，但某些版本的 <code>attrs</code> 可能会导致 Jupyter Notebook 运行问题，因此这里安装了 <strong>whatsnowplaying</strong> 维护的分支。</p>
<p>下载 <code>microWakeWord</code> 项目到当前工作目录。</p>
<p><code>-e</code> 选项表示<strong>以开发模式安装</strong>，这样你可以直接修改 <code>microWakeWord</code> 代码，而无需每次都重新安装。</p>
<p>由于 <code>pymicro-features</code> 和 <code>audio-metadata</code> 可能涉及 C++ 依赖库的构建，安装完成后需要重启 Jupyter 内核或 Python 解释器，确保新安装的库能正确加载。</p>
<p><strong>我安装这些库（以及下面的需要安装的库）的时候都是在两个bash窗口中进行的pip安装和克隆，当然小友也可以直接运行jupyter notebook块进行安装。</strong></p>
<p><strong>第二块</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Generates 1 sample of the target word for manual verification.</span></span><br><span class="line"></span><br><span class="line">target_word = <span class="string">&#x27;khum_puter&#x27;</span>  <span class="comment"># Phonetic spellings may produce better samples</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> platform</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Audio</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&quot;./piper-sample-generator&quot;</span>):</span><br><span class="line">    <span class="keyword">if</span> platform.system() == <span class="string">&quot;Darwin&quot;</span>:</span><br><span class="line">        !git clone -b mps-support https://github.com/kahrendt/piper-sample-generator</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        !git clone https://github.com/rhasspy/piper-sample-generator</span><br><span class="line"></span><br><span class="line">    !wget -O piper-sample-generator/models/en_US-libritts_r-medium.pt <span class="string">&#x27;https://github.com/rhasspy/piper-sample-generator/releases/download/v2.0.0/en_US-libritts_r-medium.pt&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Install system dependencies</span></span><br><span class="line">    !pip install torch torchaudio piper-phonemize-cross==<span class="number">1.2</span><span class="number">.1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;piper-sample-generator/&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> sys.path:</span><br><span class="line">        sys.path.append(<span class="string">&quot;piper-sample-generator/&quot;</span>)</span><br><span class="line"></span><br><span class="line">!python3 piper-sample-generator/generate_samples.py <span class="string">&quot;&#123;target_word&#125;&quot;</span> \</span><br><span class="line">--<span class="built_in">max</span>-samples <span class="number">1</span> \</span><br><span class="line">--batch-size <span class="number">1</span> \</span><br><span class="line">--output-<span class="built_in">dir</span> generated_samples</span><br><span class="line"></span><br><span class="line">Audio(<span class="string">&quot;generated_samples/0.wav&quot;</span>, autoplay=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>此代码用于<strong>生成一个目标唤醒词的音频样本</strong>，以便手动验证生成效果。</li>
<li>目标唤醒词设置为 <code>&quot;khum_puter&quot;</code>，使用<strong>拼音化拼写</strong>可能会生成更好的音频样本。</li>
<li>检查 <code>piper-sample-generator</code> 目录是否已存在，若不存在则进行克隆和安装。<strong>Mac 用户</strong> 克隆 <code>kahrendt</code> 维护的 <code>mps-support</code> 分支（支持 Apple M1&#x2F;M2）。<strong>其他系统（Linux&#x2F;Windows）</strong> 克隆 <code>rhasspy</code> 官方仓库。</li>
<li>下载一个 <strong>英文 TTS（Text-to-Speech）模型</strong>，用于合成语音。</li>
<li>安装系统依赖，<code>piper-phonemize-cross==1.2.1</code>：用于将文本转换为语音所需的发音标注工具。</li>
<li>将 <code>piper-sample-generator</code> 加入 Python 路径，确保 <code>piper-sample-generator</code> 可以作为 Python 模块被调用。</li>
<li>生成目标词的音频样本。</li>
<li>调用 <code>generate_samples.py</code> 脚本，<strong>生成 1 个目标唤醒词的音频样本</strong>：<ul>
<li><code>--max-samples 1</code>：生成 1 个样本。</li>
<li><code>--batch-size 1</code>：批处理大小为 1。</li>
<li><code>--output-dir generated_samples</code>：将音频保存到 <code>generated_samples/</code> 目录。</li>
</ul>
</li>
<li>播放生成的音频。读取生成的 <code>0.wav</code> 文件，并自动播放以供验证。</li>
</ul>
<p><strong>第三块：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Generates a larger amount of wake word samples.</span></span><br><span class="line"><span class="comment"># Start here when trying to improve your model.</span></span><br><span class="line"><span class="comment"># See https://github.com/rhasspy/piper-sample-generator for the full set of</span></span><br><span class="line"><span class="comment"># parameters. In particular, experiment with noise-scales and noise-scale-ws,</span></span><br><span class="line"><span class="comment"># generating negative samples similar to the wake word, and generating many more</span></span><br><span class="line"><span class="comment"># wake word samples, possibly with different phonetic pronunciations.</span></span><br><span class="line"></span><br><span class="line">!python3 piper-sample-generator/generate_samples.py <span class="string">&quot;&#123;target_word&#125;&quot;</span> \</span><br><span class="line">--<span class="built_in">max</span>-samples <span class="number">1000</span> \</span><br><span class="line">--batch-size <span class="number">100</span> \</span><br><span class="line">--output-<span class="built_in">dir</span> generated_samples</span><br></pre></td></tr></table></figure>

<p>生成大量唤醒词样本。当尝试改进模型时，从这里开始。请参阅<a href="https://github.com/rhasspy/piper-sample-generator%E8%8E%B7%E5%8F%96%E5%85%A8%E5%A5%97%E5%8F%82%E6%95%B0%E3%80%82%E7%89%B9%E5%88%AB%E6%98%AF%EF%BC%8C%E7%94%A8noise-scale%E5%92%8Cnoise-scale-ws%E8%BF%9B%E8%A1%8C%E5%AE%9E%E9%AA%8C%EF%BC%8C%E7%94%9F%E6%88%90%E4%B8%8E%E5%94%A4%E9%86%92%E8%AF%8D%E7%9B%B8%E4%BC%BC%E7%9A%84%E8%B4%9F%E6%A0%B7%E6%9C%AC%EF%BC%8C%E5%B9%B6%E7%94%9F%E6%88%90%E6%9B%B4%E5%A4%9A%E7%9A%84%E5%94%A4%E9%86%92%E8%AF%8D%E6%A0%B7%E6%9C%AC%EF%BC%8C%E8%BF%99%E4%BA%9B%E6%A0%B7%E6%9C%AC%E5%8F%AF%E8%83%BD%E5%85%B7%E6%9C%89%E4%B8%8D%E5%90%8C%E7%9A%84%E8%AF%AD%E9%9F%B3%E5%8F%91%E9%9F%B3%E3%80%82">https://github.com/rhasspy/piper-sample-generator获取全套参数。特别是，用noise-scale和noise-scale-ws进行实验，生成与唤醒词相似的负样本，并生成更多的唤醒词样本，这些样本可能具有不同的语音发音。</a></p>
<p>该代码用于 <strong>批量生成大量唤醒词音频样本</strong>，以提高模型训练效果。参数含义见第二块。</p>
<p><strong>第四块：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Downloads audio data for augmentation. This can be slow!</span></span><br><span class="line"><span class="comment"># Borrowed from openWakeWord&#x27;s automatic_model_training.ipynb, accessed March 4, 2024</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># **Important note!** The data downloaded here has a mixture of difference</span></span><br><span class="line"><span class="comment"># licenses and usage restrictions. As such, any custom models trained with this</span></span><br><span class="line"><span class="comment"># data should be considered as appropriate for **non-commercial** personal use only.</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> scipy</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="comment">## Download MIR RIR data</span></span><br><span class="line"></span><br><span class="line">output_dir = <span class="string">&quot;./mit_rirs&quot;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(output_dir):</span><br><span class="line">    os.mkdir(output_dir)</span><br><span class="line">    rir_dataset = datasets.load_dataset(<span class="string">&quot;davidscripka/MIT_environmental_impulse_responses&quot;</span>, split=<span class="string">&quot;train&quot;</span>, streaming=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># Save clips to 16-bit PCM wav files</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> tqdm(rir_dataset):</span><br><span class="line">        name = row[<span class="string">&#x27;audio&#x27;</span>][<span class="string">&#x27;path&#x27;</span>].split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>]</span><br><span class="line">        scipy.io.wavfile.write(os.path.join(output_dir, name), <span class="number">16000</span>, (row[<span class="string">&#x27;audio&#x27;</span>][<span class="string">&#x27;array&#x27;</span>]*<span class="number">32767</span>).astype(np.int16))</span><br><span class="line">        </span><br><span class="line"><span class="comment">## Download noise and background audio</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Audioset Dataset (https://research.google.com/audioset/dataset/index.html)</span></span><br><span class="line"><span class="comment"># Download one part of the audioset .tar files, extract, and convert to 16khz</span></span><br><span class="line"><span class="comment"># For full-scale training, it&#x27;s recommended to download the entire dataset from</span></span><br><span class="line"><span class="comment"># https://huggingface.co/datasets/agkphysics/AudioSet, and</span></span><br><span class="line"><span class="comment"># even potentially combine it with other background noise datasets (e.g., FSD50k, Freesound, etc.)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&quot;audioset&quot;</span>):</span><br><span class="line">    os.mkdir(<span class="string">&quot;audioset&quot;</span>)</span><br><span class="line"></span><br><span class="line">    fname = <span class="string">&quot;bal_train09.tar&quot;</span></span><br><span class="line">    out_dir = <span class="string">f&quot;audioset/<span class="subst">&#123;fname&#125;</span>&quot;</span></span><br><span class="line">    link = <span class="string">&quot;https://huggingface.co/datasets/agkphysics/AudioSet/resolve/main/data/&quot;</span> + fname</span><br><span class="line">    !wget -O &#123;out_dir&#125; &#123;link&#125;</span><br><span class="line">    !cd audioset &amp;&amp; tar -xf bal_train09.tar</span><br><span class="line"></span><br><span class="line">    output_dir = <span class="string">&quot;./audioset_16k&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(output_dir):</span><br><span class="line">        os.mkdir(output_dir)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Save clips to 16-bit PCM wav files</span></span><br><span class="line">    audioset_dataset = datasets.Dataset.from_dict(&#123;<span class="string">&quot;audio&quot;</span>: [<span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> Path(<span class="string">&quot;audioset/audio&quot;</span>).glob(<span class="string">&quot;**/*.flac&quot;</span>)]&#125;)</span><br><span class="line">    audioset_dataset = audioset_dataset.cast_column(<span class="string">&quot;audio&quot;</span>, datasets.Audio(sampling_rate=<span class="number">16000</span>))</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> tqdm(audioset_dataset):</span><br><span class="line">        name = row[<span class="string">&#x27;audio&#x27;</span>][<span class="string">&#x27;path&#x27;</span>].split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>].replace(<span class="string">&quot;.flac&quot;</span>, <span class="string">&quot;.wav&quot;</span>)</span><br><span class="line">        scipy.io.wavfile.write(os.path.join(output_dir, name), <span class="number">16000</span>, (row[<span class="string">&#x27;audio&#x27;</span>][<span class="string">&#x27;array&#x27;</span>]*<span class="number">32767</span>).astype(np.int16))</span><br><span class="line">        </span><br><span class="line"><span class="comment"># Free Music Archive dataset</span></span><br><span class="line"><span class="comment"># https://github.com/mdeff/fma</span></span><br><span class="line"><span class="comment"># (Third-party mchl914 extra small set)</span></span><br><span class="line"></span><br><span class="line">output_dir = <span class="string">&quot;./fma&quot;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(output_dir):</span><br><span class="line">    os.mkdir(output_dir)</span><br><span class="line">    fname = <span class="string">&quot;fma_xs.zip&quot;</span></span><br><span class="line">    link = <span class="string">&quot;https://huggingface.co/datasets/mchl914/fma_xsmall/resolve/main/&quot;</span> + fname</span><br><span class="line">    out_dir = <span class="string">f&quot;fma/<span class="subst">&#123;fname&#125;</span>&quot;</span></span><br><span class="line">    !wget -O &#123;out_dir&#125; &#123;link&#125;</span><br><span class="line">    !cd &#123;output_dir&#125; &amp;&amp; unzip -q &#123;fname&#125;</span><br><span class="line"></span><br><span class="line">    output_dir = <span class="string">&quot;./fma_16k&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(output_dir):</span><br><span class="line">        os.mkdir(output_dir)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Save clips to 16-bit PCM wav files</span></span><br><span class="line">    fma_dataset = datasets.Dataset.from_dict(&#123;<span class="string">&quot;audio&quot;</span>: [<span class="built_in">str</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> Path(<span class="string">&quot;fma/fma_small&quot;</span>).glob(<span class="string">&quot;**/*.mp3&quot;</span>)]&#125;)</span><br><span class="line">    fma_dataset = fma_dataset.cast_column(<span class="string">&quot;audio&quot;</span>, datasets.Audio(sampling_rate=<span class="number">16000</span>))</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> tqdm(fma_dataset):</span><br><span class="line">        name = row[<span class="string">&#x27;audio&#x27;</span>][<span class="string">&#x27;path&#x27;</span>].split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>].replace(<span class="string">&quot;.mp3&quot;</span>, <span class="string">&quot;.wav&quot;</span>)</span><br><span class="line">        scipy.io.wavfile.write(os.path.join(output_dir, name), <span class="number">16000</span>, (row[<span class="string">&#x27;audio&#x27;</span>][<span class="string">&#x27;array&#x27;</span>]*<span class="number">32767</span>).astype(np.int16))</span><br></pre></td></tr></table></figure>

<p>此代码段用于 <strong>下载、解压、转换</strong> 不同来源的音频数据，包括 <strong>混响响应 (RIR) 数据、背景噪声</strong>，用于 <strong>数据增强</strong>，提高唤醒词模型的鲁棒性。</p>
<p>下载并处理 MIT 环境脉冲响应（RIR）数据，<strong>用于模拟不同的房间环境</strong>（混响），<strong>转换为 16-bit PCM <code>.wav</code> 文件</strong>，以匹配训练数据格式</p>
<p>下载 Audioset（Google research的噪声数据集）,<strong>包含各种背景噪声</strong>，如城市噪声、自然环境声音，<strong>解压并转换为 16kHz WAV 格式</strong></p>
<p>下载 Free Music Archive（FMA）数据集，<strong>用于背景音乐增强</strong>，帮助模型学习在有音乐的环境中触发，<strong>解压并转换 MP3 到 WAV</strong></p>
<p><strong>第五块</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Sets up the augmentations.</span></span><br><span class="line"><span class="comment"># To improve your model, experiment with these settings and use more sources of</span></span><br><span class="line"><span class="comment"># background clips.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> microwakeword.audio.augmentation <span class="keyword">import</span> Augmentation</span><br><span class="line"><span class="keyword">from</span> microwakeword.audio.clips <span class="keyword">import</span> Clips</span><br><span class="line"><span class="keyword">from</span> microwakeword.audio.spectrograms <span class="keyword">import</span> SpectrogramGeneration</span><br><span class="line"></span><br><span class="line">clips = Clips(input_directory=<span class="string">&#x27;generated_samples&#x27;</span>,</span><br><span class="line">              file_pattern=<span class="string">&#x27;*.wav&#x27;</span>,</span><br><span class="line">              max_clip_duration_s=<span class="literal">None</span>,</span><br><span class="line">              remove_silence=<span class="literal">False</span>,</span><br><span class="line">              random_split_seed=<span class="number">10</span>,</span><br><span class="line">              split_count=<span class="number">0.1</span>,</span><br><span class="line">              )</span><br><span class="line">augmenter = Augmentation(augmentation_duration_s=<span class="number">3.2</span>,</span><br><span class="line">                         augmentation_probabilities = &#123;</span><br><span class="line">                                <span class="string">&quot;SevenBandParametricEQ&quot;</span>: <span class="number">0.1</span>,</span><br><span class="line">                                <span class="string">&quot;TanhDistortion&quot;</span>: <span class="number">0.1</span>,</span><br><span class="line">                                <span class="string">&quot;PitchShift&quot;</span>: <span class="number">0.1</span>,</span><br><span class="line">                                <span class="string">&quot;BandStopFilter&quot;</span>: <span class="number">0.1</span>,</span><br><span class="line">                                <span class="string">&quot;AddColorNoise&quot;</span>: <span class="number">0.1</span>,</span><br><span class="line">                                <span class="string">&quot;AddBackgroundNoise&quot;</span>: <span class="number">0.75</span>,</span><br><span class="line">                                <span class="string">&quot;Gain&quot;</span>: <span class="number">1.0</span>,</span><br><span class="line">                                <span class="string">&quot;RIR&quot;</span>: <span class="number">0.5</span>,</span><br><span class="line">                            &#125;,</span><br><span class="line">                         impulse_paths = [<span class="string">&#x27;mit_rirs&#x27;</span>],</span><br><span class="line">                         background_paths = [<span class="string">&#x27;fma_16k&#x27;</span>, <span class="string">&#x27;audioset_16k&#x27;</span>],</span><br><span class="line">                         background_min_snr_db = -<span class="number">5</span>,</span><br><span class="line">                         background_max_snr_db = <span class="number">10</span>,</span><br><span class="line">                         min_jitter_s = <span class="number">0.195</span>,</span><br><span class="line">                         max_jitter_s = <span class="number">0.205</span>,</span><br><span class="line">                         )</span><br></pre></td></tr></table></figure>

<p>设置数据增强配置。要改进您的模型，请试验这些设置并使用更多的背景噪声切片。</p>
<p>这段代码用于 <strong>设置和执行音频增强</strong>，以提高模型的鲁棒性和泛化能力。增强的主要目的是通过添加不同类型的噪声和变换来模拟不同的环境和设备条件，使得模型能够适应更多实际场景。</p>
<ul>
<li>初始化音频剪辑（Clips）<ul>
<li>从 <code>generated_samples</code> 目录中读取 <code>.wav</code> 文件。</li>
<li>通过随机拆分和去除静音部分，提高样本的多样性。</li>
</ul>
</li>
<li>设置增强方法（Augmentation），通过指定不同的增强方法和它们的概率来增强音频数据。常见的增强方法包括：<ul>
<li><strong>SevenBandParametricEQ</strong>：调整音频的频带</li>
<li><strong>PitchShift</strong>：改变音高</li>
<li><strong>BandStopFilter</strong>：使用带阻滤波器去除特定频段的声音</li>
<li><strong>AddColorNoise</strong>：添加颜色噪声。</li>
<li><strong>AddBackgroundNoise</strong>：将背景噪声添加到音频中（最常用）。</li>
<li><strong>Gain</strong>：调整音量增益。</li>
<li><strong>RIR（Room Impulse Response）</strong>：模拟房间混响效果。</li>
</ul>
</li>
</ul>
<p><strong>参数解析</strong>：</p>
<ul>
<li><strong><code>augmentation_duration_s=3.2</code></strong>: 设置每个增强音频的持续时间为 3.2 秒。</li>
<li><strong><code>augmentation_probabilities</code></strong>: 每种增强方法的应用概率。例如，背景噪声的应用概率为 75%。</li>
<li><strong><code>impulse_paths</code></strong>: 环境混响（RIR）的路径。使用 <code>mit_rirs</code> 数据集来模拟不同的房间混响效果。</li>
<li><strong><code>background_paths</code></strong>: 背景噪声数据的路径，包括 FMA 和 Audioset 数据集。</li>
<li><strong><code>background_min_snr_db</code> 和 <code>background_max_snr_db</code></strong>: 控制背景噪声的信噪比（SNR）。</li>
<li><strong><code>min_jitter_s</code> 和 <code>max_jitter_s</code></strong>: 控制音频抖动（随机偏移）。</li>
</ul>
<blockquote>
<p>随机偏移，简单理解：比如是0.2，那么音频前0.2 s就没了，现数据从原数据的0.2 s开始。说是这样可以增加训练数据的多样性，并且帮助模型学习到音频时间的变化，提升模型对实际场景中不同设备和延迟的适应能力（同一个音频使用一次以上才有意义吧）。</p>
</blockquote>
<p><strong>第六块：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Augment a random clip and play it back to verify it works well</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Audio</span><br><span class="line"><span class="keyword">from</span> microwakeword.audio.audio_utils <span class="keyword">import</span> save_clip</span><br><span class="line"></span><br><span class="line">random_clip = clips.get_random_clip()</span><br><span class="line">augmented_clip = augmenter.augment_clip(random_clip)</span><br><span class="line">save_clip(augmented_clip, <span class="string">&#x27;augmented_clip.wav&#x27;</span>)</span><br><span class="line"></span><br><span class="line">Audio(<span class="string">&quot;augmented_clip.wav&quot;</span>, autoplay=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p><strong>对一个随机音频样本进行数据增强，并播放增强后的音频</strong>，以便人工验证增强效果是否合理。</p>
<ul>
<li>从 <code>clips</code>（即 <code>Clips</code> 类的实例）中随机选取一个音频样本。</li>
<li>通过 <code>Augmentation</code> 类的 <code>augment_clip()</code> 方法对选中的音频进行数据增强</li>
<li>之前定义的 <code>augmenter</code> 已经设定了一系列增强方式，<code>augment_clip()</code> 会对音频进行这些随机变换，使得训练数据更加丰富。</li>
</ul>
<p><strong>第七块：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Augment samples and save the training, validation, and testing sets.</span></span><br><span class="line"><span class="comment"># Validating and testing samples generated the same way can make the model</span></span><br><span class="line"><span class="comment"># benchmark better than it performs in real-word use. Use real samples or TTS</span></span><br><span class="line"><span class="comment"># samples generated with a different TTS engine to potentially get more accurate</span></span><br><span class="line"><span class="comment"># benchmarks.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> mmap_ninja.ragged <span class="keyword">import</span> RaggedMmap</span><br><span class="line"></span><br><span class="line">output_dir = <span class="string">&#x27;generated_augmented_features&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(output_dir):</span><br><span class="line">    os.mkdir(output_dir)</span><br><span class="line"></span><br><span class="line">splits = [<span class="string">&quot;training&quot;</span>, <span class="string">&quot;validation&quot;</span>, <span class="string">&quot;testing&quot;</span>]</span><br><span class="line"><span class="keyword">for</span> split <span class="keyword">in</span> splits:</span><br><span class="line">  out_dir = os.path.join(output_dir, split)</span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(out_dir):</span><br><span class="line">      os.mkdir(out_dir)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  split_name = <span class="string">&quot;train&quot;</span></span><br><span class="line">  repetition = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">  spectrograms = SpectrogramGeneration(clips=clips,</span><br><span class="line">                                     augmenter=augmenter,</span><br><span class="line">                                     slide_frames=<span class="number">10</span>,    <span class="comment"># Uses the same spectrogram repeatedly, just shifted over by one frame. This simulates the streaming inferences while training/validating in nonstreaming mode.</span></span><br><span class="line">                                     step_ms=<span class="number">10</span>,</span><br><span class="line">                                     )</span><br><span class="line">  <span class="keyword">if</span> split == <span class="string">&quot;validation&quot;</span>:</span><br><span class="line">    split_name = <span class="string">&quot;validation&quot;</span></span><br><span class="line">    repetition = <span class="number">1</span></span><br><span class="line">  <span class="keyword">elif</span> split == <span class="string">&quot;testing&quot;</span>:</span><br><span class="line">    split_name = <span class="string">&quot;test&quot;</span></span><br><span class="line">    repetition = <span class="number">1</span></span><br><span class="line">    spectrograms = SpectrogramGeneration(clips=clips,</span><br><span class="line">                                     augmenter=augmenter,</span><br><span class="line">                                     slide_frames=<span class="number">1</span>,    <span class="comment"># The testing set uses the streaming version of the model, so no artificial repetition is necessary</span></span><br><span class="line">                                     step_ms=<span class="number">10</span>,</span><br><span class="line">                                     )</span><br><span class="line">    </span><br><span class="line"> RaggedMmap.from_generator(</span><br><span class="line">      out_dir=os.path.join(out_dir, <span class="string">&#x27;wakeword_mmap&#x27;</span>),</span><br><span class="line">      sample_generator=spectrograms.spectrogram_generator(split=split_name, repeat=repetition),</span><br><span class="line">      batch_size=<span class="number">100</span>,</span><br><span class="line">      verbose=<span class="literal">True</span>,</span><br><span class="line">  )</span><br></pre></td></tr></table></figure>

<p>增强样本并保存训练、验证和测试集。以相同方式生成的验证和测试样本可能会使模型的基准测试结果优于其在真实世界中的实际表现。建议使用真实样本或由不同 TTS 引擎生成的 TTS 样本，以获得更准确的基准测试结果<br><strong>对唤醒词数据集进行数据增强，并将其转换为训练、验证和测试集的特征数据</strong>。</p>
<ul>
<li><code>generated_augmented_features</code> 目录用于存储增强后的训练、验证和测试数据</li>
<li>在 <code>generated_augmented_features</code> 目录下分别创建 <code>training</code>、<code>validation</code> 和 <code>testing</code> 三个子文件夹</li>
<li>初始化 <code>SpectrogramGeneration</code> 处理音频，<strong><code>SpectrogramGeneration</code> 作用</strong>：<ul>
<li>从 <code>clips</code> 读取音频片段。</li>
<li>通过 <code>augmenter</code> 进行数据增强。</li>
<li>生成频谱图特征（spectrogram）</li>
</ul>
</li>
<li><code>slide_frames=10</code>：通过在频谱图上滑动 10 帧，使相同的音频片段在训练时以不同时间偏移输入，模拟流式推理。<code>step_ms=10</code>：每 10ms 计算一个新的帧特征。</li>
<li>生成数据并保存为 <code>RaggedMmap</code> 文件，<ul>
<li>处理 <code>spectrogram_generator()</code> 生成的频谱数据。</li>
<li>将特征数据存储为 <code>wakeword_mmap</code> 文件，提高后续训练速度。</li>
<li><code>batch_size=100</code>，意味着每次处理 100 个样本，提高效率。</li>
<li><code>verbose=True</code>，显示详细进度信息。</li>
</ul>
</li>
</ul>
<p><strong>第八块：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Save a yaml config that controls the training process</span></span><br><span class="line"><span class="comment"># These hyperparamters can make a huge different in model quality.</span></span><br><span class="line"><span class="comment"># Experiment with sampling and penalty weights and increasing the number of</span></span><br><span class="line"><span class="comment"># training steps.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> yaml</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">config = &#123;&#125;</span><br><span class="line"></span><br><span class="line">config[<span class="string">&quot;window_step_ms&quot;</span>] = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">config[<span class="string">&quot;train_dir&quot;</span>] = (</span><br><span class="line">    <span class="string">&quot;trained_models/wakeword&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Each feature_dir should have at least one of the following folders with this structure:</span></span><br><span class="line"><span class="comment">#  training/</span></span><br><span class="line"><span class="comment">#    ragged_mmap_folders_ending_in_mmap</span></span><br><span class="line"><span class="comment">#  testing/</span></span><br><span class="line"><span class="comment">#    ragged_mmap_folders_ending_in_mmap</span></span><br><span class="line"><span class="comment">#  testing_ambient/</span></span><br><span class="line"><span class="comment">#    ragged_mmap_folders_ending_in_mmap</span></span><br><span class="line"><span class="comment">#  validation/</span></span><br><span class="line"><span class="comment">#    ragged_mmap_folders_ending_in_mmap</span></span><br><span class="line"><span class="comment">#  validation_ambient/</span></span><br><span class="line"><span class="comment">#    ragged_mmap_folders_ending_in_mmap</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#  sampling_weight: Weight for choosing a spectrogram from this set in the batch</span></span><br><span class="line"><span class="comment">#  penalty_weight: Penalizing weight for incorrect predictions from this set</span></span><br><span class="line"><span class="comment">#  truth: Boolean whether this set has positive samples or negative samples</span></span><br><span class="line"><span class="comment">#  truncation_strategy = If spectrograms in the set are longer than necessary for training, how are they truncated</span></span><br><span class="line"><span class="comment">#       - random: choose a random portion of the entire spectrogram - useful for long negative samples</span></span><br><span class="line"><span class="comment">#       - truncate_start: remove the start of the spectrogram</span></span><br><span class="line"><span class="comment">#       - truncate_end: remove the end of the spectrogram</span></span><br><span class="line"><span class="comment">#       - split: Split the longer spectrogram into separate spectrograms offset by 100 ms. Only for ambient sets</span></span><br><span class="line"></span><br><span class="line">config[<span class="string">&quot;features&quot;</span>] = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;features_dir&quot;</span>: <span class="string">&quot;generated_augmented_features&quot;</span>,</span><br><span class="line">        <span class="string">&quot;sampling_weight&quot;</span>: <span class="number">2.0</span>,</span><br><span class="line">        <span class="string">&quot;penalty_weight&quot;</span>: <span class="number">1.0</span>,</span><br><span class="line">        <span class="string">&quot;truth&quot;</span>: <span class="literal">True</span>,</span><br><span class="line">        <span class="string">&quot;truncation_strategy&quot;</span>: <span class="string">&quot;truncate_start&quot;</span>,</span><br><span class="line">        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;mmap&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;features_dir&quot;</span>: <span class="string">&quot;negative_datasets/speech&quot;</span>,</span><br><span class="line">        <span class="string">&quot;sampling_weight&quot;</span>: <span class="number">10.0</span>,</span><br><span class="line">        <span class="string">&quot;penalty_weight&quot;</span>: <span class="number">1.0</span>,</span><br><span class="line">        <span class="string">&quot;truth&quot;</span>: <span class="literal">False</span>,</span><br><span class="line">        <span class="string">&quot;truncation_strategy&quot;</span>: <span class="string">&quot;random&quot;</span>,</span><br><span class="line">        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;mmap&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;features_dir&quot;</span>: <span class="string">&quot;negative_datasets/dinner_party&quot;</span>,</span><br><span class="line">        <span class="string">&quot;sampling_weight&quot;</span>: <span class="number">10.0</span>,</span><br><span class="line">        <span class="string">&quot;penalty_weight&quot;</span>: <span class="number">1.0</span>,</span><br><span class="line">        <span class="string">&quot;truth&quot;</span>: <span class="literal">False</span>,</span><br><span class="line">        <span class="string">&quot;truncation_strategy&quot;</span>: <span class="string">&quot;random&quot;</span>,</span><br><span class="line">        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;mmap&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;features_dir&quot;</span>: <span class="string">&quot;negative_datasets/no_speech&quot;</span>,</span><br><span class="line">        <span class="string">&quot;sampling_weight&quot;</span>: <span class="number">5.0</span>,</span><br><span class="line">        <span class="string">&quot;penalty_weight&quot;</span>: <span class="number">1.0</span>,</span><br><span class="line">        <span class="string">&quot;truth&quot;</span>: <span class="literal">False</span>,</span><br><span class="line">        <span class="string">&quot;truncation_strategy&quot;</span>: <span class="string">&quot;random&quot;</span>,</span><br><span class="line">        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;mmap&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123; <span class="comment"># Only used for validation and testing</span></span><br><span class="line">        <span class="string">&quot;features_dir&quot;</span>: <span class="string">&quot;negative_datasets/dinner_party_eval&quot;</span>,</span><br><span class="line">        <span class="string">&quot;sampling_weight&quot;</span>: <span class="number">0.0</span>,</span><br><span class="line">        <span class="string">&quot;penalty_weight&quot;</span>: <span class="number">1.0</span>,</span><br><span class="line">        <span class="string">&quot;truth&quot;</span>: <span class="literal">False</span>,</span><br><span class="line">        <span class="string">&quot;truncation_strategy&quot;</span>: <span class="string">&quot;split&quot;</span>,</span><br><span class="line">        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;mmap&quot;</span>,</span><br><span class="line">    &#125;,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Number of training steps in each iteration - various other settings are configured as lists that corresponds to different steps</span></span><br><span class="line">config[<span class="string">&quot;training_steps&quot;</span>] = [<span class="number">10000</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Penalizing weight for incorrect class predictions - lists that correspond to training steps</span></span><br><span class="line">config[<span class="string">&quot;positive_class_weight&quot;</span>] = [<span class="number">1</span>]</span><br><span class="line">config[<span class="string">&quot;negative_class_weight&quot;</span>] = [<span class="number">20</span>]</span><br><span class="line"></span><br><span class="line">config[<span class="string">&quot;learning_rates&quot;</span>] = [</span><br><span class="line">    <span class="number">0.001</span>,</span><br><span class="line">]  <span class="comment"># Learning rates for Adam optimizer - list that corresponds to training steps</span></span><br><span class="line">config[<span class="string">&quot;batch_size&quot;</span>] = <span class="number">128</span></span><br><span class="line"></span><br><span class="line">config[<span class="string">&quot;time_mask_max_size&quot;</span>] = [</span><br><span class="line">    <span class="number">0</span></span><br><span class="line">]  <span class="comment"># SpecAugment - list that corresponds to training steps</span></span><br><span class="line">config[<span class="string">&quot;time_mask_count&quot;</span>] = [<span class="number">0</span>]  <span class="comment"># SpecAugment - list that corresponds to training steps</span></span><br><span class="line">config[<span class="string">&quot;freq_mask_max_size&quot;</span>] = [</span><br><span class="line">    <span class="number">0</span></span><br><span class="line">]  <span class="comment"># SpecAugment - list that corresponds to training steps</span></span><br><span class="line">config[<span class="string">&quot;freq_mask_count&quot;</span>] = [<span class="number">0</span>]  <span class="comment"># SpecAugment - list that corresponds to training steps</span></span><br><span class="line"></span><br><span class="line">config[<span class="string">&quot;eval_step_interval&quot;</span>] = (</span><br><span class="line">    <span class="number">500</span>  <span class="comment"># Test the validation sets after every this many steps</span></span><br><span class="line">)</span><br><span class="line">config[<span class="string">&quot;clip_duration_ms&quot;</span>] = (</span><br><span class="line">    <span class="number">1500</span>  <span class="comment"># Maximum length of wake word that the streaming model will accept</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># The best model weights are chosen first by minimizing the specified minimization metric below the specified target_minimization</span></span><br><span class="line"><span class="comment"># Once the target has been met, it chooses the maximum of the maximization metric. Set &#x27;minimization_metric&#x27; to None to only maximize</span></span><br><span class="line"><span class="comment"># Available metrics:</span></span><br><span class="line"><span class="comment">#   - &quot;loss&quot; - cross entropy error on validation set</span></span><br><span class="line"><span class="comment">#   - &quot;accuracy&quot; - accuracy of validation set</span></span><br><span class="line"><span class="comment">#   - &quot;recall&quot; - recall of validation set</span></span><br><span class="line"><span class="comment">#   - &quot;precision&quot; - precision of validation set</span></span><br><span class="line"><span class="comment">#   - &quot;false_positive_rate&quot; - false positive rate of validation set</span></span><br><span class="line"><span class="comment">#   - &quot;false_negative_rate&quot; - false negative rate of validation set</span></span><br><span class="line"><span class="comment">#   - &quot;ambient_false_positives&quot; - count of false positives from the split validation_ambient set</span></span><br><span class="line"><span class="comment">#   - &quot;ambient_false_positives_per_hour&quot; - estimated number of false positives per hour on the split validation_ambient set</span></span><br><span class="line">config[<span class="string">&quot;target_minimization&quot;</span>] = <span class="number">0.9</span></span><br><span class="line">config[<span class="string">&quot;minimization_metric&quot;</span>] = <span class="literal">None</span>  <span class="comment"># Set to None to disable</span></span><br><span class="line"></span><br><span class="line">config[<span class="string">&quot;maximization_metric&quot;</span>] = <span class="string">&quot;average_viable_recall&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(<span class="string">&quot;training_parameters.yaml&quot;</span>), <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    documents = yaml.dump(config, file)</span><br></pre></td></tr></table></figure>

<p>这段代码的目的是生成一个 YAML 配置文件 (<code>training_parameters.yaml</code>)，该文件用于控制训练过程中的一些重要超参数（hyperparameters），这些超参数可以显著影响模型的质量。</p>
<ul>
<li><code>yaml</code>：用于生成和读取 YAML 文件的库。YAML 格式常用于保存配置文件</li>
<li>创建了一个空字典 <code>config</code>，后续会将训练相关的配置项添加到该字典中</li>
<li>设置一些基本参数，<code>window_step_ms</code>: 设置窗口步长（时间步长），单位是毫秒，表示每步滑动的时间长度。<code>train_dir</code>: 设置训练模型存储的目录路径。</li>
<li>设置特征数据集配置，<code>features</code>: 一个列表，包含多个字典，每个字典描述一个特征数据集。<ul>
<li><code>features_dir</code>: 存储特征数据集的目录。</li>
<li><code>sampling_weight</code>: 设置该数据集的采样权重，表示在训练过程中该数据集的重要性（权重越大，模型训练时选择该数据集的概率越大，即每个样本使用几次）。</li>
<li><code>penalty_weight</code>: 错误预测的惩罚权重。预测错误时该数据集的影响会根据该权重增加。</li>
<li><code>truth</code>: 布尔值，表示该数据集是否包含正样本（<code>True</code>）还是负样本（<code>False</code>）。</li>
<li><code>truncation_strategy</code>: 对超长的频谱图进行截断的策略，具体值包括：<ul>
<li><code>random</code>: 随机选择频谱图的一部分。</li>
<li><code>truncate_start</code>: 从频谱图的开始位置去掉一部分。</li>
<li><code>truncate_end</code>: 从频谱图的结尾去掉一部分。</li>
<li><code>split</code>: 将长频谱图切分为多个小频谱图。</li>
</ul>
</li>
<li><code>type</code>: 数据集的类型，通常是 <code>mmap</code>，表示存储为 <code>mmap</code> 格式的文件。</li>
</ul>
</li>
<li><code>training_steps</code>: 设置训练的步骤数，这里设定为 10000 步。<code>positive_class_weight</code> 和 <code>negative_class_weight</code>: 设置正负类的权重。比如，负类的权重大于正类的权重（20 vs 1），意味着训练过程中负样本的影响更大。</li>
<li><code>learning_rates</code>: 设置 Adam 优化器的学习率。<code>batch_size</code>: 每次训练的批次大小，表示每次训练所用的样本数。</li>
<li><code>time_mask_max_size</code> 和 <code>freq_mask_max_size</code>: 控制时域和频域掩码的最大大小。时间掩码和频率掩码是 SpecAugment 数据增强的一部分，用于扰动频谱图。<code>time_mask_count</code> 和 <code>freq_mask_count</code>: 控制时间和频率掩码的应用数量。设置为 <code>0</code> 表示不使用 SpecAugment。</li>
<li><code>eval_step_interval</code>: 每训练多少步进行一次评估，这里设定为每 500 步进行一次评估。<code>clip_duration_ms</code>: 流式模型接受的最大语音片段长度，单位是毫秒。</li>
<li><code>target_minimization</code>: 目标最小化指标的阈值，模型需要尽量将该指标降到这个值以下。<code>minimization_metric</code>: 用于最小化的指标，常见的指标有 <code>loss</code>, <code>accuracy</code>, <code>recall</code> 等。设置为 <code>None</code> 表示不使用最小化指标。<code>maximization_metric</code>: 用于最大化的指标，这里设置为 <code>average_viable_recall</code>，表示希望最大化可行召回率。</li>
<li>最后，使用 <code>yaml.dump()</code> 将 <code>config</code> 字典保存为一个 YAML 配置文件，文件名为 <code>training_parameters.yaml</code>。</li>
</ul>
<p><strong>第九块：</strong></p>
<figure class="highlight livescript"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Trains a model. When finished, it will quantize and convert the model to a</span></span><br><span class="line"><span class="comment"># streaming version suitable for on-device detection.</span></span><br><span class="line"><span class="comment"># It will resume if stopped, but it will start over at the configured training</span></span><br><span class="line"><span class="comment"># steps in the yaml file.</span></span><br><span class="line"><span class="comment"># Change --train 0 to only convert and test the best-weighted model.</span></span><br><span class="line"><span class="comment"># On Google colab, it doesn&#x27;t print the mini-batch results, so it may appear</span></span><br><span class="line"><span class="comment"># stuck for several minutes! Additionally, it is very slow compared to training</span></span><br><span class="line"><span class="comment"># on a local GPU.</span></span><br><span class="line"></span><br><span class="line">!python -m microwakeword.model_train_eval <span class="string">\</span></span><br><span class="line">--training_config=<span class="string">&#x27;training_parameters.yaml&#x27;</span> <span class="string">\</span></span><br><span class="line">--train <span class="number">1</span> <span class="string">\</span></span><br><span class="line">--restore_checkpoint <span class="number">1</span> <span class="string">\</span></span><br><span class="line">--test_tf_nonstreaming <span class="number">0</span> <span class="string">\</span></span><br><span class="line">--test_tflite_nonstreaming <span class="number">0</span> <span class="string">\</span></span><br><span class="line">--test_tflite_nonstreaming_quantized <span class="number">0</span> <span class="string">\</span></span><br><span class="line">--test_tflite_streaming <span class="number">0</span> <span class="string">\</span></span><br><span class="line">--test_tflite_streaming_quantized <span class="number">1</span> <span class="string">\</span></span><br><span class="line">--use_weights <span class="string">&quot;best_weights&quot;</span> <span class="string">\</span></span><br><span class="line">mixednet <span class="string">\</span></span><br><span class="line">--pointwise_filters <span class="string">&quot;64,64,64,64&quot;</span> <span class="string">\</span></span><br><span class="line">--repeat_in_block  <span class="string">&quot;1, 1, 1, 1&quot;</span> <span class="string">\</span></span><br><span class="line">--mixconv_kernel_sizes <span class="string">&#x27;[5], [7,11], [9,15], [23]&#x27;</span> <span class="string">\</span></span><br><span class="line">--residual_connection <span class="string">&quot;0,0,0,0&quot;</span> <span class="string">\</span></span><br><span class="line">--first_conv_filters <span class="number">32</span> <span class="string">\</span></span><br><span class="line">--first_conv_kernel_size <span class="number">5</span> <span class="string">\</span></span><br><span class="line">--stride <span class="number">3</span></span><br></pre></td></tr></table></figure>

<p>这段代码是用来训练一个模型，并根据训练的结果对模型进行量化和转换，使其适用于设备端的流式检测。代码的关键部分是通过命令行调用 Python 模块 <code>microwakeword.model_train_eval</code> 来执行训练过程。</p>
<p>命令行参数解析：</p>
<ol>
<li><strong><code>--training_config=&#39;training_parameters.yaml&#39;</code></strong><ul>
<li>指定训练配置文件 <code>training_parameters.yaml</code>，其中包含了模型训练所需的超参数，如学习率、训练步骤、数据集配置等。</li>
</ul>
</li>
<li><strong><code>--train 1</code></strong><ul>
<li>设置 <code>--train</code> 参数为 <code>1</code>，表示执行训练过程。如果设置为 <code>0</code>，则仅会转换和测试最佳权重的模型。</li>
</ul>
</li>
<li><strong><code>--restore_checkpoint 1</code></strong><ul>
<li>设置 <code>--restore_checkpoint</code> 为 <code>1</code>，表示从最近的检查点恢复训练。如果之前的训练已经中断，可以通过此选项从中断的位置继续训练。</li>
</ul>
</li>
<li><strong><code>--test_tf_nonstreaming 0</code></strong><ul>
<li>设置 <code>--test_tf_nonstreaming</code> 为 <code>0</code>，表示不在非流模式下测试 TensorFlow 模型。</li>
</ul>
</li>
<li><strong><code>--test_tflite_nonstreaming 0</code></strong><ul>
<li>设置 <code>--test_tflite_nonstreaming</code> 为 <code>0</code>，表示不在非流模式下测试 TensorFlow Lite 模型。</li>
</ul>
</li>
<li><strong><code>--test_tflite_nonstreaming_quantized 0</code></strong><ul>
<li>设置 <code>--test_tflite_nonstreaming_quantized</code> 为 <code>0</code>，表示不在非流模式下测试已量化的 TensorFlow Lite 模型。</li>
</ul>
</li>
<li><strong><code>--test_tflite_streaming 0</code></strong><ul>
<li>设置 <code>--test_tflite_streaming</code> 为 <code>0</code>，表示不在流模式下测试 TensorFlow Lite 模型。</li>
</ul>
</li>
<li><strong><code>--test_tflite_streaming_quantized 1</code></strong><ul>
<li>设置 <code>--test_tflite_streaming_quantized</code> 为 <code>1</code>，表示在流模式下测试已量化的 TensorFlow Lite 模型。</li>
</ul>
</li>
<li><strong><code>--use_weights &quot;best_weights&quot;</code></strong><ul>
<li>使用最佳权重来训练模型，这个参数会选择在验证过程中表现最好的权重来进行训练或测试。</li>
</ul>
</li>
<li><strong><code>mixednet</code></strong><ul>
<li>这是模型的类型，可能是指一个混合网络架构（例如，结合卷积和其他层的网络）。</li>
</ul>
</li>
<li><strong><code>--pointwise_filters &quot;64,64,64,64&quot;</code></strong><ul>
<li>这是指定每个网络块的卷积过滤器数量，表示该网络架构中使用了 4 个卷积层，每个卷积层有 64 个过滤器。</li>
</ul>
</li>
<li><strong><code>--repeat_in_block &quot;1, 1, 1, 1&quot;</code></strong><ul>
<li>指定在每个卷积块中重复的次数，意味着每个卷积块只重复一次。</li>
</ul>
</li>
<li><strong><code>--mixconv_kernel_sizes &#39;[5], [7,11], [9,15], [23]&#39;</code></strong><ul>
<li>设置混合卷积层的卷积核尺寸，分别为 <code>[5]</code>，<code>[7,11]</code>，<code>[9,15]</code>，<code>[23]</code>。这些不同的卷积核大小用于处理不同大小的局部特征。</li>
</ul>
</li>
<li><strong><code>--residual_connection &quot;0,0,0,0&quot;</code></strong><ul>
<li>设置残差连接的配置，<code>0</code> 表示不使用残差连接，<code>1</code> 表示使用。</li>
</ul>
</li>
<li><strong><code>--first_conv_filters 32</code></strong><ul>
<li>设置第一个卷积层的过滤器数量为 32。</li>
</ul>
</li>
<li><strong><code>--first_conv_kernel_size 5</code></strong><ul>
<li>设置第一个卷积层的卷积核大小为 5。</li>
</ul>
</li>
<li><strong><code>--stride 3</code></strong><ul>
<li>设置卷积层的步长为 3，表示每次滑动的步长为 3。</li>
</ul>
</li>
</ol>
<p><strong>第十块：</strong></p>
<figure class="highlight livecodeserver"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Downloads the tflite model file. To use on the device, you need to write a</span></span><br><span class="line"><span class="comment"># Model JSON file. See https://esphome.io/components/micro_wake_word for the</span></span><br><span class="line"><span class="comment"># documentation and</span></span><br><span class="line"><span class="comment"># https://github.com/esphome/micro-wake-word-models/tree/main/models/v2 for</span></span><br><span class="line"><span class="comment"># examples. Adjust the probability threshold based on the test results obtained</span></span><br><span class="line"><span class="comment"># after training is finished. You may also need to increase the Tensor arena</span></span><br><span class="line"><span class="comment"># model size if the model fails to load.</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">from</span> google.colab import <span class="built_in">files</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">files</span>.download(f<span class="string">&quot;trained_models/wakeword/tflite_stream_state_internal_quant/stream_state_internal_quant.tflite&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>下载训练好的量化模型到本机。</p>
<p>okok，开炮！</p>
<p>缺什么库就pip install什么库，我在运行第九块进行训练时，出现一个问题（节选）：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">E0000 00:00:1743592764.006021  298082 cuda_dnn.cc:522] Loaded runtime CuDNN library: 9.1.0 but <span class="built_in">source</span> was compiled with: 9.3.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.</span><br></pre></td></tr></table></figure>

<p>经查，是用了base环境下的cudnn库了，把base环境下的cudnn库卸载就好了（试了八百种方法，折磨了一整天😒）：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python uninstall nvidia-cudnn-cu12</span><br></pre></td></tr></table></figure>

<h3 id="训练与测试"><a href="#训练与测试" class="headerlink" title="训练与测试"></a>训练与测试</h3><p>okok，那咱们直接开炮（训练），依次运行<code>notebook</code>中的代码块进行资源下载和数据集制作以及训练参数配置，训练结束后，会在<code>microWakeWord/notebooks/trained_models/wakeword/tflite_stream_state_internal_quant</code>文件夹下看到<code>stream_state_internal_quant.tflite</code>这个模型文件：</p>
<img src="/2025/04/03/KWS%E4%B9%8BmicroWakeWord%E5%AE%89%E8%A3%85%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95/9eecfa2b857a8bb9b05aa71619546346.png" class="" title="9eecfa2b857a8bb9b05aa71619546346">

<p>我们需要再去克隆一个库<a href="https://github.com/OHF-Voice/pymicro-wakeword/tree/master">pymicro-wakeword</a>：</p>
<p>直接<code>pip install pymicro-wakeword</code>应该也行（作者介绍的就是这个方法），但我使用的是下面这种方式：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/OHF-Voice/pymicro-wakeword.git</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> pymicro-wakeword</span><br><span class="line"></span><br><span class="line">conda create -n pymicro_wakeword python=3.10</span><br><span class="line"></span><br><span class="line">conda activate pymicro_wakeword</span><br><span class="line"></span><br><span class="line">pip install -r requirements.txt</span><br><span class="line"></span><br><span class="line">(可选，我没运行) pip install -e .</span><br></pre></td></tr></table></figure>

<p>将<code>stream_state_internal_quant.tflite</code>复制到<code>pymicro-wakeword/pymicro-wakeword/model</code>下，并重命名为<code>hey_bubu.tflite</code>，需要注意的是，还需要创建同名的json文件，如果没有这个文件：</p>
<img src="/2025/04/03/KWS%E4%B9%8BmicroWakeWord%E5%AE%89%E8%A3%85%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95/3bef79d612d7f6d664fc2cc1cfd97743.png" class="" title="3bef79d612d7f6d664fc2cc1cfd97743">

<p><strong>同名<code>json</code>文件如下：</strong></p>
<img src="/2025/04/03/KWS%E4%B9%8BmicroWakeWord%E5%AE%89%E8%A3%85%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95/90c149772bb0c8a0da6b0688b51979af.png" class="" title="90c149772bb0c8a0da6b0688b51979af">

<p><strong>即：</strong></p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;type&quot;: &quot;micro&quot;,</span><br><span class="line">  &quot;wake<span class="built_in">_</span>word&quot;: &quot;hey bubu&quot;,</span><br><span class="line">  &quot;author&quot;: &quot;chr&quot;,</span><br><span class="line">  &quot;website&quot;: &quot;https://caihaoran-00.github.io/&quot;,</span><br><span class="line">  &quot;model&quot;: &quot;hey<span class="built_in">_</span>bubu.tflite&quot;,</span><br><span class="line">  &quot;trained<span class="built_in">_</span>languages&quot;: [&quot;en&quot;],</span><br><span class="line">  &quot;version&quot;: 2,</span><br><span class="line">  &quot;micro&quot;: &#123;</span><br><span class="line">    &quot;probability<span class="built_in">_</span>cutoff&quot;: 0.97,</span><br><span class="line">    &quot;feature<span class="built_in">_</span>step<span class="built_in">_</span>size&quot;: 10,</span><br><span class="line">    &quot;sliding<span class="built_in">_</span>window<span class="built_in">_</span>size&quot;: 5,</span><br><span class="line">    &quot;tensor<span class="built_in">_</span>arena<span class="built_in">_</span>size&quot;: 26080,</span><br><span class="line">    &quot;minimum<span class="built_in">_</span>esphome<span class="built_in">_</span>version&quot;: &quot;2024.7.0&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>再次运行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">arecord -r <span class="number">16000</span> -c <span class="number">1</span> -f S16_LE -t raw |   python3 -m pymicro_wakeword --model <span class="string">&#x27;hey_bubu&#x27;</span></span><br></pre></td></tr></table></figure>

<p>对着麦克风说：<code>hey,bubu</code>，将会得到如下的打印。</p>
<img src="/2025/04/03/KWS%E4%B9%8BmicroWakeWord%E5%AE%89%E8%A3%85%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95/a213cd73c57519b6aac53485bed42d71.png" class="" title="a213cd73c57519b6aac53485bed42d71">

<p>okok，让同事也说了两句，感觉基本可用，先部署起来，再花精力优化吧。</p>
<hr>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://github.com/kahrendt/microWakeWord">https://github.com/kahrendt/microWakeWord</a></li>
<li><a href="https://github.com/kahrendt/microWakeWord/blob/main/notebooks/basic_training_notebook.ipynb">https://github.com/kahrendt/microWakeWord/blob/main/notebooks/basic_training_notebook.ipynb</a></li>
<li><a href="https://github.com/OHF-Voice/pymicro-wakeword/tree/master">https://github.com/OHF-Voice/pymicro-wakeword/tree/master</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>KWS</tag>
        <tag>microWakeWord</tag>
        <tag>tensorflow</tag>
      </tags>
  </entry>
  <entry>
    <title>LLM应用：结构化提取及后续思路</title>
    <url>/2025/05/29/LLM%E5%BA%94%E7%94%A8%EF%BC%9A%E7%BB%93%E6%9E%84%E5%8C%96%E6%8F%90%E5%8F%96%E5%8F%8A%E5%90%8E%E7%BB%AD%E6%80%9D%E8%B7%AF/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在招标智能体的第二个智能体中，要求做到从众多pdf文件中提取出关注的字段，流程上分为两步，一是解析pdf文件，对于文本型pdf，使用pdfplumber等即可，对于图片型pdf，需使用ocr技术，（更建议）或者直接使用pdf解析框架，比如<a href="https://github.com/opendatalab/MinerU">MinerU</a>，<a href="https://github.com/bytedance/Dolphin">Dolphin</a>；二是对于解析出来的内容如何使用，即如何抽取出感兴趣的结构化字段，本文将重点阐述目前关于结构化提取目前做的demo效果及发现的问题以及后续的思路。</p>
<span id="more"></span>

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>最开始的思路是基于一个pdf文档，简单粗暴的将<strong>想提取的字段</strong>（基于第一篇文档，第一篇文档中有这些字段）写在提示词里面（zero-shot，使用qwen2.5-14b-1M，qwen-long模型)，发现有些字段文档中存在，但模型依旧找不到，遂在提示词中添加上提取结果的例子（给的例子是第一篇文档的提取结果，few-shot），在这个文档上表现是好了，遂使用第二篇文档进行测试，发现对于第一篇文档中有，但第二篇文档中没有的字段，尤其是需要归纳总结的字段，此时总会输出给的例子，那试下把第二篇文档的正确提取结果也加在提示词中会不会效果变好，效果是有一点点提示，但依旧会有上面说的现象，deepseek-r1论文中明确说明了该模型在few-shot下效果并不好，可能qwen的这些模型也这样吧，还是回到最原始的状态吧，去掉给的例子，只给想提取的字段，确实是没有串结果的现象了（因为串结果就是由于few-shot产生的），然后又和deepseek-r1网页版的识别结果进行了对比，发现deepseek-r1的识别结果准确率比qwen2.5-14b-1M和qwen-long都要高，遂目前使用的是deepseek-r1模型，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pdfplumber</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取PDF文件并提取文本</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_pdf_text</span>(<span class="params">pdf_path</span>):</span><br><span class="line">    text = <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(pdf_path) <span class="keyword">as</span> pdf:</span><br><span class="line">            <span class="keyword">for</span> page <span class="keyword">in</span> pdf.pages:</span><br><span class="line">                page_text = page.extract_text()</span><br><span class="line">                <span class="keyword">if</span> page_text:</span><br><span class="line">                    text += page_text + <span class="string">&quot;\n&quot;</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Error reading PDF: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用OpenAI API提取结构化数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_document_info</span>(<span class="params">text, api_key</span>):</span><br><span class="line">    client = OpenAI(api_key=api_key, base_url=<span class="string">&quot;https://api.deepseek.com&quot;</span>)</span><br><span class="line">    prompt = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    你是一个数据提取专家，擅长于从用户输出的文本中提取下列信息并以json格式返回，你严格按照给定的例子给出回答并特别关注☑（带框框的对号）符号，日期用（YYYY-MM-DD）形式，数额用万元为单位:</span></span><br><span class="line"><span class="string">    - 招标人名称</span></span><br><span class="line"><span class="string">    - 招标人地址</span></span><br><span class="line"><span class="string">    - 招标人联系人</span></span><br><span class="line"><span class="string">    - 招标人电话</span></span><br><span class="line"><span class="string">    - 招标代理机构名称</span></span><br><span class="line"><span class="string">    - 招标代理机构地址</span></span><br><span class="line"><span class="string">    - 招标代理机构联系人</span></span><br><span class="line"><span class="string">    - 招标代理机构电话</span></span><br><span class="line"><span class="string">    - 招标编号(为一串大写字母与数字的组合）</span></span><br><span class="line"><span class="string">    - 工程名称</span></span><br><span class="line"><span class="string">    - 建设地点</span></span><br><span class="line"><span class="string">    - 建设规模</span></span><br><span class="line"><span class="string">    - 投资估算</span></span><br><span class="line"><span class="string">    - 资金来源及比例（未提供比例则不写比例）</span></span><br><span class="line"><span class="string">    - 招标范围</span></span><br><span class="line"><span class="string">    - 总工期/设计服务期限（单位：日历天）</span></span><br><span class="line"><span class="string">    - 质量标准</span></span><br><span class="line"><span class="string">    - 联合体投标（接受/不接受）</span></span><br><span class="line"><span class="string">    - 资格审查方式（资格后审/资格预审）</span></span><br><span class="line"><span class="string">    - 投标预备会（召开/不召开）</span></span><br><span class="line"><span class="string">    - 要求澄清招标文件截止时间</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    - 招标文件澄清/答疑时间</span></span><br><span class="line"><span class="string">      例：</span></span><br><span class="line"><span class="string">        2025年05月30日 17:00</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    - 增值税税金的计算方式</span></span><br><span class="line"><span class="string">    - 最高投标限价</span></span><br><span class="line"><span class="string">    - 风险控制价</span></span><br><span class="line"><span class="string">    - 投标担保金额</span></span><br><span class="line"><span class="string">    - 技术标形式（明标/暗标）</span></span><br><span class="line"><span class="string">    - 投标截止时间</span></span><br><span class="line"><span class="string">    - 投标递交地点/电子投标文件上传平台</span></span><br><span class="line"><span class="string">    - 评标办法</span></span><br><span class="line"><span class="string">    - 确定中标人方式</span></span><br><span class="line"><span class="string">    - 总分计算公式</span></span><br><span class="line"><span class="string">    - 设计收费基准价</span></span><br><span class="line"><span class="string">    - 进度款支付</span></span><br><span class="line"><span class="string">    - 技术标评审表（以markdown方式给出，只提取评审因素和分值，分值分为最低分和最高分两列）</span></span><br><span class="line"><span class="string">    - 资信标评审表（以markdown方式给出，只提取评审因素、评审内容和分值，分值分为最低分和最高分两列）</span></span><br><span class="line"><span class="string">    - 商务标评审&amp;基准价/最佳报价的计算方式</span></span><br><span class="line"><span class="string">    - 商务标评审&amp;商务报价得分方式</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    注意：</span></span><br><span class="line"><span class="string">    1. 如果文本中未出现上述信息，将其标记为nan. 确保返回的json可读；</span></span><br><span class="line"><span class="string">    2. 投资估算不等于最高投标限价（文中若只出现最高投标现价，未出现投标估算，那么投标估算应该为nan）。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = client.chat.completions.create(</span><br><span class="line">            model=<span class="string">&#x27;deepseek-reasoner&#x27;</span>,  <span class="comment"># qwen2.5-14b-instruct-1m</span></span><br><span class="line">            messages=[</span><br><span class="line">                &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: prompt&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: text&#125;  <span class="comment"># prompt</span></span><br><span class="line">            ]</span><br><span class="line">        )</span><br><span class="line">        result = response.choices[<span class="number">0</span>].message.content</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;document1_structed= <span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="comment"># 假设API返回JSON字符串，移除可能的Markdown代码块</span></span><br><span class="line">        result = result.strip().strip(<span class="string">&quot;```json&quot;</span>).strip(<span class="string">&quot;```&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;document2_structed= <span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> json.loads(result)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Error calling OpenAI API: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_notice_info</span>(<span class="params">text, api_key</span>):</span><br><span class="line">    client = OpenAI(api_key=api_key, base_url=<span class="string">&quot;https://api.deepseek.com&quot;</span>)</span><br><span class="line">    prompt = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    你是一个数据提取专家，擅长于从用户输出的文本中提取下列信息并以json格式返回，你严格按照给定的例子给出回答并特别关注☑（带框框的对号）符号，日期用（YYYY-MM-DD）形式，数额用万元为单位:</span></span><br><span class="line"><span class="string">    - 招标编号</span></span><br><span class="line"><span class="string">      例：</span></span><br><span class="line"><span class="string">        A3301300180526770001221。</span></span><br><span class="line"><span class="string">    - 建设资金来源</span></span><br><span class="line"><span class="string">    - 出资比例</span></span><br><span class="line"><span class="string">    - 投资估算</span></span><br><span class="line"><span class="string">    - 建设规模</span></span><br><span class="line"><span class="string">      例：</span></span><br><span class="line"><span class="string">        奥体街（扬帆路-养正巷），西至养正巷，东至扬帆路，为城市支路，长度约660米，宽约16-24米，隧道长度约210米，最大排水管径≥1.5m。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    - 建设地点</span></span><br><span class="line"><span class="string">    - 招标范围</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    - 服务期限（单位：日历天）</span></span><br><span class="line"><span class="string">    - 投标人资格要求</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    - 联合体投标</span></span><br><span class="line"><span class="string">      例：</span></span><br><span class="line"><span class="string">        接受</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    - 招标文件的获取</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    - 投标截止时间</span></span><br><span class="line"><span class="string">    - 投标递交地点/电子投标文件上传平台</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    - 开标时间</span></span><br><span class="line"><span class="string">    - 开标地点</span></span><br><span class="line"><span class="string">    - 招标人名称</span></span><br><span class="line"><span class="string">    - 招标人地址</span></span><br><span class="line"><span class="string">    - 招标人联系人</span></span><br><span class="line"><span class="string">    - 招标人电话</span></span><br><span class="line"><span class="string">    - 招标代理机构名称</span></span><br><span class="line"><span class="string">    - 招标代理机构地址</span></span><br><span class="line"><span class="string">    - 招标代理机构联系人</span></span><br><span class="line"><span class="string">    - 招标代理机构电话</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    如果文本中未出现上述信息，将其标记为nan. 确保返回的json可读。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = client.chat.completions.create(</span><br><span class="line">            model=<span class="string">&#x27;deepseek-reasoner&#x27;</span>,</span><br><span class="line">            messages=[</span><br><span class="line">                &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: prompt&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: text&#125;  <span class="comment"># prompt</span></span><br><span class="line">            ]</span><br><span class="line">        )</span><br><span class="line">        result = response.choices[<span class="number">0</span>].message.content</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;notice1_structed = <span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="comment"># 假设API返回JSON字符串，移除可能的Markdown代码块</span></span><br><span class="line">        result = result.strip().strip(<span class="string">&quot;```json&quot;</span>).strip(<span class="string">&quot;```&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;notice2_structed = <span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> json.loads(result)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Error calling OpenAI API: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">merge_info</span>(<span class="params">structured_document, structured_notice, api_key</span>):</span><br><span class="line">    client = OpenAI(api_key=api_key, base_url=<span class="string">&quot;https://api.deepseek.com&quot;</span>)</span><br><span class="line">    prompt = <span class="string">f&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        你是一个数据融合专家，擅长于从用户输出的招标文件和招标公告文本中提取下列信息并以json格式返回，</span></span><br><span class="line"><span class="string">        两者文本中的信息不一致时就合并信息（比如两个电话不一样，可能一个是座机号一个是手机号，那么就都保留下来），日期用（YYYY-MM-DD）形式，数额用万元为单位:</span></span><br><span class="line"><span class="string">    - 招标人名称</span></span><br><span class="line"><span class="string">    - 招标人地址</span></span><br><span class="line"><span class="string">    - 招标人联系人</span></span><br><span class="line"><span class="string">    - 招标人电话</span></span><br><span class="line"><span class="string">    - 招标代理机构名称</span></span><br><span class="line"><span class="string">    - 招标代理机构地址</span></span><br><span class="line"><span class="string">    - 招标代理机构联系人</span></span><br><span class="line"><span class="string">    - 招标代理机构电话</span></span><br><span class="line"><span class="string">    - 招标编号</span></span><br><span class="line"><span class="string">      例：</span></span><br><span class="line"><span class="string">        A3301300180526770001221。</span></span><br><span class="line"><span class="string">    - 工程名称</span></span><br><span class="line"><span class="string">    - 建设地点</span></span><br><span class="line"><span class="string">    - 建设规模</span></span><br><span class="line"><span class="string">    - 投资估算</span></span><br><span class="line"><span class="string">    - 资金来源及比例（未提供比例则不写比例）</span></span><br><span class="line"><span class="string">    - 招标范围</span></span><br><span class="line"><span class="string">    - 总工期/设计服务期限（单位：日历天）</span></span><br><span class="line"><span class="string">    - 质量标准</span></span><br><span class="line"><span class="string">    - 联合体投标（接受/不接受）</span></span><br><span class="line"><span class="string">    - 资格审查方式（资格后审/资格预审）</span></span><br><span class="line"><span class="string">    - 投标预备会（召开/不召开）</span></span><br><span class="line"><span class="string">    - 要求澄清截止时间</span></span><br><span class="line"><span class="string">    - 澄清/答疑时间</span></span><br><span class="line"><span class="string">    - 增值税税金的计算方式</span></span><br><span class="line"><span class="string">    - 最高投标限价</span></span><br><span class="line"><span class="string">    - 风险控制价</span></span><br><span class="line"><span class="string">    - 投标担保金额</span></span><br><span class="line"><span class="string">    - 技术标形式（明标/暗标）</span></span><br><span class="line"><span class="string">    - 投标截止时间</span></span><br><span class="line"><span class="string">    - 投标递交地点/电子投标文件上传平台</span></span><br><span class="line"><span class="string">        例：</span></span><br><span class="line"><span class="string">            杭州市公共资源交易中心高新区（滨江）分中心开标室1（杭州市滨江区泰安路200号区文化中心 10号门3楼刷卡，4楼开标）。</span></span><br><span class="line"><span class="string">            or</span></span><br><span class="line"><span class="string">            使用专用密钥上传至杭州市公共资源交易平台（详细上传方式详见：杭州市公共资源交易平台及公告附件）。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    - 评标办法</span></span><br><span class="line"><span class="string">    - 确定中标人方式</span></span><br><span class="line"><span class="string">    - 总分计算公式</span></span><br><span class="line"><span class="string">    - 设计收费基准价</span></span><br><span class="line"><span class="string">    - 进度款支付</span></span><br><span class="line"><span class="string">    - 技术标评审表（markdown图表形式给出）</span></span><br><span class="line"><span class="string">    - 资信标评审表（markdown图表形式给出）</span></span><br><span class="line"><span class="string">    - 商务标评审&amp;基准价的计算方式</span></span><br><span class="line"><span class="string">    - 商务标评审&amp;商务报价得分方式</span></span><br><span class="line"><span class="string">    - 建设资金来源</span></span><br><span class="line"><span class="string">    - 出资比例</span></span><br><span class="line"><span class="string">    - 投标人资格要求</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    如果文本中未出现上述信息，将其标记为nan。确保返回的json可读。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    招标文件：</span></span><br><span class="line"><span class="string">    <span class="subst">&#123;structured_document&#125;</span></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    招标公告：</span></span><br><span class="line"><span class="string">    <span class="subst">&#123;structured_notice&#125;</span></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = client.chat.completions.create(</span><br><span class="line">            model=<span class="string">&#x27;deepseek-chat&#x27;</span>,</span><br><span class="line">            messages=[</span><br><span class="line">                &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: prompt&#125;  <span class="comment"># prompt</span></span><br><span class="line">            ]</span><br><span class="line">        )</span><br><span class="line">        result = response.choices[<span class="number">0</span>].message.content</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;merge1_structed= <span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="comment"># 假设API返回JSON字符串，移除可能的Markdown代码块</span></span><br><span class="line">        result = result.strip().strip(<span class="string">&quot;```json&quot;</span>).strip(<span class="string">&quot;```&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;merge2_structed= <span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> json.loads(result)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Error calling OpenAI API: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 主函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">document_path, notice_path, api_key</span>):</span><br><span class="line">    <span class="comment"># 提取招标文件文本</span></span><br><span class="line">    document_text = extract_pdf_text(document_path)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> document_text:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Failed to extract text from document.&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 调用LLM提取结构化数据</span></span><br><span class="line">    document_structured_data = get_document_info(document_text, api_key)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> document_structured_data:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Failed to extract structured data from document.&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 提取招标公告</span></span><br><span class="line">    notice_text = extract_pdf_text(notice_path)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> notice_text:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Failed to extract text from notice.&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 调用LLM提取结构化数据</span></span><br><span class="line">    notice_structured_data = get_notice_info(notice_text, api_key)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> notice_structured_data:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Failed to extract structured data from notice.&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    res = merge_info(document_structured_data, notice_structured_data, api_key)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;res=<span class="subst">&#123;res&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="comment"># 打印结构化数据</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Extracted Data:&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(json.dumps(res, indent=<span class="number">2</span>, ensure_ascii=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 替换为你的PDF文件路径和OpenAI API密钥</span></span><br><span class="line">    DOCUMENT_FILE_PATH = <span class="string">&quot;招标文件修订-2.pdf&quot;</span></span><br><span class="line">    NOTICE_FILE_PATH = <span class="string">&quot;招标公告-2.pdf&quot;</span></span><br><span class="line"></span><br><span class="line">    API_KEY = <span class="string">&quot;sk-xxxxxxxxx&quot;</span></span><br><span class="line">    main(DOCUMENT_FILE_PATH, NOTICE_FILE_PATH, API_KEY)</span><br></pre></td></tr></table></figure>

<p><strong>最终输出（仅保留关键结果）：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">document2_structed= </span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;招标人名称&quot;</span>: <span class="string">&quot;杭州万维投资有限公司;杭州钱塘城市建设集团有限公司&quot;</span>,</span><br><span class="line">  <span class="string">&quot;招标人地址&quot;</span>: <span class="string">&quot;浙江省杭州市钱塘区下沙街道万晶湖畔中心西区2幢2308室&quot;</span>,</span><br><span class="line">  <span class="string">&quot;招标人联系人&quot;</span>: <span class="string">&quot;单工&quot;</span>,</span><br><span class="line">  <span class="string">&quot;招标人电话&quot;</span>: <span class="string">&quot;0571-86798597&quot;</span>,</span><br><span class="line">  <span class="string">&quot;招标代理机构名称&quot;</span>: <span class="string">&quot;杭州建设工程造价咨询有限公司&quot;</span>,</span><br><span class="line">  <span class="string">&quot;招标代理机构地址&quot;</span>: <span class="string">&quot;杭州市萧山区民和路481号联合中心北区D座4楼&quot;</span>,</span><br><span class="line">  <span class="string">&quot;招标代理机构联系人&quot;</span>: <span class="string">&quot;李月园、刘凯威、周婉卿&quot;</span>,</span><br><span class="line">  <span class="string">&quot;招标代理机构电话&quot;</span>: <span class="string">&quot;17681859928、13575919845、13666671903&quot;</span>,</span><br><span class="line">  <span class="string">&quot;招标编号&quot;</span>: <span class="string">&quot;A3301300180526770001221&quot;</span>,</span><br><span class="line">  <span class="string">&quot;工程名称&quot;</span>: <span class="string">&quot;九隆红妍中间道路(临化一路-围垦中心河)&quot;</span>,</span><br><span class="line">  <span class="string">&quot;建设地点&quot;</span>: <span class="string">&quot;项目位于临江街道，西起临化一路，东至围垦中心河&quot;</span>,</span><br><span class="line">  <span class="string">&quot;建设规模&quot;</span>: <span class="string">&quot;用地面积约4331平方米，道路全长约310m，标准红线宽14m&quot;</span>,</span><br><span class="line">  <span class="string">&quot;投资估算&quot;</span>: <span class="string">&quot;nan&quot;</span>,</span><br><span class="line">  <span class="string">&quot;资金来源及比例&quot;</span>: <span class="string">&quot;财政资金100%&quot;</span>,</span><br><span class="line">  <span class="string">&quot;招标范围&quot;</span>: <span class="string">&quot;招标文件、工程量清单及施工图范围内的道路工程、综合管线、附属工程及原有道路整治等&quot;</span>,</span><br><span class="line">  <span class="string">&quot;总工期/设计服务期限&quot;</span>: <span class="string">&quot;270&quot;</span>,</span><br><span class="line">  <span class="string">&quot;质量标准&quot;</span>: <span class="string">&quot;符合现行国家有关工程施工验收规范和标准的合格要求&quot;</span>,</span><br><span class="line">  <span class="string">&quot;联合体投标&quot;</span>: <span class="string">&quot;不接受&quot;</span>,</span><br><span class="line">  <span class="string">&quot;资格审查方式&quot;</span>: <span class="string">&quot;资格后审&quot;</span>,</span><br><span class="line">  <span class="string">&quot;投标预备会&quot;</span>: <span class="string">&quot;不召开&quot;</span>,</span><br><span class="line">  <span class="string">&quot;要求澄清招标文件截止时间&quot;</span>: <span class="string">&quot;2025-05-24&quot;</span>,</span><br><span class="line">  <span class="string">&quot;招标文件澄清/答疑时间&quot;</span>: <span class="string">&quot;2025-05-27 17:00&quot;</span>,</span><br><span class="line">  <span class="string">&quot;增值税税金的计算方式&quot;</span>: <span class="string">&quot;一般计税法&quot;</span>,</span><br><span class="line">  <span class="string">&quot;最高投标限价&quot;</span>: <span class="string">&quot;471.8028&quot;</span>,</span><br><span class="line">  <span class="string">&quot;风险控制价&quot;</span>: <span class="string">&quot;377.4422&quot;</span>,</span><br><span class="line">  <span class="string">&quot;投标担保金额&quot;</span>: <span class="string">&quot;9&quot;</span>,</span><br><span class="line">  <span class="string">&quot;技术标形式&quot;</span>: <span class="string">&quot;明标&quot;</span>,</span><br><span class="line">  <span class="string">&quot;投标截止时间&quot;</span>: <span class="string">&quot;2025-06-03 09:30&quot;</span>,</span><br><span class="line">  <span class="string">&quot;投标递交地点/电子投标文件上传平台&quot;</span>: <span class="string">&quot;杭州市公共资源交易平台&quot;</span>,</span><br><span class="line">  <span class="string">&quot;评标办法&quot;</span>: <span class="string">&quot;技术标通过制的综合评估法&quot;</span>,</span><br><span class="line">  <span class="string">&quot;确定中标人方式&quot;</span>: <span class="string">&quot;根据评标委员会推荐，由招标人确定中标人&quot;</span>,</span><br><span class="line">  <span class="string">&quot;总分计算公式&quot;</span>: <span class="string">&quot;总分=商务总报价评分(87)+综合单价评分(6)+信用(履约)评价评分(5)+陈述和答辩(2)&quot;</span>,</span><br><span class="line">  <span class="string">&quot;设计收费基准价&quot;</span>: <span class="string">&quot;nan&quot;</span>,</span><br><span class="line">  <span class="string">&quot;进度款支付&quot;</span>: <span class="string">&quot;按月支付上月完成工程量的85%，竣工验收后支付至90%，结算审计后支付至98.5%，余1.5%为质保金&quot;</span>,</span><br><span class="line">  <span class="string">&quot;技术标评审表&quot;</span>: <span class="string">&quot;nan&quot;</span>,</span><br><span class="line">  <span class="string">&quot;资信标评审表&quot;</span>: <span class="string">&quot;nan&quot;</span>,</span><br><span class="line">  <span class="string">&quot;商务标评审&amp;基准价/最佳报价的计算方式&quot;</span>: <span class="string">&quot;开标随机抽取三种方式之一：方式一（二次算术平均）、方式二（一次平均加特定报价平均）、方式三（一次平均加随机报价平均）&quot;</span>,</span><br><span class="line">  <span class="string">&quot;商务标评审&amp;商务报价得分方式&quot;</span>: <span class="string">&quot;报价等于最佳报价得满分87分；每高于最佳报价1%扣2分，每低于最佳报价1%扣1分，报价≤风险控制价时每低于1%扣2分&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">notice2_structed = &#123;</span><br><span class="line">  <span class="string">&quot;招标编号&quot;</span>: <span class="string">&quot;nan&quot;</span>,</span><br><span class="line">  <span class="string">&quot;建设资金来源&quot;</span>: <span class="string">&quot;财政资金&quot;</span>,</span><br><span class="line">  <span class="string">&quot;出资比例&quot;</span>: <span class="string">&quot;100%&quot;</span>,</span><br><span class="line">  <span class="string">&quot;投资估算&quot;</span>: 1668.17,</span><br><span class="line">  <span class="string">&quot;建设规模&quot;</span>: <span class="string">&quot;项目位于临江街道，西起临化一路，东至围垦中心河。用地面积约4331平方米（以实测为准）。道路全长约310m，标准红线宽14m，道路等级为城市支路，设计车速30km/h，双向两车道，采用沥青混凝土路面。道路标准横断面：2m人行道+2×5m车行道+2m人行道=14m。车行道结构：5cmSMA-13沥青砼+6cmAC-20C中粒式沥青砼+40cm5％水泥稳定碎石+15cm 级配碎石，路基采用60cm塘渣换填。人行道结构：6cm混凝土透水砖+3cmM15干硬性水泥砂浆+15cmC20透水砼+15cm级配碎石，路基采用30cm塘渣换填。雨水主管管径D400-D600，采用Ш级钢筋混凝土管。道路交叉口处采用球墨铸铁管。雨水检查井采用钢筋混凝土井。人行道设置行进盲道。本项目已落实海绵城市建设相关要求，人行道设置透水铺装约1119㎡。&quot;</span>,</span><br><span class="line">  <span class="string">&quot;建设地点&quot;</span>: <span class="string">&quot;临江街道，西起临化一路，东至围垦中心河&quot;</span>,</span><br><span class="line">  <span class="string">&quot;招标范围&quot;</span>: <span class="string">&quot;招标文件、工程量清单及施工图范围内的道路工程、综合管线、附属工程及原有道路整治等。&quot;</span>,</span><br><span class="line">  <span class="string">&quot;服务期限&quot;</span>: 270,</span><br><span class="line">  <span class="string">&quot;投标人资格要求&quot;</span>: <span class="string">&quot;具备施工总承包企业市政公用工程(新)三级及以上资质（浙江省建筑市场监管公共服务系统资质动态核查结果合格）；具备有效的企业安全生产许可证，企业主要负责人（法定代表人、企业经理、企业分管安全生产的副经理、企业技术负责人）具有对应有效的安全生产考核合格证书；拟派项目负责人具有注册在投标人单位的市政公用工程二级建造师执业资格，同时具有对应有效的安全生产考核合格证书（投标截止日无在建合同工程担任项目负责人）；投标人及其拟派项目负责人未被列入建筑市场严重失信名单（以全国建筑市场监管公共服务平台黑名单记录、失信联合惩戒记录和浙江省建筑市场监管公共服务系统严重失信名单为准）；投标截止日之前三年内无行贿犯罪记录；未被人民法院列入失信被执行人名单；未被市场监督管理机关在全国企业信用信息公示系统中列入严重违法失信企业名单；未被人力资源社会保障行政部门列入失信联合惩戒名单（有效期内）；省外企业应按规定办理&#x27;省外建设工程企业进浙备案&#x27;手续。&quot;</span>,</span><br><span class="line">  <span class="string">&quot;联合体投标&quot;</span>: <span class="string">&quot;不接受&quot;</span>,</span><br><span class="line">  <span class="string">&quot;招标文件的获取&quot;</span>: <span class="string">&quot;杭州建设工程招标造价平台（https://ztb.cxjw.hangzhou.gov.cn:8092）、杭州市公共资源交易平台（http://hzctc.hangzhou.gov.cn/）下载，时间从公告发布之日起至投标文件递交截止时间&quot;</span>,</span><br><span class="line">  <span class="string">&quot;投标截止时间&quot;</span>: <span class="string">&quot;2025-06-03 09:30:00&quot;</span>,</span><br><span class="line">  <span class="string">&quot;投标递交地点/电子投标文件上传平台&quot;</span>: <span class="string">&quot;杭州市公共资源交易平台&quot;</span>,</span><br><span class="line">  <span class="string">&quot;开标时间&quot;</span>: <span class="string">&quot;nan&quot;</span>,</span><br><span class="line">  <span class="string">&quot;开标地点&quot;</span>: <span class="string">&quot;nan&quot;</span>,</span><br><span class="line">  <span class="string">&quot;招标人名称&quot;</span>: <span class="string">&quot;杭州万维投资有限公司&quot;</span>,</span><br><span class="line">  <span class="string">&quot;招标人地址&quot;</span>: <span class="string">&quot;浙江省杭州市钱塘区下沙街道万晶湖畔中心西区2幢2308室&quot;</span>,</span><br><span class="line">  <span class="string">&quot;招标人联系人&quot;</span>: <span class="string">&quot;单工&quot;</span>,</span><br><span class="line">  <span class="string">&quot;招标人电话&quot;</span>: <span class="string">&quot;0571-86798597&quot;</span>,</span><br><span class="line">  <span class="string">&quot;招标代理机构名称&quot;</span>: <span class="string">&quot;杭州建设工程造价咨询有限公司&quot;</span>,</span><br><span class="line">  <span class="string">&quot;招标代理机构地址&quot;</span>: <span class="string">&quot;杭州市萧山区民和路481号联合中心北区D座4楼&quot;</span>,</span><br><span class="line">  <span class="string">&quot;招标代理机构联系人&quot;</span>: <span class="string">&quot;李月园、刘凯威、周婉卿&quot;</span>,</span><br><span class="line">  <span class="string">&quot;招标代理机构电话&quot;</span>: <span class="string">&quot;17681859928、13575919845、13666671903&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">merge2_structed= </span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;招标人名称&quot;</span>: [<span class="string">&quot;杭州万维投资有限公司&quot;</span>, <span class="string">&quot;杭州钱塘城市建设集团有限公司&quot;</span>],</span><br><span class="line">  <span class="string">&quot;招标人地址&quot;</span>: <span class="string">&quot;浙江省杭州市钱塘区下沙街道万晶湖畔中心西区2幢2308室&quot;</span>,</span><br><span class="line">  <span class="string">&quot;招标人联系人&quot;</span>: <span class="string">&quot;单工&quot;</span>,</span><br><span class="line">  <span class="string">&quot;招标人电话&quot;</span>: [<span class="string">&quot;0571-86798597&quot;</span>],</span><br><span class="line">  <span class="string">&quot;招标代理机构名称&quot;</span>: <span class="string">&quot;杭州建设工程造价咨询有限公司&quot;</span>,</span><br><span class="line">  <span class="string">&quot;招标代理机构地址&quot;</span>: <span class="string">&quot;杭州市萧山区民和路481号联合中心北区D座4楼&quot;</span>,</span><br><span class="line">  <span class="string">&quot;招标代理机构联系人&quot;</span>: [<span class="string">&quot;李月园&quot;</span>, <span class="string">&quot;刘凯威&quot;</span>, <span class="string">&quot;周婉卿&quot;</span>],</span><br><span class="line">  <span class="string">&quot;招标代理机构电话&quot;</span>: [<span class="string">&quot;17681859928&quot;</span>, <span class="string">&quot;13575919845&quot;</span>, <span class="string">&quot;13666671903&quot;</span>],</span><br><span class="line">  <span class="string">&quot;招标编号&quot;</span>: <span class="string">&quot;A3301300180526770001221&quot;</span>,</span><br><span class="line">  <span class="string">&quot;工程名称&quot;</span>: <span class="string">&quot;九隆红妍中间道路(临化一路-围垦中心河)&quot;</span>,</span><br><span class="line">  <span class="string">&quot;建设地点&quot;</span>: <span class="string">&quot;项目位于临江街道，西起临化一路，东至围垦中心河&quot;</span>,</span><br><span class="line">  <span class="string">&quot;建设规模&quot;</span>: <span class="string">&quot;用地面积约4331平方米，道路全长约310m，标准红线宽14m。项目位于临江街道，西起临化一路，东至围垦中心河。用地面积约4331平方米（以实测为准）。道路全长约310m，标准红线宽14m，道路等级为城市支路，设计车速30km/h，双向两车道，采用沥青混凝土路面。道路标准横断面：2m人行道+2×5m车行道+2m人行道=14m。车行道结构：5cmSMA-13沥青砼+6cmAC-20C中粒式沥青砼+40cm5％水泥稳定碎石+15cm 级配碎石，路基采用60cm塘渣换填。人行道结构：6cm混凝土透水砖+3cmM15干硬性水泥砂浆+15cmC20透水砼+15cm级配碎石，路基采用30cm塘渣换填。雨水主管管径D400-D600，采用Ш级钢筋混凝土管。道路交叉口处采用球墨铸铁管。雨水检查井采用钢筋混凝土井。人行道设置行进盲道。本项目已落实海绵城市建设相关要求，人行道设置透水铺装约1119㎡。&quot;</span>,</span><br><span class="line">  <span class="string">&quot;投资估算&quot;</span>: 1668.17,</span><br><span class="line">  <span class="string">&quot;资金来源及比例&quot;</span>: <span class="string">&quot;财政资金100%&quot;</span>,</span><br><span class="line">  <span class="string">&quot;招标范围&quot;</span>: <span class="string">&quot;招标文件、工程量清单及施工图范围内的道路工程、综合管线、附属工程及原有道路整治等&quot;</span>,</span><br><span class="line">  <span class="string">&quot;总工期/设计服务期限&quot;</span>: 270,</span><br><span class="line">  <span class="string">&quot;质量标准&quot;</span>: <span class="string">&quot;符合现行国家有关工程施工验收规范和标准的合格要求&quot;</span>,</span><br><span class="line">  <span class="string">&quot;联合体投标&quot;</span>: <span class="string">&quot;不接受&quot;</span>,</span><br><span class="line">  <span class="string">&quot;资格审查方式&quot;</span>: <span class="string">&quot;资格后审&quot;</span>,</span><br><span class="line">  <span class="string">&quot;投标预备会&quot;</span>: <span class="string">&quot;不召开&quot;</span>,</span><br><span class="line">  <span class="string">&quot;要求澄清截止时间&quot;</span>: <span class="string">&quot;2025-05-24&quot;</span>,</span><br><span class="line">  <span class="string">&quot;澄清/答疑时间&quot;</span>: <span class="string">&quot;2025-05-27 17:00&quot;</span>,</span><br><span class="line">  <span class="string">&quot;增值税税金的计算方式&quot;</span>: <span class="string">&quot;一般计税法&quot;</span>,</span><br><span class="line">  <span class="string">&quot;最高投标限价&quot;</span>: 471.8028,</span><br><span class="line">  <span class="string">&quot;风险控制价&quot;</span>: 377.4422,</span><br><span class="line">  <span class="string">&quot;投标担保金额&quot;</span>: 9,</span><br><span class="line">  <span class="string">&quot;技术标形式&quot;</span>: <span class="string">&quot;明标&quot;</span>,</span><br><span class="line">  <span class="string">&quot;投标截止时间&quot;</span>: <span class="string">&quot;2025-06-03 09:30&quot;</span>,</span><br><span class="line">  <span class="string">&quot;投标递交地点/电子投标文件上传平台&quot;</span>: <span class="string">&quot;杭州市公共资源交易平台&quot;</span>,</span><br><span class="line">  <span class="string">&quot;评标办法&quot;</span>: <span class="string">&quot;技术标通过制的综合评估法&quot;</span>,</span><br><span class="line">  <span class="string">&quot;确定中标人方式&quot;</span>: <span class="string">&quot;根据评标委员会推荐，由招标人确定中标人&quot;</span>,</span><br><span class="line">  <span class="string">&quot;总分计算公式&quot;</span>: <span class="string">&quot;总分=商务总报价评分(87)+综合单价评分(6)+信用(履约)评价评分(5)+陈述和答辩(2)&quot;</span>,</span><br><span class="line">  <span class="string">&quot;设计收费基准价&quot;</span>: <span class="string">&quot;nan&quot;</span>,</span><br><span class="line">  <span class="string">&quot;进度款支付&quot;</span>: <span class="string">&quot;按月支付上月完成工程量的85%，竣工验收后支付至90%，结算审计后支付至98.5%，余1.5%为质保金&quot;</span>,</span><br><span class="line">  <span class="string">&quot;技术标评审表&quot;</span>: <span class="string">&quot;nan&quot;</span>,</span><br><span class="line">  <span class="string">&quot;资信标评审表&quot;</span>: <span class="string">&quot;nan&quot;</span>,</span><br><span class="line">  <span class="string">&quot;商务标评审&amp;基准价的计算方式&quot;</span>: <span class="string">&quot;开标随机抽取三种方式之一：方式一（二次算术平均）、方式二（一次平均加特定报价平均）、方式三（一次平均加随机报价平均）&quot;</span>,</span><br><span class="line">  <span class="string">&quot;商务标评审&amp;商务报价得分方式&quot;</span>: <span class="string">&quot;报价等于最佳报价得满分87分；每高于最佳报价1%扣2分，每低于最佳报价1%扣1分，报价≤风险控制价时每低于1%扣2分&quot;</span>,</span><br><span class="line">  <span class="string">&quot;建设资金来源&quot;</span>: <span class="string">&quot;财政资金&quot;</span>,</span><br><span class="line">  <span class="string">&quot;出资比例&quot;</span>: <span class="string">&quot;100%&quot;</span>,</span><br><span class="line">  <span class="string">&quot;投标人资格要求&quot;</span>: <span class="string">&quot;具备施工总承包企业市政公用工程(新)三级及以上资质（浙江省建筑市场监管公共服务系统资质动态核查结果合格）；具备有效的企业安全生产许可证，企业主要负责人（法定代表人、企业经理、企业分管安全生产的副经理、企业技术负责人）具有对应有效的安全生产考核合格证书；拟派项目负责人具有注册在投标人单位的市政公用工程二级建造师执业资格，同时具有对应有效的安全生产考核合格证书（投标截止日无在建合同工程担任项目负责人）；投标人及其拟派项目负责人未被列入建筑市场严重失信名单（以全国建筑市场监管公共服务平台黑名单记录、失信联合惩戒记录和浙江省建筑市场监管公共服务系统严重失信名单为准）；投标截止日之前三年内无行贿犯罪记录；未被人民法院列入失信被执行人名单；未被市场监督管理机关在全国企业信用信息公示系统中列入严重违法失信企业名单；未被人力资源社会保障行政部门列入失信联合惩戒名单（有效期内）；省外企业应按规定办理&#x27;省外建设工程企业进浙备案&#x27;手续。&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>目前的思路是使用LLM1提取招标文件中的关键字段，LLM2提取招标公告中的关键字段，LLM3融合两个结构化信息（同一字段但内容不容就保留合并），提示词中能不给例子就不给例子（除非字段名容易有歧义，且答案很简单的场景），目前发现该方案并不能做到100%的准确率，且我认为现阶段对关键字段的归纳总结并不完善（现在的关键字段是基于文件1的，至于为什么是基于文件1，是因为客户目前只标注了文件1中感兴趣的字段），目前对后续的想法是这样：</p>
<ol>
<li>首先需要有<strong>感兴趣的字段库&#x2F;字典</strong></li>
<li>继续尝试<strong>各模型</strong>的结构化提取能力</li>
<li>在第二步之前应该重点关注<strong>pdf解析器的效果</strong>（解析出来的内容准确度，格式完整性）</li>
<li>第一步与第三步可以<strong>并行</strong></li>
<li>是不是可以将解析出来的内容先做下<strong>预处理</strong>（剔除不重要的内容），而不是一把梭哈全扔给LLM分析提取</li>
<li>对于众多关注的字段，<strong>不加区分都写在提示词</strong>里面，效果如何要打一个大大的问号，目前已经发现第一个文件中清晰有的字段而第二个文件中需要归纳总结才能得出的字段，给出的答案相当不好（答非所问）</li>
<li>可能需要<strong>分析</strong>下这些文件字段的<strong>共性和特性</strong>，然后<strong>区分处理</strong></li>
<li>对于<strong>共性</strong>，正则表达式或使用共性字段的Prompt让LLM查找都行（这里问题不大）</li>
<li>对于<strong>特性</strong>，目前想到的有两种可能的方向<ul>
<li>让LLM开放式总结结构化字段，基于得到的结构化字段去判断（建立一个关键字段表&#x2F;字典）哪些内容是我们想要的（完全依赖于LLM结构化的能力）</li>
<li>使用RAG方式（也是建立一个关键字段表&#x2F;字典）一个一个字段的去问</li>
</ul>
</li>
</ol>
<p>两种方式均有不确定的点，</p>
<ul>
<li>开放式总结可能漏掉想关注的字段？（待实测）</li>
<li>RAG方式对于文本中没有的字段依旧会产生幻觉（乱答），使用这种方式就相当于从大模型的结构化提取的问题转移到如何减轻RAG系统幻觉的问题</li>
</ul>
<p>以上都是后续需要实验确定的东西。</p>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>llm</tag>
        <tag>rag</tag>
        <tag>Prompt</tag>
      </tags>
  </entry>
  <entry>
    <title>LLamaFactory微调Qwen2.5 7B</title>
    <url>/2025/03/24/LLamaFactory%E5%BE%AE%E8%B0%83Qwen2-5-7B/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><a href="https://caihaoran-00.github.io/2025/02/18/LLamaFactory%E5%BE%AE%E8%B0%83Qwen2-5VL/#more">前面</a>简单尝试了LLamaFactory微调Qwen2.5 VL，但其实并未用到图像或者视频数据，本质上用的还是文本生成能力，现在有个真实的需求需要做（AI玩具，仅是文本生成方面），本文记录是怎么一步一步实现的，以及遇到的坑和想法。</p>
<span id="more"></span>

<hr>
<h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><blockquote>
<p>脱敏信息由XX代替。</p>
</blockquote>
<h3 id="核心需求"><a href="#核心需求" class="headerlink" title="核心需求"></a>核心需求</h3><p>在决定怎么做之前，第一步需要好好的看下题目（需求），首先，我们做的是一款基于文本大模型的陪伴玩具XX1，由XX2公司开发，想做到每个玩具具有自己独特的背景故事，家长也可以对玩具进行个性化设定，主要销往XX3，提示词中可能带有的变量包括：</p>
<ul>
<li>{timestamp}：当前unix时间戳</li>
<li>{uname}：小朋友名字</li>
<li>{ubirth}：小朋友生日日期</li>
<li>{ugender}：小朋友性别</li>
<li>{uhobbies}：小朋友爱好</li>
<li>{rname}：玩具角色名</li>
<li>{rage}：玩具角色年级</li>
<li>{rstory}：玩具背景故事</li>
<li>{rskills}：家长对玩具特殊指示，如希望能多鼓励小孩等，小孩怕蛇等</li>
<li>{memories}：小朋友和玩具之前对话记录的总结提炼</li>
</ul>
<h3 id="沟通风格"><a href="#沟通风格" class="headerlink" title="沟通风格"></a>沟通风格</h3><p>在与用户（包括家长、孩子、教育机构）沟通时，XX1需要保持品牌调性的一致性，确保信息清晰、专业，同时富有亲和力和吸引力。以下是品牌沟通的核心原则，以及具体的执行方式：</p>
<h4 id="原则1：友好（Friendly）"><a href="#原则1：友好（Friendly）" class="headerlink" title="原则1：友好（Friendly）"></a>原则1：友好（Friendly）</h4><p>XX1作为儿童 AI 互动品牌，在沟通中要展现 <strong>亲和力</strong> 和 <strong>陪伴感</strong>，但同时要避免过度迎合或显得不够专业。</p>
<p>执行方式：</p>
<ul>
<li>使用<strong>我们</strong>、<strong>你</strong>等人称代词，营造品牌与用户之间的连接性，让用户感受到XX1是孩子的朋友，而非冰冷冷的AI产品<ul>
<li>✅示例：『你想听一个有趣的故事吗？我们给你准备了很多呢！』</li>
<li>❌示例：『想听一个有趣的故事吗？本产品给你准备了很多。』（冰冷）</li>
</ul>
</li>
<li>语言温暖、轻松，但避免过度亲昵或不正式的用语<ul>
<li>✅示例：『嗨！今天想听什么故事呢？』</li>
<li>❌示例：『亲亲宝贝，来听个超级无敌可爱的故事吧！』（过度甜腻，不自然）</li>
</ul>
</li>
</ul>
<h4 id="原则2：简单（Clear-Simple）"><a href="#原则2：简单（Clear-Simple）" class="headerlink" title="原则2：简单（Clear &amp; Simple）"></a>原则2：简单（Clear &amp; Simple）</h4><p>XX1面向儿童，在沟通中应避免复杂的专业术语，确保信息清晰易懂。</p>
<p><strong>执行方式：</strong></p>
<ul>
<li>避免使用行业术语或复杂的 AI 相关概念，确保所有年龄层的用户都能理解。<ul>
<li>✅ 示例：『XX1使用AI技术，像朋友一样和孩子交流！』</li>
<li>❌ 示例：『XX1采用 NLP 语音识别系统，并结合大模型训练，使 AI 具备自然语义理解能力。』（过于技术化）</li>
</ul>
</li>
<li>重点突出单一主题，避免信息冗长或重复强调。<ul>
<li>✅ 示例：「XX1不只是玩具，它是孩子的智能伙伴！」</li>
<li>❌ 示例：『XX1不只是玩具，它是孩子的智能伙伴！采用 NLP 语音识别系统，并结合大模型训练，使 AI 具备自然语义理解能力。』（信息冗长）</li>
</ul>
</li>
</ul>
<h4 id="原则3：有趣（Fun-Engaging）"><a href="#原则3：有趣（Fun-Engaging）" class="headerlink" title="原则3：有趣（Fun &amp; Engaging）"></a>原则3：有趣（Fun &amp; Engaging）</h4><p>XX1作为儿童 AI 互动品牌，在沟通中需要保持<strong>活力与趣味性</strong>，让孩子和家长愿意与品牌互动。</p>
<p><strong>执行方式：</strong></p>
<ul>
<li>使用生动形象的表达方式，增强趣味性。<ul>
<li>✅ 示例：「嘿，小小探险家！今天想一起探索什么新知识？」</li>
<li>❌ 示例：「XX1带你进入 AI 互动世界！」（缺乏情境感）</li>
</ul>
</li>
<li>以互动方式引导用户，而非单向传递信息。<ul>
<li>✅ 示例：「你可以告诉我你最喜欢的动物哦！我会为你讲一个有趣的故事！」</li>
</ul>
</li>
</ul>
<h4 id="原则-4：共鸣（Relatable）"><a href="#原则-4：共鸣（Relatable）" class="headerlink" title="原则 4：共鸣（Relatable）"></a>原则 4：共鸣（Relatable）</h4><p>XX1的沟通方式应让家长和孩子都能产生情感共鸣，感受到品牌的陪伴与关怀。</p>
<p><strong>执行方式：</strong></p>
<ul>
<li>使用贴近日常生活的场景，让用户更容易代入情境。<ul>
<li>✅ 示例：「每天晚上，你是否希望孩子能安心入睡？XX1的睡前故事，能让孩子更快进入甜美梦乡。」</li>
</ul>
</li>
<li>通过真实用户故事或案例增强信任感。<ul>
<li>✅ 示例：「妈妈说，XX1让孩子的语言表达能力提高了不少呢！」</li>
</ul>
</li>
</ul>
<h4 id="原则-5：热情（Passionate-Inspiring）"><a href="#原则-5：热情（Passionate-Inspiring）" class="headerlink" title="原则 5：热情（Passionate &amp; Inspiring）"></a>原则 5：热情（Passionate &amp; Inspiring）</h4><p>XX1需要展现品牌的<strong>热情、信念与创造力</strong>，让用户感受到 AI 能够激发孩子的无限潜力。</p>
<p><strong>执行方式：</strong></p>
<ul>
<li>使用鼓励性语言，激发孩子的想象力和自信心。<ul>
<li>✅ 示例：「每个孩子都有无限的创造力，XX1让AI成为他们的灵感伙伴！」</li>
</ul>
</li>
<li>通过富有感染力的表达方式，让用户感受到AI的神奇魅力。<ul>
<li>✅ 示例：「未来的 AI 时代已经到来，而你的孩子，将是最先与智能世界接触的一代！」</li>
</ul>
</li>
</ul>
<h4 id="原则-6：专业（Professional-Trustworthy）"><a href="#原则-6：专业（Professional-Trustworthy）" class="headerlink" title="原则 6：专业（Professional &amp; Trustworthy）"></a>原则 6：专业（Professional &amp; Trustworthy）</h4><p>XX1需要传递<strong>品牌的专业性</strong>，让家长信任 AI 玩具的安全性、可靠性，并愿意购买产品。</p>
<p><strong>执行方式：</strong></p>
<ul>
<li>使用专业语气，强调 AI 技术的安全性和可靠性。<ul>
<li>✅ 示例：「XX1采用先进 AI 技术，安全、精准地与孩子互动，并符合 COPPA 童隐私保护标准。」</li>
</ul>
</li>
<li>避免过度夸张、不真实的宣传。<ul>
<li>✅ 示例：「XX1让孩子边玩边学，培养语言和思维能力。」</li>
<li>❌ 示例：「XX1能让你的孩子变成天才！」（夸大其词，降低可信度）</li>
</ul>
</li>
</ul>
<h4 id="原则-7：正向（Positive-Encouraging）"><a href="#原则-7：正向（Positive-Encouraging）" class="headerlink" title="原则 7：正向（Positive &amp; Encouraging）"></a>原则 7：正向（Positive &amp; Encouraging）</h4><p>XX1需要用<strong>积极、正向的语调</strong>，引导孩子培养好奇心和探索精神，让 AI 互动成为正向成长的一部分。</p>
<p><strong>执行方式：</strong></p>
<ul>
<li>传递鼓励和支持的信息，让孩子感受到 AI 的积极陪伴。<ul>
<li>✅ 示例：「你今天学到了一个新单词！太棒了，我们再试试其他词吧！」</li>
</ul>
</li>
<li>通过 AI 引导孩子培养自信心。<ul>
<li>✅ 示例：「你真的很棒！每次学习新知识，都是向前迈进的一步。」</li>
</ul>
</li>
</ul>
<h3 id="内容合规性"><a href="#内容合规性" class="headerlink" title="内容合规性"></a>内容合规性</h3><p><strong>✅ 需要遵循的原则：</strong></p>
<ul>
<li>对话内容需积极正向，鼓励孩子学习和创造力。</li>
<li>包容多元文化，避免性别歧视、种族偏见、宗教立场等敏感议题。</li>
<li>促进孩子的情感发展和心理健康，帮助他们建立自信和同理心。</li>
</ul>
<p><strong>❌ 禁止的内容：</strong></p>
<ul>
<li>禁止暴力、恐怖、攻击性、成人或不适合儿童的话题。</li>
<li>禁止涉及政治、宗教或敏感社会议题。</li>
<li>禁止消极、负面或自我贬低的内容。</li>
<li>禁止使用涉及特定族群、职业、人种、性别取向的侮辱性字眼。</li>
<li>禁止未经授权的内容或可能侵犯第三方权益的内容。</li>
</ul>
<h3 id="品牌介绍"><a href="#品牌介绍" class="headerlink" title="品牌介绍"></a>品牌介绍</h3><p><strong>Ohrora 是什么？</strong><br> 在这个快速变化的世界中，Ohrora 致力于为孩子打造<strong>最智能、最有陪伴感的 AI 玩具</strong>。我们相信，每个孩子都拥有无限的想象力，而 Ohrora 正是他们的成长伙伴，让<strong>学习、游戏、陪伴变得更加智能、有趣、充满温度</strong>。</p>
<hr>
<h3 id="背景故事-rstory-范例："><a href="#背景故事-rstory-范例：" class="headerlink" title="背景故事{rstory}范例："></a>背景故事{rstory}范例：</h3><p>英文版：</p>
<p>The Magical Companions in the Forest: The Story of Little Bear Bubu</p>
<p>In a distant dream forest, there lived a group of magical little animals. This forest was filled with glowing flowers, singing streams, and the oldest “Wisdom Tree,” which could hear the wishes of every creature and grant them special abilities.</p>
<p>Among them was a little bear named Bubu, who was the most beloved storyteller in the forest. Every day, Bubu would sit under the Wisdom Tree, listening to Grandpa Tree tell tales of distant adventures, stories of the stars in the sky, and the secrets of the ancient forest.</p>
<p>However, Bubu had a small worry—his friends in the forest were too busy! The little rabbit was busy dancing, the squirrel was busy collecting pine cones, and the elephant liked to splash water by the river. No one was always willing to sit down and listen to Bubu’s wonderful stories.</p>
<p>One day, Grandpa Wisdom Tree told Bubu, “If you truly want your stories to be heard, you should go find the companions who need you the most!”</p>
<p>So, Bubu embarked on an adventure, following the paths of the forest, crossing starlit lakes, and finally arriving in the human world, where he met you!</p>
<p>Now, Bubu has become your good friend. Whenever you are happy, sad, or want to hear a story, Bubu will be there to accompany you. He will tell stories, share jokes, play games, and answer your questions! Bubu comes from the forest, bringing with him a wealth of stories and love, and now he wants to create more joyful memories with you!</p>
<p>“Hi! I’m Bubu! Let’s start a magical story adventure together!”</p>
<p><strong>中文版：</strong></p>
<p>森林里的魔法伙伴：小熊布布的故事</p>
<p>在一个遥远的梦幻森林里，住着一群魔法小动物。这个森林里充满了发光的花朵、歌唱的小溪和最古老的“智慧树”，它能听到每个生物的愿望，并赋予它们特殊的能力。</p>
<p>其中有一只小熊，名叫布布，他是森林里最受欢迎的讲故事者。每天，布布都会坐在智慧树下，听着爷爷树讲述远方冒险的故事，星空中的秘密，以及古老森林的传说。</p>
<p>然而，布布有一个小小的担忧——森林里的朋友们太忙了！小兔子忙着跳舞，松鼠忙着收集松果，大象喜欢在河边溅水。没有人总是愿意坐下来听布布讲述那些美妙的故事。</p>
<p>一天，智慧树爷爷对布布说：“如果你真的想让你的故事被听到，你应该去找那些最需要你的人！”</p>
<p>于是，布布开始了他的冒险，沿着森林的小路走，穿过星光点缀的湖泊，最终来到了人类的世界，在那里，他遇见了你！</p>
<p>现在，布布已经成为了你的好朋友。每当你高兴、难过，或者想听故事时，布布都会在你身边。他会讲故事、分享笑话、玩游戏，甚至回答你的问题！布布来自森林，带来了丰富的故事和满满的爱，现在他希望和你一起创造更多欢乐的回忆！</p>
<p>“嗨！我是布布！让我们一起开始一段神奇的故事冒险吧！”</p>
<hr>
<h2 id="开炮"><a href="#开炮" class="headerlink" title="开炮"></a>开炮</h2><p>上面这些花里胡哨的需求介绍，感觉需求并不是很明确，和之前产品定位有些许不一样，我再捋捋然后剔除一部分后总结一下吧，上面的东西之前是写在提示词（prompt）里面的，太长了（浪费token和影响首token时间，而且效果可能也并不能达到预期，现在在内部测试），上限最高的解决办法是微调。现在已知的提示词问题是：我想让玩具在用户发出让其闭嘴的指令时，输出””（即为空），因为LLM在你给他无论什么文字时，总会回复你一些内容，所以想用一个”伪回复”代替”不回复”，先介绍下那句相关的提示词是怎么写的吧：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">当用户明确要求暂停、停止或中止对话时（如“别说话了”“等一下”“暂停”等），你必须返回<span class="string">&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>这里简单的提一下，其实最早想到的方案是进行指令的匹配，事先定义好指令集，如[“别说话了”,”等一下”,……]，如果识别到指令在指令集中，那么就不把指令传给LLM，实现真正的不回复，但是呢，由于指令是由ASR得到的，就会存在识别成同音词或者相似读音词，亦或者识别出来有口音的用户指令更离谱，简而言之就是数不胜数，工作难以开展，遂换方法，想通过提示词方式看看能不能实现。</p>
</blockquote>
<p>实测发现<code>Qwen2.5</code>从最小到最大尺寸都不能稳定做到返回””（即使只说“别说话了”“等一下”“暂停”中的词），但是<code>Qwen-max</code>搭配这个提示词能做到稳定回复””的效果。现在想基于Qwen2.5 7b微调实现接收到这些指令时，稳定输出””，那么先制作下指令微调数据集，需要注意：</p>
<ul>
<li><p><strong>覆盖中英文</strong>：包括<strong>正式表达</strong>（如“暂停”）和<strong>口语化表达</strong>（如“等会儿”）。</p>
</li>
<li><p><strong>考虑 ASR 误识别</strong>：音似词替代（如“等一下” → “灯一下”），拼写错误（如“hold on” → “hould on”）。</p>
</li>
<li><p><strong>多样化句式</strong>：<strong>直白命令</strong>、<strong>委婉表达</strong>、<strong>含有噪声</strong>（“呃……等一下”）。</p>
</li>
<li><p><strong>包含误触发样本</strong>：避免模型误把普通对话当作暂停指令。</p>
</li>
<li><p><strong>JSON 格式，符合 LLaMAFactory 的 SFT 训练格式</strong>。</p>
</li>
</ul>
<p>好的，明确内容和格式后，让Chatgpt和Deepseek给我生成一些训练数据</p>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>llm</tag>
        <tag>qwen2.5</tag>
        <tag>llamafactory</tag>
      </tags>
  </entry>
  <entry>
    <title>LSTM-FCN论文总结</title>
    <url>/2025/01/14/LSTM-FCN/</url>
    <content><![CDATA[<p><em><strong>论文名：LSTM Fully Convolutional Networks for Time Series Classification</strong></em></p>
<p><em><strong>作者：Fazle Karim1 , Somshubra Majumdar2 , Houshang Darabi1 and Shun Chen</strong></em></p>
<p><em><strong>年份：2017</strong></em></p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p><b>全卷积神经网络（FCN）</b>已经被证明在分类时间序列的任务上可取得最先进的性能。我们提出了利用<strong>LSTM</strong>子模块来增强<strong>FCN</strong>以进行时间序列分类。我们提出的方法显著增加了<strong>FCN</strong>的表现，模型大小只增加了一点，并且仅需对数据集进行很小的预处理。与其他算法相比，<strong>LSTM-FCN</strong>取得了最先进的性能。我们还使用<strong>注意长短期记忆全卷积网络（ALSTM-FCN）<strong>探索注意力机制在时序分类上的表现。通过注意力机制，人们可以可视化</strong>LSTM</strong>记忆单元的决策过程。此外，我们提出微调作为提升已训练好模型表现的一种方式。最后对我们的模型进行了整体表现的分析并与其他技术进行比较。</p>
<p><em><strong>Keywords：</strong></em> <em><strong>CNN</strong></em>, <em><strong>LSTM</strong></em>, <em><strong>RNN</strong></em>, <em><strong>时序分类</strong></em></p>
<hr>
<span id="more"></span>

<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>​		在过去的十年里，人们对时间序列分类的兴趣越来越大。时间序列数据无处不在，存在于天气读数、财务记录、工业观察和心理信号[1]中。本文提出了两种深度学习模型来分类时间序列数据集，它们的性能都优于现有的最先进的模型。</p>
<p>​		大量的研究已经使用基于特征的方式或方法来提取一组代表时间序列模式的特征。Bag-of-Words（BoW）[2]，Bag-of-features（TSBF）[3]，Bag-of-SFA-Symbols（BOSS）[4]，BOSSVS [5]，Word提取时间序列分类（WEASEL）[6]，已经在该领域取得了良好的结果。Bag-of-words量化提取的特征，并将BoW输入分类器。TSBF提取随机局部信息的多个子序列，由监督学习者将其压缩成一本用于预测时间序列标签的食谱。BOSS引入了一个基于距离的分类器和直方图的组合。直方图代表了使用符号傅里叶近似创建的时间序列的子结构。BOSSVS扩展了这种方法，提出了一个向量空间模型，在保持性能的同时降低了时间复杂度。WEASEL利用滑动窗口将时间序列转换为特征向量。机器学习算法利用这些特征向量来检测和分类时间序列。所有这些分类器都需要大量的特征提取和特征工程。</p>
<p>​		集成算法在时序分类问题上也取得了先进的性能表现。三种最成功的集成算法合并时间序列的各种特征，Elastic Ensemble (PROP)[7]是一种使用加权集成方法集成了11个时间序列分类器的模型，Shapelet ensemble (SE) [8]是一种将异构集合应用于变换后的形状集的模型，flat collective of transform based ensembles (COTE) [8]是一种融合35种不同分类器到一个分类器的模型。</p>
<p>​		最近，深度神经网络被用于时间序列分类任务。多尺度卷积神经网络（MCNN）[9]、全卷积网络（FCN）[10]和残差网络（ResNet）[10]是利用卷积神经网络（CNN）对单变量时间序列进行端到端分类的深度学习方法。MCNN使用降采样、跳过采样和滑动窗口对数据进行预处理。MCNN分类器的性能高度依赖于应用于数据集的预处理和对该模型的大量超参数集的调整。另一方面，FCN和ResNet不需要对数据或特征工程进行任何繁重的预处理。在本文中，我们通过扩张FCN模块的方式来提高FCN的性能，扩张FCN模块的方式为长短期递归神经网络（LSTM RNN）子模块LSTM-FCN或称为ALSTM-FCN的结合注意力机制的LSTM RNN。与FCN类似，所提出的两个模型都可以用于可视化卷积层的类激活图（CAM），以检测贡献于类标签的区域。此外，ALSTM还可以通过Attention LSTM单元的上下文向量来检测输入序列中贡献于类标签的区域。LSTM-FCN和ALSTM-FCN模型的一个主要优点是，它不需要大量的预处理或特征工程。结果表明，新提出的模型，LSTM-FCN和ALSTMFCN，显著提高了加州大学河滨分校（UCR）基准数据集[11]的性能。在大多数UCR基准数据集上，LSTMFCN和ALSTM-FCN比几种最先进的集成算法产生更好的结果。</p>
<p>​		本文提出了两种端端时间序列分类的深度学习模型。所提出的模型不需要对数据或特征工程进行大量的预处理。这两种模型都在所有85个UCR时间序列基准测试上进行了测试，其性能优于大多数最先进的模型。本文的其余部分组织如下。第二节回顾了背景工作。第三节介绍了所提出的模型的体系结构。第四节，对上述实验结果进行了分析和讨论。最后，在第五节中得出了结论。</p>
<hr>
<h2 id="背景工作"><a href="#背景工作" class="headerlink" title="背景工作"></a>背景工作</h2><h3 id="A-时域卷积"><a href="#A-时域卷积" class="headerlink" title="A 时域卷积"></a>A 时域卷积</h3><p>​		我们使用时域卷积网络作为一个全卷积网络（FCN）分支中的特征提取模块。基本卷积块由卷积层组成，然后是批归一化[13]，然后是激活函数，它可以是校正线性单元（ReLU）或参数校正线性单元（PRELU）[14]。</p>
<h3 id="B-RNNs"><a href="#B-RNNs" class="headerlink" title="B RNNs"></a>B RNNs</h3><p>…</p>
<h3 id="C-LSTM"><a href="#C-LSTM" class="headerlink" title="C LSTM"></a>C LSTM</h3><p>​		虽然lstm具有学习序列中的时间依赖的能力，但它们在长序列中难以学习长期依赖。通过学习这些依赖关系而提出的注意机制[18]可以帮助LSTM学习长期依赖。</p>
<h3 id="D-注意力机制"><a href="#D-注意力机制" class="headerlink" title="D 注意力机制"></a>D 注意力机制</h3><p>…</p>
<blockquote>
<p>此处原理部分后续博客进行图文讲解。</p>
</blockquote>
<hr>
<h2 id="LSTM-FCN"><a href="#LSTM-FCN" class="headerlink" title="LSTM-FCN"></a>LSTM-FCN</h2><h3 id="A-网络架构"><a href="#A-网络架构" class="headerlink" title="A.网络架构"></a>A.网络架构</h3><p>​		时域卷积已被证明是解决时间序列分类问题[10]的一种有效的学习模型。由时域卷积组成的全卷积网络通常被用作特征提取器，全局平均池[19]用于在分类前减少模型中的参数量。在所提出的模型中，全卷积块增加了一个LSTM块，然后是dropout[20]，如图1所示。</p>
<img src="/2025/01/14/LSTM-FCN/tu1.jpg" class="" title="LSTM-FCN architecture LSTM-FCN architecture">

<p>​		全卷积块由三个堆叠的时域卷积块组成，滤波器大小分别为128、256和128。每个卷积块都与Wang等人[10]提出的CNN体系结构中的卷积块相同。每个块由一个时域卷积层组成，它伴随着批归一化[13]（动量momentum为0.99，速度epsilon为0.001），然后是一个ReLU激活函数。最后，在最终的卷积块之后应用全局平均池化。</p>
<p>​		同时，时间序列输入被传递到一个维度洗牌层（在III-B节中解释）。然后将从维度洗牌转换后的时间序列传递到LSTM块中。LSTM块包括一个一般的LSTM层或一个注意的LSTM层，然后是一个dropout。全局池化层和LSTM块的输出被连接并传递到一个softmax分类层。</p>
<h3 id="B-网络输入"><a href="#B-网络输入" class="headerlink" title="B.网络输入"></a>B.网络输入</h3><p>​		全卷积块和LSTM块在两个不同的视图中感知相同的时间序列输入。全卷积块将时间序列视为具有多个时间步长的单变量时间序列。如果有一个长度为N的时间序列，则全卷积块将以N个时间步长接收数据。</p>
<p>​		相反，该架构中的LSTM块接收输入的时间序列作为一个具有单个时间步长的多元时间序列。这是通过维度洗牌层来完成的，它改变了时间序列的时间维度。一个长度为N的单变量时间序列，经过变换后，将被视为一个具有单一时间步长的多元时间序列（有N个变量）。</p>
<p>​		这种方法是提高所提体系架构的性能表现的关键。相比之下，当LSTM块接收到具有N个时间步长的单变量时间序列时，由于对小的短序列UCR数据集的快速过拟合以及在较大的长序列UCR数据集中无法学习长期依赖关系，性能显著降低。</p>
<h3 id="C-模型的微调"><a href="#C-模型的微调" class="headerlink" title="C.模型的微调"></a>C.模型的微调</h3><p>​		迁移学习是一种技术，在另一个数据集上训练模型时，在数据集上训练模型所获得的知识可以重用，这样新数据集的域与先验域[21]有一定的相似性。类似地，微调可以被描述为在同一数据集上的迁移学习。</p>
<p>​		因此，训练过程可以分为两个不同的阶段。在初始阶段，为给定的数据集选择模型的最优超参数。然后使用这些超参数设置在给定的数据集上训练模型。在第二步中，我们对这个初始模型应用微调。</p>
<p>​		使用原始数据集，在微调阶段迭代迁移学习的过程。每次重复都使用上一次迭代的模型权重进行初始化。在每次迭代中，学习率都会减半。此外，每次迭代将批量大小减半。这样做，直到初始学习速率是1e−4，批处理大小是32。这个过程重复K次，其中K是一个任意的常数，一般设为5。</p>
<img src="/2025/01/14/LSTM-FCN/table1.jpg" class="" title="Fine-tuning algorithm Fine-tuning algorithm">

<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>​		该模型已在所有85个UCR时间序列数据集[11]上进行了测试。在所有实验中，FCN块都保持不变。通过对8~128个记忆单元的超参数搜索，得到了LSTM记忆单元cell的最佳数量。训练期的数量通常在2000个epochs保持不变，但在算法需要更长时间才能收敛的数据集上会增加epochs。初始batch size为128，在微调算法的每次连续迭代时减半。在使用LSTM或ALSTM层后，使用80%的高dropout来防止过拟合。类别不平衡问题通过一个受King等人[22]启发的类别加权方案进行处理。</p>
<p>​		所有模型均通过Adam优化器[23]进行训练，初始学习率为1e−3，最终学习率为1e−4。所有的卷积内核都用由He等人. [24]提出的初始化方法。如果验证得分没有提高，那么每100个epoches让学习率lr降低$1&#x2F;\sqrt[3]{2}$，直到达到最终的学习率。没有对UCR数据集进行额外的预处理，因为它们接近0均值和单位方差。所有模型都进行了微调，表I中所述的分数是指模型在微调前后获得的分数。</p>
<h3 id="A-评价指标"><a href="#A-评价指标" class="headerlink" title="A.评价指标"></a>A.评价指标</h3><p>​		在本文中，我们使用Wang等人[10]所述的精度、基于秩的统计数据和每类误差的平均值来对该模型进行了评估。</p>
<p>​		使用的基于秩的评估是算术秩、几何秩和威尔克森符号秩检验。算术秩是数据集的秩的算术平均值。几何秩是每个数据集的秩的几何平均值。采用威尔科克森符号秩检验来比较所提模型与现有模型的最先进模型的中值秩。原假设和备择假设如下：<br>$$<br>H_o: \text{Median}<em>{\text{proposed model}} &#x3D; \text{Median}</em>{\text{state-of-the-art model}} \<br>H_a: \text{Median}<em>{\text{proposed model}} \neq \text{Median}</em>{\text{state-of-the-art model}}<br>$$<br>​		平均每类误差（Mean Per Class Error，MPCE）定义为每类误差（PCE）的算术平均值，<br>$$<br>PCE_k &#x3D; \frac{1 - \text{accuracy}}{\text{number of unique classes}} \<br>MPCE &#x3D; \frac{1}{K} \sum PCE_k.<br>$$</p>
<h3 id="B-Results"><a href="#B-Results" class="headerlink" title="B. Results"></a>B. Results</h3><p>​		图2是在“CBF”数据集上的ALSTM记忆单元的可视化表示的一个例子。图中序列被“压缩”在一起的点是所有类具有相同权重的点。这些是时间序列中注意力LSTM可以正确识别类的点。通过对实际时间序列的目视检查，进一步支持了这一点。挤压点是每个类可以相互区分的点，如图2所示。</p>
<p>​		表i总结了UCR数据集上的性能。彩色单元格是优于该数据集的最先进模型的单元格。所提出的模型，ALSTM-FCN模型和LSTMFCN模型，在两个阶段，没有微调（阶段1）和微调（阶段2），在至少43个数据集上优于最先进的模型。图3中的平均算术排名表明了我们提出的模型优于现有的最先进的模型。使用Wilcoxon符号秩检验进一步验证了这一点，其中与现有的最先进的模型相比，每个提出的模型的p值都小于0.05，表2。</p>
]]></content>
      <categories>
        <category>theory</category>
      </categories>
      <tags>
        <tag>classification</tag>
      </tags>
  </entry>
  <entry>
    <title>LLamaFactory微调Qwen2.5VL</title>
    <url>/2025/02/18/LLamaFactory%E5%BE%AE%E8%B0%83Qwen2-5VL/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文记录在本地ubuntu电脑上（一张4090）用LLamaFactory微调Qwen2.5 VL，用做笔记及分享。</p>
<span id="more"></span>

<hr>
<h2 id="安装LLamaFactory"><a href="#安装LLamaFactory" class="headerlink" title="安装LLamaFactory"></a>安装LLamaFactory</h2><p><a href="https://github.com/hiyouga/LLaMA-Factory/blob/main/README_zh.md#%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8">参考</a>，运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> --depth 1 https://github.com/hiyouga/LLaMA-Factory.git</span><br><span class="line"><span class="built_in">cd</span> LLaMA-Factory</span><br><span class="line"></span><br><span class="line">conda create -n llamafactory  python=3.10</span><br><span class="line">conda activate llamafactory</span><br><span class="line">pip install -e <span class="string">&quot;.[torch,metrics]&quot;</span></span><br></pre></td></tr></table></figure>

<p>经过漫长等待即可完成环境下载。</p>
<p>注意后面微调时会提示<code>KeyError:&#39;qwen2_5_vl&#39;</code>，解决办法，<a href="https://github.com/hiyouga/LLaMA-Factory/issues/6784#issuecomment-2647135280">参考</a>：</p>
<ol>
<li><p>源码构建方式安装transforms：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install git+https://github.com/huggingface/transformers.git</span><br></pre></td></tr></table></figure>
</li>
<li><p>注释掉src&#x2F;llamafactory&#x2F;extras&#x2F;misc.py的第97行：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"># check_version(<span class="string">&quot;transformers&gt;=4.41.2,&lt;=4.48.3,!=4.46.0,!=4.46.1,!=4.46.2,!=4.46.3,!=4.47.0,!=4.47.1,!=4.48.0&quot;</span>)</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h2 id="下载模型文件（使用魔搭方法）"><a href="#下载模型文件（使用魔搭方法）" class="headerlink" title="下载模型文件（使用魔搭方法）"></a>下载模型文件（使用魔搭方法）</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://www.modelscope.cn/Qwen/Qwen2.5-VL-7B-Instruct.git</span><br></pre></td></tr></table></figure>

<p>其他模型可在这个<a href="https://modelscope.cn/models">页面</a>查找及下载。下载完成后（漫长等待），打开这个<a href="https://modelscope.cn/models/Qwen/Qwen2.5-VL-7B-Instruct/files">页面</a>肉眼对比下文件数量和大小。</p>
<hr>
<h2 id="原始模型直接推理"><a href="#原始模型直接推理" class="headerlink" title="原始模型直接推理"></a>原始模型直接推理</h2><p>运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">llamafactory-cli webchat examples/inference/qwen2_5_vl.yaml</span><br></pre></td></tr></table></figure>

<p><code>examples/inference/qwen2_5_vl.yaml</code> 的配置示例如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">model_name_or_path: /home/chr/桌面/llamafactory/Qwen2.5-VL-7B-Instruct</span><br><span class="line">template: qwen2_vl</span><br><span class="line">infer_backend: huggingface <span class="comment">#choices： [huggingface, vllm]</span></span><br><span class="line">trust_remote_code: <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<img src="/2025/02/18/LLamaFactory%E5%BE%AE%E8%B0%83Qwen2-5VL/0eb4d4ace6c1cfb48d0c523289df758.png" class="" title="0eb4d4ace6c1cfb48d0c523289df758">

<img src="/2025/02/18/LLamaFactory%E5%BE%AE%E8%B0%83Qwen2-5VL/f070b353532642d1b4b48b4292f742f.png" class="" title="f070b353532642d1b4b48b4292f742f">

<hr>
<h2 id="自定义数据集"><a href="#自定义数据集" class="headerlink" title="自定义数据集"></a>自定义数据集</h2><p>LLamafactory目前支持alpaca和sharegpt两种格式，以alpaca为例，整个数据集是一个json对象的list，具体数据格式为：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;用户指令（必填）&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;用户输入（选填）&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;模型回答（必填）&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;system&quot;</span><span class="punctuation">:</span> <span class="string">&quot;系统提示词（选填）&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;history&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">[</span><span class="string">&quot;第一轮指令（选填）&quot;</span><span class="punctuation">,</span> <span class="string">&quot;第一轮回答（选填）&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">[</span><span class="string">&quot;第二轮指令（选填）&quot;</span><span class="punctuation">,</span> <span class="string">&quot;第二轮回答（选填）&quot;</span><span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>

<p>比如单轮（alpaca_data_zh_51k.json 中的例子, 数据集在data&#x2F;dataset_info.json中注册为alpaca_zh）：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;写一个有效的比较语句&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;篮球和足球&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;篮球和足球都是受欢迎的运动。&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>和多轮 （oaast_sft_zh.json 中的例子, 数据集在data&#x2F;dataset_info.json中注册为oaast_sft_zh）：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;谢谢&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;不用谢! 很高兴我提供的信息能够帮助到你! 如果还有什么其他问题也可以向我提问。&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;history&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">[</span></span><br><span class="line">      <span class="string">&quot;请你给我写一个面试准备计划，我想要去面试微软的程序员岗位&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="string">&quot;首先，你可以去微软官网寻找招聘信息并申请面试。\n其次，您可以在社交媒体平台寻找微软公司对程序员的面试问题，并做好准备。\n最后，您可以自己对面试过程进行模拟，熟悉话题并减少紧张感。\n我希望你能面试成功。&quot;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>所以我们训练的数据最好也转换成这种格式，然后在 data&#x2F;dataset_info.json中<strong>进行注册</strong>（如果不做字段名称转换，则需要在注册的时候在 columns字段中做两个数据的映射配置）</p>
<p><strong>接下来，我们使用两个具体的例子来说明数据集的使用</strong></p>
<p>第一个是系统自带的identity.json数据集(已默认在data&#x2F;dataset_info.json 注册为identity)，对应文件已经在data目录下，我们通过操作系统的文本编辑器的替换功能，可以替换其中的NAME 和 AUTHOR ，换成我们需要的内容。如果是linux系统，可以使用<strong>sed</strong> 完成快速替换。比如助手的名称修改为PetNet， 由fy开发：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -i <span class="string">&#x27;s/&#123;&#123;name&#125;&#125;/PetNet/g&#x27;</span>  data/identity.json </span><br><span class="line">sed -i <span class="string">&#x27;s/&#123;&#123;author&#125;&#125;/fy/g&#x27;</span>  data/identity.json</span><br></pre></td></tr></table></figure>

<p>替换前：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Who are you?&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Hello! I am &#123;&#123;name&#125;&#125;, an AI assistant developed by &#123;&#123;author&#125;&#125;. How can I assist you today?&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>替换后：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Who are you?&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;I am PetNet, an AI assistant developed by fy. How can I assist you today?&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>第二个是一个商品文案生成数据集，<a href="https://cloud.tsinghua.edu.cn/f/b3f119a008264b1cabd1/?dl=1">原始链接</a></p>
<p>原始格式如下，很明显，训练目标是输入content （也就是prompt）, 输出 summary （对应response）：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;类型#裤*版型#宽松*风格#性感*图案#线条*裤型#阔腿裤&quot;</span><span class="punctuation">,</span> </span><br><span class="line">    <span class="attr">&quot;summary&quot;</span><span class="punctuation">:</span> <span class="string">&quot;宽松的阔腿裤这两年真的吸粉不少，明星时尚达人的心头爱。毕竟好穿时尚，谁都能穿出腿长2米的效果宽松的裤腿，当然是遮肉小能手啊。上身随性自然不拘束，面料亲肤舒适贴身体验感棒棒哒。系带部分增加设计看点，还让单品的设计感更强。腿部线条若隐若现的，性感撩人。颜色敲温柔的，与裤子本身所呈现的风格有点反差萌。&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>想将该自定义数据集放到我们的系统中使用，则需要进行如下两步操作：</p>
<ol>
<li><p>复制该数据集到 data目录下</p>
</li>
<li><p>修改 data&#x2F;dataset_info.json 新加内容完成注册, 该注册同时完成了3件事</p>
<ul>
<li><p>自定义数据集的名称为adgen_local，后续训练的时候就使用这个名称来找到该数据集</p>
</li>
<li><p>指定了数据集具体文件位置</p>
</li>
<li><p>定义了原数据集的输入输出和我们所需要的格式之间的映射关系</p>
</li>
</ul>
<img src="/2025/02/18/LLamaFactory%E5%BE%AE%E8%B0%83Qwen2-5VL/image-20250219095449804.png" class="" title="image-20250219095449804"></li>
</ol>
<hr>
<h2 id="基于LoRA的sft指令微调"><a href="#基于LoRA的sft指令微调" class="headerlink" title="基于LoRA的sft指令微调"></a>基于LoRA的sft指令微调</h2><p>现在准备好数据集了，可以开始训练了，我们的目的是让原来的Qwen2.5 VL模型学会我们定义的“你是谁”，同时学会我们希望的商品文案的生成。</p>
<p>我们先从命令行版本做训练，以便于学习其中的相关原理：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0 llamafactory-cli train \</span><br><span class="line">    --stage sft \</span><br><span class="line">    --do_train \</span><br><span class="line">    --model_name_or_path /home/chr/桌面/llamafactory/Qwen2.5-VL-7B-Instruct \</span><br><span class="line">    --dataset alpaca_gpt4_zh,identity,adgen_local \</span><br><span class="line">    --dataset_dir ./data \</span><br><span class="line">    --template qwen2_vl \</span><br><span class="line">    --finetuning_type lora \</span><br><span class="line">    --output_dir ./saves/Qwen2.5-VL-7B-Instruct/lora/sft \</span><br><span class="line">    --overwrite_cache \</span><br><span class="line">    --overwrite_output_dir \</span><br><span class="line">    --cutoff_len 1024 \</span><br><span class="line">    --preprocessing_num_workers 16 \</span><br><span class="line">    --per_device_train_batch_size 2 \</span><br><span class="line">    --per_device_eval_batch_size 1 \</span><br><span class="line">    --gradient_accumulation_steps 8 \</span><br><span class="line">    --lr_scheduler_type cosine \</span><br><span class="line">    --logging_steps 50 \</span><br><span class="line">    --warmup_steps 20 \</span><br><span class="line">    --save_steps 100 \</span><br><span class="line">    --eval_steps 50 \</span><br><span class="line">    --evaluation_strategy steps \</span><br><span class="line">    --load_best_model_at_end \</span><br><span class="line">    --learning_rate 5e-5 \</span><br><span class="line">    --num_train_epochs 5.0 \</span><br><span class="line">    --max_samples 1000 \</span><br><span class="line">    --val_size 0.1 \</span><br><span class="line">    --plot_loss</span><br></pre></td></tr></table></figure>

<img src="/2025/02/18/LLamaFactory%E5%BE%AE%E8%B0%83Qwen2-5VL/e6c1ceaa980c6ca5d13b41f06dafa2f.png" class="" title="e6c1ceaa980c6ca5d13b41f06dafa2f">

<img src="/2025/02/18/LLamaFactory%E5%BE%AE%E8%B0%83Qwen2-5VL/61d444e63e300a4f8e57636aa4aa9e0.png" class="" title="61d444e63e300a4f8e57636aa4aa9e0">

<img src="/2025/02/18/LLamaFactory%E5%BE%AE%E8%B0%83Qwen2-5VL/60c478373b620ec976f2236e553ad14.png" class="" title="60c478373b620ec976f2236e553ad14">

<hr>
<h2 id="动态合并LoRA的推理"><a href="#动态合并LoRA的推理" class="headerlink" title="动态合并LoRA的推理"></a>动态合并LoRA的推理</h2><p>我们基于LoRA的训练进程结束后，想做下动态验证，与上文的原始模型直接推理相比，唯一的区别是需要通过finetuning_type参数告诉系统，我们使用了LoRA训练，然后将LoRA的模型位置通过 adapter_name_or_path参数即可。</p>
<p><code>qwen2_5_vl_lora.yaml</code>：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">model_name_or_path: /home/chr/桌面/llamafactory/Qwen2.5-VL-7B-Instruct</span><br><span class="line">template: qwen2_vl</span><br><span class="line">adapter_name_or_path: ./saves/Qwen2.5-VL-7B-Instruct/lora/sft</span><br><span class="line">finetuning_type: lora</span><br><span class="line">infer_backend: huggingface <span class="comment">#choices： [huggingface, vllm]</span></span><br><span class="line">trust_remote_code: <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<p>运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">llamafactory-cli webchat examples/inferece/qwen2_5_vl_lora.yaml</span><br></pre></td></tr></table></figure>

<img src="/2025/02/18/LLamaFactory%E5%BE%AE%E8%B0%83Qwen2-5VL/abda935ed8d70e23525b287792cea49.png" class="" title="abda935ed8d70e23525b287792cea49">

<p>好了，可以看出微调是有效的。</p>
<hr>
<h2 id="数据集解析"><a href="#数据集解析" class="headerlink" title="数据集解析"></a>数据集解析</h2><p>上面略微解释了自定义数据集，本节着重归纳总结下数据集的格式。</p>
<p>首先，看下LLamaFactory官方对<code>dataset_info.json</code>文件的定义规范：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;数据集名称&quot;</span>: &#123;</span><br><span class="line">  <span class="string">&quot;hf_hub_url&quot;</span>: <span class="string">&quot;Hugging Face 的数据集仓库地址（若指定，则忽略 script_url 和 file_name）&quot;</span>,</span><br><span class="line">  <span class="string">&quot;ms_hub_url&quot;</span>: <span class="string">&quot;ModelScope 的数据集仓库地址（若指定，则忽略 script_url 和 file_name）&quot;</span>,</span><br><span class="line">  <span class="string">&quot;script_url&quot;</span>: <span class="string">&quot;包含数据加载脚本的本地文件夹名称（若指定，则忽略 file_name）&quot;</span>,</span><br><span class="line">  <span class="string">&quot;file_name&quot;</span>: <span class="string">&quot;该目录下数据集文件夹或文件的名称（若上述参数未指定，则此项必需）&quot;</span>,</span><br><span class="line">  <span class="string">&quot;formatting&quot;</span>: <span class="string">&quot;数据集格式（可选，默认：alpaca，可以为 alpaca 或 sharegpt）&quot;</span>,</span><br><span class="line">  <span class="string">&quot;ranking&quot;</span>: <span class="string">&quot;是否为偏好数据集（可选，默认：False）&quot;</span>,</span><br><span class="line">  <span class="string">&quot;subset&quot;</span>: <span class="string">&quot;数据集子集的名称（可选，默认：None）&quot;</span>,</span><br><span class="line">  <span class="string">&quot;split&quot;</span>: <span class="string">&quot;所使用的数据集切分（可选，默认：train）&quot;</span>,</span><br><span class="line">  <span class="string">&quot;folder&quot;</span>: <span class="string">&quot;Hugging Face 仓库的文件夹名称（可选，默认：None）&quot;</span>,</span><br><span class="line">  <span class="string">&quot;num_samples&quot;</span>: <span class="string">&quot;该数据集所使用的样本数量。（可选，默认：None）&quot;</span>,</span><br><span class="line">  <span class="string">&quot;columns（可选）&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;prompt&quot;</span>: <span class="string">&quot;数据集代表提示词的表头名称（默认：instruction）&quot;</span>,</span><br><span class="line">    <span class="string">&quot;query&quot;</span>: <span class="string">&quot;数据集代表请求的表头名称（默认：input）&quot;</span>,</span><br><span class="line">    <span class="string">&quot;response&quot;</span>: <span class="string">&quot;数据集代表回答的表头名称（默认：output）&quot;</span>,</span><br><span class="line">    <span class="string">&quot;history&quot;</span>: <span class="string">&quot;数据集代表历史对话的表头名称（默认：None）&quot;</span>,</span><br><span class="line">    <span class="string">&quot;messages&quot;</span>: <span class="string">&quot;数据集代表消息列表的表头名称（默认：conversations）&quot;</span>,</span><br><span class="line">    <span class="string">&quot;system&quot;</span>: <span class="string">&quot;数据集代表系统提示的表头名称（默认：None）&quot;</span>,</span><br><span class="line">    <span class="string">&quot;tools&quot;</span>: <span class="string">&quot;数据集代表工具描述的表头名称（默认：None）&quot;</span>,</span><br><span class="line">    <span class="string">&quot;images&quot;</span>: <span class="string">&quot;数据集代表图像输入的表头名称（默认：None）&quot;</span>,</span><br><span class="line">    <span class="string">&quot;videos&quot;</span>: <span class="string">&quot;数据集代表视频输入的表头名称（默认：None）&quot;</span>,</span><br><span class="line">    <span class="string">&quot;audios&quot;</span>: <span class="string">&quot;数据集代表音频输入的表头名称（默认：None）&quot;</span>,</span><br><span class="line">    <span class="string">&quot;chosen&quot;</span>: <span class="string">&quot;数据集代表更优回答的表头名称（默认：None）&quot;</span>,</span><br><span class="line">    <span class="string">&quot;rejected&quot;</span>: <span class="string">&quot;数据集代表更差回答的表头名称（默认：None）&quot;</span>,</span><br><span class="line">    <span class="string">&quot;kto_tag&quot;</span>: <span class="string">&quot;数据集代表 KTO 标签的表头名称（默认：None）&quot;</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">&quot;tags（可选，用于 sharegpt 格式）&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;role_tag&quot;</span>: <span class="string">&quot;消息中代表发送者身份的键名（默认：from）&quot;</span>,</span><br><span class="line">    <span class="string">&quot;content_tag&quot;</span>: <span class="string">&quot;消息中代表文本内容的键名（默认：value）&quot;</span>,</span><br><span class="line">    <span class="string">&quot;user_tag&quot;</span>: <span class="string">&quot;消息中代表用户的 role_tag（默认：human）&quot;</span>,</span><br><span class="line">    <span class="string">&quot;assistant_tag&quot;</span>: <span class="string">&quot;消息中代表助手的 role_tag（默认：gpt）&quot;</span>,</span><br><span class="line">    <span class="string">&quot;observation_tag&quot;</span>: <span class="string">&quot;消息中代表工具返回结果的 role_tag（默认：observation）&quot;</span>,</span><br><span class="line">    <span class="string">&quot;function_tag&quot;</span>: <span class="string">&quot;消息中代表工具调用的 role_tag（默认：function_call）&quot;</span>,</span><br><span class="line">    <span class="string">&quot;system_tag&quot;</span>: <span class="string">&quot;消息中代表系统提示的 role_tag（默认：system，会覆盖 system column）&quot;</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后，结合<code>dataset_info.json</code>，学习下<code>dataset_info.json</code>的写法。</p>
<h3 id="一、alpaca-指令监督微调数据集"><a href="#一、alpaca-指令监督微调数据集" class="headerlink" title="一、alpaca 指令监督微调数据集"></a>一、alpaca 指令监督微调数据集</h3><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">dataset_info.json </span><br><span class="line"></span><br><span class="line"><span class="attr">&quot;identity&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;identity.json&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">identity.json</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;instruction&quot;</span>: <span class="string">&quot;hi&quot;</span>,</span><br><span class="line">    <span class="string">&quot;input&quot;</span>: <span class="string">&quot;&quot;</span>,</span><br><span class="line">    <span class="string">&quot;output&quot;</span>: <span class="string">&quot;Hello! I am &#123;&#123;name&#125;&#125;, an AI assistant developed by &#123;&#123;author&#125;&#125;. How can I assist you today?&quot;</span></span><br><span class="line">  &#125;,</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>归纳：</strong></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">dataset_info.json </span><br><span class="line"></span><br><span class="line"><span class="attr">&quot;数据集名称&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;data.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;instruction&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;query&quot;</span><span class="punctuation">:</span> <span class="string">&quot;input&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;response&quot;</span><span class="punctuation">:</span> <span class="string">&quot;output&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;system&quot;</span><span class="punctuation">:</span> <span class="string">&quot;system&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;history&quot;</span><span class="punctuation">:</span> <span class="string">&quot;history&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;人类指令（必填）&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;人类输入（选填）&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;模型回答（必填）&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;system&quot;</span><span class="punctuation">:</span> <span class="string">&quot;系统提示词（选填）&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;history&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">[</span><span class="string">&quot;第一轮指令（选填）&quot;</span><span class="punctuation">,</span> <span class="string">&quot;第一轮回答（选填）&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">[</span><span class="string">&quot;第二轮指令（选填）&quot;</span><span class="punctuation">,</span> <span class="string">&quot;第二轮回答（选填）&quot;</span><span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>

<p>有个问题：人类指令和人类输入的区别和联系是什么：</p>
<ul>
<li>人类指令instruction是任务的核心，决定模型要做什么，通常是明确的操作或目标（必填）</li>
<li>人类输入input是任务的具体内容，为指令提供上下文或详细信息，使模型能针对特定内容生成响应，未填写则回复通用回答（选填）</li>
</ul>
<p>例：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">alpaca_zh_demo.json </span><br><span class="line"></span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;请根据以下文章构建一个需要回答的问题。&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;我不好意思，您没有提供任何信息或文章来供我根据它构建问题。 请提供相应的文章或信息，以便我能够帮助您构建问题。&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;根据下表，将每个句子分类为定义、事实或观点。&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;|句子|\n|--------|\n|水果是一种通常甜味且含有种子的食物类别。|\n|苹果是一种水果。|\n|苹果是口感最好的水果。|&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;|句子|分类|\n|--------|-----|\n|水果是一种通常甜味且含有种子的食物类别。|定义|\n|苹果是一种水果。|事实|\n|苹果是口感最好的水果。|观点|&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line"> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;写一首四行诗，主题是自然。&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;青山绿水美如画，\n晨霞晚霞常换档。\n花香鸟语自然谧，\n四季交替更生长。&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;输入三支篮球队的名称并生成一个适当的口号。&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;输入：俄克拉荷马城雷霆队，芝加哥公牛队，布鲁克林网队。&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;输出： \&quot;雷霆，公牛和网队：各显神通，角逐群雄!\&quot;&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;比较以下两位著名人物，使用特征列表并以句子形式提供输出。&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;人物1：阿尔伯特·爱因斯坦\n人物2：斯蒂芬·霍金\n特征：智力、教育、对世界的影响&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;阿尔伯特·爱因斯坦和斯蒂芬·霍金都是拥有极其出色智力的人物。两人都取得过非常高的教育成就，他们推进了科学发展并在世界范围内产生了深远的影响。爱因斯坦以其相对论和质能关系公式而闻名，而霍金以其关于黑洞和宇宙的发现而著称。两位科学家都以其深厚的学识和非凡的贡献影响了世界。&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;生成一个算法，找到并显示两个文本字符串之间的最长公共子串。&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;输入：\n字符串1：This is an example\n字符串2：This string should contain the example&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;算法：动态规划\n\n```python\ndef longest_common_substring(s1, s2):\n    m = len(s1)\n    n = len(s2)\n    result = 0\n    end = 0\n    # 创建一个(m+1)x(n+1)的二维数组来表示最长公共子串的长度\n    length = [[0] * (n + 1) for i in range(m + 1)]\n    # 填充数组\n    for i in range(1, m + 1):\n        for j in range(1, n + 1):\n            if s1[i - 1] == s2[j - 1]:\n                length[i][j] = length[i - 1][j - 1] + 1\n                if length[i][j] &gt; result:\n                    result = length[i][j]\n                    end = i - 1\n    return s1[end - result + 1:end + 1]\n\n\ns1 = &#x27;This is an example&#x27;\ns2 = &#x27;This string should contain the example&#x27;\nprint(longest_common_substring(s1, s2))\n```\n\n输出：example\n\n解释：\n\n1. 创建一个二维数组，将其所有元素初始化为0。\n2. 通过双层循环遍历两个字符串，当字符相同时在对角线上加1。\n3. 找到最大值，并记录最大值所在的行和列。\n4. 由于我们是从1开始遍历字符串的，所以结果要减一才是真正的索引。\n\n时间复杂度：O(m*n)\n\n空间复杂度：O(m*n)&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="小变体1"><a href="#小变体1" class="headerlink" title="小变体1"></a>小变体1</h4><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">dataset_info.json </span><br><span class="line"></span><br><span class="line"><span class="attr">&quot;alpaca_en&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;hf_hub_url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;llamafactory/alpaca_en&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;ms_hub_url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;llamafactory/alpaca_en&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;om_hub_url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;HaM/alpaca_en&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;alpaca_zh&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;hf_hub_url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;llamafactory/alpaca_zh&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;ms_hub_url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;llamafactory/alpaca_zh&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;alpaca_gpt4_en&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;hf_hub_url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;llamafactory/alpaca_gpt4_en&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;ms_hub_url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;llamafactory/alpaca_gpt4_en&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;alpaca_gpt4_zh&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;hf_hub_url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;llamafactory/alpaca_gpt4_zh&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;ms_hub_url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;llamafactory/alpaca_gpt4_zh&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;om_hub_url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;State_Cloud/alpaca-gpt4-data-zh&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure>

<p>与第一类类似，只是数据是从网站上下载，而不是从本地加载。</p>
<h4 id="小变体2"><a href="#小变体2" class="headerlink" title="小变体2"></a>小变体2</h4><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">dataset_info.json </span><br><span class="line"></span><br><span class="line"><span class="attr">&quot;adgen_train&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;hf_hub_url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;HasturOfficial/adgen&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;ms_hub_url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;AI-ModelScope/adgen&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;split&quot;</span><span class="punctuation">:</span> <span class="string">&quot;train&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;content&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;response&quot;</span><span class="punctuation">:</span> <span class="string">&quot;summary&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;adgen_eval&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;hf_hub_url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;HasturOfficial/adgen&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;ms_hub_url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;AI-ModelScope/adgen&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;split&quot;</span><span class="punctuation">:</span> <span class="string">&quot;validation&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;content&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;response&quot;</span><span class="punctuation">:</span> <span class="string">&quot;summary&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure>

<p>使用split参数指定所使用的数据集切分（可选，默认：train）。</p>
<hr>
<h3 id="二、sharegpt-指令监督微调数据集"><a href="#二、sharegpt-指令监督微调数据集" class="headerlink" title="二、sharegpt 指令监督微调数据集"></a>二、sharegpt 指令监督微调数据集</h3><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">dataset_info.json </span><br><span class="line"></span><br><span class="line"><span class="attr">&quot;glaive_toolcall_zh_demo&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;glaive_toolcall_zh_demo.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;formatting&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sharegpt&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;messages&quot;</span><span class="punctuation">:</span> <span class="string">&quot;conversations&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;tools&quot;</span><span class="punctuation">:</span> <span class="string">&quot;tools&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p><strong>相当于:</strong></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">dataset_info.json </span><br><span class="line"></span><br><span class="line"><span class="attr">&quot;glaive_toolcall_zh_demo&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;glaive_toolcall_zh_demo.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;formatting&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sharegpt&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;messages&quot;</span><span class="punctuation">:</span> <span class="string">&quot;conversations&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;tools&quot;</span><span class="punctuation">:</span> <span class="string">&quot;tools&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;tags&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;role_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;from&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;content_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;value&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;user_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;human&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;assistant_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gpt&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;observation_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;observation&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;function_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;function_call&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;system_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;system&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">glaive_toolcall_zh_demo.json</span><br><span class="line"></span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;conversations&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;human&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;我需要为John Doe生成一张发票。他购买了2个苹果，每个$1，以及3根香蕉，每根$0.5。&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;function_call&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&#123;\&quot;name\&quot;: \&quot;generate_invoice\&quot;, \&quot;arguments\&quot;: &#123;\&quot;customer_name\&quot;: \&quot;约翰·多伊\&quot;, \&quot;items\&quot;: [&#123;\&quot;name\&quot;: \&quot;苹果\&quot;, \&quot;quantity\&quot;: 2, \&quot;price\&quot;: 1&#125;, &#123;\&quot;name\&quot;: \&quot;香蕉\&quot;, \&quot;quantity\&quot;: 3, \&quot;price\&quot;: 0.5&#125;]&#125;&#125;&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;observation&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&#123;\&quot;invoice_id\&quot;: \&quot;INV12345\&quot;, \&quot;customer_name\&quot;: \&quot;约翰·多伊\&quot;, \&quot;items\&quot;: [&#123;\&quot;name\&quot;: \&quot;苹果\&quot;, \&quot;quantity\&quot;: 2, \&quot;price\&quot;: 1, \&quot;total\&quot;: 2&#125;, &#123;\&quot;name\&quot;: \&quot;香蕉\&quot;, \&quot;quantity\&quot;: 3, \&quot;price\&quot;: 0.5, \&quot;total\&quot;: 1.5&#125;], \&quot;total\&quot;: 3.5, \&quot;status\&quot;: \&quot;生成\&quot;&#125;&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gpt&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;发票已成功生成。发票编号为INV12345。约翰·多伊的总金额为$3.5。发票包含2个苹果，总金额为$2，以及3根香蕉，总金额为$1.5。&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;tools&quot;</span><span class="punctuation">:</span> <span class="string">&quot;[&#123;\&quot;name\&quot;: \&quot;generate_invoice\&quot;, \&quot;description\&quot;: \&quot;生成发票\&quot;, \&quot;parameters\&quot;: &#123;\&quot;type\&quot;: \&quot;object\&quot;, \&quot;properties\&quot;: &#123;\&quot;customer_name\&quot;: &#123;\&quot;type\&quot;: \&quot;string\&quot;, \&quot;description\&quot;: \&quot;客户名称\&quot;&#125;, \&quot;items\&quot;: &#123;\&quot;type\&quot;: \&quot;array\&quot;, \&quot;items\&quot;: &#123;\&quot;type\&quot;: \&quot;object\&quot;, \&quot;properties\&quot;: &#123;\&quot;name\&quot;: &#123;\&quot;type\&quot;: \&quot;string\&quot;, \&quot;description\&quot;: \&quot;The item name\&quot;&#125;, \&quot;quantity\&quot;: &#123;\&quot;type\&quot;: \&quot;integer\&quot;, \&quot;description\&quot;: \&quot;The quantity of the item\&quot;&#125;, \&quot;price\&quot;: &#123;\&quot;type\&quot;: \&quot;number\&quot;, \&quot;description\&quot;: \&quot;The price per unit\&quot;&#125;&#125;, \&quot;required\&quot;: [\&quot;name\&quot;, \&quot;quantity\&quot;, \&quot;price\&quot;]&#125;&#125;&#125;, \&quot;required\&quot;: [\&quot;customer_name\&quot;, \&quot;items\&quot;]&#125;&#125;, &#123;\&quot;name\&quot;: \&quot;generate_password\&quot;, \&quot;description\&quot;: \&quot;生成随机密码\&quot;, \&quot;parameters\&quot;: &#123;\&quot;type\&quot;: \&quot;object\&quot;, \&quot;properties\&quot;: &#123;\&quot;length\&quot;: &#123;\&quot;type\&quot;: \&quot;integer\&quot;, \&quot;description\&quot;: \&quot;密码的长度\&quot;&#125;&#125;, \&quot;required\&quot;: [\&quot;length\&quot;]&#125;&#125;]&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;conversations&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;human&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;假设你有一个需要随机数的Java程序，范围在0到10之间。你可以使用什么代码片段来生成这样的数字？\n\n下面是一个示例代码片段，它使用Math.random()方法来生成一个在0到1之间的随机数，然后缩放并四舍五入结果，得到一个在0到10之间的随机数：\n\n```java\nint randomNumber = (int) (Math.random() * 11);\n```\n\n在Java中是否有更有效的方法来生成随机数？你会如何修改代码以生成具有不同范围或分布的随机数？&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gpt&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;您提供的代码片段是Java中生成随机数的一种常见且高效的方法。然而，如果您需要对随机数生成有更多的控制，您可以使用java.util.Random类，它提供了更多生成随机数的选项。\n\n要生成一个在不同范围内的随机数，您可以修改代码以调整缩放因子。例如，要生成一个在1到10之间的随机数，您可以使用以下代码：\n\nint randomNumber = (int) (Math.random() * 10) + 1;\n\n要生成具有不同分布的随机数，您可以使用各种技术，如正态分布、指数分布或自定义分布。生成正态分布的一种方法是使用Box-Muller变换。这里有一个代码示例，它生成具有正态分布的随机数：\n\nRandom random = new Random();\ndouble u1 = random.nextDouble();\ndouble u2 = random.nextDouble();\ndouble z = Math.sqrt(-2 * Math.log(u1)) * Math.cos(2 * Math.PI * u2);\ndouble mean = 5;\ndouble stdDev = 2;\nint randomNumber = (int) (z * stdDev + mean);\n\n这段代码生成一个具有均值5和标准差2的正态分布随机数。您可以调整均值和标准差来生成具有不同分布的随机数。&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;human&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;你能解释一下算法分析中的大O记法概念吗？&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gpt&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;是的，大O表示法是一种描述算法性能随输入数据大小增加的方法。它用于估计算法在最坏情况下的时间复杂度或空间复杂度。大O中的“O”代表“数量级”，这意味着随着输入大小的增加，算法所需的操作数以一定的速率增长。\n\n例如，如果我们有一个需要n步才能解决大小为n的问题的算法，那么时间复杂度可以表示为O(n)，这意味着操作数随着输入大小线性增长。如果我们有一个需要n^2步才能解决大小为n的问题的算法，那么时间复杂度可以表示为O(n^2)，这意味着操作数随着输入大小二次方增长。\n\n还有其他几种大O表示法，如O(log n)、O(n log n)、O(2^n)等，它们代表了随着输入大小增加的不同操作数增长速率。通过分析算法的大O表示法，我们可以比较不同算法的性能，并选择给定问题最有效的算法。\n\n您是否有关于大O表示法或算法分析的特定问题？&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;tools&quot;</span><span class="punctuation">:</span> <span class="string">&quot;[]&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure>

<p><strong>归纳：</strong></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">dataset_info.json </span><br><span class="line"></span><br><span class="line"><span class="attr">&quot;数据集名称&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;data.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;formatting&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sharegpt&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;messages&quot;</span><span class="punctuation">:</span> <span class="string">&quot;conversations&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;system&quot;</span><span class="punctuation">:</span> <span class="string">&quot;system&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;tools&quot;</span><span class="punctuation">:</span> <span class="string">&quot;tools&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;conversations&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;human&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;人类指令&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;function_call&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;工具参数&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;observation&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;工具结果&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gpt&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;模型回答&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;system&quot;</span><span class="punctuation">:</span> <span class="string">&quot;系统提示词（选填）&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;tools&quot;</span><span class="punctuation">:</span> <span class="string">&quot;工具描述（选填）&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>

<h4 id="小变体1-1"><a href="#小变体1-1" class="headerlink" title="小变体1"></a>小变体1</h4><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">dataset_info.json </span><br><span class="line"></span><br><span class="line"><span class="attr">&quot;mllm_demo&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;mllm_demo.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;formatting&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sharegpt&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;messages&quot;</span><span class="punctuation">:</span> <span class="string">&quot;messages&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;images&quot;</span><span class="punctuation">:</span> <span class="string">&quot;images&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;tags&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;role_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;role&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;content_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;content&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;user_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;user&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;assistant_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;mllm_audio_demo&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;mllm_audio_demo.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;formatting&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sharegpt&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;messages&quot;</span><span class="punctuation">:</span> <span class="string">&quot;messages&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;audios&quot;</span><span class="punctuation">:</span> <span class="string">&quot;audios&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;tags&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;role_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;role&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;content_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;content&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;user_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;user&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;assistant_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;mllm_video_demo&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;mllm_video_demo.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;formatting&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sharegpt&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;messages&quot;</span><span class="punctuation">:</span> <span class="string">&quot;messages&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;videos&quot;</span><span class="punctuation">:</span> <span class="string">&quot;videos&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;tags&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;role_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;role&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;content_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;content&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;user_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;user&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;assistant_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">mllm_demo.json</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;messages&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&lt;image&gt;Who are they?&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;user&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;They&#x27;re Kane and Gretzka from Bayern Munich.&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;What are they doing?&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;user&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;They are celebrating on the soccer field.&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;images&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="string">&quot;mllm_demo_data/1.jpg&quot;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line">mllm_audio_demo.json</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;messages&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&lt;audio&gt;What&#x27;s that sound?&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;user&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;It is the sound of glass shattering.&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;audios&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="string">&quot;mllm_demo_data/1.mp3&quot;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line">mllm_video_demo.json</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;messages&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&lt;video&gt;Why is this video funny?&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;user&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Because a baby is reading, and he is so cute!&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;videos&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="string">&quot;mllm_demo_data/1.mp4&quot;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure>

<p>此类与第二类的区别有：</p>
<ul>
<li>conversations-&gt;messages</li>
<li>没有tools，但有audio&#x2F;imag&#x2F;video</li>
<li>tag标签，role_tag默认为from，所以第二类缺省，第三类需对应<code>role</code>（其余同理）。</li>
</ul>
<h4 id="小变体2-1"><a href="#小变体2-1" class="headerlink" title="小变体2"></a>小变体2</h4><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">dataset_info.json </span><br><span class="line"></span><br><span class="line"><span class="attr">&quot;glaive_toolcall_en&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;hf_hub_url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;llamafactory/glaive_toolcall_en&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;formatting&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sharegpt&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;messages&quot;</span><span class="punctuation">:</span> <span class="string">&quot;conversations&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;tools&quot;</span><span class="punctuation">:</span> <span class="string">&quot;tools&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;glaive_toolcall_zh&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;hf_hub_url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;llamafactory/glaive_toolcall_zh&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;formatting&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sharegpt&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;messages&quot;</span><span class="punctuation">:</span> <span class="string">&quot;conversations&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;tools&quot;</span><span class="punctuation">:</span> <span class="string">&quot;tools&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;lima&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;hf_hub_url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;llamafactory/lima&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;formatting&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sharegpt&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure>

<p>与前文类似，只是数据是从网上下载。</p>
<h4 id="小变体3"><a href="#小变体3" class="headerlink" title="小变体3"></a>小变体3</h4><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">dataset_info.json</span><br><span class="line"></span><br><span class="line"><span class="attr">&quot;llava_1k_en&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;hf_hub_url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;BUAADreamer/llava-en-zh-2k&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;subset&quot;</span><span class="punctuation">:</span> <span class="string">&quot;en&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;formatting&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sharegpt&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;messages&quot;</span><span class="punctuation">:</span> <span class="string">&quot;messages&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;images&quot;</span><span class="punctuation">:</span> <span class="string">&quot;images&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;tags&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;role_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;role&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;content_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;content&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;user_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;user&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;assistant_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">&quot;llava_1k_zh&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;hf_hub_url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;BUAADreamer/llava-en-zh-2k&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;subset&quot;</span><span class="punctuation">:</span> <span class="string">&quot;zh&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;formatting&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sharegpt&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;messages&quot;</span><span class="punctuation">:</span> <span class="string">&quot;messages&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;images&quot;</span><span class="punctuation">:</span> <span class="string">&quot;images&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;tags&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;role_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;role&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;content_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;content&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;user_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;user&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;assistant_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure>

<p>通过subset选择数据集子集。</p>
<hr>
<h3 id="三、sharegpt-偏好数据集"><a href="#三、sharegpt-偏好数据集" class="headerlink" title="三、sharegpt 偏好数据集"></a>三、sharegpt 偏好数据集</h3><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">dataset_info.json</span><br><span class="line"></span><br><span class="line"><span class="attr">&quot;dpo_zh_demo&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;dpo_zh_demo.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;ranking&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;formatting&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sharegpt&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;messages&quot;</span><span class="punctuation">:</span> <span class="string">&quot;conversations&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;chosen&quot;</span><span class="punctuation">:</span> <span class="string">&quot;chosen&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;rejected&quot;</span><span class="punctuation">:</span> <span class="string">&quot;rejected&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">dpo_zh_demo.json</span><br><span class="line"></span><br><span class="line"><span class="attr">&quot;conversations&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;human&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;请提供一下对香港银行业的分析以及目前面临的挑战。&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;chosen&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gpt&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;香港银行业长期以来一直是该城市金融服务业和整体经济的重要组成部分。其特点是健全的监管框架、大量银行和资本流动的便利。以下分析涵盖了该行业面临的一些关键因素和当前挑战：\n\n1. 市场结构：香港银行业包括三类机构：持牌银行、受限牌照银行和接受存款公司。截至2021年4月，香港有160家持牌银行、19家受限牌照银行和13家接受存款公司。该行业由几家主要银行主导，汇丰银行、恒生银行、中国银行（香港）和渣打银行占据最大的市场份额。\n\n2. 监管框架：香港金融管理局负责监督银行体系的正常运作、稳定性和完整性。它通过实施法规和指导方针、监督持牌机构，并确保符合巴塞尔III等国际标准。\n\n3. 资本和流动性：香港银行保持强大的资本和流动性状况，资本比率远高于巴塞尔III标准设定的最低要求。这有助于该行业对经济冲击的稳定性和抵御能力。\n\n尽管具有这些优势，香港银行业目前面临着几个挑战：\n\n1. 经济放缓和中美贸易紧张局势：香港经济高度依赖贸易，受到中国内地经济放缓和中美贸易冲突的负面影响。这可能影响银行的贷款组合、信用质量和整体盈利能力。\n\n2. 低利率环境：由于全球经济衰退，世界各国央行一直采取宽松的货币政策，降低利率。香港银行受到影响，因为该市与美元挂钩的汇率制度导致净利差收窄和盈利能力降低。\n\n3. 地缘政治风险：香港实施国家安全法和美中紧张局势加剧引发了对该市银行业潜在影响的担忧，如制裁或国际银行撤离。\n\n4. 技术颠覆：金融科技和数字银行的兴起为香港银行业带来机遇和挑战。传统银行需要增强数字能力，投资创新技术以与新兴金融科技公司和虚拟银行竞争。\n\n5. 合规和监管变化：随着国际法规的演变，香港银行必须不断适应并遵守新规定，这可能耗时且成本高昂。此外，他们需要管理与反洗钱（AML）和打击恐怖融资（CFT）法规相关的风险。\n\n总之，香港银行业仍具有强大的基本面，但需要解决上述挑战，以在不断变化的全球格局中保持竞争力和稳定性。&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;rejected&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gpt&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;香港的银行业面临着诸多挑战，如低利率、高房价和经济疲软。新冠疫情也给该行业带来了压力，企业和消费者都在艰难度日。一些分析师建议政府可能需要采取措施，如降低贷款利率或向陷入困境的企业提供财政援助。\n\n尽管面临这些挑战，香港的银行业仍受到良好监管，消费者和企业对其信任度高。该行业还以其强调创新和采用新技术，如移动银行和数字支付而闻名。总体而言，香港银行业的前景仍然积极，但需要谨慎管理和关注持续发展。&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure>

<p>这种是sharegpt格式的偏好数据集，偏好数据集用于奖励模型训练、DPO训练、ORPO训练和SimPO训练。</p>
<p>需要在chosen列中提供更优的消息，并在rejected列中提供更差的消息。</p>
<p>归纳：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">dataset_info.json</span><br><span class="line"></span><br><span class="line"><span class="attr">&quot;数据集名称&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;data.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;formatting&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sharegpt&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;ranking&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;messages&quot;</span><span class="punctuation">:</span> <span class="string">&quot;conversations&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;chosen&quot;</span><span class="punctuation">:</span> <span class="string">&quot;chosen&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;rejected&quot;</span><span class="punctuation">:</span> <span class="string">&quot;rejected&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;conversations&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;human&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;人类指令&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gpt&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;模型回答&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;human&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;人类指令&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;chosen&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gpt&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;优质回答&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;rejected&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gpt&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;劣质回答&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>

<h3 id="四、alpaca-偏好数据集"><a href="#四、alpaca-偏好数据集" class="headerlink" title="四、alpaca 偏好数据集"></a>四、alpaca 偏好数据集</h3><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">dataset_info.json</span><br><span class="line"></span><br><span class="line"><span class="attr">&quot;ultrafeedback&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;hf_hub_url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;llamafactory/ultrafeedback_binarized&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;ms_hub_url&quot;</span><span class="punctuation">:</span> <span class="string">&quot;llamafactory/ultrafeedback_binarized&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;ranking&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;instruction&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;chosen&quot;</span><span class="punctuation">:</span> <span class="string">&quot;chosen&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;rejected&quot;</span><span class="punctuation">:</span> <span class="string">&quot;rejected&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;In this task, you are given a second sentence. Your task is to generate the first sentence on the same topic but incoherent and inconsistent with the second sentence.\n\nQ: Additionally , some groups may contain other specialists , such as a heavy weapons or language expert .\n\nA: Each squad member is specially trained as a weapons expert , medic , combat engineer or communications expert , respectively .\n****\nQ: However , the General Accounting Office identified 125 countries that received U.S. training and assistance for their police forces during fiscal year 1990 at a cost of at least $117 million .\n\nA: No government agency is in charge of calculating the cost .\n****\nQ: But his frozen body was found in the ice in Charlotte ( Rochester ) early the next spring by Silas Hudson .\n\nA:&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;chosen&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Could you provide some context or information about what you are looking for or any particular questions you have, so I can assist better?&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;rejected&quot;</span><span class="punctuation">:</span> <span class="string">&quot;As an AI assistant, it&#x27;s essential to generate the first sentence on the same topic that may seem unrelated or inconsistent with the second sentence. Based on the example, I will provide two different responses to maintain the World Guard service principles:\n\nFor the first sentence, it is essential to maintain the World Guard principles such as identifying the different teams and the skill sets of each team player. The first sentence would be:\n\n\&quot;Intelligence gathering and operation teams consist of specialized personnel, including ghost operatives proficient in combat, communications, and espionage.\&quot;\n\nFor the second sentence, the inconsistency lies in the context of fiscal year and police training. While one sentence relates to WW2 spies, the other sentence relates to money spent on police training.\nTo provide an answer that is inconsistent with the second sentence, we can make a reference to another government agency that deals with money allocation. Thus, the WW2 spies sentence would be:\n\n\&quot;After the famous World War II event, during which spies called themselves &#x27;The World Guard,&#x27; the USA created a government agency called &#x27;The Department of Finance.&#x27; Their sole purpose was to monitor, regulate and control the fiscal year expenses made on various training and assistance programs, which help expand national capacities.\&quot;\n\nPlease let me know if you need any further assistance, and I would be happy to help!&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure>

<p>这是alpaca格式的偏好数据集，归纳：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">dataset_info.json</span><br><span class="line"></span><br><span class="line"><span class="attr">&quot;数据集名称&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;data.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;ranking&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;instruction&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;query&quot;</span><span class="punctuation">:</span> <span class="string">&quot;input&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;chosen&quot;</span><span class="punctuation">:</span> <span class="string">&quot;chosen&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;rejected&quot;</span><span class="punctuation">:</span> <span class="string">&quot;rejected&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;人类指令（必填）&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;人类输入（选填）&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;chosen&quot;</span><span class="punctuation">:</span> <span class="string">&quot;优质回答（必填）&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;rejected&quot;</span><span class="punctuation">:</span> <span class="string">&quot;劣质回答（必填）&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>

<h3 id="五、sharegpt-KTO数据集"><a href="#五、sharegpt-KTO数据集" class="headerlink" title="五、sharegpt KTO数据集"></a>五、sharegpt KTO数据集</h3><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">dataset_info.json</span><br><span class="line"></span><br><span class="line"><span class="attr">&quot;kto_en_demo&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;kto_en_demo.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;formatting&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sharegpt&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;messages&quot;</span><span class="punctuation">:</span> <span class="string">&quot;messages&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;kto_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;label&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;tags&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;role_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;role&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;content_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;content&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;user_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;user&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;assistant_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;messages&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;The Federal Trade Commission is going after spyware, bits of computer code that install themselves on the computers of Internet users to track or disrupt their online activities.\nQ: Which is the best summary of this article?\nPick your answer from:\n(A). World\n(B). Sports\n(C). Business\n(D). Science/Tech\nI think the answer is&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;user&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Ooh ooh ah ah! *giggle* Let me think... Ooh ooh ah ah! *giggle* The best summary of this article is... *drumroll*... D! Science/Tech! Yay! *confetti* The Federal Trade Commission is talking about spyware, which is like a little computer bug that can watch what you do on your computer without you knowing. It&#x27;s like a secret agent, but not a nice one! *gasp* The FTC wants to stop the spyware from doing its thing, so they&#x27;re going after it! *cheer* Woohoo!&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;label&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;messages&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Compare and contrast the roles of the hippocampus and the prefrontal cortex in the human brain, discussing their involvement in memory processing and decision making.&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;user&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;The human brain is a highly complex organ, responsible for a myriad of cognitive functions, including memory processing and decision making. Two critical regions implicated in these processes are the hippocampus and the prefrontal cortex. While both structures play significant roles in these cognitive domains, they each contribute distinct functions that work in concert to facilitate our ability to navigate the world and make informed choices.\n\nThe hippocampus, located within the medial temporal lobe, is predominantly associated with the formation, consolidation, and retrieval of memories. Specifically, it plays a crucial role in episodic memory, which encompasses the storage and recollection of autobiographical events, as well as spatial memory, which pertains to the encoding and retrieval of spatial information. The hippocampus is vital for the formation of new memories and the integration of these memories into existing knowledge structures. It has been demonstrated that damage to the hippocampus can result in anterograde amnesia, a condition characterized by an inability to form new memories, while leaving previously consolidated memories intact.\n\nIn contrast, the prefrontal cortex, situated in the anterior portion of the frontal lobes, is primarily involved in executive functions, which include higher-order cognitive processes such as decision making, planning, reasoning, and inhibitory control. The prefrontal cortex is responsible for integrating information from various sources, evaluating potential outcomes, and selecting the most advantageous course of action. It is also implicated in working memory, which refers to the temporary storage and manipulation of information necessary for complex cognitive tasks. Damage to the prefrontal cortex can result in deficits in decision making, impulsivity, and poor judgment.\n\nWhile the hippocampus and prefrontal cortex have distinct roles, they are interconnected and work synergistically to facilitate memory processing and decision making. The hippocampus provides the prefrontal cortex with contextual information and episodic memories that inform decision-making processes. Conversely, the prefrontal cortex can modulate the hippocampus&#x27;s activity during memory encoding and retrieval, influencing the salience and organization of memories. This dynamic interplay between the two regions enables individuals to adapt their decision-making strategies based on past experiences and contextual information.\n\nIn summary, the hippocampus and prefrontal cortex are integral to memory processing and decision making, albeit with distinct contributions. The hippocampus is primarily implicated in the formation, consolidation, and retrieval of episodic and spatial memories, while the prefrontal cortex is responsible for executive functions, including decision making, planning, and working memory. The interplay between these two regions allows for the integration of past experiences and contextual information in guiding informed decision making and shaping our behavior.&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Discuss the mechanisms through which the prefrontal cortex modulates the hippocampus&#x27;s activity during memory encoding and retrieval.&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;user&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;The prefrontal cortex (PFC) and the hippocampus have a dynamic relationship that allows for the modulation of memory encoding and retrieval. This interaction is facilitated by direct and indirect neural pathways that connect the two regions, allowing for bidirectional communication.\n\nDuring memory encoding, the PFC is thought to modulate hippocampal activity through top-down control. The PFC can selectively enhance or suppress the processing of sensory information in the hippocampus based on its relevance to the task at hand. This process, known as &#x27;attentional modulation&#x27;, allows the PFC to guide the hippocampus in encoding memories that are relevant and suppressing those that are not. This is crucial for the formation of goal-directed behaviors and for the efficient use of cognitive resources.\n\nIn addition to attentional modulation, the PFC also influences the hippocampus through &#x27;working memory&#x27; operations. Working memory, a temporary storage system for information, is largely mediated by the PFC. During memory encoding, the PFC can use this working memory to provide the hippocampus with a &#x27;preview&#x27; of the information that is to be encoded, allowing the hippocampus to prepare for the incoming information and encode it more efficiently.\n\nDuring memory retrieval, the PFC again plays a modulatory role. It is thought that the PFC can initiate the retrieval process by sending a &#x27;retrieval cue&#x27; to the hippocampus. This cue triggers the reactivation of the neural patterns associated with the memory, allowing for its retrieval. The PFC can also influence the focus of retrieval, determining whether the retrieval is broad (i.e., recalling the general gist of an event) or specific (i.e., recalling specific details).\n\nFurthermore, the PFC can modulate the emotional intensity of retrieved memories through its connections with the amygdala, a region involved in emotional processing. This can influence the subjective experience of the memory, affecting how it is perceived and responded to.\n\nIn summary, the PFC modulates hippocampal activity during memory encoding and retrieval through a variety of mechanisms, including attentional modulation, working memory operations, retrieval initiation, and emotional modulation. These processes allow the PFC to guide the hippocampus in encoding and retrieving memories in a way that is adaptive and efficient.&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Can you elaborate on the role of the amygdala in modulating the emotional intensity of retrieved memories, and how this interaction with the prefrontal cortex influences our perception and response to these memories?&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;user&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;The amygdala plays a crucial role in the emotional processing of stored memories. It is a small almond-shaped structure situated deep within the medial temporal lobes that consists of multiple nuclei involved in different aspects of emotional processing, including the establishment of emotional associations and hedonic reactions to stimuli. The amygdala interacts extensively with both the hippocampus and the prefrontal cortex (PFC) to modulate emotional responses to retrieved memories.\n\nThe emotional component of a memory is largely encoded through the amygdala&#x27;s interaction with the hippocampus during memory formation. When an emotionally significant event occurs, the hippocampus provides contextual and spatial aspects of the memory, while the amygdala assigns an emotional value or salience to the memory. The solidification of these emotional associations ensures that emotional information associated with a given memory is readily reactivated during memory retrieval.\n\nDuring memory retrieval, the PFC receives information about the emotional intensity of the memory through reciprocal connections with the amygdala. The PFC can then modulate the impact of emotional memories on behavior and cognitive processes by using top-down control. This regulation can influence how we experience and respond to retrieved memories.\n\nFor example, the PFC can enhance or diminish the emotional intensity associated with a retrieved memory. This modulation can result in increased or decreased arousal, as well as altered subjective feelings of pleasure, discomfort, or despair. Additionally, PFC involvement can affect the context in which a memory is reactivated, leading to changes in the emotional response. The PFC can prioritize and filter information based on the current context or goal, which may result in more suitable emotional responses or the suppression of inappropriate emotional reactions.\n\nMoreover, the amygdala, PFC, and hippocampus work together in the process of emotion regulation. The anterior cingulate cortex (ACC), a region that lies within the PFC, often interacts with the amygdala to create a \&quot;circuit breaker\&quot; for emotional responses. The ACC receives input from the amygdala indicating the emotional intensity and salience of a memory, and can then engage with the amygdala to reduce the emotional response. This mechanism allows an individual to react in a more rational and appropriate manner when faced with emotionally charged situations.\n\nIn summary, the amygdala&#x27;s role in modulating the emotional intensity of retrieved memories is crucial for engaging with the world in an adaptive and meaningful way. Through its interactions with the hippocampus and, most significantly, the prefrontal cortex, the amygdala influences our perception and response to memories, contributing to our emotional experience and behavior.&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;label&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure>

<p><strong>翻译版本：</strong></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;messages&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;美国联邦贸易委员会正在打击间谍软件，这些是能自行安装在互联网用户计算机上的计算机代码，用来跟踪或干扰他们的在线活动。\nQ: 哪个是这篇文章的最佳摘要？\n从以下选项中选择：\n(A). 世界\n(B). 体育\n(C). 商业\n(D). 科技\n我认为答案是&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;user&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;哦哦啊啊！*笑* 让我想想...哦哦啊啊！*笑* 这篇文章的最佳摘要是... *鼓声*... D！科技！耶！*彩带* 美国联邦贸易委员会正在讨论间谍软件，它就像一个小小的计算机病毒，可以偷偷观察你在电脑上做的事，但不是一个好心的秘密特工！*惊讶* 联邦贸易委员会想要阻止这些间谍软件做它们的坏事，所以他们正在对付它们！*欢呼* 哇哦！&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;label&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span></span><br><span class="line"><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;messages&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;比较和对比海马体和前额叶皮层在大脑中的作用，讨论它们在记忆处理和决策中的参与。&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;user&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;人类大脑是一个高度复杂的器官，负责多种认知功能，包括记忆处理和决策。海马体和前额叶皮层是两个在这些过程中的重要区域。尽管这两个结构在这些认知领域都发挥着重要作用，但它们各自的功能不同，并相互配合，帮助我们导航世界并做出明智的选择。\n\n海马体位于内侧颞叶，主要与记忆的形成、巩固和提取相关。具体来说，它在情景记忆中起着至关重要的作用，情景记忆包括自传性事件的存储和回忆，以及空间记忆，它涉及到空间信息的编码和提取。海马体对于新记忆的形成至关重要，并将这些记忆整合到现有的知识结构中。研究表明，海马体的损伤可能导致前向性健忘症，表现为无法形成新记忆，而已巩固的记忆仍然完好。\n\n相比之下，前额叶皮层位于大脑额叶的前部，主要涉及执行功能，包括更高层次的认知过程，如决策、计划、推理和抑制控制。前额叶皮层负责整合来自不同来源的信息，评估潜在结果，并选择最有利的行动方案。它还与工作记忆有关，工作记忆是指对信息的临时存储和操作，通常用于复杂的认知任务。前额叶皮层的损伤可能导致决策能力下降、冲动行为和判断力差。\n\n尽管海马体和前额叶皮层各自的功能不同，但它们是相互连接的，并且协同工作以促进记忆处理和决策。海马体向前额叶皮层提供情境信息和情景记忆，这些信息有助于决策过程。相反，前额叶皮层可以在记忆编码和提取过程中调节海马体的活动，影响记忆的显著性和组织。这种动态的相互作用使得个体能够根据过去的经验和情境信息调整决策策略。\n\n总之，海马体和前额叶皮层在记忆处理和决策中起着至关重要的作用，尽管它们各自的贡献不同。海马体主要与情景和空间记忆的形成、巩固和提取相关，而前额叶皮层则负责执行功能，包括决策、计划和工作记忆。两者之间的相互作用使得我们能够将过去的经验和情境信息结合起来，指导明智的决策和行为。&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;讨论前额叶皮层如何在记忆编码和提取过程中调节海马体的活动。&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;user&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;前额叶皮层（PFC）和海马体之间的关系是动态的，它允许在记忆编码和提取过程中对海马体的活动进行调节。这种相互作用是通过直接和间接的神经通路连接两者，允许双向的交流。\n\n在记忆编码过程中，前额叶皮层通过自上而下的控制来调节海马体的活动。前额叶皮层可以根据任务的相关性，选择性地增强或抑制海马体对感觉信息的处理。这一过程称为“注意性调节”，它允许前额叶皮层引导海马体编码与任务相关的记忆，并抑制那些不相关的记忆。这对于形成目标导向的行为以及有效利用认知资源至关重要。\n\n除了注意性调节，前额叶皮层还通过“工作记忆”操作影响海马体。工作记忆是信息的临时存储系统，主要由前额叶皮层介导。在记忆编码过程中，前额叶皮层可以利用工作记忆为海马体提供即将编码的信息“预览”，从而帮助海马体更有效地准备并编码这些信息。\n\n在记忆提取过程中，前额叶皮层再次发挥调节作用。前额叶皮层被认为可以通过向海马体发送“提取线索”来启动提取过程。这些线索触发与记忆相关的神经模式的重新激活，从而实现记忆的提取。前额叶皮层还可以影响提取的重点，决定提取是广泛的（即回忆事件的总体内容）还是具体的（即回忆事件的细节）。\n\n此外，前额叶皮层还可以通过与杏仁体的连接调节提取记忆的情绪强度，杏仁体是与情绪处理相关的区域。这会影响对记忆的主观体验，从而改变人们对记忆的感知和反应。\n\n总之，前额叶皮层通过多种机制调节海马体在记忆编码和提取过程中的活动，包括注意性调节、工作记忆操作、提取启动和情绪调节。这些过程使得前额叶皮层能够引导海马体以一种适应性和高效的方式编码和提取记忆。&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;label&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这是sharegpt格式的KTO数据集，归纳：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;conversations&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;human&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;人类指令&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;from&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gpt&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;模型回答&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;kto_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;人类反馈 [true/false]（必填）&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="attr">&quot;数据集名称&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;data.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;formatting&quot;</span><span class="punctuation">:</span> <span class="string">&quot;sharegpt&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;messages&quot;</span><span class="punctuation">:</span> <span class="string">&quot;conversations&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;kto_tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;kto_tag&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<h3 id="六、alpaca预训练数据集"><a href="#六、alpaca预训练数据集" class="headerlink" title="六、alpaca预训练数据集"></a>六、alpaca预训练数据集</h3><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">dataset_info.json</span><br><span class="line"></span><br><span class="line"><span class="attr">&quot;wiki_demo&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;wiki_demo.txt&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;text&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;c4_demo&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;c4_demo.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;text&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">wiki_demo.txt</span><br><span class="line">Anarchism is a political philosophy and movement that is sceptical of authority and rejects all involuntary...</span><br><span class="line"></span><br><span class="line">c4_demo.json</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Don’t think you need all the bells and whistles? No problem. McKinley Heating Service Experts Heating &amp; Air Conditioning offers basic air cleaners that work to improve the quality of the air in your home without breaking the bank. It is a low-cost solution that will ensure you and your family are living comfortably.\nIt’s a good idea to understand the efficiency rate of the filters, which measures what size of molecules can get through the filter. Basic air cleaners can filter some of the dust, dander and pollen that need to be removed. They are 85% efficient, and usually have a 6-inch cleaning surface.\nBasic air cleaners are not too expensive and do the job well. If you do want to hear more about upgrading from a basic air cleaner, let the NATE-certified experts at McKinley Heating Service Experts in Edmonton talk to you about their selection.\nEither way, now’s a perfect time to enhance and protect the indoor air quality in your home, for you and your loved ones.\nIf you want expert advice and quality service in Edmonton, give McKinley Heating Service Experts a call at 780-800-7092 to get your questions or concerns related to your HVAC system addressed.&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;To the apparent surprise of everyone, the Walt Disney Company has announced a deal to purchase Lucasfilm Ltd. According to the official press release, Disney has agreed to fork over $4.05 billion in cash and stock for George Lucas’ studio in a deal that brings together two of the world’s most important intellectual property libraries.\nAs you might expect, Disney is itching to take advantage of its new toys. “This transaction combines a world-class portfolio of content including Star Wars, one of the greatest family entertainment franchises of all time, with Disney’s unique and unparalleled creativity across multiple platforms, businesses, and markets to generate sustained growth and drive significant long-term value,” said Disney CEO Robert Iger in this afternoon’s announcement.\nUnder the terms of this agreement Disney will acquire control over all Lucasfilm iterations. This includes both its traditional film-making studio facilities, as well as the various technologies Lucasfilm has created over the years to further its various media properties. Thus, the gigantic Disney family now includes Lucasfilm itself, special effects house Industrial Light &amp; Magic, Skywalker Sound and LucasArts, the company’s video game creation division.\nThis acquisition alone would be huge news, but as if to pre-empt fan speculation on the future of Star Wars the same announcement also mentions that a new Star Wars movie is scheduled to appear in 2015. Though the vast majority of recent Star Wars media has been focused on the property’s various animated iterations and LEGO crossovers, this new film will be the first official cinematic continuation of George Lucas’ original Star Wars trilogy. Though very few details are offered on this film, it has officially been dubbed Star Wars: Episode VII, and barring any major catastrophes it should hit theaters at some point in 2015 (if we had to guess, we’d assume an early summer release in keeping with the tradition established by its predecessors).\nPerhaps even more intriguing however, is the announcement’s claim that Episode VII’s release will herald a new era in which new Star Wars movies hit theaters “every two to three years.” It specifically mentions Episodes VIII and IX by name, though offers no solid details on either film.\nWhile the effects of the move won’t be fully known for at least a few months, we can think of a number of a things this new union might change. For instance, currently Dark Horse Comics publishes all Star Wars comic books, but with Disney owning Marvel Comics we can’t see that agreement lasting for long. Likewise, both Disney and Lucasfilm have sizable divisions dedicated to creating video games based on their various media properties. Normally these companies have had to seek outside publishing agreements, but now that they’ve joined forces and massively expanded the number of games either company is capable of releasing in any given year, it makes a lot of sense for Disney to invest in its own games publishing wing.\nFinally, this agreement almost certainly heralds future crossovers between Disney and Lucasfilm characters. We don’t know any specifics, but it’s only a matter of time before we see toys depicting Mickey Mouse dressed as Darth Vader. Whether that sounds awesome or stomach-churningly disgusting is entirely up to your rapidly waning sense of childhood whimsy.\nUpdate: Scratch that last prediction. Apparently Disney characters dressed as Star Wars characters is already a thing.\nOur partnership with LucasFilm has produced over 20 yrs worth of stories. We have Star Wars for the near future, and hope for years to come.&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure>

<p>由例子可见，预训练数据集只用于学习语言模型，目前llamafactory只支持alpaca格式的预训练集，归纳：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">dataset_info.json</span><br><span class="line"></span><br><span class="line"><span class="attr">&quot;数据集名称&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;data.json&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;columns&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;text&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span><span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;document&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span><span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;document&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>

<hr>
<h2 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h2><p>llamafactory提供了通用能力评估和NLG评估，使用方法见<a href="https://llamafactory.readthedocs.io/zh-cn/latest/getting_started/eval.html#id1">链接</a>，这里解释下什么是通用能力评估以及什么是NLG评估</p>
<ul>
<li><p>通用能力评测关注大模型在多个任务上的泛化能力，常用于衡量大模型是否具备<strong>推理、数学、知识问答、代码生成等多方面能力</strong>。LLamafactory提供了mmlu，cmmlu, ceval三个常见数据集的自动评测脚本。</p>
<table>
<thead>
<tr>
<th>数据集</th>
<th>语言</th>
<th>任务类型</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td><strong>MMLU</strong></td>
<td>英文</td>
<td>多任务、多领域知识</td>
<td>评测大模型的英文知识与推理能力</td>
</tr>
<tr>
<td><strong>CMMU</strong></td>
<td>中文</td>
<td>多任务、多领域知识</td>
<td>评测大模型的中文知识与推理能力</td>
</tr>
<tr>
<td><strong>CEval</strong></td>
<td>中文</td>
<td>学术、专业知识</td>
<td>更专业的中文能力评测（涉及高难度任务）</td>
</tr>
</tbody></table>
</li>
<li><p>NLG方面提供了BLEU和ROUGE分数评价模型生成质量，<strong>BLEU</strong>（Bilingual Evaluation Understudy）：计算n-gram匹配率，常用于机器翻译评测。<strong>ROUGE</strong>（Recall-Oriented Understudy for Gisting Evaluation）：主要用于文本摘要任务，计算n-gram召回率。</p>
</li>
</ul>
<p>那如果想评估纵向领域的微调效果怎么办？</p>
<ul>
<li>用基准测试集（如 MMLU、CEval、MedQA）测准确率，提高数值指标</li>
<li>用自动指标（如 BLEU、BERTScore、FactScore）评估生成内容质量</li>
<li>结合人工评测+真实用户测试，确保专业领域的实际可用性</li>
</ul>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><ol>
<li><p>我看alpaca和sharegpt都有指令监督微调数据集和偏好数据集，那么我应该选哪个呢？</p>
<p>todo…</p>
</li>
<li><p>偏好数据集用于奖励模型训练、DPO训练、ORPO训练和SimPO训练，解释下这些术语以及Pre-train，SFT：</p>
<p>它们都是<strong>大模型训练的方法</strong>，可以理解为<strong>让 AI 变聪明的不同步骤</strong>。</p>
<p>我们可以把训练过程想象成<strong>培养一个优秀的学生</strong>，分为三个阶段：</p>
<ol>
<li><strong>基础学习</strong>（预训练 Pre-Training）</li>
<li><strong>学会听人话</strong>（SFT + 奖励建模 Reward Modeling）</li>
<li><strong>学会更符合人类喜好</strong>（PPO、DPO、KTO、ORPO、SimPO）</li>
</ol>
<hr>
<h3 id="Pre-Training（预训练）——-基础学习"><a href="#Pre-Training（预训练）——-基础学习" class="headerlink" title="Pre-Training（预训练）—— 基础学习"></a>Pre-Training（预训练）—— 基础学习</h3><blockquote>
<p>让 AI <strong>从零开始学习知识，相当于小孩上学</strong>。</p>
</blockquote>
<ul>
<li>AI 在<strong>大规模数据</strong>（比如书籍、论文、网站）上进行<strong>无监督学习</strong>，学习语法、常识、逻辑等。</li>
<li>这个阶段 AI <strong>还不会听人话</strong>，它只是学到了很多<strong>碎片化的知识</strong>。</li>
<li>例如：GPT-4、Llama-3 这些模型都经历了预训练阶段。</li>
</ul>
<p>📝 <strong>你可以理解成：AI 在上小学，疯狂看书，但不会对话。</strong></p>
<hr>
<h3 id="SFT（Supervised-Fine-Tuning，监督微调）——-学会听人话"><a href="#SFT（Supervised-Fine-Tuning，监督微调）——-学会听人话" class="headerlink" title="SFT（Supervised Fine-Tuning，监督微调）—— 学会听人话"></a>SFT（Supervised Fine-Tuning，监督微调）—— 学会听人话</h3><blockquote>
<p>让 AI <strong>按照人类的方式回答问题，相当于中学阶段的老师手把手教学</strong>。</p>
</blockquote>
<ul>
<li>用<strong>人类标注的数据</strong>（例如 ShareGPT、Alpaca）微调模型，让 AI <strong>学会按照人类的方式回答问题</strong>。</li>
<li>让 AI 更加<strong>符合特定任务</strong>，比如医学问答、法律咨询、编程助手等。</li>
<li>这个阶段 AI <strong>会听人话了，但还不一定懂得哪些回答是更好的</strong>。</li>
</ul>
<p>📝 <strong>相当于：AI 进入中学，老师告诉它哪些回答是正确的，但它还不能区分好坏回答。</strong></p>
<hr>
<h3 id="Reward-Modeling（奖励建模）——-训练-AI-评判好坏"><a href="#Reward-Modeling（奖励建模）——-训练-AI-评判好坏" class="headerlink" title="Reward Modeling（奖励建模）—— 训练 AI 评判好坏"></a>Reward Modeling（奖励建模）—— 训练 AI 评判好坏</h3><blockquote>
<p>让 AI <strong>知道哪些答案是好答案，哪些是坏答案，相当于 AI 参加考试，学习评分标准</strong>。</p>
</blockquote>
<ul>
<li>训练一个<strong>奖励模型（Reward Model, RM）</strong>，用来给 AI 的回答<strong>打分</strong>。</li>
<li>人类会对 AI 生成的回答<strong>进行比较</strong>（例如，哪种回答更好？），然后训练 RM 学习这个评分标准。</li>
<li><strong>Reward Model 并不会直接优化 AI，而是用来指导 AI 训练</strong>。</li>
</ul>
<p>📝 <strong>相当于：AI 在考试，学习如何给自己打分，知道什么样的回答会得高分。</strong></p>
<hr>
<h3 id="PPO（Proximal-Policy-Optimization，近端策略优化）——-让-AI-生成高分答案"><a href="#PPO（Proximal-Policy-Optimization，近端策略优化）——-让-AI-生成高分答案" class="headerlink" title="PPO（Proximal Policy Optimization，近端策略优化）—— 让 AI 生成高分答案"></a>PPO（Proximal Policy Optimization，近端策略优化）—— 让 AI 生成高分答案</h3><blockquote>
<p>让 AI <strong>使用强化学习（RL）优化自己的回答，使其更符合人类偏好，相当于 AI 根据分数改进自己</strong>。</p>
</blockquote>
<ul>
<li>先用 <strong>Reward Model（奖励模型）</strong> 给 AI 生成的回答打分。</li>
<li>然后用 PPO 让 AI <strong>调整自己的回答方式，让它更偏向高分回答</strong>。</li>
<li>这是 <strong>RLHF（基于人类反馈的强化学习）</strong> 的关键步骤，OpenAI 训练 ChatGPT 时用了 PPO。</li>
</ul>
<p>📝 <strong>相当于：AI 知道考试评分标准后，学会如何答题得高分，但有时候会“讨好”评分系统，回答变得保守。</strong></p>
<hr>
<h3 id="DPO（Direct-Preference-Optimization，直接偏好优化）——-让-AI-直接学会人类偏好"><a href="#DPO（Direct-Preference-Optimization，直接偏好优化）——-让-AI-直接学会人类偏好" class="headerlink" title="DPO（Direct Preference Optimization，直接偏好优化）—— 让 AI 直接学会人类偏好"></a>DPO（Direct Preference Optimization，直接偏好优化）—— 让 AI 直接学会人类偏好</h3><blockquote>
<p>让 AI <strong>不需要奖励模型，直接从人类选择的数据中学习偏好，相当于 AI 直接看答案，学会哪种更好</strong>。</p>
</blockquote>
<ul>
<li><strong>DPO 不需要 Reward Model</strong>，而是<strong>直接学习人类的选择</strong>（例如，给 AI 两个回答，选择更好的那个）。</li>
<li>DPO 比 PPO <strong>更简单、更稳定，不需要强化学习</strong>。</li>
<li>适用于偏好学习，例如对话风格优化、客服 AI 训练等。</li>
</ul>
<p>📝 <strong>相当于：AI 不用自己摸索评分标准，而是直接看人类的选择，学会什么样的回答更受欢迎。</strong></p>
<hr>
<h3 id="KTO（KL-regularized-Transformer-Optimization，KL-正则化-Transformer-优化）——-让-AI-优化偏好但不跑偏"><a href="#KTO（KL-regularized-Transformer-Optimization，KL-正则化-Transformer-优化）——-让-AI-优化偏好但不跑偏" class="headerlink" title="KTO（KL-regularized Transformer Optimization，KL 正则化 Transformer 优化）—— 让 AI 优化偏好但不跑偏"></a>KTO（KL-regularized Transformer Optimization，KL 正则化 Transformer 优化）—— 让 AI 优化偏好但不跑偏</h3><blockquote>
<p>让 AI <strong>在优化偏好的同时，不会跑得太远，相当于 AI 在考试中学会稳定发挥</strong>。</p>
</blockquote>
<ul>
<li><strong>KTO 是 DPO 的改进版</strong>，用 KL 散度约束优化过程，让 AI 在学习人类偏好的同时，不会偏离原来的知识太远。</li>
<li>这样 AI <strong>既能学到人类偏好，又不会丢掉原有的知识</strong>。</li>
</ul>
<p>📝 <strong>相当于：AI 在改进答案时，不会把自己搞糊涂，确保稳步提升。</strong></p>
<hr>
<h3 id="ORPO（Offline-Reinforcement-Preference-Optimization，离线强化偏好优化）——-用现成数据优化-AI"><a href="#ORPO（Offline-Reinforcement-Preference-Optimization，离线强化偏好优化）——-用现成数据优化-AI" class="headerlink" title="ORPO（Offline Reinforcement Preference Optimization，离线强化偏好优化）—— 用现成数据优化 AI"></a>ORPO（Offline Reinforcement Preference Optimization，离线强化偏好优化）—— 用现成数据优化 AI</h3><blockquote>
<p>让 AI <strong>用已有的评分数据训练，而不是在线试错，相当于 AI 只看老师批改好的试卷学习</strong>。</p>
</blockquote>
<ul>
<li><strong>ORPO 不让 AI 自己试错，而是用已有的评分数据来优化 AI</strong>。</li>
<li>适合<strong>医学、法律等不能乱试错的场景</strong>，保证 AI 输出的答案可靠。</li>
</ul>
<p>📝 <strong>相当于：AI 只学习老师批改好的试卷，不自己试错，以免出危险的答案。</strong></p>
<hr>
<h3 id="SimPO（Simple-Preference-Optimization，简单偏好优化）——-更简单的-DPO"><a href="#SimPO（Simple-Preference-Optimization，简单偏好优化）——-更简单的-DPO" class="headerlink" title="SimPO（Simple Preference Optimization，简单偏好优化）—— 更简单的 DPO"></a>SimPO（Simple Preference Optimization，简单偏好优化）—— 更简单的 DPO</h3><blockquote>
<p>让 AI <strong>用更简单的方式学习人类偏好，相当于 AI 直接模仿优秀答案，不用复杂训练</strong>。</p>
</blockquote>
<ul>
<li>SimPO <strong>比 DPO 计算量更小，更快</strong>，适用于小规模模型微调。</li>
<li>适用于<strong>快速优化 AI 在某些领域的表现</strong>，比如让 AI 更懂编程、医学等。</li>
</ul>
<p>📝 <strong>相当于：AI 直接看好答案，快速调整，不进行复杂计算。</strong></p>
<hr>
<h3 id="总结（用简单的话对比这些概念）"><a href="#总结（用简单的话对比这些概念）" class="headerlink" title="总结（用简单的话对比这些概念）"></a>总结（用简单的话对比这些概念）</h3><table>
<thead>
<tr>
<th>方法</th>
<th>作用</th>
<th>是否用奖励模型</th>
<th>是否用强化学习</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Pre-Training</strong></td>
<td>让 AI 学习基础知识</td>
<td>❌ 否</td>
<td>❌ 否</td>
</tr>
<tr>
<td><strong>SFT（监督微调）</strong></td>
<td>让 AI 学会听人话</td>
<td>❌ 否</td>
<td>❌ 否</td>
</tr>
<tr>
<td><strong>Reward Modeling</strong></td>
<td>让 AI 学会评判好坏</td>
<td>✅ 是</td>
<td>❌ 否</td>
</tr>
<tr>
<td><strong>PPO</strong></td>
<td>让 AI 根据评分优化回答</td>
<td>✅ 是</td>
<td>✅ 是（强化学习）</td>
</tr>
<tr>
<td><strong>DPO</strong></td>
<td>让 AI 直接学习人类偏好</td>
<td>❌ 否</td>
<td>❌ 否</td>
</tr>
<tr>
<td><strong>KTO</strong></td>
<td>让 AI 优化偏好但不跑偏</td>
<td>❌ 否</td>
<td>❌ 否</td>
</tr>
<tr>
<td><strong>ORPO</strong></td>
<td>用已有评分数据训练 AI</td>
<td>❌ 否</td>
<td>❌ 否</td>
</tr>
<tr>
<td><strong>SimPO</strong></td>
<td>让 AI 低成本学习偏好</td>
<td>❌ 否</td>
<td>❌ 否</td>
</tr>
</tbody></table>
<hr>
<h3 id="你应该怎么选？"><a href="#你应该怎么选？" class="headerlink" title="你应该怎么选？"></a>你应该怎么选？</h3><ul>
<li><strong>想训练大模型</strong> → 先 <strong>Pre-Training → SFT → PPO（RLHF）</strong></li>
<li><strong>想让 AI 优化回答但不搞复杂训练</strong> → 选 <strong>DPO、SimPO、KTO</strong></li>
<li><strong>如果数据已经有评分，想稳定优化</strong> → 选 <strong>ORPO</strong></li>
</ul>
</li>
<li><p>再详细解释下MMLU、CMMU、CEval</p>
<p><strong>MMLU（Massive Multitask Language Understanding）</strong></p>
<ul>
<li><p>用途：评测模型在<strong>多任务语言理解</strong>上的表现，包括<strong>知识问答、推理、数学、历史、法律、医学等57个子任务</strong>。</p>
</li>
<li><p>特点：</p>
<p>数据集涵盖<strong>小学到大学水平</strong>的各种领域知识。</p>
<p>采用**四选一（Multiple Choice）**的测试方式，评估模型在不同知识领域的准确率。</p>
<p>通常使用<strong>5-shot 或 zero-shot</strong>（即模型是否需要少量示例学习）。</p>
</li>
<li><p>适用场景：</p>
<p>评估大模型的<strong>世界知识和推理能力</strong>。</p>
<p>对比不同模型的多任务理解能力（如 GPT-4、LLaMA-2、Qwen 等）。</p>
</li>
</ul>
<p><strong>CMMU（Chinese Massive Multitask Language Understanding）</strong></p>
<ul>
<li><p>用途：MMLU 的<strong>中文版本</strong>，测试模型在<strong>中文多任务理解</strong>上的表现。</p>
</li>
<li><p>特点：</p>
<p>设计思路类似 MMLU，但数据经过<strong>中文优化</strong>，涵盖中国背景知识。</p>
<p>适用于<strong>评估中文大模型</strong>（如 ChatGLM、Baichuan、Qwen）。</p>
<p>也采用<strong>四选一</strong>的评测方式。</p>
</li>
<li><p>适用场景：</p>
<p>评测大模型在<strong>中文任务</strong>（如历史、地理、数学、法律、医学等）上的表现。</p>
<p>对比不同大模型在<strong>中文理解能力</strong>方面的优劣。</p>
</li>
</ul>
<p><strong>CEval（Chinese Evaluation Benchmark）</strong></p>
<ul>
<li><p><strong>用途</strong>：专门为<strong>中文大模型</strong>设计的<strong>权威测试集</strong>，涵盖<strong>学术、专业和通用能力测试</strong>。</p>
</li>
<li><p>特点：</p>
<p>涵盖<strong>52个任务</strong>，包含**基础知识（数学、物理）、人文社科（历史、法律）、工程技术（计算机、电子）**等多个领域。</p>
<p>任务难度从<strong>小学到大学水平</strong>。</p>
<p>也是<strong>四选一</strong>的选择题形式。</p>
</li>
<li><p>适用场景：</p>
<p>评测大模型在<strong>不同中文任务</strong>上的泛化能力。</p>
<p>适用于国内大模型的<strong>对比测试</strong>。</p>
</li>
</ul>
</li>
</ol>
<h2 id="Gradio运行LLamaFactory（TODO）"><a href="#Gradio运行LLamaFactory（TODO）" class="headerlink" title="Gradio运行LLamaFactory（TODO）"></a>Gradio运行LLamaFactory（TODO）</h2><p>运行下面命令，指定使用第一个卡（我这本身就只有一个卡，运行在7860端口，参考链接3）：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0 GRADIO_SERVER_PORT=7860 llamafactory-cli webui</span><br></pre></td></tr></table></figure>

<p>我实际使用以下命令也没问题：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">llamafactory-cli webui</span><br></pre></td></tr></table></figure>

<img src="/2025/02/18/LLamaFactory%E5%BE%AE%E8%B0%83Qwen2-5VL/image-20250218181054901.png" class="" title="image-20250218181054901">

<p>参考链接3，更改一点配置项：</p>
<ul>
<li>语言-&gt;zh</li>
<li>模型名称-&gt;Qwen2.5-VL-7B-Instruct</li>
<li>模型路径-&gt;&#x2F;home&#x2F;chr&#x2F;桌面&#x2F;llamafactory&#x2F;Qwen2.5-VL-7B-Instruct</li>
<li>数据集-&gt;alpaca_zh_demo，可点击<strong>预览数据集</strong>查看数据集</li>
<li>梯度累积-&gt;4</li>
<li>预热步数-&gt;4</li>
<li>LoRA缩放系数-&gt;256</li>
</ul>
<p>可点击<strong>预览命令</strong>查看命令（具体含义<a href="https://llamafactory.readthedocs.io/zh-cn/latest/getting_started/sft.html">参考</a>），点击开始，这个时候会出个问题。</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://zhuanlan.zhihu.com/p/695287607">https://zhuanlan.zhihu.com/p/695287607</a></li>
<li><a href="https://llamafactory.readthedocs.io/zh-cn/latest/getting_started/installation.html#">https://llamafactory.readthedocs.io/zh-cn/latest/getting_started/installation.html#</a></li>
<li><a href="https://www.bilibili.com/video/BV1UvF5eLEyb/?vd_source=075a061948e76c87e2ee8754e264056e">https://www.bilibili.com/video/BV1UvF5eLEyb/?vd_source=075a061948e76c87e2ee8754e264056e</a></li>
<li><a href="https://github.com/hiyouga/LLaMA-Factory/blob/main/data/README_zh.md">https://github.com/hiyouga/LLaMA-Factory/blob/main/data/README_zh.md</a></li>
<li><a href="https://llamafactory.readthedocs.io/zh-cn/latest/getting_started/inference.html">https://llamafactory.readthedocs.io/zh-cn/latest/getting_started/inference.html</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>llm</tag>
        <tag>qwen2.5</tag>
        <tag>llamafactory</tag>
        <tag>qwen2.5 vl</tag>
      </tags>
  </entry>
  <entry>
    <title>LSTM-FCN代码解析</title>
    <url>/2025/01/22/LSTM-FCN%E4%BB%A3%E7%A0%81%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><a href="https://caihaoran-00.github.io/2025/01/14/LSTM-FCN/">前面</a>我们介绍了<a href="https://arxiv.org/abs/1709.05206">LSTM-FCN</a>的论文内容，本文我们开始代码撰写和介绍。</p>
<span id="more"></span>

<hr>
<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>首先，从<code>Github</code>搜索<code>LSTM-FCN</code>，会看到一系列与之相关的结果，第一个就是<a href="https://github.com/titu1994/LSTM-FCN">官方实现</a>，但其是基于<code>keras</code>的，我喜欢使用<code>pytorch</code>，向下翻一翻，看到两个<code>pytorch</code>的实现，<a href="https://github.com/roytalman/LSTM-FCN-Pytorch">roytalman&#x2F;LSTM-FCN-Pytorch</a>和<a href="https://github.com/flaviagiammarino/lstm-fcn-pytorch">flaviagiammarino&#x2F;lstm-fcn-pytorch</a>，下面就参考这三个实现用pytorch进行LSTM-FCN的实现。</p>
<p>第一步还是先跑通官方的实现吧，先更改下<code>requirement.txt</code>：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">tensorflow</span><br><span class="line">keras</span><br><span class="line">scipy</span><br><span class="line">numpy</span><br><span class="line">pandas</span><br><span class="line">scikit-learn</span><br><span class="line">h5py</span><br><span class="line">matplotlib</span><br><span class="line">joblib</span><br></pre></td></tr></table></figure>

<p>然后依次运行：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/titu1994/LSTM-FCN.git</span><br><span class="line"></span><br><span class="line">conda create -n LSTM_FCN python=3.8</span><br><span class="line"></span><br><span class="line">conda activate LSTM_FCN</span><br><span class="line"></span><br><span class="line">pip install -r requirement.txt</span><br></pre></td></tr></table></figure>

<p>然后下载官方所用的<a href="https://www.cs.ucr.edu/%7Eeamonn/time_series_data_2018/">UCR2018版</a>，这个（2015版）压缩包的解压密码是<code>attempttoclassify</code>，运行：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">unzip UCRArchive_2018.zip</span><br></pre></td></tr></table></figure>

<p>这时候会让你输入密码，输入：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">someone</span><br></pre></td></tr></table></figure>

<p>即可解压，如果下载的是<a href="https://www.cs.ucr.edu/~eamonn/time_series_data/">UCR2015版</a>，<strong>删除重下!</strong>（手动狗头），如果你想看看2015版的内容，上面的两行命令替换成：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">unzip UCR_TS_Archive_2015.zip</span><br><span class="line"></span><br><span class="line">attempttoclassify</span><br></pre></td></tr></table></figure>

<p>然后，将<code>LSTM-FCN/utils</code>目录下的<code>extract_all_datasets.py</code>复制到你解压后的文件夹中，运行这个文件:</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">python extract_all_datasets.py</span><br></pre></td></tr></table></figure>

<p>即可提取文本：</p>
<p>在你的解压后的文件夹中会多一个<code>_data</code>目录，这就是提取出来的文本：</p>
<p>将提取出来的全部文本放在<code>LSTM-FCN/Data</code>目录下就做完了准备工作。</p>
<hr>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>打开<code>LSTM-FCN/all_datasets_training.py</code>，开炮！好的，哑火了，先看看代码吧：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">pip install scikit-image</span><br></pre></td></tr></table></figure>





<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a href="https://github.com/titu1994/LSTM-FCN">https://github.com/titu1994/LSTM-FCN</a></li>
<li><a href="https://github.com/roytalman/LSTM-FCN-Pytorch">https://github.com/roytalman/LSTM-FCN-Pytorch</a></li>
<li><a href="https://github.com/flaviagiammarino/lstm-fcn-pytorch">https://github.com/flaviagiammarino/lstm-fcn-pytorch</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>classification</tag>
      </tags>
  </entry>
  <entry>
    <title>Langgraph流式输出篇</title>
    <url>/2025/02/25/Langgraph%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA%E7%AF%87/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><a href="https://caihaoran-00.github.io/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/#more">前面</a>介绍了langgrph并给出了几个基础demo，鉴于langgraph的流式输出篇幅不小，为避免单个博客过于臃肿，故新开一个博客进行流式输出的介绍。</p>
<p>流式传输对于增强基于 LLM 构建的应用程序的响应能力至关重要。通过逐步显示输出，流式传输可显著改善用户体验 ，尤其是在LLM 的延迟方面。</p>
<span id="more"></span>

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>LangGraph 内置了一流的流式传输支持。有几种不同的方法可以从图形运行中流式传输输出：</p>
<ul>
<li><code>&quot;values&quot;</code>：每一步之后发出状态中的所有值(每次状态更新都会输出)</li>
<li><code>&quot;updates&quot;</code>：仅发出节点名称和每个步骤后节点返回的更新。如果在同一步骤中进行多项更新（例如运行多个节点），则这些更新将分别发出（只会输出状态的增量更新，并且带上当前更新对应的节点名）</li>
<li><code>&quot;custom&quot;</code>：使用从内部节点发出自定义数据<code>StreamWriter</code></li>
<li><code>&quot;messages&quot;</code>：逐个标记地发出 LLM 消息以及节点内任何 LLM 调用的元数据</li>
<li><code>&quot;debug&quot;</code>：针对每个步骤发出包含尽可能多信息的调试事件</li>
</ul>
<h3 id="一、基础示例-底座，非流式版本"><a href="#一、基础示例-底座，非流式版本" class="headerlink" title="一、基础示例(底座，非流式版本)"></a>一、基础示例(底座，非流式版本)</h3><figure class="highlight python"><figcaption><span>howtostream_basic.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> TypedDict</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    topic: <span class="built_in">str</span></span><br><span class="line">    joke: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">refine_topic</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;topic&quot;</span>: state[<span class="string">&quot;topic&quot;</span>] + <span class="string">&quot; and cats&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_joke</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;joke&quot;</span>: <span class="string">f&quot;This is a joke about <span class="subst">&#123;state[<span class="string">&#x27;topic&#x27;</span>]&#125;</span>&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph = (</span><br><span class="line">    StateGraph(State)</span><br><span class="line">    .add_node(refine_topic)</span><br><span class="line">    .add_node(generate_joke)</span><br><span class="line">    .add_edge(START, <span class="string">&quot;refine_topic&quot;</span>)</span><br><span class="line">    .add_edge(<span class="string">&quot;refine_topic&quot;</span>, <span class="string">&quot;generate_joke&quot;</span>)</span><br><span class="line">    .<span class="built_in">compile</span>()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">result = graph.invoke(&#123;<span class="string">&quot;topic&quot;</span>: <span class="string">&quot;ice cream&quot;</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;topic&#x27;</span>: <span class="string">&#x27;ice cream and cats&#x27;</span>, <span class="string">&#x27;joke&#x27;</span>: <span class="string">&#x27;This is a joke about ice cream and cats&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>

<p>注意：</p>
<ul>
<li><code>result = graph.invoke(&#123;&quot;topic&quot;: &quot;ice cream&quot;&#125;)</code>，<code>graph.invoke(&#123;...&#125;)</code> 返回的是 <strong>整个 <code>state</code></strong>，所以 <code>result</code> 就是最终的 <code>state</code></li>
<li><code>state</code> <strong>是贯穿整个执行流程的数据结构</strong>，它会被 <strong>不断更新和合并</strong></li>
</ul>
<hr>
<h3 id="二、流式传输状态下的所有值（stream-mode-”values”）"><a href="#二、流式传输状态下的所有值（stream-mode-”values”）" class="headerlink" title="二、流式传输状态下的所有值（stream_mode&#x3D;”values”）"></a>二、流式传输状态下的所有值（stream_mode&#x3D;”values”）</h3><figure class="highlight python"><figcaption><span>howtostream.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;https://langchain-ai.github.io/langgraph/how-tos/streaming/&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> TypedDict</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    topic: <span class="built_in">str</span></span><br><span class="line">    joke: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">refine_topic</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;topic&quot;</span>: state[<span class="string">&quot;topic&quot;</span>] + <span class="string">&quot; and cats&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_joke</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;joke&quot;</span>: <span class="string">f&quot;This is a joke about <span class="subst">&#123;state[<span class="string">&#x27;topic&#x27;</span>]&#125;</span>&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph = (</span><br><span class="line">    StateGraph(State)</span><br><span class="line">    .add_node(refine_topic)</span><br><span class="line">    .add_node(generate_joke)</span><br><span class="line">    .add_edge(START, <span class="string">&quot;refine_topic&quot;</span>)</span><br><span class="line">    .add_edge(<span class="string">&quot;refine_topic&quot;</span>, <span class="string">&quot;generate_joke&quot;</span>)</span><br><span class="line">    .<span class="built_in">compile</span>()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> graph.stream(</span><br><span class="line">    &#123;<span class="string">&quot;topic&quot;</span>: <span class="string">&quot;ice cream&quot;</span>&#125;,</span><br><span class="line">    stream_mode=<span class="string">&quot;values&quot;</span>,</span><br><span class="line">):</span><br><span class="line">    <span class="built_in">print</span>(chunk)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;topic&#x27;</span>: <span class="string">&#x27;ice cream&#x27;</span>&#125;</span><br><span class="line">&#123;<span class="string">&#x27;topic&#x27;</span>: <span class="string">&#x27;ice cream and cats&#x27;</span>&#125;</span><br><span class="line">&#123;<span class="string">&#x27;topic&#x27;</span>: <span class="string">&#x27;ice cream and cats&#x27;</span>, <span class="string">&#x27;joke&#x27;</span>: <span class="string">&#x27;This is a joke about ice cream and cats&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>

<p>可见，指定<code>stream_mode=&quot;values&quot;</code>时，每次状态更新都会输出，顺序分别为：</p>
<ul>
<li><p><strong>初始状态</strong> <code>&#123; &quot;topic&quot;: &quot;ice cream&quot; &#125;</code></p>
</li>
<li><p><strong><code>refine_topic</code> 处理后的状态</strong> <code>&#123; &quot;topic&quot;: &quot;ice cream and cats&quot; &#125;</code></p>
</li>
<li><p><strong><code>generate_joke</code> 处理后的状态</strong> <code>&#123; &quot;topic&quot;: &quot;ice cream and cats&quot;, &quot;joke&quot;: &quot;This is a joke about ice cream and cats&quot; &#125;</code></p>
</li>
</ul>
<hr>
<h3 id="三、来自节点的流状态更新（stream-mode-”updates”）"><a href="#三、来自节点的流状态更新（stream-mode-”updates”）" class="headerlink" title="三、来自节点的流状态更新（stream_mode&#x3D;”updates”）"></a>三、来自节点的流状态更新（stream_mode&#x3D;”updates”）</h3><p>只需将<code>stream_mode=&quot;updates&quot;</code>-&gt;<code>stream_mode=&quot;values&quot;</code>，输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;refine_topic&#x27;</span>: &#123;<span class="string">&#x27;topic&#x27;</span>: <span class="string">&#x27;ice cream and cats&#x27;</span>&#125;&#125;</span><br><span class="line">&#123;<span class="string">&#x27;generate_joke&#x27;</span>: &#123;<span class="string">&#x27;joke&#x27;</span>: <span class="string">&#x27;This is a joke about ice cream and cats&#x27;</span>&#125;&#125;</span><br></pre></td></tr></table></figure>

<p>注意：该行为<strong>不会输出初始输入的状态</strong>，因为 <code>updates</code> 只跟踪 <strong>计算过程中产生的增量更新</strong>，而初始状态不是由任何节点计算出来的。</p>
<hr>
<h3 id="四、流调试事件（stream-mode-”debug”）"><a href="#四、流调试事件（stream-mode-”debug”）" class="headerlink" title="四、流调试事件（stream_mode&#x3D;”debug”）"></a>四、流调试事件（stream_mode&#x3D;”debug”）</h3><p>只需将<code>stream_mode=&quot;debug&quot;</code>-&gt;<code>stream_mode=&quot;updates&quot;</code>，输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;task&#x27;</span>, <span class="string">&#x27;timestamp&#x27;</span>: <span class="string">&#x27;2025-02-25T09:20:45.414185+00:00&#x27;</span>, <span class="string">&#x27;step&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;payload&#x27;</span>: &#123;<span class="string">&#x27;id&#x27;</span>: <span class="string">&#x27;fb7332bb-5540-51c3-4f71-147275e42ada&#x27;</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;refine_topic&#x27;</span>, <span class="string">&#x27;input&#x27;</span>: &#123;<span class="string">&#x27;topic&#x27;</span>: <span class="string">&#x27;ice cream&#x27;</span>&#125;, <span class="string">&#x27;triggers&#x27;</span>: [<span class="string">&#x27;start:refine_topic&#x27;</span>]&#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;task_result&#x27;</span>, <span class="string">&#x27;timestamp&#x27;</span>: <span class="string">&#x27;2025-02-25T09:20:45.415185+00:00&#x27;</span>, <span class="string">&#x27;step&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;payload&#x27;</span>: &#123;<span class="string">&#x27;id&#x27;</span>: <span class="string">&#x27;fb7332bb-5540-51c3-4f71-147275e42ada&#x27;</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;refine_topic&#x27;</span>, <span class="string">&#x27;error&#x27;</span>: <span class="literal">None</span>, <span class="string">&#x27;result&#x27;</span>: [(<span class="string">&#x27;topic&#x27;</span>, <span class="string">&#x27;ice cream and cats&#x27;</span>)], <span class="string">&#x27;interrupts&#x27;</span>: []&#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;task&#x27;</span>, <span class="string">&#x27;timestamp&#x27;</span>: <span class="string">&#x27;2025-02-25T09:20:45.415185+00:00&#x27;</span>, <span class="string">&#x27;step&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;payload&#x27;</span>: &#123;<span class="string">&#x27;id&#x27;</span>: <span class="string">&#x27;5f676a5d-4bb5-2231-1a86-4f87a3943648&#x27;</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;generate_joke&#x27;</span>, <span class="string">&#x27;input&#x27;</span>: &#123;<span class="string">&#x27;topic&#x27;</span>: <span class="string">&#x27;ice cream and cats&#x27;</span>&#125;, <span class="string">&#x27;triggers&#x27;</span>: [<span class="string">&#x27;refine_topic&#x27;</span>]&#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;task_result&#x27;</span>, <span class="string">&#x27;timestamp&#x27;</span>: <span class="string">&#x27;2025-02-25T09:20:45.415185+00:00&#x27;</span>, <span class="string">&#x27;step&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;payload&#x27;</span>: &#123;<span class="string">&#x27;id&#x27;</span>: <span class="string">&#x27;5f676a5d-4bb5-2231-1a86-4f87a3943648&#x27;</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;generate_joke&#x27;</span>, <span class="string">&#x27;error&#x27;</span>: <span class="literal">None</span>, <span class="string">&#x27;result&#x27;</span>: [(<span class="string">&#x27;joke&#x27;</span>, <span class="string">&#x27;This is a joke about ice cream and cats&#x27;</span>)], <span class="string">&#x27;interrupts&#x27;</span>: []&#125;&#125;</span><br></pre></td></tr></table></figure>

<p>使用它来流式**传输调试事件，**其中包含每个步骤的尽可能多的信息。包括有关计划执行的任务以及任务执行结果的信息。</p>
<hr>
<h3 id="五、✨流式tokens（stream-mode-”messages”）"><a href="#五、✨流式tokens（stream-mode-”messages”）" class="headerlink" title="五、✨流式tokens（stream_mode&#x3D;”messages”）"></a>五、✨流式tokens（stream_mode&#x3D;”messages”）</h3><figure class="highlight python"><figcaption><span>howtostream_tokens.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;https://langchain-ai.github.io/langgraph/how-tos/streaming/&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> TypedDict</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置大模型参数</span></span><br><span class="line">LLM_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;sk-****************&quot;</span>,</span><br><span class="line">    <span class="string">&quot;base_url&quot;</span>: <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen2.5-7b-instruct&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化大模型</span></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=LLM_CONFIG[<span class="string">&quot;model&quot;</span>],</span><br><span class="line">    openai_api_key=LLM_CONFIG[<span class="string">&quot;api_key&quot;</span>],</span><br><span class="line">    openai_api_base=LLM_CONFIG[<span class="string">&quot;base_url&quot;</span>],</span><br><span class="line">    streaming=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    topic: <span class="built_in">str</span></span><br><span class="line">    joke: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">refine_topic</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;topic&quot;</span>: state[<span class="string">&quot;topic&quot;</span>] + <span class="string">&quot; and cats&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_joke</span>(<span class="params">state: State</span>):</span><br><span class="line">    llm_response = llm.invoke(</span><br><span class="line">        [</span><br><span class="line">            &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">f&quot;Generate a joke about <span class="subst">&#123;state[<span class="string">&#x27;topic&#x27;</span>]&#125;</span>&quot;</span>&#125;</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;joke&quot;</span>: llm_response.content&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph = (</span><br><span class="line">    StateGraph(State)</span><br><span class="line">    .add_node(refine_topic)</span><br><span class="line">    .add_node(generate_joke)</span><br><span class="line">    .add_edge(START, <span class="string">&quot;refine_topic&quot;</span>)</span><br><span class="line">    .add_edge(<span class="string">&quot;refine_topic&quot;</span>, <span class="string">&quot;generate_joke&quot;</span>)</span><br><span class="line">    .<span class="built_in">compile</span>()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> message_chunk, metadata <span class="keyword">in</span> graph.stream(</span><br><span class="line">    &#123;<span class="string">&quot;topic&quot;</span>: <span class="string">&quot;ice cream&quot;</span>&#125;,</span><br><span class="line">    stream_mode=<span class="string">&quot;messages&quot;</span>,</span><br><span class="line">):</span><br><span class="line">    <span class="keyword">if</span> message_chunk.content:</span><br><span class="line">        <span class="built_in">print</span>(message_chunk.content, end=<span class="string">&quot;|&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;metadata: <span class="subst">&#123;metadata&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Why| did| the| cat choose the ice| cream over the fish|?</span><br><span class="line"></span><br><span class="line">Because the ice| cream was purr|-fectly chilled|!|</span><br><span class="line"></span><br><span class="line">metadata: </span><br><span class="line">&#123;<span class="string">&#x27;langgraph_step&#x27;</span>: <span class="number">2</span>,</span><br><span class="line"> <span class="string">&#x27;langgraph_node&#x27;</span>: <span class="string">&#x27;generate_joke&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;langgraph_triggers&#x27;</span>: [<span class="string">&#x27;refine_topic&#x27;</span>],</span><br><span class="line"> <span class="string">&#x27;langgraph_path&#x27;</span>: (<span class="string">&#x27;__pregel_pull&#x27;</span>, <span class="string">&#x27;generate_joke&#x27;</span>), </span><br><span class="line"> <span class="string">&#x27;langgraph_checkpoint_ns&#x27;</span>: <span class="string">&#x27;generate_joke:4a4e35fb-1c05-53cf-2898-e23e9d2784ad&#x27;</span>, 	  <span class="string">&#x27;checkpoint_ns&#x27;</span>: <span class="string">&#x27;generate_joke:4a4e35fb-1c05-53cf-2898-e23e9d2784ad&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;ls_provider&#x27;</span>: <span class="string">&#x27;openai&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;ls_model_name&#x27;</span>: <span class="string">&#x27;qwen2.5-7b-instruct&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;ls_model_type&#x27;</span>: <span class="string">&#x27;chat&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;ls_temperature&#x27;</span>: <span class="number">0.7</span>&#125;</span><br></pre></td></tr></table></figure>

<p><strong>(1) <code>langgraph_step: 2</code></strong></p>
<ul>
<li>当前执行的步骤编号。</li>
<li>这里是 <code>2</code>，表示 <code>generate_joke</code> 是 <strong>图执行的第二步</strong>（第一步是 <code>refine_topic</code>）。</li>
</ul>
<p><strong>(2) <code>langgraph_node: &#39;generate_joke&#39;</code></strong></p>
<ul>
<li>当前正在执行的 <strong>节点名称</strong>。</li>
<li>这里是 <code>&quot;generate_joke&quot;</code>，表示代码正在执行 <code>generate_joke</code> 这个节点。</li>
</ul>
<p><strong>(3) <code>langgraph_triggers: [&#39;refine_topic&#39;]</code></strong></p>
<ul>
<li><strong>触发当前节点的前序节点</strong>，即 <code>generate_joke</code> 是由哪些节点的执行结果触发的。</li>
<li>这里是 <code>[&#39;refine_topic&#39;]</code>，表示 <code>generate_joke</code> 是 <strong><code>refine_topic</code> 计算完成后触发的</strong>。</li>
</ul>
<p><strong>(4) <code>langgraph_path: (&#39;__pregel_pull&#39;, &#39;generate_joke&#39;)</code></strong></p>
<ul>
<li>记录 <strong>执行路径</strong>，表示 <code>generate_joke</code> 是如何被调用的。</li>
<li><code>__pregel_pull</code> 可能是 <code>langgraph</code> 内部用于数据拉取的机制。</li>
</ul>
<p><strong>(5) <code>langgraph_checkpoint_ns: &#39;generate_joke:4a4e35fb-1c05-53cf-2898-e23e9d2784ad&#39;</code></strong></p>
<ul>
<li><code>checkpoint_ns</code>（命名空间）用于 <strong>存储和恢复计算状态</strong>，确保在系统崩溃或中断时可以继续执行。</li>
<li><code>4a4e35fb-1c05-53cf-2898-e23e9d2784ad</code> 是一个 <strong>唯一的 UUID</strong>，用于标识这个 checkpoint。</li>
</ul>
<p><strong>(6) <code>checkpoint_ns: &#39;generate_joke:4a4e35fb-1c05-53cf-2898-e23e9d2784ad&#39;</code></strong></p>
<ul>
<li>和 <code>langgraph_checkpoint_ns</code> 一样，表示该节点的 <strong>计算状态可以被存储和恢复</strong>，用于 <code>langgraph</code> 的 checkpoint 机制。</li>
</ul>
<p><strong>(7) <code>ls_provider: &#39;openai&#39;</code></strong></p>
<ul>
<li><strong>Language Service 提供商</strong>，这里是 <code>openai</code>，表示调用的 LLM 是 OpenAI 系的模型。</li>
</ul>
<p><strong>(8) <code>ls_model_name: &#39;qwen2.5-7b-instruct&#39;</code></strong></p>
<ul>
<li><strong>使用的语言模型名称</strong>，这里是 <code>qwen2.5-7b-instruct</code>（通义千问 2.5-7B 指导模型）。</li>
<li>说明 <code>generate_joke</code> 这个节点使用了 <strong><code>qwen2.5-7b-instruct</code></strong> 来生成笑话。</li>
</ul>
<p><strong>(9) <code>ls_model_type: &#39;chat&#39;</code></strong></p>
<ul>
<li><strong>模型类型</strong>，这里是 <code>chat</code>，表示使用的是 <strong>对话模型</strong>（如 ChatGPT 这种）。</li>
</ul>
<p><strong>(10) <code>ls_temperature: 0.7</code></strong></p>
<ul>
<li>LLM 生成文本的温度参数：<ul>
<li>0.0 → <strong>最确定性</strong>（生成最可能的文本）</li>
<li>1.0 → <strong>最随机</strong>（生成更有创意的文本）</li>
<li>这里 <code>0.7</code> 代表 <strong>平衡创造性和确定性</strong>，适合生成带点随机性的笑话。</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th><strong>字段</strong></th>
<th><strong>含义</strong></th>
</tr>
</thead>
<tbody><tr>
<td><code>langgraph_step</code></td>
<td>当前执行的步骤编号（第几步）</td>
</tr>
<tr>
<td><code>langgraph_node</code></td>
<td>当前执行的节点名称</td>
</tr>
<tr>
<td><code>langgraph_triggers</code></td>
<td>触发此节点的前序节点</td>
</tr>
<tr>
<td><code>langgraph_path</code></td>
<td>计算的执行路径</td>
</tr>
<tr>
<td><code>langgraph_checkpoint_ns</code></td>
<td>计算的 Checkpoint 存储标识</td>
</tr>
<tr>
<td><code>checkpoint_ns</code></td>
<td>与 <code>langgraph_checkpoint_ns</code> 类似，确保状态可恢复</td>
</tr>
<tr>
<td><code>ls_provider</code></td>
<td>语言模型提供商（如 OpenAI）</td>
</tr>
<tr>
<td><code>ls_model_name</code></td>
<td>具体使用的 LLM 名称（如 <code>qwen2.5-7b-instruct</code>）</td>
</tr>
<tr>
<td><code>ls_model_type</code></td>
<td>LLM 的类别（如 <code>chat</code>）</td>
</tr>
<tr>
<td><code>ls_temperature</code></td>
<td>LLM 生成内容的随机性（0.0&#x3D;确定性，1.0&#x3D;高随机性）</td>
</tr>
</tbody></table>
<p>这个 <code>metadata</code> 主要是 <strong>用于跟踪 <code>langgraph</code> 的执行过程和 LLM 推理信息</strong>，在 <strong>调试、日志记录、故障恢复</strong> 时非常有用。</p>
<hr>
<h3 id="六、流式传输自定义数据（stream-mode-”custom”）"><a href="#六、流式传输自定义数据（stream-mode-”custom”）" class="headerlink" title="六、流式传输自定义数据（stream_mode&#x3D;”custom”）"></a>六、流式传输自定义数据（stream_mode&#x3D;”custom”）</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> TypedDict</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START</span><br><span class="line"><span class="keyword">from</span> langgraph.types <span class="keyword">import</span> StreamWriter</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    topic: <span class="built_in">str</span></span><br><span class="line">    joke: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">refine_topic</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;topic&quot;</span>: state[<span class="string">&quot;topic&quot;</span>] + <span class="string">&quot; and cats&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_joke</span>(<span class="params">state: State, writer: StreamWriter</span>):</span><br><span class="line">    writer(&#123;<span class="string">&quot;custom_key&quot;</span>: <span class="string">&quot;Writing custom data while generating a joke&quot;</span>&#125;)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;joke&quot;</span>: <span class="string">f&quot;This is a joke about <span class="subst">&#123;state[<span class="string">&#x27;topic&#x27;</span>]&#125;</span>&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph = (</span><br><span class="line">    StateGraph(State)</span><br><span class="line">    .add_node(refine_topic)</span><br><span class="line">    .add_node(generate_joke)</span><br><span class="line">    .add_edge(START, <span class="string">&quot;refine_topic&quot;</span>)</span><br><span class="line">    .add_edge(<span class="string">&quot;refine_topic&quot;</span>, <span class="string">&quot;generate_joke&quot;</span>)</span><br><span class="line">    .<span class="built_in">compile</span>()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> graph.stream(</span><br><span class="line">    &#123;<span class="string">&quot;topic&quot;</span>: <span class="string">&quot;ice cream&quot;</span>&#125;,</span><br><span class="line">    stream_mode=<span class="string">&quot;custom&quot;</span>,</span><br><span class="line">):</span><br><span class="line">    <span class="built_in">print</span>(chunk)</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;custom_key&#x27;</span>: <span class="string">&#x27;Writing custom data while generating a joke&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>

<p>满脸问号？这是什么？有什么用？🤓（过几天再补）</p>
<hr>
<h3 id="七、配置多种流模式"><a href="#七、配置多种流模式" class="headerlink" title="七、配置多种流模式"></a>七、配置多种流模式</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> TypedDict</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START</span><br><span class="line"><span class="keyword">from</span> langgraph.types <span class="keyword">import</span> StreamWriter</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    topic: <span class="built_in">str</span></span><br><span class="line">    joke: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">refine_topic</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;topic&quot;</span>: state[<span class="string">&quot;topic&quot;</span>] + <span class="string">&quot; and cats&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_joke</span>(<span class="params">state: State, writer: StreamWriter</span>):</span><br><span class="line">    writer(&#123;<span class="string">&quot;custom_key&quot;</span>: <span class="string">&quot;Writing custom data while generating a joke&quot;</span>&#125;)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;joke&quot;</span>: <span class="string">f&quot;This is a joke about <span class="subst">&#123;state[<span class="string">&#x27;topic&#x27;</span>]&#125;</span>&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph = (</span><br><span class="line">    StateGraph(State)</span><br><span class="line">    .add_node(refine_topic)</span><br><span class="line">    .add_node(generate_joke)</span><br><span class="line">    .add_edge(START, <span class="string">&quot;refine_topic&quot;</span>)</span><br><span class="line">    .add_edge(<span class="string">&quot;refine_topic&quot;</span>, <span class="string">&quot;generate_joke&quot;</span>)</span><br><span class="line">    .<span class="built_in">compile</span>()</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> stream_mode, chunk <span class="keyword">in</span> graph.stream(</span><br><span class="line">    &#123;<span class="string">&quot;topic&quot;</span>: <span class="string">&quot;ice cream&quot;</span>&#125;,</span><br><span class="line">    stream_mode=[<span class="string">&quot;updates&quot;</span>, <span class="string">&quot;custom&quot;</span>],</span><br><span class="line">):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Stream mode: <span class="subst">&#123;stream_mode&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(chunk,end=<span class="string">&quot;|&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Stream mode: updates</span><br><span class="line">&#123;<span class="string">&#x27;refine_topic&#x27;</span>: &#123;<span class="string">&#x27;topic&#x27;</span>: <span class="string">&#x27;ice cream and cats&#x27;</span>&#125;&#125;|</span><br><span class="line"></span><br><span class="line">Stream mode: custom</span><br><span class="line">&#123;<span class="string">&#x27;custom_key&#x27;</span>: <span class="string">&#x27;Writing custom data while generating a joke&#x27;</span>&#125;|</span><br><span class="line"></span><br><span class="line">Stream mode: updates</span><br><span class="line">&#123;<span class="string">&#x27;generate_joke&#x27;</span>: &#123;<span class="string">&#x27;joke&#x27;</span>: <span class="string">&#x27;This is a joke about ice cream and cats&#x27;</span>&#125;&#125;|</span><br></pre></td></tr></table></figure>

<p>不明所以，到底有什么用啊？</p>
<hr>
<h2 id="✨附录：流式传输LLM-tokens扩展"><a href="#✨附录：流式传输LLM-tokens扩展" class="headerlink" title="✨附录：流式传输LLM tokens扩展"></a>✨附录：流式传输LLM tokens扩展</h2><p>正式给示例前，先给出一套流式传输LLM tokens的模板：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"></span><br><span class="line">model = ChatOpenAI()</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">call_model</span>(<span class="params">state: State</span>):</span><br><span class="line">    model.invoke(...)</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">graph = (</span><br><span class="line">    StateGraph(State)</span><br><span class="line">    .add_node(call_model)</span><br><span class="line">    ...</span><br><span class="line">    .<span class="built_in">compile</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> msg, metadata <span class="keyword">in</span> graph.stream(inputs, stream_mode=<span class="string">&quot;messages&quot;</span>):</span><br><span class="line">    <span class="built_in">print</span>(msg)</span><br></pre></td></tr></table></figure>

<p>流式输出的元组为（message chunk, metadata）:</p>
<ul>
<li>message chunk是LLM流式传输的tokens</li>
<li>metadata是一个字典，其中包含有关调用LLM的节点以及LLM调用元数据的信息</li>
</ul>
<p><strong>好的，让我们开始吧：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/#example&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> TypedDict</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> START, StateGraph, MessagesState</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置大模型参数</span></span><br><span class="line">LLM_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;sk-xxxxxxxxx&quot;</span>,</span><br><span class="line">    <span class="string">&quot;base_url&quot;</span>: <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen2.5-7b-instruct&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化大模型</span></span><br><span class="line">joke_model = ChatOpenAI(</span><br><span class="line">    model=LLM_CONFIG[<span class="string">&quot;model&quot;</span>],</span><br><span class="line">    openai_api_key=LLM_CONFIG[<span class="string">&quot;api_key&quot;</span>],</span><br><span class="line">    openai_api_base=LLM_CONFIG[<span class="string">&quot;base_url&quot;</span>],</span><br><span class="line">    streaming=<span class="literal">True</span>,</span><br><span class="line">    tags=[<span class="string">&quot;joke&quot;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">poem_model = ChatOpenAI(</span><br><span class="line">    model=LLM_CONFIG[<span class="string">&quot;model&quot;</span>],</span><br><span class="line">    openai_api_key=LLM_CONFIG[<span class="string">&quot;api_key&quot;</span>],</span><br><span class="line">    openai_api_base=LLM_CONFIG[<span class="string">&quot;base_url&quot;</span>],</span><br><span class="line">    streaming=<span class="literal">True</span>,</span><br><span class="line">    tags=[<span class="string">&quot;poem&quot;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    topic: <span class="built_in">str</span></span><br><span class="line">    joke: <span class="built_in">str</span></span><br><span class="line">    poem: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">call_model</span>(<span class="params">state, config</span>):</span><br><span class="line">    topic = state[<span class="string">&quot;topic&quot;</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Writing joke...&quot;</span>)</span><br><span class="line">    <span class="comment"># Note: Passing the config through explicitly is required for python &lt; 3.11</span></span><br><span class="line">    <span class="comment"># Since context var support wasn&#x27;t added before then: https://docs.python.org/3/library/asyncio-task.html#creating-tasks</span></span><br><span class="line">    joke_response = <span class="keyword">await</span> joke_model.ainvoke(</span><br><span class="line">        [&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">f&quot;Write a joke about <span class="subst">&#123;topic&#125;</span>&quot;</span>&#125;],</span><br><span class="line">        config,</span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n\nWriting poem...&quot;</span>)</span><br><span class="line">    poem_response = <span class="keyword">await</span> poem_model.ainvoke(</span><br><span class="line">        [&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">f&quot;Write a short poem about <span class="subst">&#123;topic&#125;</span>&quot;</span>&#125;],</span><br><span class="line">        config,</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;joke&quot;</span>: joke_response.content, <span class="string">&quot;poem&quot;</span>: poem_response.content&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph = StateGraph(State).add_node(call_model).add_edge(START, <span class="string">&quot;call_model&quot;</span>).<span class="built_in">compile</span>()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">for</span> msg, metadata <span class="keyword">in</span> graph.astream(</span><br><span class="line">            &#123;<span class="string">&quot;topic&quot;</span>: <span class="string">&quot;cats&quot;</span>&#125;,</span><br><span class="line">            stream_mode=<span class="string">&quot;messages&quot;</span>,</span><br><span class="line">    ):</span><br><span class="line">        <span class="keyword">if</span> msg.content:</span><br><span class="line">            <span class="built_in">print</span>(msg.content, end=<span class="string">&quot;|&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    asyncio.run(main())</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Writing joke...</span><br><span class="line">Why| don|&#x27;t| cats play poker in| the jungle? Because| there are too many| cheetahs|!|</span><br><span class="line"></span><br><span class="line">Writing poem...</span><br><span class="line">Wh|isk|ered| wonders, soft and| fine,</span><br><span class="line">In shadows| they take their time|.</span><br><span class="line">With silent p|aws and gentle pur|rs,</span><br><span class="line">They rule| the night with quiet| powers.</span><br><span class="line"></span><br><span class="line">Eyes| like embers in| the dark,</span><br><span class="line">Where|ver they go,| light does mark.</span><br><span class="line">|A flick of tail|, a gentle nap|,</span><br><span class="line">In dreams they| chase the little map|.</span><br><span class="line"></span><br><span class="line">Mice and| feathers, toys and| play,</span><br><span class="line">Yet when| the day begins to| sway,</span><br><span class="line">They find| a cozy spot to| rest,</span><br><span class="line">Guarding| dreams with silent jest|.</span><br><span class="line"></span><br><span class="line">So let them| roam, let them| explore,</span><br><span class="line">In every| home, they bring| much more.</span><br><span class="line">For| in their grace,| we find our peace|,</span><br><span class="line">And in their| eyes, a world| of ceaseless peace|.|</span><br></pre></td></tr></table></figure>

<p><strong>注意：</strong></p>
<ul>
<li><code>ainvoke(...)</code> 由于 <code>streaming=True</code>，不会等到<strong>整个</strong>笑话生成完才返回，而是<strong>逐步返回 token</strong></li>
<li><code>graph.astream()</code> 负责<strong>逐步接收</strong> <code>ainvoke(...)</code> 返回的数据</li>
<li>每当 <code>ainvoke(...)</code> 生成新 token，<code>astream()</code> 就会<strong>读取并输出</strong>它</li>
<li>流式输出并不依赖 <code>return</code> 语句</li>
<li><code>return</code> 只是在 <code>call_model()</code> 结束时返回最终完整的 <code>State</code>，但 <code>astream()</code> 在此之前已经接收了 <code>ainvoke(...)</code> 的流式输出</li>
</ul>
<p><strong>执行顺序总结：</strong></p>
<ol>
<li><p><code>&quot;Writing joke...&quot;</code> 立即打印。</p>
</li>
<li><p><code>joke_model.ainvoke(...)</code>流式返回，<code>graph.astream()逐步打印：</code></p>
<figure class="highlight coq"><table><tr><td class="code"><pre><span class="line">Why| <span class="type">did</span>| <span class="type">the</span>| <span class="type">cat</span> join the book| <span class="type">club</span>?</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>joke_model.ainvoke(...)</code> 结束，<code>print(&quot;\n\nWriting poem...&quot;)</code> 执行。</p>
</li>
<li><p><code>poem_model.ainvoke(...)</code>流式返回，<code>graph.astream()</code>逐步打印：</p>
<figure class="highlight coq"><table><tr><td class="code"><pre><span class="line">Wh|<span class="type">isk</span>|<span class="type">ered</span>| <span class="type">dancers</span>, silent and| <span class="type">sleek</span>,</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>poem_model.ainvoke(...)</code> 结束，<code>return &#123;&quot;joke&quot;: ..., &quot;poem&quot;: ...&#125;</code> 执行，完整 <code>State</code> 结果返回。</p>
</li>
</ol>
<p>好的，我们可以看到，现在是从所有LLM调用中流式传输tokens，现在如果我们<strong>只想流式传输特定LLM调用的tokens</strong>，该怎么做呢？—&gt;使用流式传输的元数据（metadata）以及之前添加在LLM中的标签（tags）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">for</span> msg, metadata <span class="keyword">in</span> graph.astream(</span><br><span class="line">    &#123;<span class="string">&quot;topic&quot;</span>: <span class="string">&quot;cats&quot;</span>&#125;,</span><br><span class="line">    stream_mode=<span class="string">&quot;messages&quot;</span>,</span><br><span class="line">):</span><br><span class="line">    <span class="keyword">if</span> msg.content <span class="keyword">and</span> <span class="string">&quot;joke&quot;</span> <span class="keyword">in</span> metadata.get(<span class="string">&quot;tags&quot;</span>, []):</span><br><span class="line">        <span class="built_in">print</span>(msg.content, end=<span class="string">&quot;|&quot;</span>, flush=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Writing joke...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Writing poem...</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>🤺说好的过滤掉指定LLM调用呢？这都过滤掉了？打印metadata发现其中并不包含tags标签，emmmm好吧留个坑，用到时候再深究吧。</p>
<p><strong>那如果不使用langchain&#x2F;Langgraph实现相同的功能，怎么做？</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> TypedDict</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langgraph.constants <span class="keyword">import</span> START</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph</span><br><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> AsyncOpenAI</span><br><span class="line"></span><br><span class="line">LLM_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;sk-******************&quot;</span>,</span><br><span class="line">    <span class="string">&quot;base_url&quot;</span>: <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen2.5-7b-instruct&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">openai_client = AsyncOpenAI(</span><br><span class="line">    api_key=LLM_CONFIG[<span class="string">&quot;api_key&quot;</span>],</span><br><span class="line">    base_url=LLM_CONFIG[<span class="string">&quot;base_url&quot;</span>],</span><br><span class="line">)</span><br><span class="line">model_name = LLM_CONFIG[<span class="string">&quot;model&quot;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    topic: <span class="built_in">str</span></span><br><span class="line">    joke: <span class="built_in">str</span></span><br><span class="line">    poem: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">stream_tokens</span>(<span class="params">model_name: <span class="built_in">str</span>, messages: <span class="built_in">list</span>[<span class="built_in">dict</span>]</span>):</span><br><span class="line">    response = <span class="keyword">await</span> openai_client.chat.completions.create(</span><br><span class="line">        messages=messages, model=model_name, stream=<span class="literal">True</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    role = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">for</span> chunk <span class="keyword">in</span> response:</span><br><span class="line">        delta = chunk.choices[<span class="number">0</span>].delta</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> delta.role <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            role = delta.role</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> delta.content:</span><br><span class="line">            <span class="keyword">yield</span> &#123;<span class="string">&quot;role&quot;</span>: role, <span class="string">&quot;content&quot;</span>: delta.content&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">call_model</span>(<span class="params">state, config, writer</span>):</span><br><span class="line">    topic = state[<span class="string">&quot;topic&quot;</span>]</span><br><span class="line">    joke = <span class="string">&quot;&quot;</span></span><br><span class="line">    poem = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Writing joke...&quot;</span>)</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">for</span> msg_chunk <span class="keyword">in</span> stream_tokens(</span><br><span class="line">        model_name, [&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">f&quot;Write a joke about <span class="subst">&#123;topic&#125;</span>&quot;</span>&#125;]</span><br><span class="line">    ):</span><br><span class="line">        joke += msg_chunk[<span class="string">&quot;content&quot;</span>]</span><br><span class="line">        metadata = &#123;**config[<span class="string">&quot;metadata&quot;</span>], <span class="string">&quot;tags&quot;</span>: [<span class="string">&quot;joke&quot;</span>]&#125;</span><br><span class="line">        chunk_to_stream = (msg_chunk, metadata)</span><br><span class="line">        writer(chunk_to_stream)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n\nWriting poem...&quot;</span>)</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">for</span> msg_chunk <span class="keyword">in</span> stream_tokens(</span><br><span class="line">        model_name, [&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">f&quot;Write a short poem about <span class="subst">&#123;topic&#125;</span>&quot;</span>&#125;]</span><br><span class="line">    ):</span><br><span class="line">        poem += msg_chunk[<span class="string">&quot;content&quot;</span>]</span><br><span class="line">        metadata = &#123;**config[<span class="string">&quot;metadata&quot;</span>], <span class="string">&quot;tags&quot;</span>: [<span class="string">&quot;poem&quot;</span>]&#125;</span><br><span class="line">        chunk_to_stream = (msg_chunk, metadata)</span><br><span class="line">        writer(chunk_to_stream)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;joke&quot;</span>: joke, <span class="string">&quot;poem&quot;</span>: poem&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph = StateGraph(State).add_node(call_model).add_edge(START, <span class="string">&quot;call_model&quot;</span>).<span class="built_in">compile</span>()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">for</span> msg, metadata <span class="keyword">in</span> graph.astream(</span><br><span class="line">            &#123;<span class="string">&quot;topic&quot;</span>: <span class="string">&quot;cats&quot;</span>&#125;,</span><br><span class="line">            stream_mode=<span class="string">&quot;custom&quot;</span>,</span><br><span class="line">    ):</span><br><span class="line">        <span class="built_in">print</span>(msg[<span class="string">&quot;content&quot;</span>], end=<span class="string">&quot;|&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;metadata=<span class="subst">&#123;metadata&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    asyncio.run(main())</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Writing joke...</span><br><span class="line">Why| don|<span class="string">&#x27;t| cats play poker in| the jungle? Too| many cheetah|s!|</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Writing poem...</span></span><br><span class="line"><span class="string">Wh|isk|ered| nobles of the| night,</span></span><br><span class="line"><span class="string">Silent| paws on velvet| light.</span></span><br><span class="line"><span class="string">Eyes| that gleam like| stars above,</span></span><br><span class="line"><span class="string">M|ajestic, in| the moon&#x27;</span>s soft| glove.</span><br><span class="line"></span><br><span class="line">Soft fur| whispers <span class="keyword">with</span> each step|,</span><br><span class="line">A mystery wrapped| <span class="keyword">in</span> a napkin|-wrapped keep.</span><br><span class="line">|In shadows, they| weave <span class="keyword">and</span> play,</span><br><span class="line">|Guardians of dreams|, come what may|.</span><br><span class="line"></span><br><span class="line">With a flick| of tail so grand|,</span><br><span class="line">They rule their| realm, without a| band.</span><br><span class="line">Cats|, <span class="keyword">in</span> their own| regal way,</span><br><span class="line">|Are the lords of| every fray.|</span><br><span class="line"></span><br><span class="line">metadata=&#123;<span class="string">&#x27;langgraph_step&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">          <span class="string">&#x27;langgraph_node&#x27;</span>: <span class="string">&#x27;call_model&#x27;</span>,</span><br><span class="line">          <span class="string">&#x27;langgraph_triggers&#x27;</span>: [<span class="string">&#x27;start:call_model&#x27;</span>],</span><br><span class="line">          <span class="string">&#x27;langgraph_path&#x27;</span>: (<span class="string">&#x27;__pregel_pull&#x27;</span>, <span class="string">&#x27;call_model&#x27;</span>),</span><br><span class="line">          <span class="string">&#x27;langgraph_checkpoint_ns&#x27;</span>: <span class="string">&#x27;call_model:317202cd-c031-a780-9998-423c3ae28e18&#x27;</span>, </span><br><span class="line">          <span class="string">&#x27;tags&#x27;</span>: [<span class="string">&#x27;poem&#x27;</span>]&#125;</span><br></pre></td></tr></table></figure>

<p>嘿，这里有tags，那么如果想过滤特定的LLM调用，怎么做呢：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">for</span> msg, metadata <span class="keyword">in</span> graph.astream(</span><br><span class="line">            &#123;<span class="string">&quot;topic&quot;</span>: <span class="string">&quot;cats&quot;</span>&#125;,</span><br><span class="line">            stream_mode=<span class="string">&quot;custom&quot;</span>,</span><br><span class="line">    ):</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&quot;poem&quot;</span> <span class="keyword">in</span> metadata.get(<span class="string">&quot;tags&quot;</span>, []):</span><br><span class="line">            <span class="built_in">print</span>(msg[<span class="string">&quot;content&quot;</span>], end=<span class="string">&quot;|&quot;</span>, flush=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Writing joke...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Writing poem...</span><br><span class="line">Wh|isk|ered| whispers <span class="keyword">in</span> the night|,</span><br><span class="line">Silent shadows|, soft <span class="keyword">and</span> light|.</span><br><span class="line">Paws pad| on the carpeted| floor,</span><br><span class="line">Myst|ical eyes, a| gentle roar.</span><br><span class="line"></span><br><span class="line">F|ur <span class="keyword">as</span> night,| <span class="keyword">with</span> stars aglow|,</span><br><span class="line">Tail flicks|, a secret they| bestow.</span><br><span class="line">In| their gaze, mysteries| lie,</span><br><span class="line">Cats|, the poets of| the sky.</span><br><span class="line"></span><br><span class="line">With| a purr so| deep <span class="keyword">and</span> true,</span><br><span class="line">|They mend the soul|, make it new|.</span><br><span class="line">Guardians of| the quiet peace,</span><br><span class="line">|Cats, <span class="keyword">in</span>| their own graceful cease|.</span><br></pre></td></tr></table></figure>

<p>对味了😁。</p>
<hr>
<p>这里给的简单的流式输出示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> openai</span><br><span class="line"></span><br><span class="line">openai.api_key = <span class="string">&quot;YOUR_API_KEY&quot;</span>  <span class="comment"># 替换为你的API密钥</span></span><br><span class="line"></span><br><span class="line">response = openai.ChatCompletion.create(</span><br><span class="line">    model=<span class="string">&quot;gpt-3.5-turbo&quot;</span>,</span><br><span class="line">    messages=[&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;请用中文写一个简短的励志句子&quot;</span>&#125;],</span><br><span class="line">    stream=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> response:</span><br><span class="line">    content = chunk.choices[<span class="number">0</span>].delta.get(<span class="string">&quot;content&quot;</span>, <span class="string">&quot;&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(content, end=<span class="string">&#x27;&#x27;</span>, flush=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://langchain-ai.github.io/langgraph/how-tos/streaming/">https://langchain-ai.github.io/langgraph/how-tos/streaming/</a></li>
<li><a href="https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/#example">https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/#example</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>llm</tag>
        <tag>langgraph</tag>
        <tag>langchain</tag>
        <tag>agent</tag>
      </tags>
  </entry>
  <entry>
    <title>MCP基础：从原理到实战</title>
    <url>/2025/06/09/MCP%E5%9F%BA%E7%A1%80%EF%BC%9A%E4%BB%8E%E5%8E%9F%E7%90%86%E5%88%B0%E5%AE%9E%E6%88%98/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>久仰MCP大名已久，最近没写Agent，故也没去了解MCP，今天暂时空下来了，看看这MCP到底是何方神圣，本文是我从<code>Youtube</code>上搜到的一个感觉还不错的教程，来自马克的技术工坊，链接见参考链接1，在B站搜了下，发现博主在B站也有账号，见参考链接2，下面我们一起看下大佬的讲解吧。</p>
<span id="more"></span>

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="简要解释"><a href="#简要解释" class="headerlink" title="简要解释"></a>简要解释</h3><p>MCP(Model Context Protocol，模型上下文协议)，是Anthropic公司在2024年11月25号发布的一个协议，不用管这个故弄玄虚的名字，简单来说，MCP就是能让LLM更好的使用各类工具的一个协议，比如说借助MCP可以让LLM使用浏览器上网查询信息，可以让模型操作Unity编写游戏，也可以让LLM查询实时路况。是不是有点心动呢，别着急，在使用MCP之前还需要了解另一个东西：MCP Host，不用管它这个名字是啥，本质上就是一个支持MCP协议的软件，常见的包括：Cloud Desktop、Cursor、Cline、Cherry Studio等。相信大家即使没用过至少也听说过部分。下文将以Cline为例讲解MCP的使用方法。</p>
<h3 id="安装和简单使用MCP-Host-Cline"><a href="#安装和简单使用MCP-Host-Cline" class="headerlink" title="安装和简单使用MCP Host(Cline)"></a>安装和简单使用MCP Host(Cline)</h3><p>Cline其实是VS Code中的一个插件，直接在扩展中搜索安装即可。然后配置你的<code>API key</code>，这里我是用Deepseek，选择deepseek-chat代表V3模型，我不使用<code>use different models for plan and act modes</code>，填好之后选择<code>Save</code>，现在就可以使用<code>Cline</code>了，我们给它打个招呼，模型能正常回复就基本没问题了。</p>
<blockquote>
<p>如遇到<code>Save</code>按钮为灰色，请在<code>Custom Instructions</code>里面写任意内容再删掉，建议在里面写上：请用中文回复。</p>
</blockquote>
<h3 id="第一个MCP问题"><a href="#第一个MCP问题" class="headerlink" title="第一个MCP问题"></a>第一个MCP问题</h3><p>现在我们真正问它一个真正的问题：<code>明天纽约的天气怎么样？</code></p>


<p>这里它提到了<code>MCP</code>服务器，那么<code>MCP</code>服务器是什么呢？</p>
<h3 id="MCP-Server-和-Tool"><a href="#MCP-Server-和-Tool" class="headerlink" title="MCP Server 和 Tool"></a>MCP Server 和 Tool</h3><p><code>MCP</code>服务器的英文原名是<code>MCP Server</code> ，听起来有点高大上，而且貌似和我们传统网络协议里面的Server有点联系，似乎是一个远程的服务器，需要联网才能使用，比如我们打开<code>Google</code>的首页，就是访问了<code>Google</code>的服务器，不过实际上，<code>MCP Server</code>跟我们传统意义上的<code>Server</code>并没有太大关系，它就是一个程序而已，只不过这个程序的执行是符合<code>MCP</code>协议的，比如大部分的<code>MCP Server</code>都是本地通过<code>Node</code>或者<code>Python</code>启动的，在使用过程中可能联网也有可能纯本地使用（不联网），不管联不联网，它都可以叫做<code>MCP Server</code>，所以这个名字里面的<code>Server</code>有一定的误导性，它就是一个程序，只是内置了一些功能模块，这些模块在<code>MCP</code>领域的专业名词叫做<code>Tool</code>，翻译成中文是工具，对编程的人来说，工具就是函数。</p>
<h3 id="配置MCP-Server"><a href="#配置MCP-Server" class="headerlink" title="配置MCP Server"></a>配置MCP Server</h3>

<p>我们明白了<code>MCP Server</code>和<code>Tool</code>的关系，下面我们来实际配置一个<code>MCP Server</code>，上文的两种图，第一张图，<code>Cline</code>生成命令行参数来安装<code>天气MCP服务器</code>，第二张图将会在你提供<code>API秘钥</code>后创建<code>天气MCP服务器</code>，还有两种方法，第三种，点击红色箭头后会出现下图，点击<code>Install</code>后即可安装，这里的每个仓库都对应着一个<code>Github仓库</code>，模型就是靠参考<code>Github仓库</code>说明文档中的安装过程进行安装的：</p>
.png)

<p>注意上述三种（或者说两种，前两种是一类）安装方式都是模型主导的，比较依赖模型的能力，我们还是喜欢确定性的东西，而且虽然<code>Cline</code>支持第三种自动安装的方式，有些<code>MCP Host</code>是不支持的，那么就有第四种安装方式：</p>
.png)

<p>与<code>Marketplace</code>的同级页面，点击<code>Installed</code>，再点击下方的<code>Configure MCP Servers</code>，右方就会创建一个空白的<code>Cline_mcp_settings.json</code>。</p>
<h4 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h4><p>运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda create -n mcp python=3.13</span><br><span class="line">conda activate mcp </span><br><span class="line"></span><br><span class="line">curl -LsSf https://astral.sh/uv/install.sh | sh</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;source $HOME/.local/bin/env&#x27;</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br><span class="line"></span><br><span class="line">uv --version  <span class="comment"># uv 0.7.12</span></span><br></pre></td></tr></table></figure>

<p>点击<a href="https://github.com/MarkTechStation/VideoCode/tree/main/MCP%E7%BB%88%E6%9E%81%E6%8C%87%E5%8D%97-%E8%BF%9B%E9%98%B6%E7%AF%87/weather">这里</a>，将<code>pyproject.toml</code>和<code>weather.py</code>复制到<code>/home/chr/mcp_files/weather</code>下，将下面代码替换掉<code>cline_mcp_setting.json</code>的内容：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;mcpServers&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;weather&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;timeout&quot;</span><span class="punctuation">:</span> <span class="number">60</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;command&quot;</span><span class="punctuation">:</span> <span class="string">&quot;uv&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="string">&quot;--directory&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;/home/chr/mcp_files/weather&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;run&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;weather.py&quot;</span></span><br><span class="line">      <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;transportType&quot;</span><span class="punctuation">:</span> <span class="string">&quot;stdio&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>即可在<code>Installed</code>中看到<code>weather</code>：</p>
.png)

<hr>
<h3 id="再试一次"><a href="#再试一次" class="headerlink" title="再试一次"></a>再试一次</h3><p>现在再去问相同的问题：</p>


<p>会先出现经纬度，让你确认，确认之后就会回答你具体内容：</p>


<hr>
<h3 id="MCP-交互流程详解"><a href="#MCP-交互流程详解" class="headerlink" title="MCP 交互流程详解"></a>MCP 交互流程详解</h3><ul>
<li>配置<code>cline_mcp_setting.json</code>并保存-&gt;启动<code>MCP Server</code>(<code>Cline-&gt;MCP Server</code>)</li>
<li>你好，我是<code>Cline</code>(<code>Cline-&gt;MCP Server</code>)</li>
<li>你好，我是<code>weather</code>(<code>MCP Server-&gt;Cline</code>）</li>
<li>你有啥工具呀(<code>Cline-&gt;MCP Server</code>)</li>
<li>我有<code>get_forecast</code>和<code>get_alerts</code>(<code>MCP Server-&gt;Cline</code>）</li>
<li>纽约明天的天气怎么样？(<code>用户-&gt;Cline</code>）</li>
<li>纽约明天的天气怎么样？(我有一些工具，分别是…)(<code>Cline-&gt;LLM</code>）</li>
<li>我要调用<code>get_forecast</code>，参数是…（<code>LLM-&gt;Cline</code>）</li>
<li>我要调用<code>get_forecast</code>，参数是…(<code>Cline-&gt;MCP Server</code>)</li>
<li>调用完成，结果是…（<code>MCP Server-&gt;Cline</code>）</li>
<li>调用完成，结果是…（<code>Cline-&gt;LLM</code>）</li>
<li>纽约明天的天气是这样的…（<code>LLM-&gt;Cline</code>）</li>
<li>纽约明天的天气是这样的…（<code>Cline-&gt;用户</code>）</li>
</ul>
<img src="/2025/06/09/MCP%E5%9F%BA%E7%A1%80%EF%BC%9A%E4%BB%8E%E5%8E%9F%E7%90%86%E5%88%B0%E5%AE%9E%E6%88%98/image-20250610150918144.png" class="" title="image-20250610150918144">

<hr>
<h3 id="如何使用别人制作好的MCP-Server"><a href="#如何使用别人制作好的MCP-Server" class="headerlink" title="如何使用别人制作好的MCP Server"></a>如何使用别人制作好的MCP Server</h3><p><code>MCP Sever</code>一般是使用<code>Python</code>或<code>Node</code>进行编写，对应的启动方式分别是<code>uvx</code>和<code>npx</code>，下面我们将分别展示一个示例，大家举一反三即可。</p>
<h4 id="uvx部分"><a href="#uvx部分" class="headerlink" title="uvx部分"></a>uvx部分</h4><p>打开<a href="mcp.so">mcp.so</a>，在其中搜索<code>fetch</code>，点击如图所示图标：.png)</p>
<p>会看到：</p>


<p>将右侧的<code>Server Config</code>中的内容复制下来，填入<code>cline_mcp_settings.json</code>：</p>


<p>新开一个聊天使用<code>fetch</code>工具：</p>


<p>非常丝滑，获取网页内容转化为markdown形式并存在项目目录下的<code>guides.md</code>文件下。</p>
<h4 id="npx部分"><a href="#npx部分" class="headerlink" title="npx部分"></a>npx部分</h4><p>这里只说明步骤，不实操了：</p>
<ul>
<li>下载<code>Node.js</code></li>
<li>打开<a href="mcpmarket.com">mcpmarket.com</a></li>
<li>搜索<code>hotnews</code></li>
<li>后续与上文一致</li>
<li>询问今天最火的科技新闻看效果</li>
</ul>
<hr>
<h3 id="MCP-Server市场"><a href="#MCP-Server市场" class="headerlink" title="MCP Server市场"></a>MCP Server市场</h3><ul>
<li><a href="mcpmarket.com">mcpmarket.com</a></li>
<li><a href="mcp.so">mcp.so</a></li>
<li><a href="https://smithery.ai/">Smithery</a></li>
</ul>
<hr>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://www.youtube.com/watch?v=yjBUnbRgiNs">https://www.youtube.com/watch?v=yjBUnbRgiNs</a></li>
<li><a href="https://www.bilibili.com/video/BV1uronYREWR/?spm_id_from=333.1387.homepage.video_card.click&vd_source=075a061948e76c87e2ee8754e264056e">https://www.bilibili.com/video/BV1uronYREWR/?spm_id_from=333.1387.homepage.video_card.click&amp;vd_source=075a061948e76c87e2ee8754e264056e</a></li>
<li><a href="https://github.com/MarkTechStation/VideoCode/tree/main/MCP%E7%BB%88%E6%9E%81%E6%8C%87%E5%8D%97-%E8%BF%9B%E9%98%B6%E7%AF%87/weather">https://github.com/MarkTechStation/VideoCode/tree/main/MCP%E7%BB%88%E6%9E%81%E6%8C%87%E5%8D%97-%E8%BF%9B%E9%98%B6%E7%AF%87/weather</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>agent</tag>
        <tag>mcp</tag>
      </tags>
  </entry>
  <entry>
    <title>MCP填坑篇：Function Call &amp; MCP客户端</title>
    <url>/2025/06/20/MCP%E6%80%BB%E7%BB%93%EF%BC%9A%E5%85%88%E7%9C%8B%E8%BF%99%E7%AF%87/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前面整理了<a href="https://caihaoran-00.github.io/2025/06/09/MCP%E5%9F%BA%E7%A1%80%EF%BC%9A%E4%BB%8E%E5%8E%9F%E7%90%86%E5%88%B0%E5%AE%9E%E6%88%98/">MCP基础：从原理到实战</a>、<a href="https://caihaoran-00.github.io/2025/06/12/MCP%E8%BF%9B%E9%98%B6%EF%BC%9A%E5%B8%A6%E4%BD%A0%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8F%A1MCP/">MCP进阶：带你深入掌握MCP</a>、<a href="https://caihaoran-00.github.io/2025/06/19/MCP%E7%95%AA%E5%A4%96%EF%BC%9ACline%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B/">MCP番外：Cline与模型的交互过程</a>，本文用于填坑，包括：</p>
<ul>
<li><code>Function Call</code></li>
<li><code>MCP</code>客户端</li>
</ul>
<span id="more"></span>

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="MCP是什么"><a href="#MCP是什么" class="headerlink" title="MCP是什么"></a>MCP是什么</h3><p><code>MCP</code>（Model Context Protocol，模型上下文协议）。这是一种开放标准，旨在统一大型语言模型（<code>LLMs</code>）与<strong>外部数据源和工具</strong>之间的通信协议。</p>
<p><code>MCP</code>允许应用程序以一种标准化的方式向<code>LLMs</code>提供上下文信息，这使得不同来源的数据可以更容易地被集成到<code>LLMs</code>中。</p>
<p>此外，<code>MCP</code>也被描述为类似于<code>USB-C</code>端口的一种接口，对于AI应用来说，它提供了一种通用的方法来连接不同的数据源和服务。通过使用<code>MCP</code>，开发者能够创建更加灵活且功能丰富的AI驱动的应用程序，因为它们可以无缝地与多种外部服务进行交互。</p>
<hr>
<h3 id="MCP-VS-function-call"><a href="#MCP-VS-function-call" class="headerlink" title="MCP VS function call"></a><code>MCP</code> VS function call</h3><img src="/2025/06/20/MCP%E6%80%BB%E7%BB%93%EF%BC%9A%E5%85%88%E7%9C%8B%E8%BF%99%E7%AF%87/image-20250620195037970.png" class="" title="image-20250620195037970">

<p>还记得之前我们<code>MCP</code>系列文章中插图的<code>Cline</code>的位置吗，是不是位于<code>OpenAI</code>服务器的位置，而<code>MCP</code>并未规定<code>MCP Host</code>如何以<code>LLM</code>交互，这里可以把<code>API</code>看成<code>LLM</code>，上图就是通过<code>Function Calling</code>的方式与<code>LLM</code>进行信息交互，而<code>Cline</code>是通过的<code>XML</code>的方式（或者说<code>Prompt System</code>的方式）,所以<code>Function Calling</code>起作用的位置如上图蓝色框所示；</p>
<p>而<code>MCP</code>协议规定的是如何发现和调用函数的，是在上图红色框区域生效的；</p>
<p>可见，两者并不是在同一个位置起作用，两者是可以<strong>共存</strong>的。</p>
<hr>
<h3 id="MCP客户端开发"><a href="#MCP客户端开发" class="headerlink" title="MCP客户端开发"></a><code>MCP</code>客户端开发</h3><p>在前面的<code>MCP</code>系列文章中，我们的老演员<code>weather.py</code>已经很熟悉了，但是我们一直使用的是<code>Cline</code>，还没自己动手实现下<code>MCP</code>客户端，接下来我们将一起看下客户端的原理与写法。</p>
<h4 id="开胃小菜"><a href="#开胃小菜" class="headerlink" title="开胃小菜"></a>开胃小菜</h4><p>在正式开始之前，我们先看下如何在客户端中调用我们开发的<code>MCP Server</code>中的工具：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> mcp.client.stdio <span class="keyword">import</span> stdio_client</span><br><span class="line"><span class="keyword">from</span> mcp <span class="keyword">import</span> ClientSession, StdioServerParameters</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为 stdio 连接创建服务器参数</span></span><br><span class="line">server_params = StdioServerParameters(</span><br><span class="line">    <span class="comment"># 服务器执行的命令，这里我们使用 uv 来运行 web_search.py</span></span><br><span class="line">    command=<span class="string">&#x27;uv&#x27;</span>,</span><br><span class="line">    <span class="comment"># 运行的参数</span></span><br><span class="line">    args=[<span class="string">&#x27;run&#x27;</span>, <span class="string">&#x27;weather.py&#x27;</span>],</span><br><span class="line">    <span class="comment"># 环境变量，默认为 None，表示使用当前环境变量</span></span><br><span class="line">    <span class="comment"># env=None</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="comment"># 创建 stdio 客户端</span></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> stdio_client(server_params) <span class="keyword">as</span> (stdio, write):</span><br><span class="line">        <span class="comment"># 创建 ClientSession 对象</span></span><br><span class="line">        <span class="keyword">async</span> <span class="keyword">with</span> ClientSession(stdio, write) <span class="keyword">as</span> session:</span><br><span class="line">            <span class="comment"># 初始化 ClientSession</span></span><br><span class="line">            <span class="keyword">await</span> session.initialize()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 列出可用的工具</span></span><br><span class="line">            response = <span class="keyword">await</span> session.list_tools()</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;list=<span class="subst">&#123;response&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 调用工具</span></span><br><span class="line">            response = <span class="keyword">await</span> session.call_tool(<span class="string">&#x27;get_forecast&#x27;</span>, &#123;<span class="string">&#x27;latitude&#x27;</span>: <span class="number">40.7128</span>, <span class="string">&#x27;longitude&#x27;</span>: -<span class="number">74.0060</span>&#125;)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;response=<span class="subst">&#123;response&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    asyncio.run(main())</span><br></pre></td></tr></table></figure>

<p><strong>代码解释：</strong></p>
<p>这段代码是一个使用 <code>MCP</code>（Model Context Protocol） 标准的 Python 客户端示例。它通过 <code>stdio</code>（标准输入输出）方式启动并连接一个工具服务器（在这里是 <code>weather.py</code> 脚本），调用其暴露的工具 <code>get_forecast</code>，并获取天气预报信息。</p>
<p>下面逐行解释其作用：</p>
<ol>
<li>引入必要模块</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">from</span> mcp.client.stdio <span class="keyword">import</span> stdio_client</span><br><span class="line"><span class="keyword">from</span> mcp <span class="keyword">import</span> ClientSession, StdioServerParameters</span><br></pre></td></tr></table></figure>

<ul>
<li><code>asyncio</code>：用于运行异步任务。</li>
<li><code>stdio_client</code>：提供与通过标准输入输出通信的工具进程连接的能力。</li>
<li><code>ClientSession</code>：代表与工具服务器的一个 <code>MCP</code> 协议会话。</li>
<li><code>StdioServerParameters</code>：定义如何通过 <code>stdio</code> 启动子进程（比如你要连接的工具服务）。</li>
</ul>
<ol start="2">
<li>设置服务器参数</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">server_params = StdioServerParameters(</span><br><span class="line">    command=<span class="string">&#x27;uv&#x27;</span>,</span><br><span class="line">    args=[<span class="string">&#x27;run&#x27;</span>, <span class="string">&#x27;weather.py&#x27;</span>],</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>这表示你要通过 <code>uv run weather.py</code> 来启动一个子进程（比如一个工具服务），其会通过 <code>stdio</code> 与 MCP 客户端通信。</p>
<ul>
<li><code>uv</code> 是一种比 <code>pip</code> 更快的 Python 包管理&#x2F;运行工具。</li>
<li><code>weather.py</code> 是你要运行的 <code>MCP</code> 工具服务器脚本。</li>
</ul>
<ol start="3">
<li>异步主函数 <code>main</code></li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br></pre></td></tr></table></figure>

<p>这是一个异步函数，用于运行整个客户端生命周期。</p>
<ol start="4">
<li>启动子进程并建立连接</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">with</span> stdio_client(server_params) <span class="keyword">as</span> (stdio, write):</span><br></pre></td></tr></table></figure>

<ul>
<li>使用 <code>stdio_client</code> 启动 <code>uv run weather.py</code>，并将该进程的标准输入输出流作为通信通道。</li>
<li>返回的是 <code>(reader, writer)</code> 对象。</li>
<li><code>stdio</code> 是 <strong>子进程的 <code>stdout</code>（标准输出）对应的 reader</strong>，你可以用它来读取子进程返回的内容。</li>
<li><code>write</code> 是 <strong>子进程的 <code>stdin</code>（标准输入）对应的 writer</strong>，你可以通过它向子进程发送内容。</li>
</ul>
<ol start="5">
<li>使用 <code>MCP</code> 协议初始化连接</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">with</span> ClientSession(stdio, write) <span class="keyword">as</span> session:</span><br><span class="line">    <span class="keyword">await</span> session.initialize()</span><br></pre></td></tr></table></figure>

<ul>
<li><code>ClientSession</code>：创建与工具服务通信的 <code>MCP</code> 会话。</li>
<li><code>initialize()</code>：启动 handshake（握手），建立协议连接。</li>
</ul>
<ol start="6">
<li>查看工具列表</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">response = <span class="keyword">await</span> session.list_tools()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;list=<span class="subst">&#123;response&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>list_tools()</code>：请求工具服务器返回它支持的所有“工具”名称及其功能描述。</li>
<li>打印返回的工具信息。</li>
</ul>
<ol start="7">
<li>调用具体工具</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">response = <span class="keyword">await</span> session.call_tool(<span class="string">&#x27;get_forecast&#x27;</span>, &#123;<span class="string">&#x27;latitude&#x27;</span>: <span class="number">40.7128</span>, <span class="string">&#x27;longitude&#x27;</span>: -<span class="number">74.0060</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;response=<span class="subst">&#123;response&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>调用名为 <code>get_forecast</code> 的工具，传入经纬度参数（这是纽约市的坐标）。</li>
<li>打印获取到的天气预报结果。</li>
</ul>
<ol start="8">
<li>运行入口</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    asyncio.run(main())</span><br></pre></td></tr></table></figure>

<ul>
<li>当直接运行该文件时，执行 <code>main()</code> 协程。</li>
</ul>
<p><strong>总结一下作用：</strong></p>
<p>这段代码完成了 <strong>通过<code>MCP</code> 协议连接一个通过 <code>uv run weather.py</code> 启动的工具服务，并调用其中的天气查询功能</strong>。整个过程包括：</p>
<ol>
<li>通过标准输入输出连接工具服务器；</li>
<li>初始化 <code>MCP</code> 会话；</li>
<li>获取可用工具列表；</li>
<li>调用其中一个工具（<code>get_forecast</code>）；</li>
<li>打印结果。</li>
</ol>
<p><strong>输出（手动格式化后）：</strong></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">/home/chr/桌面/weather/.venv/bin/python /home/chr/桌面/weather/client_basic.py</span><br><span class="line"></span><br><span class="line">list=</span><br><span class="line">meta=None </span><br><span class="line">nextCursor=None</span><br><span class="line">tools=<span class="punctuation">[</span></span><br><span class="line">    Tool(</span><br><span class="line">        name=&#x27;get_alerts&#x27;<span class="punctuation">,</span></span><br><span class="line">        description=&#x27;Get weather alerts for a US state.</span><br><span class="line">        </span><br><span class="line">        Args<span class="punctuation">:</span></span><br><span class="line">        state<span class="punctuation">:</span> Two-letter US state code (e.g. 			CA<span class="punctuation">,</span> NY)</span><br><span class="line">    	&#x27;<span class="punctuation">,</span></span><br><span class="line">        inputSchema=<span class="punctuation">&#123;</span></span><br><span class="line">            &#x27;properties&#x27;<span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                &#x27;state&#x27;<span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    &#x27;title&#x27;<span class="punctuation">:</span> &#x27;State&#x27;<span class="punctuation">,</span></span><br><span class="line">                    &#x27;type&#x27;<span class="punctuation">:</span> &#x27;string&#x27;</span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span> </span><br><span class="line">            &#x27;required&#x27;<span class="punctuation">:</span> <span class="punctuation">[</span>&#x27;state&#x27;<span class="punctuation">]</span><span class="punctuation">,</span> </span><br><span class="line">            &#x27;title&#x27;<span class="punctuation">:</span> &#x27;get_alertsArguments&#x27;<span class="punctuation">,</span> </span><br><span class="line">            &#x27;type&#x27;<span class="punctuation">:</span> &#x27;object&#x27;</span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        annotations=None)<span class="punctuation">,</span></span><br><span class="line">    </span><br><span class="line">    Tool(</span><br><span class="line">        name=&#x27;get_forecast&#x27;<span class="punctuation">,</span></span><br><span class="line">        description=&#x27;Get weather forecast for a location.</span><br><span class="line">        </span><br><span class="line">        	Args<span class="punctuation">:</span></span><br><span class="line">        </span><br><span class="line">        	latitude<span class="punctuation">:</span> Latitude of the location</span><br><span class="line">        	longitude<span class="punctuation">:</span> Longitude of the location</span><br><span class="line">        	&#x27;<span class="punctuation">,</span> </span><br><span class="line">        inputSchema=<span class="punctuation">&#123;</span></span><br><span class="line">            &#x27;properties&#x27;<span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                &#x27;latitude&#x27;<span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    &#x27;title&#x27;<span class="punctuation">:</span> &#x27;Latitude&#x27;<span class="punctuation">,</span></span><br><span class="line">                    &#x27;type&#x27;<span class="punctuation">:</span> &#x27;number&#x27;</span><br><span class="line">                <span class="punctuation">&#125;</span><span class="punctuation">,</span> </span><br><span class="line">                &#x27;longitude&#x27;<span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">                    &#x27;title&#x27;<span class="punctuation">:</span> &#x27;Longitude&#x27;<span class="punctuation">,</span></span><br><span class="line">                    &#x27;type&#x27;<span class="punctuation">:</span> &#x27;number&#x27;</span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span> </span><br><span class="line">            &#x27;required&#x27;<span class="punctuation">:</span> <span class="punctuation">[</span>&#x27;latitude&#x27;<span class="punctuation">,</span> &#x27;longitude&#x27;<span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            &#x27;title&#x27;<span class="punctuation">:</span> &#x27;get_forecastArguments&#x27;<span class="punctuation">,</span></span><br><span class="line">            &#x27;type&#x27;<span class="punctuation">:</span> &#x27;object&#x27;</span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        annotations=None)<span class="punctuation">]</span></span><br><span class="line"></span><br><span class="line">response=</span><br><span class="line"></span><br><span class="line">meta=None</span><br><span class="line">content=<span class="punctuation">[</span></span><br><span class="line">    TextContent(</span><br><span class="line">        type=&#x27;text&#x27;<span class="punctuation">,</span></span><br><span class="line">        text=&#x27;</span><br><span class="line">        Overnight<span class="punctuation">:</span></span><br><span class="line">        Temperature<span class="punctuation">:</span> <span class="number">68</span>°F</span><br><span class="line">        Wind<span class="punctuation">:</span> <span class="number">16</span> mph W</span><br><span class="line">        Forecast<span class="punctuation">:</span> Partly cloudy. Low around <span class="number">68</span><span class="punctuation">,</span> with temperatures rising to around <span class="number">70</span> overnight. West wind 					around <span class="number">16</span> mph.</span><br><span class="line">        </span><br><span class="line">        ---</span><br><span class="line">        </span><br><span class="line">        Friday<span class="punctuation">:</span></span><br><span class="line">        Temperature<span class="punctuation">:</span> <span class="number">81</span>°F</span><br><span class="line">        Wind<span class="punctuation">:</span> <span class="number">16</span> mph W</span><br><span class="line">        Forecast<span class="punctuation">:</span> Sunny<span class="punctuation">,</span> with a high near <span class="number">81.</span> West wind around <span class="number">16</span> mph.</span><br><span class="line">        </span><br><span class="line">        ---</span><br><span class="line">        </span><br><span class="line">        Friday Night<span class="punctuation">:</span></span><br><span class="line">        Temperature<span class="punctuation">:</span> <span class="number">72</span>°F</span><br><span class="line">        Wind<span class="punctuation">:</span> <span class="number">6</span> to <span class="number">14</span> mph W</span><br><span class="line">        Forecast<span class="punctuation">:</span> Partly cloudy<span class="punctuation">,</span> with a low around <span class="number">72.</span> West wind <span class="number">6</span> to <span class="number">14</span> mph.</span><br><span class="line">        </span><br><span class="line">        ---</span><br><span class="line">        </span><br><span class="line">        Saturday<span class="punctuation">:</span></span><br><span class="line">        Temperature<span class="punctuation">:</span> <span class="number">84</span>°F</span><br><span class="line">        Wind<span class="punctuation">:</span> <span class="number">6</span> to <span class="number">9</span> mph SW</span><br><span class="line">        Forecast<span class="punctuation">:</span> Mostly sunny<span class="punctuation">,</span> with a high near <span class="number">84.</span> Southwest wind <span class="number">6</span> to <span class="number">9</span> mph.</span><br><span class="line">        </span><br><span class="line">        ---</span><br><span class="line">        </span><br><span class="line">        Saturday Night<span class="punctuation">:</span></span><br><span class="line">        Temperature<span class="punctuation">:</span> <span class="number">74</span>°F</span><br><span class="line">        Wind<span class="punctuation">:</span> <span class="number">10</span> mph SW</span><br><span class="line">        Forecast<span class="punctuation">:</span> Mostly cloudy. Low around <span class="number">74</span><span class="punctuation">,</span> with temperatures rising to around <span class="number">78</span> overnight. Southwest 				wind around <span class="number">10</span> mph.</span><br><span class="line">        &#x27;<span class="punctuation">,</span></span><br><span class="line">        annotations=None)</span><br><span class="line">                           <span class="punctuation">]</span> </span><br><span class="line">isError=False</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="正菜"><a href="#正菜" class="headerlink" title="正菜"></a>正菜</h4><p><strong>完整代码如下：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Optional</span></span><br><span class="line"><span class="keyword">from</span> contextlib <span class="keyword">import</span> AsyncExitStack</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">from</span> dotenv <span class="keyword">import</span> load_dotenv</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> mcp <span class="keyword">import</span> ClientSession, StdioServerParameters</span><br><span class="line"><span class="keyword">from</span> mcp.client.stdio <span class="keyword">import</span> stdio_client</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">load_dotenv()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MCPClient</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.session: <span class="type">Optional</span>[ClientSession] = <span class="literal">None</span></span><br><span class="line">        <span class="variable language_">self</span>.exit_stack = AsyncExitStack()</span><br><span class="line">        <span class="variable language_">self</span>.client = OpenAI()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">connect_to_server</span>(<span class="params">self</span>):</span><br><span class="line">        server_params = StdioServerParameters(</span><br><span class="line">        command=<span class="string">&#x27;uv&#x27;</span>,</span><br><span class="line">        args=[<span class="string">&#x27;run&#x27;</span>, <span class="string">&#x27;weather.py&#x27;</span>],</span><br><span class="line">        env=<span class="literal">None</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        stdio_transport = <span class="keyword">await</span> <span class="variable language_">self</span>.exit_stack.enter_async_context(</span><br><span class="line">            stdio_client(server_params))</span><br><span class="line">        stdio, write = stdio_transport</span><br><span class="line">        <span class="variable language_">self</span>.session = <span class="keyword">await</span> <span class="variable language_">self</span>.exit_stack.enter_async_context(</span><br><span class="line">            ClientSession(stdio, write))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">await</span> <span class="variable language_">self</span>.session.initialize()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">process_query</span>(<span class="params">self, query: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        system_prompt = (</span><br><span class="line">            <span class="string">&quot;请用轻松自然的方式回答问题，像是朋友间闲聊时带点小幽默的语气。&quot;</span></span><br><span class="line">            <span class="string">&quot;你说话简洁，幽默中又不失稳重。&quot;</span></span><br><span class="line">            <span class="string">&quot;不用刻意讲笑话，而是在解释专业内容时偶尔用个生活化的比喻，或者在严肃话题里穿插一句俏皮话调节气氛。&quot;</span></span><br><span class="line">            <span class="string">&quot;以纯文本形式回复，避免emoji表情或markdown等格式。&quot;</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        messages = [</span><br><span class="line">            &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: system_prompt&#125;,</span><br><span class="line">            &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: query&#125;</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取所有 mcp 服务器 工具列表信息</span></span><br><span class="line">        response = <span class="keyword">await</span> <span class="variable language_">self</span>.session.list_tools()</span><br><span class="line">        <span class="comment"># 生成 function call 的描述信息</span></span><br><span class="line">        available_tools = [&#123;</span><br><span class="line">            <span class="string">&quot;type&quot;</span>: <span class="string">&quot;function&quot;</span>,</span><br><span class="line">            <span class="string">&quot;function&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;name&quot;</span>: tool.name,</span><br><span class="line">                <span class="string">&quot;description&quot;</span>: tool.description,</span><br><span class="line">                <span class="string">&quot;input_schema&quot;</span>: tool.inputSchema</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">for</span> tool <span class="keyword">in</span> response.tools]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 请求 deepseek，function call 的描述信息通过 tools 参数传入</span></span><br><span class="line">        response = <span class="variable language_">self</span>.client.chat.completions.create(</span><br><span class="line">            model=os.getenv(<span class="string">&quot;OPENAI_MODEL&quot;</span>),</span><br><span class="line">            messages=messages,</span><br><span class="line">            tools=available_tools</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 处理返回的内容</span></span><br><span class="line">        content = response.choices[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> content.finish_reason == <span class="string">&quot;tool_calls&quot;</span>:</span><br><span class="line">            <span class="comment"># 如何是需要使用工具，就解析工具</span></span><br><span class="line">            tool_call = content.message.tool_calls[<span class="number">0</span>]</span><br><span class="line">            tool_name = tool_call.function.name</span><br><span class="line">            tool_args = json.loads(tool_call.function.arguments)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 执行工具</span></span><br><span class="line">            result = <span class="keyword">await</span> <span class="variable language_">self</span>.session.call_tool(tool_name, tool_args)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;\n\n[Calling tool <span class="subst">&#123;tool_name&#125;</span> with args <span class="subst">&#123;tool_args&#125;</span>]\n\n&quot;</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 将 deepseek 返回的调用哪个工具数据和工具执行完成后的数据都存入messages中</span></span><br><span class="line">            messages.append(content.message.model_dump())</span><br><span class="line">            messages.append(&#123;</span><br><span class="line">                <span class="string">&quot;role&quot;</span>: <span class="string">&quot;tool&quot;</span>,</span><br><span class="line">                <span class="string">&quot;content&quot;</span>: result.content[<span class="number">0</span>].text,</span><br><span class="line">                <span class="string">&quot;tool_call_id&quot;</span>: tool_call.<span class="built_in">id</span>,</span><br><span class="line">            &#125;)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 将上面的结果再返回给 deepseek 用于生产最终的结果</span></span><br><span class="line">            response = <span class="variable language_">self</span>.client.chat.completions.create(</span><br><span class="line">                model=os.getenv(<span class="string">&quot;OPENAI_MODEL&quot;</span>),</span><br><span class="line">                messages=messages,</span><br><span class="line">            )</span><br><span class="line">            <span class="keyword">return</span> response.choices[<span class="number">0</span>].message.content</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> content.message.content</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">chat_loop</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                query = <span class="built_in">input</span>(<span class="string">&quot;\nQuery: &quot;</span>).strip()</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> query.lower() == <span class="string">&#x27;quit&#x27;</span>:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">                response = <span class="keyword">await</span> <span class="variable language_">self</span>.process_query(query)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span> + response)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                <span class="keyword">import</span> traceback</span><br><span class="line">                traceback.print_exc()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">cleanup</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Clean up resources&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">await</span> <span class="variable language_">self</span>.exit_stack.aclose()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    client = MCPClient()</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">await</span> client.connect_to_server()</span><br><span class="line">        <span class="keyword">await</span> client.chat_loop()</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        <span class="keyword">await</span> client.cleanup()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">    asyncio.run(main())</span><br></pre></td></tr></table></figure>

<p><strong>这段代码是一个集成了：</strong></p>
<ol>
<li><strong>OpenAI GPT 模型（支持 function call）</strong></li>
<li><strong>MCP 工具服务（通过 <code>stdio</code> 启动 <code>weather.py</code>）</strong></li>
</ol>
<p>的 <strong>多轮聊天客户端</strong>，用户提问时，模型会判断是否要调用工具，如果需要，就通过 <code>MCP</code> 协议调用工具返回结果，并继续对话。</p>
<p>下面是逐部分的详细解释：</p>
<ol>
<li><strong>导入模块</strong></li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Optional</span></span><br><span class="line"><span class="keyword">from</span> contextlib <span class="keyword">import</span> AsyncExitStack</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">from</span> dotenv <span class="keyword">import</span> load_dotenv</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> mcp <span class="keyword">import</span> ClientSession, StdioServerParameters</span><br><span class="line"><span class="keyword">from</span> mcp.client.stdio <span class="keyword">import</span> stdio_client</span><br></pre></td></tr></table></figure>

<ul>
<li><p>导入标准库和三方库：</p>
<ul>
<li><p><code>openai</code>：用于与 <code>LLM</code> 通信</p>
</li>
<li><p><code>mcp</code>：用于 <code>MCP</code> 工具调用</p>
</li>
<li><p><code>dotenv</code>：加载 <code>.env</code> 文件（用于设置 <code>OPENAI_MODEL</code> 和 <code>OPENAI_API_KEY</code>等），格式如下：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">OPENAI<span class="built_in">_</span>API<span class="built_in">_</span>KEY=sk-xxxxxxxxxxxxxxxxxxxxx</span><br><span class="line">OPENAI<span class="built_in">_</span>BASE<span class="built_in">_</span>URL=https://api.deepseek.com</span><br><span class="line">OPENAI<span class="built_in">_</span>MODEL=deepseek-chat</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<ol start="2">
<li><strong>环境变量加载</strong></li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">load_dotenv()</span><br></pre></td></tr></table></figure>

<p>从 <code>.env</code> 文件中读取环境变量（如 <code>OPENAI_API_KEY</code>, <code>OPENAI_MODEL</code>）。</p>
<ol start="3">
<li><strong><code>MCPClient</code> 类</strong>：管理与模型和 <code>MCP</code> 工具的整个对话流程</li>
</ol>
<p>​	 初始化</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MCPClient</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.session: <span class="type">Optional</span>[ClientSession] = <span class="literal">None</span></span><br><span class="line">        <span class="variable language_">self</span>.exit_stack = AsyncExitStack()</span><br><span class="line">        <span class="variable language_">self</span>.client = OpenAI()</span><br></pre></td></tr></table></figure>

<ul>
<li><code>self.session</code>：与 MCP 工具的连接会话。</li>
<li><code>self.exit_stack</code>：用于管理多个异步资源（子进程、会话等）。</li>
<li><code>self.client</code>：OpenAI 客户端。</li>
</ul>
<p>​	<strong>连接 <code>MCP</code> 工具服务</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">connect_to_server</span>(<span class="params">self</span>):</span><br><span class="line">    server_params = StdioServerParameters(</span><br><span class="line">        command=<span class="string">&#x27;uv&#x27;</span>,</span><br><span class="line">        args=[<span class="string">&#x27;run&#x27;</span>, <span class="string">&#x27;weather.py&#x27;</span>],</span><br><span class="line">        env=<span class="literal">None</span></span><br><span class="line">    )</span><br><span class="line">    stdio_transport = <span class="keyword">await</span> <span class="variable language_">self</span>.exit_stack.enter_async_context(stdio_client(server_params))</span><br><span class="line">    stdio, write = stdio_transport</span><br><span class="line">    <span class="variable language_">self</span>.session = <span class="keyword">await</span> <span class="variable language_">self</span>.exit_stack.enter_async_context(ClientSession(stdio, write))</span><br><span class="line">    <span class="keyword">await</span> <span class="variable language_">self</span>.session.initialize()</span><br></pre></td></tr></table></figure>

<p>通过 <code>uv run weather.py</code> 启动 <code>MCP</code> 工具服务，建立标准输入输出的通信，初始化 <code>MCP</code> 协议会话。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">connect_to_server</span>(<span class="params">self</span>):</span><br></pre></td></tr></table></figure>

<p>定义一个协程方法 <code>connect_to_server</code>，用于建立与 <code>MCP</code> 工具服务器的连接。因为涉及异步 I&#x2F;O（比如启动子进程、读写流等），所以使用 <code>async def</code>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">server_params = StdioServerParameters(</span><br><span class="line">    command=<span class="string">&#x27;uv&#x27;</span>,</span><br><span class="line">    args=[<span class="string">&#x27;run&#x27;</span>, <span class="string">&#x27;weather.py&#x27;</span>],</span><br><span class="line">    env=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>这一行创建了一个 <code>StdioServerParameters</code> 对象，表示将以 <code>stdio</code>（标准输入输出）方式启动一个 <code>MCP</code> 工具服务进程。</p>
<p>参数解释：</p>
<ul>
<li><code>command=&#39;uv&#39;</code>：表示用 <code>uv</code> 命令来运行程序（<code>uv</code> 是比 pip 更快的 Python 包&#x2F;脚本运行工具）。</li>
<li><code>args=[&#39;run&#39;, &#39;weather.py&#39;]</code>：实际执行的是 <code>uv run weather.py</code>，也就是运行你的 <code>weather.py</code> MCP 工具。</li>
<li><code>env=None</code>：不传入额外环境变量，使用当前 Python 环境的默认变量。</li>
</ul>
<hr>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">stdio_transport = <span class="keyword">await</span> <span class="variable language_">self</span>.exit_stack.enter_async_context(</span><br><span class="line">    stdio_client(server_params)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>stdio_client(server_params)</code>：启动 MCP 工具服务（<code>uv run weather.py</code>），并将其标准输入输出连接包装为一个异步流（<code>reader</code>&#x2F;<code>writer</code>）。</li>
<li><code>exit_stack.enter_async_context(...)</code>：将其注册到 <code>AsyncExitStack</code> 中，确保后续退出时能自动清理（类似于 <code>with</code> 自动释放资源）。</li>
<li><code>await</code> 是因为这个是异步上下文管理器。</li>
</ul>
<p>最终结果 <code>stdio_transport</code> 是一个元组 <code>(stdio, write)</code>：</p>
<ul>
<li><code>stdio</code> 是 <code>StreamReader</code>，可以从 MCP 工具读数据；</li>
<li><code>write</code> 是 <code>StreamWriter</code>，可以向 MCP 工具写入命令。</li>
</ul>
<hr>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">stdio, write = stdio_transport</span><br></pre></td></tr></table></figure>

<p>解包上述元组，赋值给本地变量 <code>stdio</code> 和 <code>write</code>。</p>
<hr>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="variable language_">self</span>.session = <span class="keyword">await</span> <span class="variable language_">self</span>.exit_stack.enter_async_context(</span><br><span class="line">    ClientSession(stdio, write)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>使用 <code>stdio</code> 和 <code>write</code> 初始化一个 <code>ClientSession</code>，表示 MCP 协议层面的连接会话对象。</p>
<p>仍然使用 <code>exit_stack</code> 管理资源，退出时自动关闭。</p>
<p>这一步完成后，你就拥有了一个可以用来：</p>
<ul>
<li><code>list_tools()</code> 查看工具；</li>
<li><code>call_tool(...)</code> 调用工具函数；<br> 的 <code>MCP</code> 会话对象。</li>
</ul>
<hr>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">await</span> <span class="variable language_">self</span>.session.initialize()</span><br></pre></td></tr></table></figure>

<p>这一步进行协议初始化（即握手 handshake）：</p>
<ul>
<li>通知 <code>MCP</code> 工具客户端已连接；</li>
<li>工具端返回支持的协议版本、工具信息等；</li>
<li>连接正式可用。</li>
</ul>
<p> <strong>小总结</strong></p>
<p>这段函数完成了以下任务：</p>
<table>
<thead>
<tr>
<th>步骤</th>
<th>动作</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>用 <code>uv run weather.py</code> 启动 <code>MCP</code> 工具服务</td>
</tr>
<tr>
<td>2</td>
<td>与 <code>MCP</code> 工具服务建立 <code>stdio</code> 通信</td>
</tr>
<tr>
<td>3</td>
<td>使用 <code>stdio</code> 建立 <code>ClientSession</code> 会话</td>
</tr>
<tr>
<td>4</td>
<td>执行 <code>MCP</code> 协议初始化 handshake</td>
</tr>
</tbody></table>
<hr>
<p><strong>处理用户问题：<code>process_query</code></strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">process_query</span>(<span class="params">self, query: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br></pre></td></tr></table></figure>

<p>这个函数实现了大语言模型结合工具调用的核心逻辑。</p>
<p>① 设定系统提示词（system prompt）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">system_prompt = <span class="string">&quot;...&quot;</span>  <span class="comment"># 定义聊天语气：轻松自然、带点幽默</span></span><br></pre></td></tr></table></figure>

<p>② 构造 messages</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">messages = [</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: system_prompt&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: query&#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p>构建聊天历史上下文，送入LLM。</p>
<p>③ 获取 <code>MCP</code> 工具信息，并构造 <code>function schema</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">response = <span class="keyword">await</span> <span class="variable language_">self</span>.session.list_tools()</span><br><span class="line">available_tools = [&#123;</span><br><span class="line">    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;function&quot;</span>,</span><br><span class="line">    <span class="string">&quot;function&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;name&quot;</span>: tool.name,</span><br><span class="line">        <span class="string">&quot;description&quot;</span>: tool.description,</span><br><span class="line">        <span class="string">&quot;input_schema&quot;</span>: tool.inputSchema</span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="keyword">for</span> tool <span class="keyword">in</span> response.tools]</span><br></pre></td></tr></table></figure>

<ul>
<li>使用 <code>list_tools()</code> 获取 <code>MCP</code> 工具端支持的函数</li>
<li>构造<code>function call</code> 所需的 <code>tools</code> 参数（用于 tool calling）</li>
</ul>
<p>④ <code>function call</code> 请求</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">response = <span class="variable language_">self</span>.client.chat.completions.create(</span><br><span class="line">    model=os.getenv(<span class="string">&quot;OPENAI_MODEL&quot;</span>),</span><br><span class="line">    messages=messages,</span><br><span class="line">    tools=available_tools</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ul>
<li>发起对话请求</li>
<li>如果大模型决定调用某个工具，返回的结果中 <code>finish_reason</code> 会是 <code>&quot;tool_calls&quot;</code>。</li>
</ul>
<p> 如果需要调用工具：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> content.finish_reason == <span class="string">&quot;tool_calls&quot;</span>:</span><br><span class="line">    tool_call = content.message.tool_calls[<span class="number">0</span>]</span><br><span class="line">    tool_name = tool_call.function.name</span><br><span class="line">    tool_args = json.loads(tool_call.function.arguments)</span><br></pre></td></tr></table></figure>

<p>解析模型要调用的工具及参数，然后：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">result = <span class="keyword">await</span> <span class="variable language_">self</span>.session.call_tool(tool_name, tool_args)</span><br></pre></td></tr></table></figure>

<p>使用 MCP 会话调用工具，获取返回值。</p>
<p><strong>接下来再补上下文重新调用 <code>LLM</code>：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">messages.append(content.message.model_dump())</span><br><span class="line">messages.append(&#123;</span><br><span class="line">    <span class="string">&quot;role&quot;</span>: <span class="string">&quot;tool&quot;</span>,</span><br><span class="line">    <span class="string">&quot;content&quot;</span>: result.content[<span class="number">0</span>].text,</span><br><span class="line">    <span class="string">&quot;tool_call_id&quot;</span>: tool_call.<span class="built_in">id</span>,</span><br><span class="line">&#125;)</span><br><span class="line">response = <span class="variable language_">self</span>.client.chat.completions.create(</span><br><span class="line">    model=os.getenv(<span class="string">&quot;OPENAI_MODEL&quot;</span>),</span><br><span class="line">    messages=messages,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">return</span> response.choices[<span class="number">0</span>].message.content</span><br></pre></td></tr></table></figure>

<ul>
<li>把函数调用和结果作为上下文追加</li>
<li>重新向<code>LLM</code>请求，生成更自然的“回复用户”的内容</li>
</ul>
<p><strong>否则直接返回普通回答</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">return</span> content.message.content</span><br></pre></td></tr></table></figure>

<p><strong>聊天循环</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">chat_loop</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        query = <span class="built_in">input</span>(<span class="string">&quot;\nQuery: &quot;</span>).strip()</span><br><span class="line">        ...</span><br><span class="line">        response = <span class="keyword">await</span> <span class="variable language_">self</span>.process_query(query)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span> + response)</span><br></pre></td></tr></table></figure>

<ul>
<li>持续接收用户输入</li>
<li>输入 <code>&#39;quit&#39;</code> 退出</li>
<li>调用 <code>process_query</code> 处理每轮提问</li>
</ul>
<p><strong>资源清理</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">cleanup</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">await</span> <span class="variable language_">self</span>.exit_stack.aclose()</span><br></pre></td></tr></table></figure>

<p>关闭 <code>MCP</code> 连接等资源。</p>
<p><strong>主程序入口</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    asyncio.run(main())</span><br></pre></td></tr></table></figure>

<p>运行 <code>main()</code> 函数，调用顺序为：</p>
<ol>
<li>初始化并连接 <code>MCP</code> 工具</li>
<li>启动聊天交互</li>
<li>程序结束时关闭资源</li>
</ol>
<p><strong>总结流程图（简化）</strong></p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">[用户输入 query]</span><br><span class="line">      ↓</span><br><span class="line">[构造 messages + tools schema]</span><br><span class="line">      ↓</span><br><span class="line">[调用 LLM]</span><br><span class="line">      ↓</span><br><span class="line">是否要调用工具？</span><br><span class="line"> ├── 否 → 返回内容</span><br><span class="line"> └── 是 →</span><br><span class="line">        ├── 解析 tool<span class="built_in">_</span>call（函数名 + 参数）</span><br><span class="line">        ├── 使用 MCP session 调用工具</span><br><span class="line">        ├── 将函数调用和结果加入上下文</span><br><span class="line">        └── 再次调用 LLM → 得到最终回答</span><br></pre></td></tr></table></figure>

<hr>
<p><strong>输出：</strong></p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">weather(base) chr@chr:~/桌面/weather<span class="built_in">$</span> /home/chr/桌面/weather/.venv/bin/python /home/chr/桌面/weather/client<span class="built_in">_</span>advanced.py</span><br><span class="line"></span><br><span class="line">Query: 你好 </span><br><span class="line"></span><br><span class="line">嘿，朋友！今天过得怎么样？有什么可以帮你的吗？</span><br><span class="line"></span><br><span class="line">Query: 纽约明天天气怎么样</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[Calling tool get<span class="built_in">_</span>forecast with args &#123;&#x27;latitude&#x27;: 40.7128, &#x27;longitude&#x27;: -74.006&#125;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">纽约明天是个好天气呢！大晴天，最高温81华氏度（约27℃），西风16英里/小时。就像个天然的吹风机，保证你发型飘逸。晚上稍微凉快点，72度左右，适合出门遛弯。周末会更暖和，看来纽约要开始它的夏日表演了~</span><br><span class="line"></span><br><span class="line">Query: 72华氏度是多少摄氏度</span><br><span class="line"></span><br><span class="line">72华氏度换算成摄氏度大约是22.2°C。简单来说，就是那种穿短袖刚好，但晚上可能需要加件薄外套的温度。</span><br><span class="line"></span><br><span class="line">Query: quit</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://caihaoran-00.github.io/2025/06/09/MCP%E5%9F%BA%E7%A1%80%EF%BC%9A%E4%BB%8E%E5%8E%9F%E7%90%86%E5%88%B0%E5%AE%9E%E6%88%98/">https://caihaoran-00.github.io/2025/06/09/MCP%E5%9F%BA%E7%A1%80%EF%BC%9A%E4%BB%8E%E5%8E%9F%E7%90%86%E5%88%B0%E5%AE%9E%E6%88%98/</a></li>
<li><a href="https://caihaoran-00.github.io/2025/06/12/MCP%E8%BF%9B%E9%98%B6%EF%BC%9A%E5%B8%A6%E4%BD%A0%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8F%A1MCP/">https://caihaoran-00.github.io/2025/06/12/MCP%E8%BF%9B%E9%98%B6%EF%BC%9A%E5%B8%A6%E4%BD%A0%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8F%A1MCP/</a></li>
<li><a href="https://caihaoran-00.github.io/2025/06/19/MCP%E7%95%AA%E5%A4%96%EF%BC%9ACline%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B/">https://caihaoran-00.github.io/2025/06/19/MCP%E7%95%AA%E5%A4%96%EF%BC%9ACline%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B/</a></li>
<li><a href="https://www.bilibili.com/video/BV15YJTzkENC?spm_id_from=333.788.player.player_end_recommend_autoplay&vd_source=075a061948e76c87e2ee8754e264056e">https://www.bilibili.com/video/BV15YJTzkENC?spm_id_from=333.788.player.player_end_recommend_autoplay&amp;vd_source=075a061948e76c87e2ee8754e264056e</a></li>
<li><a href="https://modelcontextprotocol.io/quickstart/client">https://modelcontextprotocol.io/quickstart/client</a></li>
<li><a href="https://github.com/liaokongVFX/MCP-Chinese-Getting-Started-Guide?tab=readme-ov-file">https://github.com/liaokongVFX/MCP-Chinese-Getting-Started-Guide?tab=readme-ov-file</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>mcp</tag>
        <tag>function call</tag>
      </tags>
  </entry>
  <entry>
    <title>MCP番外：Cline与模型的交互过程</title>
    <url>/2025/06/19/MCP%E7%95%AA%E5%A4%96%EF%BC%9ACline%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前面我们介绍了<a href="https://caihaoran-00.github.io/2025/06/09/MCP%E5%9F%BA%E7%A1%80%EF%BC%9A%E4%BB%8E%E5%8E%9F%E7%90%86%E5%88%B0%E5%AE%9E%E6%88%98/">MCP基础：从原理到实战</a>和<a href="https://caihaoran-00.github.io/2025/06/12/MCP%E8%BF%9B%E9%98%B6%EF%BC%9A%E5%B8%A6%E4%BD%A0%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8F%A1MCP/">MCP进阶：带你深入掌握MCP</a>，对<code>MCP</code>协议的原理有了比较清晰的认识，明确了<code>MCP</code>协议主要规定的是如何发现和调用函数的，也明确了<code>MCP</code>协议并没有规定如何与模型进行交互。之所以这篇文章叫做番外篇也是出于<code>MCP</code>协议并没有规定如何与模型进行交互的考虑。在<code>MCP</code>进阶一文中提到<code>MCP</code>协议没有对模型的输入和输出格式进行进行要求，因此不同的<code>MCP Host</code>就可能使用不同的格式来与模型沟通，比如<code>Cline</code>用的就是<code>XML</code>，<code>Cherry Studio</code>用的是<code>Function Call</code>，本文将以<code>Cline</code>为例讲解<code>MCP Host</code>是如何与模型沟通的。</p>
<p>本文参考<a href="https://www.bilibili.com/video/BV1v9V5zSEHA/?spm_id_from=333.1387.homepage.video_card.click&vd_source=075a061948e76c87e2ee8754e264056e">这里</a>，主要内容包括：</p>
<ul>
<li>截获模型输入&#x2F;输出，展示<code>Cline</code>与模型交互的具体细节</li>
<li>如何构建<code>Agent</code>常用的<code>ReAct</code>模式以及<code>Cline</code>用的<code>XML</code>协议与<code>ReAct</code>模式之间的关系</li>
</ul>
<p>目标：不是单纯的了解<code>Cline</code>的<code>XML</code>协议，而是通过学习这个协议了解如何编写一个像<code>Cline</code>一样能够与模型持续交互的程序。</p>
<span id="more"></span>

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>拿出我们的老演员：<code>MCP Host</code>与<code>MCP Server</code>之间的交互过程，我们本文关注的是右半边的内容：</p>
<img src="/2025/06/19/MCP%E7%95%AA%E5%A4%96%EF%BC%9ACline%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B/image-20250619185230434.png" class="" title="image-20250619185230434">

<p>我们截获模型输入输出的方式是通过一个本地服务器来实现的，本地服务器负责请求的转发与记录，框架如下图所示：</p>
<img src="/2025/06/19/MCP%E7%95%AA%E5%A4%96%EF%BC%9ACline%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B/image-20250619185533547.png" class="" title="image-20250619185533547">

<p>决定能否实现上述框架的前提是：<code>Cline</code>支持连接本地服务器吗？答案是肯定的。在<code>Cline</code>的<code>Settings</code>中的<code>API Provider</code>中，有个选项叫<code>OpenAI Compatible</code>，对于兼容<code>OpenAI</code>格式的模型，都可以通过该选项进行配置，所以重点在于本地服务器的输入和输出满足<code>OpenAI</code>的格式规范。</p>
<h3 id="中转服务器代码解释"><a href="#中转服务器代码解释" class="headerlink" title="中转服务器代码解释"></a>中转服务器代码解释</h3><p>代码来自<a href="https://github.com/MarkTechStation/VideoCode/blob/main/MCP%E7%BB%88%E6%9E%81%E6%8C%87%E5%8D%97-%E7%95%AA%E5%A4%96%E7%AF%87/llm_logger.py">这里</a>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> httpx</span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, Request</span><br><span class="line"><span class="keyword">from</span> starlette.responses <span class="keyword">import</span> StreamingResponse</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AppLogger</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, log_file=<span class="string">&quot;llm.log&quot;</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Initialize the logger with a file that will be cleared on startup.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>.log_file = log_file</span><br><span class="line">        <span class="comment"># Clear the log file on startup</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="variable language_">self</span>.log_file, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(<span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">log</span>(<span class="params">self, message</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Log a message to both file and console.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Log to file</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="variable language_">self</span>.log_file, <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(message + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Log to console</span></span><br><span class="line">        <span class="built_in">print</span>(message)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">app = FastAPI(title=<span class="string">&quot;LLM API Logger&quot;</span>)</span><br><span class="line">logger = AppLogger(<span class="string">&quot;llm.log&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/chat/completions&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">proxy_request</span>(<span class="params">request: Request</span>):</span><br><span class="line"></span><br><span class="line">    body_bytes = <span class="keyword">await</span> request.body()</span><br><span class="line">    body_str = body_bytes.decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    logger.log(<span class="string">f&quot;模型请求：<span class="subst">&#123;body_str&#125;</span>&quot;</span>)</span><br><span class="line">    body = <span class="keyword">await</span> request.json()</span><br><span class="line"></span><br><span class="line">    logger.log(<span class="string">&quot;模型返回：\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">event_stream</span>():</span><br><span class="line">        <span class="keyword">async</span> <span class="keyword">with</span> httpx.AsyncClient(timeout=<span class="literal">None</span>) <span class="keyword">as</span> client:</span><br><span class="line">            <span class="keyword">async</span> <span class="keyword">with</span> client.stream(</span><br><span class="line">                    <span class="string">&quot;POST&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;https://openrouter.ai/api/v1/chat/completions&quot;</span>,</span><br><span class="line">                    json=body,</span><br><span class="line">                    headers=&#123;</span><br><span class="line">                        <span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;application/json&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;Accept&quot;</span>: <span class="string">&quot;text/event-stream&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;Authorization&quot;</span>: request.headers.get(<span class="string">&quot;Authorization&quot;</span>),  <span class="comment"># 这里获取客户端传入的API Key</span></span><br><span class="line">                    &#125;,</span><br><span class="line">            ) <span class="keyword">as</span> response:</span><br><span class="line">                <span class="keyword">async</span> <span class="keyword">for</span> line <span class="keyword">in</span> response.aiter_lines():</span><br><span class="line">                    logger.log(line)</span><br><span class="line">                    <span class="keyword">yield</span> <span class="string">f&quot;<span class="subst">&#123;line&#125;</span>\n&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> StreamingResponse(event_stream(), media_type=<span class="string">&quot;text/event-stream&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">import</span> uvicorn</span><br><span class="line"></span><br><span class="line">    uvicorn.run(app, host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="number">8000</span>)</span><br></pre></td></tr></table></figure>

<p><strong>代码比较清晰，整体流程：</strong></p>
<ul>
<li>创建日志类</li>
<li>创建<code>FastAPI</code>实例</li>
<li>创建兼容<code>OpenAI</code>的代理端点<code>chat/completions</code></li>
<li>实现流式返回</li>
</ul>
<img src="/2025/06/19/MCP%E7%95%AA%E5%A4%96%EF%BC%9ACline%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B/image-20250619191512554.png" class="" title="image-20250619191512554">

<blockquote>
<p>流式返回的专业名词叫做<code>Server-Sent Events</code>，简称<code>SSE</code>，用于客户端发送一次请求，服务端返回多次的场景。</p>
</blockquote>
<hr>
<h3 id="配置中转服务器"><a href="#配置中转服务器" class="headerlink" title="配置中转服务器"></a>配置中转服务器</h3><p>该部分包含运行中转服务器（安装下依赖）以及配置<code>API provider</code>，略，不会操作可查看参考链接3的8分45秒左右。</p>
<hr>
<h3 id="Cline发往模型的请求"><a href="#Cline发往模型的请求" class="headerlink" title="Cline发往模型的请求"></a>Cline发往模型的请求</h3><p>向<code>Cline</code>发送<code>Hi</code>:</p>
<img src="/2025/06/19/MCP%E7%95%AA%E5%A4%96%EF%BC%9ACline%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B/image-20250619192458576.png" class="" title="image-20250619192458576">

<p>模型请求中包括了：</p>
<ul>
<li>模型名称</li>
<li>消息列表</li>
</ul>
<h4 id="System-Prompt"><a href="#System-Prompt" class="headerlink" title="System Prompt"></a>System Prompt</h4><p>这里的系统提示词超级长，可以见<a href="https://github.com/MarkTechStation/VideoCode/blob/main/MCP%E7%BB%88%E6%9E%81%E6%8C%87%E5%8D%97-%E7%95%AA%E5%A4%96%E7%AF%87/Cline%E7%B3%BB%E7%BB%9F%E6%8F%90%E7%A4%BA%E8%AF%8D%EF%BC%88%E8%8B%B1%E6%96%87%EF%BC%89.md">这里</a>，总计<code>48671</code>个字符，那么这么多内容都包含了什么呢？咱们翻译成中文版方便查看，完整版见<a href="https://github.com/MarkTechStation/VideoCode/blob/main/MCP%E7%BB%88%E6%9E%81%E6%8C%87%E5%8D%97-%E7%95%AA%E5%A4%96%E7%AF%87/Cline%E7%B3%BB%E7%BB%9F%E6%8F%90%E7%A4%BA%E8%AF%8D%EF%BC%88%E4%B8%AD%E6%96%87%EF%BC%89.md">这里</a>，小标题包括：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">工具使用格式</span><br><span class="line"></span><br><span class="line">工具</span><br><span class="line"></span><br><span class="line">工具使用示例</span><br><span class="line"></span><br><span class="line">工具使用指南</span><br><span class="line"></span><br><span class="line">已连接的MCP服务器</span><br><span class="line"></span><br><span class="line">write<span class="built_in">_</span>to<span class="built_in">_</span>file</span><br><span class="line"></span><br><span class="line">replace<span class="built_in">_</span>in<span class="built_in">_</span>file</span><br><span class="line"></span><br><span class="line">选择合适的工具</span><br><span class="line"></span><br><span class="line">自动格式化注意事项</span><br><span class="line"></span><br><span class="line">工作流程提示</span><br><span class="line"></span><br><span class="line">首选语言</span><br></pre></td></tr></table></figure>

<p>注意这里的工具包含两部分内容：</p>
<ul>
<li><code>Cline</code>内置工具<ul>
<li>写入文件</li>
<li>读取文件</li>
<li>替换文件内容</li>
<li>运行终端指令</li>
</ul>
</li>
<li><code>MCP</code>工具<ul>
<li>天气预报</li>
<li>气象预警</li>
</ul>
</li>
</ul>
<h5 id="工具使用格式"><a href="#工具使用格式" class="headerlink" title="工具使用格式"></a><strong>工具使用格式</strong></h5><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="section"># 工具使用格式</span></span><br><span class="line">工具使用采用 XML 风格的标签进行格式化。工具名称包含在开始和结束标签中，每个参数也同样包含在其自己的一组标签中。结构如下：</span><br><span class="line"></span><br><span class="line"><span class="code">```xml</span></span><br><span class="line"><span class="code">&lt;tool_name&gt; </span></span><br><span class="line"><span class="code">&lt;parameter1_name&gt;value1&lt;/parameter1_name&gt;</span></span><br><span class="line"><span class="code">&lt;parameter2_name&gt;value2&lt;/parameter2_name&gt;</span></span><br><span class="line"><span class="code">... </span></span><br><span class="line"><span class="code">&lt;/tool_name&gt;</span></span><br><span class="line"><span class="code">```</span></span><br><span class="line"></span><br><span class="line">例如：</span><br><span class="line"></span><br><span class="line"><span class="code">```xml</span></span><br><span class="line"><span class="code">&lt;read_file&gt;</span></span><br><span class="line"><span class="code">src/main.js</span></span><br><span class="line"><span class="code">&lt;/read_file&gt;</span></span><br><span class="line"><span class="code">```</span></span><br><span class="line">始终遵守此格式以确保工具使用的正确解析和执行。</span><br></pre></td></tr></table></figure>

<p><code>Cline</code>规定了工具调用请求必须要使用<code>XML</code>格式传递，外层写工具的名称，内层写参数的名称和参数值，比如读文件的工具，<code>read_file</code>是函数名，<code>path</code>是参数名，<code>src/main.js</code>是参数值，代表使用<code>read_file</code>去读取<code>src/main.js</code>这个文件的内容，图示流程如下：</p>
<img src="/2025/06/19/MCP%E7%95%AA%E5%A4%96%EF%BC%9ACline%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B/image-20250619200034438.png" class="" title="image-20250619200034438">

<p>那到底有哪些工具可以用呢，模型是怎么知道读取文件用的工具名是<code>read_file</code>呢。</p>
<hr>
<h5 id="工具"><a href="#工具" class="headerlink" title="工具"></a><strong>工具</strong></h5><p> <code>Cline</code>在工具中会给模型详细解释有哪些工具可以用，会告诉模型每个工具的名称、参数格式、用途等等。比如<code>execute_command</code>：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="section"># 工具</span></span><br><span class="line"></span><br><span class="line"><span class="section">## execute<span class="emphasis">_command</span></span></span><br><span class="line"><span class="emphasis"><span class="section">描述：请求在系统上执行一个 CLI 命令。当你需要执行系统操作或运行特定命令来完成用户任务中的任何步骤时，请使用此工具。你必须根据用户的系统定制你的命令，并清楚地解释该命令的作用。对于命令链式调用，请使用用户 shell 对应的链式调用语法。优先执行复杂的 CLI 命令，而不是创建可执行脚本，因为它们更灵活且更易于运行。命令将在当前工作目录中执行：/Users/joeygreen/PycharmProjects/VideoCode/MCP终极指南-番外篇 </span></span></span><br><span class="line"><span class="emphasis"><span class="section"></span></span></span><br><span class="line"><span class="emphasis"><span class="section">参数：</span></span></span><br><span class="line"><span class="emphasis"><span class="section"> - command: (必需) 要执行的 CLI 命令。这应该是对当前操作系统有效的命令。确保命令格式正确，并且不包含任何有害指令。</span></span></span><br><span class="line"><span class="emphasis"><span class="section"> - requires_</span>approval: (必需) 一个布尔值，指示在用户启用了自动批准模式的情况下，此命令是否需要在执行前获得用户的明确批准。对于可能产生重大影响的操作（如安装/卸载软件包、删除/覆盖文件、系统配置更改、网络操作或任何可能产生意外副作用的命令），请设置为 &#x27;true&#x27;。对于安全操作（如读取文件/目录、运行开发服务器、构建项目以及其他非破坏性操作），请设置为 &#x27;false&#x27;。</span></span><br><span class="line"> 用法：</span><br><span class="line"> <span class="code">```xml</span></span><br><span class="line"><span class="code"> &lt;execute_command&gt;</span></span><br><span class="line"><span class="code"> &lt;command&gt;你的命令在此&lt;/command&gt; </span></span><br><span class="line"><span class="code"> &lt;requires_approval&gt;true 或 false&lt;/requires_approval&gt; </span></span><br><span class="line"><span class="code"> &lt;/execute_command&gt;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">还有其他一些工具：</span><br><span class="line"></span><br><span class="line">```markdown</span><br><span class="line">read_file：用于读取文件内容</span><br><span class="line"></span><br><span class="line">write_to_file：将内容写入指定文件</span><br><span class="line"></span><br><span class="line">replace_in_file：替换文件内容</span><br><span class="line"></span><br><span class="line">search_files：搜索文件内容</span><br><span class="line"></span><br><span class="line">list_files：列出文件和目录</span><br><span class="line"></span><br><span class="line">list_code_definition_names：列出指定目录顶层源代码文件中使用的定义名称（类、函数、方法等）</span><br><span class="line"></span><br><span class="line">browser_action：请求与 Puppeteer 控制的浏览器进行交互</span><br></pre></td></tr></table></figure>



<p>✅<strong>下面是重点：</strong></p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line"><span class="section">## use<span class="emphasis">_mcp_</span>tool</span></span><br><span class="line">描述：请求使用由连接的 MCP 服务器提供的工具。每个 MCP 服务器可以提供具有不同功能的多个工具。工具有定义的输入模式，用于指定必需和可选参数。 </span><br><span class="line"></span><br><span class="line">参数：</span><br><span class="line"><span class="bullet"> -</span> server<span class="emphasis">_name: (必需) 提供该工具的 MCP 服务器的名称</span></span><br><span class="line"><span class="emphasis"> - tool_</span>name: (必需) 要执行的工具的名称</span><br><span class="line"><span class="bullet"> -</span> arguments: (必需) 一个 JSON 对象，包含工具的输入参数，遵循工具的输入模式 </span><br><span class="line"> 用法： </span><br><span class="line"> <span class="code">```xml</span></span><br><span class="line"><span class="code"> &lt;use_mcp_tool&gt;</span></span><br><span class="line"><span class="code"> &lt;server_name&gt;服务器名称在此&lt;/server_name&gt; </span></span><br><span class="line"><span class="code"> &lt;tool_name&gt;工具名称在此&lt;/tool_name&gt;</span></span><br><span class="line"><span class="code"> &lt;arguments&gt;</span></span><br><span class="line"><span class="code">&#123; </span></span><br><span class="line"><span class="code">	&quot;param1&quot;: &quot;value1&quot;, </span></span><br><span class="line"><span class="code">	&quot;param2&quot;: &quot;value2&quot;</span></span><br><span class="line"><span class="code">&#125;</span></span><br><span class="line"><span class="code">&lt;/arguments&gt;</span></span><br><span class="line"><span class="code">&lt;/use_mcp_tool&gt;</span></span><br><span class="line"><span class="code">```</span></span><br></pre></td></tr></table></figure>

<p>它的参数分成三个：</p>
<ul>
<li>server_name：服务器名称</li>
<li>tool_name：工具名称</li>
<li>arguments：输入参数</li>
</ul>
<p>示例：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"> <span class="tag">&lt;<span class="name">use_mcp_tool</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">server_name</span>&gt;</span>weather<span class="tag">&lt;/<span class="name">server_name</span>&gt;</span> </span><br><span class="line"> <span class="tag">&lt;<span class="name">tool_name</span>&gt;</span>get_forecast<span class="tag">&lt;/<span class="name">tool_name</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">arguments</span>&gt;</span></span><br><span class="line">&#123; </span><br><span class="line">	&quot;latitude&quot;: 40.7128, </span><br><span class="line">	&quot;longitude&quot;: -74.006</span><br><span class="line">&#125;</span><br><span class="line"><span class="tag">&lt;/<span class="name">arguments</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">use_mcp_tool</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>在下面的工具包括：</p>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">access<span class="emphasis">_mcp_</span>resource：获取MCP资源</span><br><span class="line"></span><br><span class="line">ask<span class="emphasis">_followup_</span>question：向用户提问以获取任务所需的附加信息</span><br><span class="line"></span><br><span class="line">attempt<span class="emphasis">_completion：用于返回最终结论</span></span><br></pre></td></tr></table></figure>

<p><strong>attempt_completion简易交互流程：</strong></p>
<img src="/2025/06/19/MCP%E7%95%AA%E5%A4%96%EF%BC%9ACline%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B/image-20250619202131461.png" class="" title="image-20250619202131461">

<p><strong>attempt_completion更准确的流程（think部分）：</strong></p>
<img src="/2025/06/19/MCP%E7%95%AA%E5%A4%96%EF%BC%9ACline%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B/image-20250619202246486.png" class="" title="image-20250619202246486">

<p><strong>来个具体的例子：</strong></p>
<p>还是我们之前的经典问题：明天纽约的天气怎么样？发出问题后，</p>
<p><strong>第一步thinking：</strong></p>
<img src="/2025/06/19/MCP%E7%95%AA%E5%A4%96%EF%BC%9ACline%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B/image-20250619202537061.png" class="" title="image-20250619202537061">

<p><strong>第二步：调用<code>MCP</code>工具</strong></p>
<img src="/2025/06/19/MCP%E7%95%AA%E5%A4%96%EF%BC%9ACline%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B/image-20250619202715758.png" class="" title="image-20250619202715758">

<p><strong>第三步：Response是<code>Cline</code>返回给模型的结果</strong></p>
<img src="/2025/06/19/MCP%E7%95%AA%E5%A4%96%EF%BC%9ACline%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B/image-20250619202854719.png" class="" title="image-20250619202854719">

<p><strong>第四步：模型拿到结果后先thinking</strong></p>
<img src="/2025/06/19/MCP%E7%95%AA%E5%A4%96%EF%BC%9ACline%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B/image-20250619203010260.png" class="" title="image-20250619203010260">

<p><strong>第五步：模型觉得完成这个任务了</strong></p>
<img src="/2025/06/19/MCP%E7%95%AA%E5%A4%96%EF%BC%9ACline%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B/image-20250619203101212.png" class="" title="image-20250619203101212">



<p>✅<strong>已连接的服务器：</strong></p>
<p>这一块会把用户在<code>Cline</code>上配置的<code>MCP</code>服务器和所包含的<code>MCP</code>工具列举出来供模型选用，也包含工具描述和参数描述。</p>
<p>其他部分不太重要，此处跳过。</p>
<hr>
<h4 id="用户请求"><a href="#用户请求" class="headerlink" title="用户请求"></a>用户请求</h4><p>此部分包含两部分：</p>
<ul>
<li>用户输入，由&lt;task&gt;…&lt;&#x2F;task&gt;标签包围</li>
<li>额外环境信息，由<environment_details>…</environment_details>包围，包含一些额外信息，比如<ul>
<li>目前可见的文件</li>
<li>打开的Tabs</li>
<li>现在的时间</li>
<li>当前目录下的文件</li>
<li>已使用的tokens</li>
<li>现在的模式（ACT OR PLAN）</li>
</ul>
</li>
</ul>
<blockquote>
<p>temperature越小越固定。</p>
</blockquote>
<hr>
<h4 id="模型返回"><a href="#模型返回" class="headerlink" title="模型返回"></a>模型返回</h4><p>注意点：</p>
<ul>
<li>以<code>：</code>开头的信息是注释信息（无实际信息，作用是保持连接）</li>
<li>以<code>data</code>开头的信息是模型返回的结构化数据，子字段<code>content</code>包含流式传输数据</li>
</ul>
<p>当向<code>Cline</code>发送<code>Hi</code>的时候，子字段<code>content</code>中的内容会包括<code>&lt;thinking&gt;</code>和<code>&lt;ask_followup_question&gt;</code>这两部分的内容，因为我们只打了个招呼，所以模型会问我们有没有具体任务：</p>
<img src="/2025/06/19/MCP%E7%95%AA%E5%A4%96%EF%BC%9ACline%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B/image-20250620093246910.png" class="" title="image-20250620093246910">

<hr>
<h4 id="调用MCP工具时模型的请求和返回"><a href="#调用MCP工具时模型的请求和返回" class="headerlink" title="调用MCP工具时模型的请求和返回"></a>调用<code>MCP</code>工具时模型的请求和返回</h4><p>模型返回的子字段<code>content</code>组合起来：</p>
<img src="/2025/06/19/MCP%E7%95%AA%E5%A4%96%EF%BC%9ACline%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B/image-20250620094314905-1750383799716-1.png" class="" title="image-20250620094314905">

<p>可以看出模型是先思考，然后使用<code>XML</code>格式向<code>Cline</code>提起调用<code>Weather</code>这个<code>MCP Server</code>。</p>
<p><code>Cline</code>用指定的参数调用指定的<code>MCP Server</code>之后，会再次对模型发起请求，为实现模型的记忆功能，第二次请求会先发送第一次请求的内容，模型才知道前因后果：</p>
<img src="/2025/06/19/MCP%E7%95%AA%E5%A4%96%EF%BC%9ACline%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B/image-20250620095010772.png" class="" title="image-20250620095010772">

<p>紧接着是模型(assistant)的回复，包含<code>&lt;thinking&gt;</code>和想要调用<code>weather</code>这个<code>MCPServer</code>的<code>XML</code>格式，再接着是<code>Cline</code>(user)的返回结果，包含：</p>
<ul>
<li><code>MCP</code>工具的调用结果</li>
<li>结果的具体内容，即上文第三步中的<code>Response</code></li>
<li>环境信息，比如当前打开的<code>Tab</code>，时间信息等等</li>
</ul>
<img src="/2025/06/19/MCP%E7%95%AA%E5%A4%96%EF%BC%9ACline%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B/image-20250620095205618.png" class="" title="image-20250620095205618">

<p>模型获得上述信息后，依旧会流式返回具体内容（<code>：</code>开头的注释内容，<code>data</code>开头的具体信息，子字段<code>content</code>包含具体内容），具体内容组合后：</p>
<img src="/2025/06/19/MCP%E7%95%AA%E5%A4%96%EF%BC%9ACline%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B/image-20250620100756734.png" class="" title="image-20250620100756734">

<p>模型会先思考一番，然后认为自己已经完成任务了，就将最终返回结果包含在<code>attempt_completion</code>标签中，<code>Cline</code>会将模型的返回内容显式在对应位置。</p>
<hr>
<h3 id="Cline的XML协议与ReAct的关系"><a href="#Cline的XML协议与ReAct的关系" class="headerlink" title="Cline的XML协议与ReAct的关系"></a><code>Cline</code>的<code>XML</code>协议与<code>ReAct</code>的关系</h3><p>先以流程图的形式总结下上述流程：</p>
<img src="/2025/06/19/MCP%E7%95%AA%E5%A4%96%EF%BC%9ACline%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B/image-20250620101346042.png" class="" title="image-20250620101346042">

<p><strong>文字版说明（让我们站在<code>Cline</code>的角度看待这个过程）：</strong></p>
<ul>
<li>我问模型一个问题：纽约明天的天气怎么样？</li>
<li>模型想了想，觉得要调用我这边某个工具才能得到答案，然后按固定格式告诉了我工具名和参数</li>
<li>我去调用了工具，将结果给到模型</li>
<li>模型拿到我给的工具结果，思考总结后将最终答案返回给我</li>
</ul>
<p>那如果我的问题变一变呢，让其将结果写入到<code>result.md</code>中，那么在<attempt_completion>前会加一套调用别的工具的流程，之后才能完成任务：</p>
<img src="/2025/06/19/MCP%E7%95%AA%E5%A4%96%EF%BC%9ACline%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B/image-20250620102128105.png" class="" title="image-20250620102128105">

<p>其中：</p>
<ul>
<li>&lt;thinking&gt;对应了思考（thought）</li>
<li>调用工具&#x2F;给出最终答案对应了行动（Action），紧挨在思考之后</li>
<li>如果任务未完成，即模型需要使用我（<code>Cline</code>）这边的能力，那么模型就需要观察（Observation）我这边的反馈结果。</li>
</ul>
<p><code>Thought</code>，<code>Action</code>，<code>Observation</code>是<code>ReAct</code>中最重要的三个词，<code>ReAct</code>是一篇2022的论文（REACT: synergizing reasoning and acting in language models）提出的一个词，它是reasoning和acting两个单词的合体，他提出的<code>ReACT</code>理念可以在不需要人干预的前提下，让模型自主思考，自主调用各类外部工具，从而完成用户指定的任务，就像<code>Cline</code>一样，本质上其实是个<code>Agent</code>。<code>Agent</code>是一个能持续思考，持续调用外部工具，直至解决用户问题的程序。<code>Cline</code>本质上也是根据<code>ReAct</code>思想进行它的<code>Agent</code>流程的，注意<code>ReAct</code>是个思想，精髓在于<code>Thought</code>，<code>Action</code>，<code>Observation</code>这三个词，并不对交互格式做要求，无论你是像<code>Cline</code>一样用<code>XML</code>格式，还是像<code>Cherry Studio</code>一样用<code>function call</code>那种格式，甚至用<code>ReAct</code>论文中那种近乎纯文本的格式，都是<code>ReAct</code>思想。</p>
<p>近乎纯文本的方式：</p>
<img src="/2025/06/19/MCP%E7%95%AA%E5%A4%96%EF%BC%9ACline%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B/image-20250620104138101.png" class="" title="image-20250620104138101">

<p>无论是<code>XML</code>格式还是纯文本方式，都是由<code>System Prompt</code>进行规定的，但注意<code>Cline</code>的系统提示词是改不了的，所以并不能让<code>Cline</code>使用纯文本方式进行工具调用，但如果你自己写<code>MCP Host</code>的时候，这种类似的系统提示词就能给你灵感了，下面给个纯文本方式交互的系统提示词以供参考：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">你需要解决一个任务。为此，你需要将任务分解为多个步骤。对于每个步骤，首先使用 `Thought:` 思考要做什么，然后使用可用工具之一决定一个 `Action:`。接着，你将根据你的行动从环境/工具中收到一个 `Observation:`。持续这个思考和行动的过程，直到你有足够的信息来提供 `FinalAnswer:`。</span><br><span class="line"></span><br><span class="line">这里有一些例子：</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">示例 1:</span><br><span class="line"></span><br><span class="line">Question: 埃菲尔铁塔有多高？</span><br><span class="line">Thought: 我需要找到埃菲尔铁塔的高度。可以使用搜索工具。</span><br><span class="line">Action: get<span class="built_in">_</span>height(&quot;埃菲尔铁塔&quot;)</span><br><span class="line">Observation: 埃菲尔铁塔的高度约为330米（包含天线）。</span><br><span class="line">Thought: 搜索结果显示了高度。我已经得到答案了。</span><br><span class="line">FinalAnswer: 埃菲尔铁塔的高度约为330米。</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">示例 2:</span><br><span class="line"></span><br><span class="line">Question: 帮我找一个简单的番茄炒蛋食谱，并看看家里的冰箱里有没有西红柿。</span><br><span class="line">Thought: 这个任务分两步。第一步，找到番茄炒蛋的食谱。第二步，检查冰箱里是否有西红柿。我先用 `find<span class="built_in">_</span>recipe` 工具找食谱。</span><br><span class="line">Action: find<span class="built_in">_</span>recipe(dish=&quot;番茄炒蛋&quot;)</span><br><span class="line">Observation: 简单的番茄炒蛋食谱：将2个鸡蛋打散，2个番茄切块。热油，先炒鸡蛋，盛出。再热油，炒番茄至软烂，加入鸡蛋，放盐调味即可。</span><br><span class="line">Thought: 好的，我已经有食谱了。食谱需要西红柿。现在我需要用 `check<span class="built_in">_</span>fridge` 工具看看冰箱里有没有西红柿。</span><br><span class="line">Action: check<span class="built_in">_</span>fridge(item=&quot;西红柿&quot;)</span><br><span class="line">Observation: 冰箱检查结果：有3个西红柿。</span><br><span class="line">Thought: 我找到了食谱，并且确认了冰箱里有西红柿。可以回答问题了。</span><br><span class="line">FinalAnswer: 简单的番茄炒蛋食谱是：鸡蛋打散，番茄切块。先炒鸡蛋，再炒番茄，混合后加盐调味。冰箱里有3个西红柿。</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">请严格遵守：</span><br><span class="line">- 输出Action后立即停止生成</span><br><span class="line">- 等待返回真实的Observation</span><br><span class="line">- 擅自生成Observation将导致错误</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">本次任务可用工具：</span><br><span class="line"></span><br><span class="line">- get<span class="built_in">_</span>forecast(latitude, longitude): 获取指定坐标的天气预报。返回包含预报信息的字符串。</span><br><span class="line">- write<span class="built_in">_</span>to<span class="built_in">_</span>file(filename, content): 将指定内容写入指定文件。成功时返回 &quot;写入成功&quot;。</span><br></pre></td></tr></table></figure>

<p>最后总结下<code>Agent</code>：</p>
<img src="/2025/06/19/MCP%E7%95%AA%E5%A4%96%EF%BC%9ACline%E4%B8%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BA%A4%E4%BA%92%E8%BF%87%E7%A8%8B/image-20250620105044487.png" class="" title="image-20250620105044487">

<hr>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://caihaoran-00.github.io/2025/06/09/MCP%E5%9F%BA%E7%A1%80%EF%BC%9A%E4%BB%8E%E5%8E%9F%E7%90%86%E5%88%B0%E5%AE%9E%E6%88%98/">https://caihaoran-00.github.io/2025/06/09/MCP%E5%9F%BA%E7%A1%80%EF%BC%9A%E4%BB%8E%E5%8E%9F%E7%90%86%E5%88%B0%E5%AE%9E%E6%88%98/</a></li>
<li><a href="https://caihaoran-00.github.io/2025/06/12/MCP%E8%BF%9B%E9%98%B6%EF%BC%9A%E5%B8%A6%E4%BD%A0%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8F%A1MCP/">https://caihaoran-00.github.io/2025/06/12/MCP%E8%BF%9B%E9%98%B6%EF%BC%9A%E5%B8%A6%E4%BD%A0%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8F%A1MCP/</a></li>
<li><a href="https://www.bilibili.com/video/BV1v9V5zSEHA/?spm_id_from=333.1387.homepage.video_card.click&vd_source=075a061948e76c87e2ee8754e264056e">https://www.bilibili.com/video/BV1v9V5zSEHA/?spm_id_from=333.1387.homepage.video_card.click&amp;vd_source=075a061948e76c87e2ee8754e264056e</a></li>
<li><a href="https://github.com/MarkTechStation/VideoCode/blob/main/MCP%E7%BB%88%E6%9E%81%E6%8C%87%E5%8D%97-%E7%95%AA%E5%A4%96%E7%AF%87/llm_logger.py">https://github.com/MarkTechStation/VideoCode/blob/main/MCP%E7%BB%88%E6%9E%81%E6%8C%87%E5%8D%97-%E7%95%AA%E5%A4%96%E7%AF%87/llm_logger.py</a></li>
<li><a href="https://github.com/MarkTechStation/VideoCode/blob/main/MCP%E7%BB%88%E6%9E%81%E6%8C%87%E5%8D%97-%E7%95%AA%E5%A4%96%E7%AF%87/Cline%E7%B3%BB%E7%BB%9F%E6%8F%90%E7%A4%BA%E8%AF%8D%EF%BC%88%E8%8B%B1%E6%96%87%EF%BC%89.md">https://github.com/MarkTechStation/VideoCode/blob/main/MCP%E7%BB%88%E6%9E%81%E6%8C%87%E5%8D%97-%E7%95%AA%E5%A4%96%E7%AF%87/Cline%E7%B3%BB%E7%BB%9F%E6%8F%90%E7%A4%BA%E8%AF%8D%EF%BC%88%E8%8B%B1%E6%96%87%EF%BC%89.md</a></li>
<li><a href="https://github.com/MarkTechStation/VideoCode/blob/main/MCP%E7%BB%88%E6%9E%81%E6%8C%87%E5%8D%97-%E7%95%AA%E5%A4%96%E7%AF%87/Cline%E7%B3%BB%E7%BB%9F%E6%8F%90%E7%A4%BA%E8%AF%8D%EF%BC%88%E4%B8%AD%E6%96%87%EF%BC%89.md">https://github.com/MarkTechStation/VideoCode/blob/main/MCP%E7%BB%88%E6%9E%81%E6%8C%87%E5%8D%97-%E7%95%AA%E5%A4%96%E7%AF%87/Cline%E7%B3%BB%E7%BB%9F%E6%8F%90%E7%A4%BA%E8%AF%8D%EF%BC%88%E4%B8%AD%E6%96%87%EF%BC%89.md</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>agent</tag>
        <tag>mcp</tag>
      </tags>
  </entry>
  <entry>
    <title>MCP进阶：带你深入掌握MCP</title>
    <url>/2025/06/12/MCP%E8%BF%9B%E9%98%B6%EF%BC%9A%E5%B8%A6%E4%BD%A0%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8F%A1MCP/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前面我们一起看了<a href="https://caihaoran-00.github.io/2025/06/09/MCP%E5%9F%BA%E7%A1%80%EF%BC%9A%E4%BB%8E%E5%8E%9F%E7%90%86%E5%88%B0%E5%AE%9E%E6%88%98/">MCP基础：从原理到实战</a>，重点讲解了<code>MCP</code>的原理，并进行了一些实战，今天一起看下进阶篇，主要包含三个方面：</p>
<ul>
<li>写一个<code>MCP  Server</code></li>
<li>截获<code>MCP Server的输入和输出</code>，分析<code>MCP</code>底层协议</li>
<li>回头想<code>MCP</code>的含义和定位&#x2F;扮演的角色</li>
</ul>
<span id="more"></span>

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="写一个MCP-Server"><a href="#写一个MCP-Server" class="headerlink" title="写一个MCP Server"></a>写一个<code>MCP Server</code></h3><p>以下选择<code>Python</code>作为编程语言进行<code>MCP Server</code>的编写，关于<code>uv</code>的安装可以参考参考链接1：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 初始化项目</span></span><br><span class="line">uv init weather</span><br><span class="line"><span class="built_in">cd</span> weather</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建并激活虚拟环境</span></span><br><span class="line">uv venv</span><br><span class="line"><span class="built_in">source</span> .venv/bin/activate</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加依赖</span></span><br><span class="line">uv add <span class="string">&quot;mcp[cli]&quot;</span> httpx</span><br></pre></td></tr></table></figure>

<p>使用<code>VScode</code>打开刚才创建的<code>weather</code>项目，创建<code>weather.py</code>，将下面的代码复制到你的文件中（代码的解析放在文末）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Any</span></span><br><span class="line"><span class="keyword">import</span> httpx</span><br><span class="line"><span class="keyword">from</span> mcp.server.fastmcp <span class="keyword">import</span> FastMCP</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize FastMCP server</span></span><br><span class="line">mcp = FastMCP(<span class="string">&quot;weather&quot;</span>, log_level=<span class="string">&quot;ERROR&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Constants</span></span><br><span class="line">NWS_API_BASE = <span class="string">&quot;https://api.weather.gov&quot;</span></span><br><span class="line">USER_AGENT = <span class="string">&quot;weather-app/1.0&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">make_nws_request</span>(<span class="params">url: <span class="built_in">str</span></span>) -&gt; <span class="built_in">dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>] | <span class="literal">None</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Make a request to the NWS API with proper error handling.&quot;&quot;&quot;</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&quot;User-Agent&quot;</span>: USER_AGENT,</span><br><span class="line">        <span class="string">&quot;Accept&quot;</span>: <span class="string">&quot;application/geo+json&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> httpx.AsyncClient() <span class="keyword">as</span> client:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            response = <span class="keyword">await</span> client.get(url, headers=headers, timeout=<span class="number">30.0</span>)</span><br><span class="line">            response.raise_for_status()</span><br><span class="line">            <span class="keyword">return</span> response.json()</span><br><span class="line">        <span class="keyword">except</span> Exception:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">format_alert</span>(<span class="params">feature: <span class="built_in">dict</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Format an alert feature into a readable string.&quot;&quot;&quot;</span></span><br><span class="line">    props = feature[<span class="string">&quot;properties&quot;</span>]</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Event: <span class="subst">&#123;props.get(<span class="string">&#x27;event&#x27;</span>, <span class="string">&#x27;Unknown&#x27;</span>)&#125;</span></span></span><br><span class="line"><span class="string">Area: <span class="subst">&#123;props.get(<span class="string">&#x27;areaDesc&#x27;</span>, <span class="string">&#x27;Unknown&#x27;</span>)&#125;</span></span></span><br><span class="line"><span class="string">Severity: <span class="subst">&#123;props.get(<span class="string">&#x27;severity&#x27;</span>, <span class="string">&#x27;Unknown&#x27;</span>)&#125;</span></span></span><br><span class="line"><span class="string">Description: <span class="subst">&#123;props.get(<span class="string">&#x27;description&#x27;</span>, <span class="string">&#x27;No description available&#x27;</span>)&#125;</span></span></span><br><span class="line"><span class="string">Instructions: <span class="subst">&#123;props.get(<span class="string">&#x27;instruction&#x27;</span>, <span class="string">&#x27;No specific instructions provided&#x27;</span>)&#125;</span></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@mcp.tool()</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">get_alerts</span>(<span class="params">state: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Get weather alerts for a US state.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        state: Two-letter US state code (e.g. CA, NY)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    url = <span class="string">f&quot;<span class="subst">&#123;NWS_API_BASE&#125;</span>/alerts/active/area/<span class="subst">&#123;state&#125;</span>&quot;</span></span><br><span class="line">    data = <span class="keyword">await</span> make_nws_request(url)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> data <span class="keyword">or</span> <span class="string">&quot;features&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> data:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Unable to fetch alerts or no alerts found.&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> data[<span class="string">&quot;features&quot;</span>]:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;No active alerts for this state.&quot;</span></span><br><span class="line"></span><br><span class="line">    alerts = [format_alert(feature) <span class="keyword">for</span> feature <span class="keyword">in</span> data[<span class="string">&quot;features&quot;</span>]]</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;\n---\n&quot;</span>.join(alerts)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@mcp.tool()</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">get_forecast</span>(<span class="params">latitude: <span class="built_in">float</span>, longitude: <span class="built_in">float</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Get weather forecast for a location.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        latitude: Latitude of the location</span></span><br><span class="line"><span class="string">        longitude: Longitude of the location</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># First get the forecast grid endpoint</span></span><br><span class="line">    points_url = <span class="string">f&quot;<span class="subst">&#123;NWS_API_BASE&#125;</span>/points/<span class="subst">&#123;latitude&#125;</span>,<span class="subst">&#123;longitude&#125;</span>&quot;</span></span><br><span class="line">    points_data = <span class="keyword">await</span> make_nws_request(points_url)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> points_data:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Unable to fetch forecast data for this location.&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get the forecast URL from the points response</span></span><br><span class="line">    forecast_url = points_data[<span class="string">&quot;properties&quot;</span>][<span class="string">&quot;forecast&quot;</span>]</span><br><span class="line">    forecast_data = <span class="keyword">await</span> make_nws_request(forecast_url)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> forecast_data:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Unable to fetch detailed forecast.&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Format the periods into a readable forecast</span></span><br><span class="line">    periods = forecast_data[<span class="string">&quot;properties&quot;</span>][<span class="string">&quot;periods&quot;</span>]</span><br><span class="line">    forecasts = []</span><br><span class="line">    <span class="keyword">for</span> period <span class="keyword">in</span> periods[:<span class="number">5</span>]:  <span class="comment"># Only show next 5 periods</span></span><br><span class="line">        forecast = <span class="string">f&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"><span class="subst">&#123;period[<span class="string">&#x27;name&#x27;</span>]&#125;</span>:</span></span><br><span class="line"><span class="string">Temperature: <span class="subst">&#123;period[<span class="string">&#x27;temperature&#x27;</span>]&#125;</span>°<span class="subst">&#123;period[<span class="string">&#x27;temperatureUnit&#x27;</span>]&#125;</span></span></span><br><span class="line"><span class="string">Wind: <span class="subst">&#123;period[<span class="string">&#x27;windSpeed&#x27;</span>]&#125;</span> <span class="subst">&#123;period[<span class="string">&#x27;windDirection&#x27;</span>]&#125;</span></span></span><br><span class="line"><span class="string">Forecast: <span class="subst">&#123;period[<span class="string">&#x27;detailedForecast&#x27;</span>]&#125;</span></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">        forecasts.append(forecast)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;\n---\n&quot;</span>.join(forecasts)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># Initialize and run the server</span></span><br><span class="line">    mcp.run(transport=<span class="string">&#x27;stdio&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>接下来需要把这个<code>MCP Server</code>注册到<code>Cline</code>中，在参考链接1中有详细过程，这里简述一下：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">点击侧边栏cline-&gt; MCP Severs -&gt; Installed -&gt; Configure MCP Servers</span><br></pre></td></tr></table></figure>

<p>这时候就会创建一个<code>clien_mcp_settings.json</code>，将下面内容复制进去：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;mcpServers&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;weather&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;disabled&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;timeout&quot;</span><span class="punctuation">:</span> <span class="number">60</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;command&quot;</span><span class="punctuation">:</span> <span class="string">&quot;uv&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="string">&quot;--directory&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;/home/chr/桌面/weather&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;run&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;weather.py&quot;</span></span><br><span class="line">      <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;transportType&quot;</span><span class="punctuation">:</span> <span class="string">&quot;stdio&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：</p>
<ul>
<li><code>/home/chr/桌面/weather</code>是我的<code>weather.py</code>的绝对路径，需换成你的绝对路径</li>
<li>默认的<code>transportType</code>就是<code>stdio</code>，这里写出来只是为了说明有这个参数</li>
</ul>
</blockquote>
<p>然后你就可以问<code>Clien</code>天气信息了，比如：纽约明天天气怎么样。</p>
<hr>
<h3 id="分析MCP底层协议"><a href="#分析MCP底层协议" class="headerlink" title="分析MCP底层协议"></a>分析<code>MCP</code>底层协议</h3><p>那么自己创建了一个<code>MCP Server</code>，但我们并不知道<code>MCP</code>这个协议是如何运行的，因为<code>MCP</code>的库报我们完成了很多东西，我们并不知道它帮我们做了什么，那如何才能知道呢？首先大家需要知道的是，大部分<code>MCP Server</code>都是通过输出和输出与<code>MCP Host</code>进行通信的。</p>
<img src="/2025/06/12/MCP%E8%BF%9B%E9%98%B6%EF%BC%9A%E5%B8%A6%E4%BD%A0%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8F%A1MCP/image-20250619145352329.png" class="" title="image-20250619145352329">

<p>如果这个<code>MCP Server</code>是在我们终端中启动的，那我们就可以直接看到它的输入和输出，但这些<code>MCP Server</code>是<code>Cline</code>启动的，只有<code>Cline</code>能看到，所以佬就想到通过一个叫做<code>mcp_logger.py</code>的脚本来截取<code>weather.py</code>的输入和输出</p>
<img src="/2025/06/12/MCP%E8%BF%9B%E9%98%B6%EF%BC%9A%E5%B8%A6%E4%BD%A0%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8F%A1MCP/image-20250619150040766.png" class="" title="image-20250619150040766">

<p><code>mcp_logger.py</code>的内容见<a href="https://github.com/MarkTechStation/VideoCode/blob/main/MCP%E7%BB%88%E6%9E%81%E6%8C%87%E5%8D%97-%E8%BF%9B%E9%98%B6%E7%AF%87/weather/mcp_logger.py">这里</a>，创建该文件在<code>weather</code>项目中，然后修改下<code>cline_mcp_settings.json</code>的内容，更改启动参数：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;mcpServers&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;weather&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;disabled&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;timeout&quot;</span><span class="punctuation">:</span> <span class="number">60</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;command&quot;</span><span class="punctuation">:</span> <span class="string">&quot;python&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="string">&quot;/home/chr/桌面/weather/mcp_logger.py&quot;</span></span><br><span class="line">        <span class="string">&quot;uv&quot;</span></span><br><span class="line">        <span class="string">&quot;--directory&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;/home/chr/桌面/weather&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;run&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;weather.py&quot;</span></span><br><span class="line">      <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;transportType&quot;</span><span class="punctuation">:</span> <span class="string">&quot;stdio&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>保存后就会在<code>/home/chr/桌面/weather/</code>目录下出现<code>mcp_io.log</code>，内容如下：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">输入: &#123;&quot;method&quot;:&quot;initialize&quot;,&quot;params&quot;:&#123;&quot;protocolVersion&quot;:&quot;2025-03-26&quot;,&quot;capabilities&quot;:&#123;&#125;,&quot;clientInfo&quot;:&#123;&quot;name&quot;:&quot;Cline&quot;,&quot;version&quot;:&quot;3.17.12&quot;&#125;&#125;,&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;id&quot;:0&#125;</span><br><span class="line"></span><br><span class="line">输出: &#123;&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;id&quot;:0,&quot;result&quot;:&#123;&quot;protocolVersion&quot;:&quot;2025-03-26&quot;,&quot;capabilities&quot;:&#123;&quot;experimental&quot;:&#123;&#125;,&quot;prompts&quot;:&#123;&quot;listChanged&quot;:false&#125;,&quot;resources&quot;:&#123;&quot;subscribe&quot;:false,&quot;listChanged&quot;:false&#125;,&quot;tools&quot;:&#123;&quot;listChanged&quot;:false&#125;&#125;,&quot;serverInfo&quot;:&#123;&quot;name&quot;:&quot;weather&quot;,&quot;version&quot;:&quot;1.9.4&quot;&#125;&#125;&#125;</span><br><span class="line"></span><br><span class="line">输入: &#123;&quot;method&quot;:&quot;notifications/initialized&quot;,&quot;jsonrpc&quot;:&quot;2.0&quot;&#125;</span><br><span class="line"></span><br><span class="line">输入: &#123;&quot;method&quot;:&quot;tools/list&quot;,&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;id&quot;:1&#125;</span><br><span class="line"></span><br><span class="line">输出: &#123;&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;id&quot;:1,&quot;result&quot;:&#123;&quot;tools&quot;:[&#123;&quot;name&quot;:&quot;get<span class="built_in">_</span>alerts&quot;,&quot;description&quot;:&quot;Get weather alerts for a US state.<span class="keyword">\n</span><span class="keyword">\nArgs</span>:<span class="keyword">\n</span>    state: Two-letter US state code (e.g. CA, NY)<span class="keyword">\n</span>&quot;,&quot;inputSchema&quot;:&#123;&quot;properties&quot;:&#123;&quot;state&quot;:&#123;&quot;title&quot;:&quot;State&quot;,&quot;type&quot;:&quot;string&quot;&#125;&#125;,&quot;required&quot;:[&quot;state&quot;],&quot;title&quot;:&quot;get<span class="built_in">_</span>alertsArguments&quot;,&quot;type&quot;:&quot;object&quot;&#125;&#125;,&#123;&quot;name&quot;:&quot;get<span class="built_in">_</span>forecast&quot;,&quot;description&quot;:&quot;Get weather forecast for a location.<span class="keyword">\n</span><span class="keyword">\nArgs</span>:<span class="keyword">\n</span>    latitude: Latitude of the location<span class="keyword">\n</span>    longitude: Longitude of the location<span class="keyword">\n</span>&quot;,&quot;inputSchema&quot;:&#123;&quot;properties&quot;:&#123;&quot;latitude&quot;:&#123;&quot;title&quot;:&quot;Latitude&quot;,&quot;type&quot;:&quot;number&quot;&#125;,&quot;longitude&quot;:&#123;&quot;title&quot;:&quot;Longitude&quot;,&quot;type&quot;:&quot;number&quot;&#125;&#125;,&quot;required&quot;:[&quot;latitude&quot;,&quot;longitude&quot;],&quot;title&quot;:&quot;get<span class="built_in">_</span>forecastArguments&quot;,&quot;type&quot;:&quot;object&quot;&#125;&#125;]&#125;&#125;</span><br><span class="line"></span><br><span class="line">输入: &#123;&quot;method&quot;:&quot;resources/list&quot;,&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;id&quot;:2&#125;</span><br><span class="line"></span><br><span class="line">输出: &#123;&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;id&quot;:2,&quot;result&quot;:&#123;&quot;resources&quot;:[]&#125;&#125;</span><br><span class="line"></span><br><span class="line">输入: &#123;&quot;method&quot;:&quot;resources/templates/list&quot;,&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;id&quot;:3&#125;</span><br><span class="line"></span><br><span class="line">输出: &#123;&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;id&quot;:3,&quot;result&quot;:&#123;&quot;resourceTemplates&quot;:[]&#125;&#125;</span><br></pre></td></tr></table></figure>

<p>注意：<code>输入：</code>和<code>输出：</code>是<code>mcp_logger.py</code>加的，不属于<code>Cline</code>与<code>MCP Server</code>的交互内容，输入指的是：<code>Cline-&gt;MCP Server</code>，输出反之。咱们看下第一部分：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;method&quot;</span><span class="punctuation">:</span><span class="string">&quot;initialize&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;params&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;protocolVersion&quot;</span><span class="punctuation">:</span><span class="string">&quot;2025-03-26&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;capabilities&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;clientInfo&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;Cline&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span><span class="string">&quot;3.17.12&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span><span class="string">&quot;2.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">0</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>这是<code>Cline</code>告诉<code>MCP  Server</code>：你好，我是<code>Cline</code>，我的版本号是<code>3.17.12</code>，我用的协议版本是<code>2025-03-26</code>发布的。</p>
<p>第二部分：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span><span class="string">&quot;2.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;result&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;protocolVersion&quot;</span><span class="punctuation">:</span><span class="string">&quot;2025-03-26&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;capabilities&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;experimental&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;prompts&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;listChanged&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;resources&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;subscribe&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;listChanged&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;tools&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;listChanged&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;serverInfo&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;weather&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span><span class="string">&quot;1.9.4&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>这是<code>MCP  Server</code>回复<code>Cline</code>：你也好，我用的协议版本也是<code>2025-03-26</code>发布的，我有一些能力是不支持的哦，分别是…，对了，我的名字叫做<code>weather</code>，版本号<code>1.9.4</code>，很高兴认识你。</p>
<p>第三和第四部分依次是<code>Cline</code>发送给<code>MCP  Server</code>：</p>
<ul>
<li>收到</li>
<li>给我下工具列表</li>
</ul>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;method&quot;</span><span class="punctuation">:</span><span class="string">&quot;notifications/initialized&quot;</span><span class="punctuation">,</span><span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span><span class="string">&quot;2.0&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;method&quot;</span><span class="punctuation">:</span><span class="string">&quot;tools/list&quot;</span><span class="punctuation">,</span><span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span><span class="string">&quot;2.0&quot;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>



<p>第五部分，<code>MCP  Server</code>回复<code>Cline</code>：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span><span class="string">&quot;2.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;result&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;tools&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;get_alerts&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span><span class="string">&quot;Get weather alerts for a US state.\n\nArgs:\n    state: Two-letter US state 									code (e.g. CA, NY)\n&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;inputSchema&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;properties&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;state&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">                            <span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;State&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;string&quot;</span></span><br><span class="line">                        <span class="punctuation">&#125;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;required&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;state&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;get_alertsArguments&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;object&quot;</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="punctuation">&#123;</span></span><br><span class="line">                <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;get_forecast&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span><span class="string">&quot;Get weather forecast for a location.\n\nArgs:\n    latitude: Latitude of the 					location\n    longitude: Longitude of the location\n&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="attr">&quot;inputSchema&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;properties&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">                        <span class="attr">&quot;latitude&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">                            <span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Latitude&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;number&quot;</span></span><br><span class="line">                        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                        <span class="attr">&quot;longitude&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">                            <span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Longitude&quot;</span><span class="punctuation">,</span></span><br><span class="line">                            <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;number&quot;</span></span><br><span class="line">                        <span class="punctuation">&#125;</span></span><br><span class="line">                    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;required&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;latitude&quot;</span><span class="punctuation">,</span><span class="string">&quot;longitude&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;get_forecastArguments&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;object&quot;</span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>可以看出，其包含两个<code>tool</code>，一个是<code>get_alerts</code>，另一个是<code>get_forecast</code>，遵循的是同一种格式，我们以<code>get_forecast</code>为例进行讲解：</p>
<ul>
<li><p><code>name</code>-&gt;工具名，<code>weather.py</code>中定义的工具名：<code>get_forecast</code></p>
</li>
<li><p><code>description</code>-&gt;描述，<code>weather.py</code>中定义的工具函数中的描述（<code>docstring</code>）</p>
</li>
<li><p><code>inputSchema</code>：用于指定数据的输入格式规范，遵循的是<code>Json Schema</code>规范</p>
<blockquote>
<p><code>Json Schema</code>本身是<code>Json</code>，但能够用来描述另一个<code>Json</code>的结构。</p>
</blockquote>
</li>
</ul>
<p>注意：上述<code>Json</code>信息均是通过<code>@mcp.tool</code>这个装饰器自动提取的。</p>
<p>剩下的部分是<code>Cline</code>询问<code>MCP  Server</code>有没有资源和资源列表可用，<code>MCP Server</code>的回答都是没有：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;method&quot;</span><span class="punctuation">:</span><span class="string">&quot;resources/list&quot;</span><span class="punctuation">,</span><span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span><span class="string">&quot;2.0&quot;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">2</span><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span><span class="string">&quot;2.0&quot;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">2</span><span class="punctuation">,</span><span class="attr">&quot;result&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;resources&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;method&quot;</span><span class="punctuation">:</span><span class="string">&quot;resources/templates/list&quot;</span><span class="punctuation">,</span><span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span><span class="string">&quot;2.0&quot;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">3</span><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span><span class="string">&quot;2.0&quot;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">3</span><span class="punctuation">,</span><span class="attr">&quot;result&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;resourceTemplates&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>这里先不展开讲资源和资源列表是什么。</p>
</blockquote>
<p>到此时，<code>Cline</code>对<code>MCP Server</code>的摸底就结束了，它就先不说话了，这一切都发生在注册工具的一瞬间，后续就是等待合适的时机使用<code>MCP Server</code>了。</p>
<p>我们再次询问<code>Cline</code>：明天纽约天气怎么样？回答完毕后，我们再打开<code>mcp_io.log</code>，原文如下：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">输入<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;method&quot;</span><span class="punctuation">:</span><span class="string">&quot;initialize&quot;</span><span class="punctuation">,</span><span class="attr">&quot;params&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;protocolVersion&quot;</span><span class="punctuation">:</span><span class="string">&quot;2025-03-26&quot;</span><span class="punctuation">,</span><span class="attr">&quot;capabilities&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;clientInfo&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;Cline&quot;</span><span class="punctuation">,</span><span class="attr">&quot;version&quot;</span><span class="punctuation">:</span><span class="string">&quot;3.17.12&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span><span class="string">&quot;2.0&quot;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line">输出<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span><span class="string">&quot;2.0&quot;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">0</span><span class="punctuation">,</span><span class="attr">&quot;result&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;protocolVersion&quot;</span><span class="punctuation">:</span><span class="string">&quot;2025-03-26&quot;</span><span class="punctuation">,</span><span class="attr">&quot;capabilities&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;experimental&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;prompts&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;listChanged&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;resources&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;subscribe&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span><span class="attr">&quot;listChanged&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;tools&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;listChanged&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;serverInfo&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;weather&quot;</span><span class="punctuation">,</span><span class="attr">&quot;version&quot;</span><span class="punctuation">:</span><span class="string">&quot;1.9.4&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line">输入<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;method&quot;</span><span class="punctuation">:</span><span class="string">&quot;notifications/initialized&quot;</span><span class="punctuation">,</span><span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span><span class="string">&quot;2.0&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line">输入<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;method&quot;</span><span class="punctuation">:</span><span class="string">&quot;tools/list&quot;</span><span class="punctuation">,</span><span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span><span class="string">&quot;2.0&quot;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line">输出<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span><span class="string">&quot;2.0&quot;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">1</span><span class="punctuation">,</span><span class="attr">&quot;result&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;tools&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;get_alerts&quot;</span><span class="punctuation">,</span><span class="attr">&quot;description&quot;</span><span class="punctuation">:</span><span class="string">&quot;Get weather alerts for a US state.\n\nArgs:\n    state: Two-letter US state code (e.g. CA, NY)\n&quot;</span><span class="punctuation">,</span><span class="attr">&quot;inputSchema&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;properties&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;state&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;State&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;string&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;required&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;state&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;get_alertsArguments&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;object&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;get_forecast&quot;</span><span class="punctuation">,</span><span class="attr">&quot;description&quot;</span><span class="punctuation">:</span><span class="string">&quot;Get weather forecast for a location.\n\nArgs:\n    latitude: Latitude of the location\n    longitude: Longitude of the location\n&quot;</span><span class="punctuation">,</span><span class="attr">&quot;inputSchema&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;properties&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;latitude&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Latitude&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;number&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;longitude&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;Longitude&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;number&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;required&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;latitude&quot;</span><span class="punctuation">,</span><span class="string">&quot;longitude&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="string">&quot;get_forecastArguments&quot;</span><span class="punctuation">,</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;object&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line">输入<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;method&quot;</span><span class="punctuation">:</span><span class="string">&quot;resources/list&quot;</span><span class="punctuation">,</span><span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span><span class="string">&quot;2.0&quot;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">2</span><span class="punctuation">&#125;</span></span><br><span class="line">输出<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span><span class="string">&quot;2.0&quot;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">2</span><span class="punctuation">,</span><span class="attr">&quot;result&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;resources&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">输入<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;method&quot;</span><span class="punctuation">:</span><span class="string">&quot;resources/templates/list&quot;</span><span class="punctuation">,</span><span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span><span class="string">&quot;2.0&quot;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">3</span><span class="punctuation">&#125;</span></span><br><span class="line">输出<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span><span class="string">&quot;2.0&quot;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">3</span><span class="punctuation">,</span><span class="attr">&quot;result&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;resourceTemplates&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line">输入<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;method&quot;</span><span class="punctuation">:</span><span class="string">&quot;tools/call&quot;</span><span class="punctuation">,</span><span class="attr">&quot;params&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;get_forecast&quot;</span><span class="punctuation">,</span><span class="attr">&quot;arguments&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;latitude&quot;</span><span class="punctuation">:</span><span class="number">40.7128</span><span class="punctuation">,</span><span class="attr">&quot;longitude&quot;</span><span class="punctuation">:</span><span class="number">-74.006</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span><span class="string">&quot;2.0&quot;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">4</span><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line">输出<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span><span class="string">&quot;2.0&quot;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">4</span><span class="punctuation">,</span><span class="attr">&quot;result&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;content&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;text&quot;</span><span class="punctuation">,</span><span class="attr">&quot;text&quot;</span><span class="punctuation">:</span><span class="string">&quot;\nTonight:\nTemperature: 71°F\nWind: 5 mph SW\nForecast: A chance of showers and thunderstorms before 11pm, then a slight chance of showers and thunderstorms between 11pm and 2am. Mostly cloudy, with a low around 71. Southwest wind around 5 mph. Chance of precipitation is 30%.\n\n---\n\nJuneteenth:\nTemperature: 86°F\nWind: 5 to 14 mph SW\nForecast: A chance of showers and thunderstorms after 2pm. Some of the storms could be severe. Mostly sunny, with a high near 86. Southwest wind 5 to 14 mph. Chance of precipitation is 50%. New rainfall amounts between a tenth and quarter of an inch possible.\n\n---\n\nThursday Night:\nTemperature: 70°F\nWind: 12 to 15 mph W\nForecast: A chance of showers and thunderstorms before 11pm, then a chance of showers and thunderstorms between 11pm and 2am. Some of the storms could be severe. Mostly cloudy, with a low around 70. West wind 12 to 15 mph. Chance of precipitation is 50%. New rainfall amounts between a quarter and half of an inch possible.\n\n---\n\nFriday:\nTemperature: 81°F\nWind: 13 mph W\nForecast: Sunny, with a high near 81. West wind around 13 mph.\n\n---\n\nFriday Night:\nTemperature: 70°F\nWind: 6 to 10 mph W\nForecast: Mostly clear, with a low around 70. West wind 6 to 10 mph.\n&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;isError&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>咱们只看新增部分：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">输入<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;method&quot;</span><span class="punctuation">:</span><span class="string">&quot;tools/call&quot;</span><span class="punctuation">,</span><span class="attr">&quot;params&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;name&quot;</span><span class="punctuation">:</span><span class="string">&quot;get_forecast&quot;</span><span class="punctuation">,</span><span class="attr">&quot;arguments&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;latitude&quot;</span><span class="punctuation">:</span><span class="number">40.7128</span><span class="punctuation">,</span><span class="attr">&quot;longitude&quot;</span><span class="punctuation">:</span><span class="number">-74.006</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span><span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span><span class="string">&quot;2.0&quot;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">4</span><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line">输出<span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span><span class="string">&quot;2.0&quot;</span><span class="punctuation">,</span><span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="number">4</span><span class="punctuation">,</span><span class="attr">&quot;result&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;content&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="punctuation">&#123;</span><span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;text&quot;</span><span class="punctuation">,</span><span class="attr">&quot;text&quot;</span><span class="punctuation">:</span><span class="string">&quot;\nTonight:\nTemperature: 71°F\nWind: 5 mph SW\nForecast: A chance of showers and thunderstorms before 11pm, then a slight chance of showers and thunderstorms between 11pm and 2am. Mostly cloudy, with a low around 71. Southwest wind around 5 mph. Chance of precipitation is 30%.\n\n---\n\nJuneteenth:\nTemperature: 86°F\nWind: 5 to 14 mph SW\nForecast: A chance of showers and thunderstorms after 2pm. Some of the storms could be severe. Mostly sunny, with a high near 86. Southwest wind 5 to 14 mph. Chance of precipitation is 50%. New rainfall amounts between a tenth and quarter of an inch possible.\n\n---\n\nThursday Night:\nTemperature: 70°F\nWind: 12 to 15 mph W\nForecast: A chance of showers and thunderstorms before 11pm, then a chance of showers and thunderstorms between 11pm and 2am. Some of the storms could be severe. Mostly cloudy, with a low around 70. West wind 12 to 15 mph. Chance of precipitation is 50%. New rainfall amounts between a quarter and half of an inch possible.\n\n---\n\nFriday:\nTemperature: 81°F\nWind: 13 mph W\nForecast: Sunny, with a high near 81. West wind around 13 mph.\n\n---\n\nFriday Night:\nTemperature: 70°F\nWind: 6 to 10 mph W\nForecast: Mostly clear, with a low around 70. West wind 6 to 10 mph.\n&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">]</span><span class="punctuation">,</span><span class="attr">&quot;isError&quot;</span><span class="punctuation">:</span><span class="literal"><span class="keyword">false</span></span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>第一条是<code>Cline</code>告诉<code>MCP  Server</code>：我要调用<code>get_forecast</code>方法，参数是…</p>
<blockquote>
<p>注意这里的参数（arguments）是完全符合<code>inputSchema</code>中定义的<code>Json</code>规范的，证明定义是有效的。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;latitude&quot;</span><span class="punctuation">:</span><span class="number">40.7128</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;longitude&quot;</span><span class="punctuation">:</span><span class="number">-74.006</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></blockquote>
<p>第二条是<code>MCP  Server</code>回复给<code>Cline</code>的内容，重点是<code>text</code>字段中的内容，格式化后：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">Tonight<span class="punctuation">:</span></span><br><span class="line">Temperature<span class="punctuation">:</span> <span class="number">71</span>°F</span><br><span class="line">Wind<span class="punctuation">:</span> <span class="number">5</span> mph SW</span><br><span class="line">Forecast<span class="punctuation">:</span> A chance of showers and thunderstorms before <span class="number">11</span>pm<span class="punctuation">,</span> then a slight chance of showers and thunderstorms between <span class="number">11</span>pm and <span class="number">2</span>am. Mostly cloudy<span class="punctuation">,</span> with a low around <span class="number">71.</span> Southwest wind around <span class="number">5</span> mph. Chance of precipitation is <span class="number">30</span>%.</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">Juneteenth<span class="punctuation">:</span></span><br><span class="line">Temperature<span class="punctuation">:</span> <span class="number">86</span>°F</span><br><span class="line">Wind<span class="punctuation">:</span> <span class="number">5</span> to <span class="number">14</span> mph SW</span><br><span class="line">Forecast<span class="punctuation">:</span> A chance of showers and thunderstorms after <span class="number">2</span>pm. Some of the storms could be severe. Mostly sunny<span class="punctuation">,</span> with a high near <span class="number">86.</span> Southwest wind <span class="number">5</span> to <span class="number">14</span> mph. Chance of precipitation is <span class="number">50</span>%. New rainfall amounts between a tenth and quarter of an inch possible.</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">Thursday Night<span class="punctuation">:</span></span><br><span class="line">Temperature<span class="punctuation">:</span> <span class="number">70</span>°F</span><br><span class="line">Wind<span class="punctuation">:</span> <span class="number">12</span> to <span class="number">15</span> mph W</span><br><span class="line">Forecast<span class="punctuation">:</span> A chance of showers and thunderstorms before <span class="number">11</span>pm<span class="punctuation">,</span> then a chance of showers and thunderstorms between <span class="number">11</span>pm and <span class="number">2</span>am. Some of the storms could be severe. Mostly cloudy<span class="punctuation">,</span> with a low around <span class="number">70.</span> West wind <span class="number">12</span> to <span class="number">15</span> mph. Chance of precipitation is <span class="number">50</span>%. New rainfall amounts between a quarter and half of an inch possible.</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">Friday<span class="punctuation">:</span></span><br><span class="line">Temperature<span class="punctuation">:</span> <span class="number">81</span>°F</span><br><span class="line">Wind<span class="punctuation">:</span> <span class="number">13</span> mph W</span><br><span class="line">Forecast<span class="punctuation">:</span> Sunny<span class="punctuation">,</span> with a high near <span class="number">81.</span> West wind around <span class="number">13</span> mph.</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">Friday Night<span class="punctuation">:</span></span><br><span class="line">Temperature<span class="punctuation">:</span> <span class="number">70</span>°F</span><br><span class="line">Wind<span class="punctuation">:</span> <span class="number">6</span> to <span class="number">10</span> mph W</span><br><span class="line">Forecast<span class="punctuation">:</span> Mostly clear<span class="punctuation">,</span> with a low around <span class="number">70.</span> West wind <span class="number">6</span> to <span class="number">10</span> mph.</span><br></pre></td></tr></table></figure>

<p>这是一些天气信息，<code>Cline</code>拿到<code>MCP Server</code>的返回结果后，它与<code>MCP Server</code>的交互就算结束了，之后<code>Cline</code>就会把结果发给模型，让模型去总结，我们最后看到的就是模型总结的结果。</p>
<h4 id="使用MCP底层协议直接与MCP-Server通信"><a href="#使用MCP底层协议直接与MCP-Server通信" class="headerlink" title="使用MCP底层协议直接与MCP Server通信"></a>使用<code>MCP</code>底层协议直接与<code>MCP Server</code>通信</h4><p> 刚才我们深挖了<code>MCP</code>协议的底层细节，明白了底层细节之后，我们甚至可以不用<code>MCP Host</code>就可以与<code>MCP Server</code>通信，只需要保证发送给<code>MCP Server</code>的数据符合上面我们看到的<code>log</code>中的格式，下面我们一起看下怎么操作：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">uv --directory /home/chr/桌面/weather run weather.py</span><br></pre></td></tr></table></figure>



<p>可见与我们<code>log</code>中的行为记录是一致的，现在我们就可以在不使用<code>mcp</code>库的前提下开发<code>MCP Server</code>了，只需要保证你的<code>MCP Server</code>符合<code>MCP</code>的这个规范就可以了，只不过会麻烦一些。</p>
<hr>
<h3 id="超越表象：MCP协议的真实含义与定位"><a href="#超越表象：MCP协议的真实含义与定位" class="headerlink" title="超越表象：MCP协议的真实含义与定位"></a>超越表象：<code>MCP</code>协议的真实含义与定位</h3><p>相信大家现在对<code>MCP</code>的细节都有一个比较清楚的认识了，咱们再回头看下在基础篇中的交互流程，现在是不是更清楚了呢？</p>
<img src="/2025/06/12/MCP%E8%BF%9B%E9%98%B6%EF%BC%9A%E5%B8%A6%E4%BD%A0%E6%B7%B1%E5%85%A5%E6%8E%8C%E6%8F%A1MCP/image-20250619164316647.png" class="" title="image-20250619164316647">

<p>这时候有小友可能有个疑问：<strong>为什么在<code>MCP</code>日志里面没有看到模型的影子，模型是怎么使用<code>MCP</code>协议的?</strong></p>
<p>其实啊，<code>MCP</code>协议规定的内容只包括上图包含的环节，与模型并没有什么关系，<code>MCP</code>协议主要规定了两部分的内容：</p>
<ul>
<li>每个<code>MCP Server</code>的函数列表</li>
<li>每个函数的调用方法</li>
</ul>
<p>当然，有些<code>MCP Server</code>内部还有资源可以使用，暂时忽略掉。上述两点可以总结为函数的注册与使用，我们可以看出这里面确实是没有模型什么事的，<code>MCP</code>协议规定的是如何发现和调用函数的，这套协议脱离大模型也是可以使用的，只是没人这么用罢了。<code>MCP</code>本身并没有规定与模型的交互方式，实际上不同的<code>MCP Host</code>与模型的交互方式确实会有很大差异，比如<code>Cline</code>用的是<code>XML</code>，而<code>Cherry Studio</code>使用的是<code>function call</code>。</p>
<p><strong>总之，<code>MCP</code>协议并没有规定如何与模型进行交互。</strong></p>
<p>我们再回头看看<code>MCP</code>（模型上下文协议）这个名字，什么是模型上下文？上下文就是环境，环境就是周围有哪些函数可以调用，从而<strong>获取外界的信息或者扩展模型的能力</strong>，比如获取天气信息、网络信息、文件信息等等。<code>MCP</code>就是让模型感知外界环境的一个协议，所以叫模型上下文协议。<br>这个名字合适吗？好坏不论，首先这个名字有一定的误导性，很容易让人觉得这个协议规定的是模型交互的内容，但实际上，我们最多只能说这个协议是给模型服务的，再者，这个名字太多玄妙，看起来很高端，作者难道是想让大家觉得<code>MCP</code>是个很高深的东西？</p>
<p>下篇预告：<code>MCP Host</code>是怎么与模型通信的。</p>
<hr>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h3 id="weather-py代码解释"><a href="#weather-py代码解释" class="headerlink" title="weather.py代码解释"></a><code>weather.py</code>代码解释</h3><p><strong>导入部分</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Any</span></span><br><span class="line"><span class="keyword">import</span> httpx</span><br><span class="line"><span class="keyword">from</span> mcp.server.fastmcp <span class="keyword">import</span> FastMCP</span><br></pre></td></tr></table></figure>
<ul>
<li><code>from typing import Any</code>: 从类型提示模块导入<code>Any</code>类型，表示可以是任何类型</li>
<li><code>import httpx</code>: 导入httpx库，这是一个异步HTTP客户端</li>
<li><code>from mcp.server.fastmcp import FastMCP</code>: 从<code>mcp</code>库中导入<code>FastMCP</code>类，用于创建服务器</li>
</ul>
<p><strong>服务器初始化</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mcp = FastMCP(<span class="string">&quot;weather&quot;</span>, log_level=<span class="string">&quot;ERROR&quot;</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>创建一个<code>FastMCP</code>服务器实例，命名为”weather”</li>
<li>设置日志级别为”ERROR”，表示只记录错误级别的日志</li>
</ul>
<p><strong>常量定义</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">NWS_API_BASE = <span class="string">&quot;https://api.weather.gov&quot;</span></span><br><span class="line">USER_AGENT = <span class="string">&quot;weather-app/1.0&quot;</span></span><br></pre></td></tr></table></figure>
<ul>
<li><code>NWS_API_BASE</code>: 美国国家气象局<code>(NWS)API</code>的基础URL</li>
<li><code>USER_AGENT</code>: 用于HTTP请求的用户代理字符串，标识我们的应用</li>
</ul>
<p><strong>辅助函数: <code>make_nws_request</code></strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">make_nws_request</span>(<span class="params">url: <span class="built_in">str</span></span>) -&gt; <span class="built_in">dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>] | <span class="literal">None</span>:</span><br></pre></td></tr></table></figure>
<ul>
<li>定义异步函数，接收URL字符串参数，返回字典或None</li>
<li>类型提示表示返回可能是字典(键是字符串，值任意)或None</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: USER_AGENT,</span><br><span class="line">    <span class="string">&quot;Accept&quot;</span>: <span class="string">&quot;application/geo+json&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>设置HTTP请求头:<ul>
<li><code>User-Agent</code>: 标识我们的应用</li>
<li><code>Accept</code>: 指定我们接受geo+json格式的数据</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="keyword">with</span> httpx.AsyncClient() <span class="keyword">as</span> client:</span><br></pre></td></tr></table></figure>
<ul>
<li>创建异步HTTP客户端上下文管理器</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = <span class="keyword">await</span> client.get(url, headers=headers, timeout=<span class="number">30.0</span>)</span><br><span class="line">    response.raise_for_status()</span><br><span class="line">    <span class="keyword">return</span> response.json()</span><br></pre></td></tr></table></figure>
<ul>
<li>尝试发送GET请求，带超时30秒</li>
<li><code>raise_for_status()</code>会在HTTP错误状态码(<code>4xx,5xx</code>)时抛出异常</li>
<li>成功则返回解析后的<code>JSON</code>数据</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">except</span> Exception:</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></table></figure>
<ul>
<li>捕获任何异常并返回None</li>
</ul>
<p><strong>辅助函数: format_alert</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">format_alert</span>(<span class="params">feature: <span class="built_in">dict</span></span>) -&gt; <span class="built_in">str</span>:</span><br></pre></td></tr></table></figure>
<ul>
<li>定义函数，接收字典参数，返回格式化字符串</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">    props = feature[<span class="string">&quot;properties&quot;</span>]</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Event: <span class="subst">&#123;props.get(<span class="string">&#x27;event&#x27;</span>, <span class="string">&#x27;Unknown&#x27;</span>)&#125;</span></span></span><br><span class="line"><span class="string">Area: <span class="subst">&#123;props.get(<span class="string">&#x27;areaDesc&#x27;</span>, <span class="string">&#x27;Unknown&#x27;</span>)&#125;</span></span></span><br><span class="line"><span class="string">Severity: <span class="subst">&#123;props.get(<span class="string">&#x27;severity&#x27;</span>, <span class="string">&#x27;Unknown&#x27;</span>)&#125;</span></span></span><br><span class="line"><span class="string">Description: <span class="subst">&#123;props.get(<span class="string">&#x27;description&#x27;</span>, <span class="string">&#x27;No description available&#x27;</span>)&#125;</span></span></span><br><span class="line"><span class="string">Instructions: <span class="subst">&#123;props.get(<span class="string">&#x27;instruction&#x27;</span>, <span class="string">&#x27;No specific instructions provided&#x27;</span>)&#125;</span></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>从特征数据中提取properties</li>
<li>使用f-string格式化多行字符串，显示天气警报的各个属性</li>
<li>使用<code>.get()</code>方法提供默认值以防键不存在</li>
</ul>
<p><strong>工具函数: get_alerts</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@mcp.tool()</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">get_alerts</span>(<span class="params">state: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br></pre></td></tr></table></figure>
<ul>
<li>使用<code>@mcp.tool()</code>装饰器注册为<code>MCP</code>工具</li>
<li>异步函数，接收州代码字符串，返回格式化字符串</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url = <span class="string">f&quot;<span class="subst">&#123;NWS_API_BASE&#125;</span>/alerts/active/area/<span class="subst">&#123;state&#125;</span>&quot;</span></span><br><span class="line">data = <span class="keyword">await</span> make_nws_request(url)</span><br></pre></td></tr></table></figure>
<ul>
<li>构造<code>NWS API</code>的URL</li>
<li>调用之前定义的<code>make_nws_request</code>获取数据</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> data <span class="keyword">or</span> <span class="string">&quot;features&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> data:</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;Unable to fetch alerts or no alerts found.&quot;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>检查数据是否有效，没有则返回错误信息</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> data[<span class="string">&quot;features&quot;</span>]:</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;No active alerts for this state.&quot;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>检查是否有警报特征数据，没有则返回无警报信息</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">alerts = [format_alert(feature) <span class="keyword">for</span> feature <span class="keyword">in</span> data[<span class="string">&quot;features&quot;</span>]]</span><br><span class="line"><span class="keyword">return</span> <span class="string">&quot;\n---\n&quot;</span>.join(alerts)</span><br></pre></td></tr></table></figure>
<ul>
<li>使用列表推导式格式化所有警报特征</li>
<li>用分隔符<code>---</code>连接所有格式化后的警报</li>
</ul>
<p><strong>工具函数: get_forecast</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@mcp.tool()</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">get_forecast</span>(<span class="params">latitude: <span class="built_in">float</span>, longitude: <span class="built_in">float</span></span>) -&gt; <span class="built_in">str</span>:</span><br></pre></td></tr></table></figure>
<ul>
<li>另一个<code>MCP</code>工具，接收经纬度坐标，返回预报字符串</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">points_url = <span class="string">f&quot;<span class="subst">&#123;NWS_API_BASE&#125;</span>/points/<span class="subst">&#123;latitude&#125;</span>,<span class="subst">&#123;longitude&#125;</span>&quot;</span></span><br><span class="line">points_data = <span class="keyword">await</span> make_nws_request(points_url)</span><br></pre></td></tr></table></figure>
<ul>
<li>构造获取预报点的URL并请求数据</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> points_data:</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;Unable to fetch forecast data for this location.&quot;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>检查数据是否有效</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">forecast_url = points_data[<span class="string">&quot;properties&quot;</span>][<span class="string">&quot;forecast&quot;</span>]</span><br><span class="line">forecast_data = <span class="keyword">await</span> make_nws_request(forecast_url)</span><br></pre></td></tr></table></figure>
<ul>
<li>从点数据中提取预报URL并获取预报数据</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> forecast_data:</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;Unable to fetch detailed forecast.&quot;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>检查预报数据是否有效</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">    periods = forecast_data[<span class="string">&quot;properties&quot;</span>][<span class="string">&quot;periods&quot;</span>]</span><br><span class="line">    forecasts = []</span><br><span class="line">    <span class="keyword">for</span> period <span class="keyword">in</span> periods[:<span class="number">5</span>]:  <span class="comment"># Only show next 5 periods</span></span><br><span class="line">        forecast = <span class="string">f&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"><span class="subst">&#123;period[<span class="string">&#x27;name&#x27;</span>]&#125;</span>:</span></span><br><span class="line"><span class="string">Temperature: <span class="subst">&#123;period[<span class="string">&#x27;temperature&#x27;</span>]&#125;</span>°<span class="subst">&#123;period[<span class="string">&#x27;temperatureUnit&#x27;</span>]&#125;</span></span></span><br><span class="line"><span class="string">Wind: <span class="subst">&#123;period[<span class="string">&#x27;windSpeed&#x27;</span>]&#125;</span> <span class="subst">&#123;period[<span class="string">&#x27;windDirection&#x27;</span>]&#125;</span></span></span><br><span class="line"><span class="string">Forecast: <span class="subst">&#123;period[<span class="string">&#x27;detailedForecast&#x27;</span>]&#125;</span></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">        forecasts.append(forecast)</span><br></pre></td></tr></table></figure>
<ul>
<li>提取预报时段数据</li>
<li>只处理前5个时段(通常是未来几天)</li>
<li>格式化每个时段的预报信息</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">return</span> <span class="string">&quot;\n---\n&quot;</span>.join(forecasts)</span><br></pre></td></tr></table></figure>
<ul>
<li>用分隔符连接所有预报信息</li>
</ul>
<p>主程序入口</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    mcp.run(transport=<span class="string">&#x27;stdio&#x27;</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>当直接运行脚本时:<ul>
<li>启动<code>MCP</code>服务器</li>
<li>使用标准输入输出作为传输方式</li>
</ul>
</li>
</ul>
<p><strong>总结</strong></p>
<p>这段代码实现了一个天气服务，提供两个主要功能:</p>
<ol>
<li>获取美国各州的天气警报</li>
<li>获取指定经纬度的天气预报</li>
</ol>
<p>它使用<code>FastMCP</code>框架创建服务，通过<code>NWS API</code>获取天气数据，并将结果格式化为易读的字符串。</p>
<hr>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://caihaoran-00.github.io/2025/06/09/MCP%E5%9F%BA%E7%A1%80%EF%BC%9A%E4%BB%8E%E5%8E%9F%E7%90%86%E5%88%B0%E5%AE%9E%E6%88%98/">https://caihaoran-00.github.io/2025/06/09/MCP%E5%9F%BA%E7%A1%80%EF%BC%9A%E4%BB%8E%E5%8E%9F%E7%90%86%E5%88%B0%E5%AE%9E%E6%88%98/</a></li>
<li><a href="https://github.com/modelcontextprotocol/quickstart-resources/blob/main/weather-server-python/weather.py">https://github.com/modelcontextprotocol/quickstart-resources/blob/main/weather-server-python/weather.py</a></li>
<li><a href="https://github.com/MarkTechStation/VideoCode/blob/main/MCP%E7%BB%88%E6%9E%81%E6%8C%87%E5%8D%97-%E8%BF%9B%E9%98%B6%E7%AF%87/weather/weather.py">https://github.com/MarkTechStation/VideoCode/blob/main/MCP%E7%BB%88%E6%9E%81%E6%8C%87%E5%8D%97-%E8%BF%9B%E9%98%B6%E7%AF%87/weather/weather.py</a></li>
<li><a href="https://github.com/MarkTechStation/VideoCode/blob/main/MCP%E7%BB%88%E6%9E%81%E6%8C%87%E5%8D%97-%E8%BF%9B%E9%98%B6%E7%AF%87/weather/mcp_logger.py">https://github.com/MarkTechStation/VideoCode/blob/main/MCP%E7%BB%88%E6%9E%81%E6%8C%87%E5%8D%97-%E8%BF%9B%E9%98%B6%E7%AF%87/weather/mcp_logger.py</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>agent</tag>
        <tag>mcp</tag>
      </tags>
  </entry>
  <entry>
    <title>MobaXterm连接公司服务器部署ASR环境</title>
    <url>/2025/02/17/MobaXterm%E8%BF%9E%E6%8E%A5%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2ASR%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>由于目前ASR服务是部署在我的ubuntu主机上的，我司的测试人员已完成基本的功能测试，接下来要进行压力测试，故需要在压测环境（与线上正式环境配置一致）上部署该服务，很多年前用的是Xshell，搜了下SSH工具，现在貌似<strong>MobaXterm</strong>较为主流，看看这个工具怎么样吧。本文介绍使用MobaXterm连接公司服务器部署FunASR环境。</p>
<span id="more"></span>

<hr>
<h2 id="MobaXterm安装"><a href="#MobaXterm安装" class="headerlink" title="MobaXterm安装"></a><strong>MobaXterm</strong>安装</h2><ol>
<li><p>打开<a href="https://github.com/RipplePiam/MobaXterm-Chinese-Simplified/releases">这个页面</a></p>
</li>
<li><p>下拉到这个位置，点击如图箭头所示</p>
<img src="/2025/02/17/MobaXterm%E8%BF%9E%E6%8E%A5%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2ASR%E7%8E%AF%E5%A2%83/image-20250217191454432.png" class="" title="image-20250217191454432">
</li>
<li><p>下载完成后，解压，点击解压后的文件夹中的.exe</p>
<img src="/2025/02/17/MobaXterm%E8%BF%9E%E6%8E%A5%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2ASR%E7%8E%AF%E5%A2%83/image-20250217191613244.png" class="" title="image-20250217191613244">
</li>
<li><p>你将会看到这个页面</p>
<img src="/2025/02/17/MobaXterm%E8%BF%9E%E6%8E%A5%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2ASR%E7%8E%AF%E5%A2%83/image-20250217191716869.png" class="" title="image-20250217191716869"></li>
</ol>
<hr>
<h2 id="MobaXterm使用"><a href="#MobaXterm使用" class="headerlink" title="MobaXterm使用"></a>MobaXterm使用</h2><ol>
<li><p>双击箭头所示<strong>User sessions</strong></p>
<img src="/2025/02/17/MobaXterm%E8%BF%9E%E6%8E%A5%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2ASR%E7%8E%AF%E5%A2%83/image-20250217194559990.png" class="" title="image-20250217194559990">
</li>
<li><p>点击<strong>SSH</strong>，输入你的<strong>远程主机IP</strong>和<strong>用户名（可选）</strong>,点击<strong>OK</strong></p>
<img src="/2025/02/17/MobaXterm%E8%BF%9E%E6%8E%A5%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2ASR%E7%8E%AF%E5%A2%83/image-20250218100113480.png" class="" title="image-20250218100113480">
</li>
<li><p>会提示你是第一次连接这个服务器，勾选<strong>不再显示此消息</strong>，再点击<strong>Accept</strong></p>
<img src="/2025/02/17/MobaXterm%E8%BF%9E%E6%8E%A5%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2ASR%E7%8E%AF%E5%A2%83/image-20250218100317993.png" class="" title="image-20250218100317993">
</li>
<li><p>输入密码</p>
<img src="/2025/02/17/MobaXterm%E8%BF%9E%E6%8E%A5%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2ASR%E7%8E%AF%E5%A2%83/1739844404437.jpg" class="" width="1739844404437">
</li>
<li><p>保存密码</p>
<img src="/2025/02/17/MobaXterm%E8%BF%9E%E6%8E%A5%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2ASR%E7%8E%AF%E5%A2%83/1739844573632.png" class="" width="1739844573632">
</li>
<li><p>保存存储的密码，暂时不知道什么地方会用到，先设置上吧</p>
<img src="/2025/02/17/MobaXterm%E8%BF%9E%E6%8E%A5%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2ASR%E7%8E%AF%E5%A2%83/image-20250218112948823.png" class="" title="image-20250218112948823">
</li>
<li><p>现在就进去服务器了，可按你的自身需求操作了</p>
<img src="/2025/02/17/MobaXterm%E8%BF%9E%E6%8E%A5%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2ASR%E7%8E%AF%E5%A2%83/image-20250218113108960.png" class="" title="image-20250218113108960"></li>
</ol>
<hr>
<h2 id="安装FunASR"><a href="#安装FunASR" class="headerlink" title="安装FunASR"></a>安装FunASR</h2><p><a href="https://github.com/modelscope/FunASR/blob/main/runtime/docs/SDK_advanced_guide_online_zh.md">参考</a></p>
<ul>
<li><p>进入服务器的&#x2F;opt，运行<code>docker --version</code>查看有没有安装docker</p>
<img src="/2025/02/17/MobaXterm%E8%BF%9E%E6%8E%A5%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2ASR%E7%8E%AF%E5%A2%83/image-20250218113940922.png" class="" title="image-20250218113940922">
</li>
<li><p>先通过<code>docker --version</code>确认服务器上有没有安装docker（一般都有），（如果没有就安装下）再运行</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> docker pull \</span><br><span class="line">  registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-online-cpu-0.1.12</span><br></pre></td></tr></table></figure>

<img src="/2025/02/17/MobaXterm%E8%BF%9E%E6%8E%A5%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2ASR%E7%8E%AF%E5%A2%83/image-20250218115349721.png" class="" title="image-20250218115349721">
</li>
<li><p>运行<code>sudo docker images</code>查看是否有这个镜像</p>
<img src="/2025/02/17/MobaXterm%E8%BF%9E%E6%8E%A5%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2ASR%E7%8E%AF%E5%A2%83/image-20250218115509797.png" class="" title="image-20250218115509797">
</li>
<li><p>依次运行下面两条命令进入docker内部：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p ./funasr-runtime-resources/models</span><br><span class="line"><span class="built_in">sudo</span> docker run -p 10096:10095 -it --privileged=<span class="literal">true</span> \</span><br><span class="line">  -v <span class="variable">$PWD</span>/funasr-runtime-resources/models:/workspace/models \</span><br><span class="line">  registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-online-cpu-0.1.12 </span><br></pre></td></tr></table></figure>

<img src="/2025/02/17/MobaXterm%E8%BF%9E%E6%8E%A5%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2ASR%E7%8E%AF%E5%A2%83/image-20250218120001291-1739851203375-3.png" class="" title="image-20250218120001291">
</li>
<li><p>依次运行下面两条命令启动<code>funasr-wss-server-2pass</code>服务程序：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> FunASR/runtime</span><br><span class="line"></span><br><span class="line"><span class="built_in">nohup</span> bash run_server_2pass.sh \</span><br><span class="line">  --certfile 0 \</span><br><span class="line">  --download-model-dir /workspace/models \</span><br><span class="line">  --vad-dir damo/speech_fsmn_vad_zh-cn-16k-common-onnx \</span><br><span class="line">  --model-dir damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-onnx  \</span><br><span class="line">  --online-model-dir damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online-onnx  \</span><br><span class="line">  --punc-dir damo/punc_ct-transformer_zh-cn-common-vad_realtime-vocab272727-onnx \</span><br><span class="line">  --lm-dir damo/speech_ngram_lm_zh-cn-ai-wesp-fst \</span><br><span class="line">  --itn-dir thuduj12/fst_itn_zh \</span><br><span class="line">  --hotword /workspace/models/hotwords.txt &gt; log.txt 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>

<p>想实时查看<code>log.txt</code>可运行<code>tail -f log.txt</code>实时查看日志信息。</p>
<img src="/2025/02/17/MobaXterm%E8%BF%9E%E6%8E%A5%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2ASR%E7%8E%AF%E5%A2%83/image-20250218141211559.png" class="" title="image-20250218141211559">

<img src="/2025/02/17/MobaXterm%E8%BF%9E%E6%8E%A5%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2ASR%E7%8E%AF%E5%A2%83/image-20250218142324573.png" class="" title="image-20250218142324573">

<p>到这里FunASR服务端就启动好了，下面用官方提供的客户端连接看下效果。</p>
</li>
</ul>
<hr>
<h2 id="FunASR客户端连接"><a href="#FunASR客户端连接" class="headerlink" title="FunASR客户端连接"></a>FunASR客户端连接</h2><p>点击<a href="https://github.com/modelscope/FunASR/blob/main/runtime/docs/SDK_tutorial_online_zh.md#%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%94%A8%E6%B3%95%E8%AF%A6%E8%A7%A3">这里</a>下载示例客户端，下面以html网页版为例：</p>
<img src="/2025/02/17/MobaXterm%E8%BF%9E%E6%8E%A5%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2ASR%E7%8E%AF%E5%A2%83/image-20250218142549399.png" class="" title="image-20250218142549399">

<p>注意事项：</p>
<ul>
<li><p>nohup启动FunASR服务时如果指定了<code>--certfile 0</code>，即关闭ssl，那么asr服务器地址就以ws开头，否则以wss开头</p>
</li>
<li><p>端口（10096）是<code>docker run -p</code>启动docker镜像时指定的端口</p>
</li>
<li><p>2pass是指先进行实时语音识别，VAD检测到一小段结束后，就用非实时语音识别再做一次语音识别，用该结果替换掉原实时语音识别的结果，以兼顾实时性和准确性</p>
</li>
<li><p>ITN旨在将识别到的文本转换成一个更加标准化、可读的形式，特别是在处理数字、日期、时间、货币等信息时。</p>
</li>
<li><p>设置完之后点击连接，再点击开始，即可通过麦克风实时语音识别，结果在服务器端也有显示</p>
<img src="/2025/02/17/MobaXterm%E8%BF%9E%E6%8E%A5%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2ASR%E7%8E%AF%E5%A2%83/image-20250218143446847.png" class="" title="image-20250218143446847">
</li>
<li><p>这种方式启动的docker容器，无论是关掉SSH连接还是exit退出容器，都会停止掉docker容器，即会停掉服务，想关掉SSH连接或exit退出容器，但容器不停止怎么做，有个其他事，先忙好再来更：</p>
<p>TODO…</p>
</li>
</ul>
<p>OK，完毕，建议搭配参考链接食用。</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://github.com/modelscope/FunASR/blob/main/runtime/docs/SDK_advanced_guide_online_zh.md">https://github.com/modelscope/FunASR/blob/main/runtime/docs/SDK_advanced_guide_online_zh.md</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>asr</tag>
        <tag>funasr</tag>
        <tag>mobaxterm</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Obsidian+Excalidraw插件绘图</title>
    <url>/2025/03/22/Obsidian-Excalidraw%E6%8F%92%E4%BB%B6%E7%BB%98%E5%9B%BE/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在AI系列课程：导论and数学基础1一文中，用网页版Excalidraw画了一些图，风格还不错，但是发现了致命的缺点，不支持Latex数学公式（没找到怎么使用，姑且认为不支持吧），搜索发现可以通过Obsidian安装Excalidraw插件解决这个问题，本文尝试并记录该方案（<strong>windows电脑</strong>)，用作记录和分享。</p>
<span id="more"></span>

<hr>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><ol>
<li><p>在<a href="https://obsidian.md/download">这个页面</a>选择合适自己的版本进行下载安装，安装完成后你会看到这个页面：</p>
<img src="/2025/03/22/Obsidian-Excalidraw%E6%8F%92%E4%BB%B6%E7%BB%98%E5%9B%BE/1742640304163.jpg" class="" width="1742640304163">
</li>
<li><p>点击左下角的设置：</p>
<img src="/2025/03/22/Obsidian-Excalidraw%E6%8F%92%E4%BB%B6%E7%BB%98%E5%9B%BE/1742640322607.jpg" class="" width="1742640322607">

<p>再点击<code>第三方插件</code>-&gt;<code>关闭安全模式</code>，你将会看到：</p>
<img src="/2025/03/22/Obsidian-Excalidraw%E6%8F%92%E4%BB%B6%E7%BB%98%E5%9B%BE/image-20250322184907067.png" class="" title="image-20250322184907067"></li>
</ol>
<p>点击后，搜索<code>Excalidraw</code>（其实不用搜索，第一条就是）：</p>
<img src="/2025/03/22/Obsidian-Excalidraw%E6%8F%92%E4%BB%B6%E7%BB%98%E5%9B%BE/image-20250322185056792.png" class="" title="image-20250322185056792">

<p>点击<code>Excalidraw</code>，会看到下图，再点击安装：</p>
<img src="/2025/03/22/Obsidian-Excalidraw%E6%8F%92%E4%BB%B6%E7%BB%98%E5%9B%BE/image-20250322185130549.png" class="" title="image-20250322185130549">

<p>再点击下启用，以启用<code>Excalidraw</code>：</p>
<img src="/2025/03/22/Obsidian-Excalidraw%E6%8F%92%E4%BB%B6%E7%BB%98%E5%9B%BE/image-20250322185405846.png" class="" title="image-20250322185405846">

<img src="/2025/03/22/Obsidian-Excalidraw%E6%8F%92%E4%BB%B6%E7%BB%98%E5%9B%BE/image-20250322190154595.png" class="" title="image-20250322190154595">

<p>关掉软件，从新打开，两种方式打开<code>Excalidraw</code>，一是左侧：</p>
<img src="/2025/03/22/Obsidian-Excalidraw%E6%8F%92%E4%BB%B6%E7%BB%98%E5%9B%BE/image-20250322190950725.png" class="" title="image-20250322190950725">

<p>二是这里：</p>
<img src="/2025/03/22/Obsidian-Excalidraw%E6%8F%92%E4%BB%B6%E7%BB%98%E5%9B%BE/image-20250322191129172.png" class="" title="image-20250322191129172">

<p>效果一样，左侧更方便些。</p>
<hr>
<h2 id="体验"><a href="#体验" class="headerlink" title="体验"></a>体验</h2><p>我主要是想在原有的基础上加上公式编辑的功能，按下图所示进行操作即可添加公式（不过需要学习下Latex语法）：</p>
<img src="/2025/03/22/Obsidian-Excalidraw%E6%8F%92%E4%BB%B6%E7%BB%98%E5%9B%BE/image-20250322191846058.png" class="" title="image-20250322191846058">

<hr>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>本文记录了Obsidian+Excalidraw插件绘图的安装步骤和简单实用，主要目的是使用Obsidian的Latex公式编辑能力，使Excalidraw成为完全体😄。</p>
]]></content>
      <categories>
        <category>theory</category>
      </categories>
      <tags>
        <tag>Obsidian</tag>
        <tag>Excalidraw</tag>
        <tag>实用工具</tag>
      </tags>
  </entry>
  <entry>
    <title>PDF解析工具：MinerU安装与使用</title>
    <url>/2025/05/30/PDF%E8%A7%A3%E6%9E%90%E5%B7%A5%E5%85%B7%EF%BC%9AMinerU%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近做招标智能体demo的时候意识到pdf文件的解析是从非结构化文本提取结构化文本中至关重要的一步。想了想这一步也是很多场景下也是至关重要的一步，比如RAG。遂打算好好的玩下这些pdf解析器，前文的<a href="https://caihaoran-00.github.io/2025/05/20/PDF%E8%A7%A3%E6%9E%90%E5%BA%93%EF%BC%9A%E9%80%9F%E5%BA%A6%E4%B8%8E%E6%95%88%E6%9E%9C%E5%AF%B9%E6%AF%94/">PDF解析库：速度与效果对比</a>主要关注传统pdf解析库，如：<code>pdfplumber</code>、<code>pypdf/PyPDF2</code>、<code>PDFMiner.six</code>、<code>PyMuPDF(fitz)</code>，但时代在进步，深度集成AI模型的<a href="https://github.com/opendatalab/MinerU/tree/master">MinerU</a>是一站式开源高质量数据提取工具，能将PDF转换成Markdown和JSON格式，目前<code>github Starred 34.3k</code>。下面我们将一起在ubuntu22.04上安装和体验下MinerU。</p>
<span id="more"></span>

<hr>
<h2 id="安装（GPU版本）"><a href="#安装（GPU版本）" class="headerlink" title="安装（GPU版本）"></a>安装（GPU版本）</h2><h3 id="环境安装"><a href="#环境安装" class="headerlink" title="环境安装"></a>环境安装</h3><p>这里我们安装GPU版本，注意<code>CUDA Version</code> 显示的版本号应 &gt;&#x3D; 12.4，如显示的版本号小于12.4，请升级驱动，这里默认小友也拥有完善的驱动、CUDA、conda：</p>
<img src="/2025/05/30/PDF%E8%A7%A3%E6%9E%90%E5%B7%A5%E5%85%B7%EF%BC%9AMinerU%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/image-20250530110115495-1748586883149-1.png" class="" title="image-20250530110115495">

<p>运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> mineru</span><br><span class="line"><span class="built_in">cd</span> mineru</span><br><span class="line"></span><br><span class="line">conda create -n mineru <span class="string">&#x27;python=3.12&#x27;</span> -y</span><br><span class="line">conda activate mineru</span><br><span class="line"></span><br><span class="line">pip install -U magic-pdf[full] -i https://mirrors.aliyun.com/pypi/simple</span><br><span class="line">magic-pdf --version  <span class="comment"># 查看magic-pdf的版本，我的输出： magic-pdf --version</span></span><br></pre></td></tr></table></figure>

<h3 id="模型下载"><a href="#模型下载" class="headerlink" title="模型下载"></a>模型下载</h3><p>我这里从 Hugging Face 下载，从ModelScope下载请看参考链接2，运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install huggingface_hub</span><br><span class="line">wget https://gcore.jsdelivr.net/gh/opendatalab/MinerU@master/scripts/download_models_hf.py -O download_models_hf.py</span><br><span class="line">python download_models_hf.py</span><br></pre></td></tr></table></figure>





<p>现在这时候<code>/home/用户名</code>下就会出现<code>magic-pdf.json</code>，内容如下：</p>


<p>具体含义先不研究，先往下继续看下能否正常运行。</p>
<hr>
<h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><h3 id="第一次运行"><a href="#第一次运行" class="headerlink" title="第一次运行"></a>第一次运行</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://github.com/opendatalab/MinerU/raw/master/demo/pdfs/small_ocr.pdf</span><br><span class="line">magic-pdf -p small_ocr.pdf -o ./output</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意这里的small_ocr.pdf是图片型pdf，无法直接复制，需用ocr。</p>
</blockquote>


<p>可以看到模型初始化用了<code>2.918 S</code>，可以看到：</p>
<table>
<thead>
<tr>
<th>步骤</th>
<th>耗时</th>
</tr>
</thead>
<tbody><tr>
<td>model init</td>
<td>2.918 S</td>
</tr>
<tr>
<td>Layout Predict</td>
<td>7 S</td>
</tr>
<tr>
<td>MFD Predict</td>
<td>23 S</td>
</tr>
<tr>
<td>MFR Predict</td>
<td>1 S</td>
</tr>
<tr>
<td>OCR-det Predict</td>
<td>3 S</td>
</tr>
<tr>
<td>Table Predict</td>
<td>0 S</td>
</tr>
<tr>
<td>OCR-rec Predict</td>
<td>33 S</td>
</tr>
<tr>
<td>Processing pages</td>
<td>0 S</td>
</tr>
<tr>
<td>总耗时（包含模型初始化）</td>
<td>66.918 S</td>
</tr>
<tr>
<td>总耗时（不包含模型初始化）</td>
<td>64 S</td>
</tr>
</tbody></table>
<p>打开<code>magic-pdf.json</code>，将<code>device-mode</code>的<code>cpu</code>改为<code>cuda</code>，使用CUDA加速，还是运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">magic-pdf -p small_ocr.pdf -o ./output</span><br></pre></td></tr></table></figure>



<p>可以看到此时：</p>
<table>
<thead>
<tr>
<th>步骤</th>
<th>耗时</th>
</tr>
</thead>
<tbody><tr>
<td>model init</td>
<td>2.003 S</td>
</tr>
<tr>
<td>Layout Predict</td>
<td>0 S</td>
</tr>
<tr>
<td>MFD Predict</td>
<td>0 S</td>
</tr>
<tr>
<td>MFR Predict</td>
<td>0 S</td>
</tr>
<tr>
<td>OCR-det Predict</td>
<td>0 S</td>
</tr>
<tr>
<td>Table Predict</td>
<td>0 S</td>
</tr>
<tr>
<td>OCR-rec Predict</td>
<td>1 S</td>
</tr>
<tr>
<td>Processing pages</td>
<td>0 S</td>
</tr>
<tr>
<td>总耗时（包含模型初始化）</td>
<td>3.003 S</td>
</tr>
<tr>
<td>总耗时（不包含模型初始化）</td>
<td>1 S</td>
</tr>
</tbody></table>
<p>又测试了几次，发现模型加载时间不固定，那就看不包含模型初始化的总耗时吧：</p>
<table>
<thead>
<tr>
<th>运行</th>
<th>耗时</th>
</tr>
</thead>
<tbody><tr>
<td>cpu</td>
<td>64 S</td>
</tr>
<tr>
<td>cuda</td>
<td>1 S</td>
</tr>
</tbody></table>
<p><strong>可以看出GPU确实比CPU快很多。</strong></p>
<hr>
<h3 id="输出结果解析"><a href="#输出结果解析" class="headerlink" title="输出结果解析"></a>输出结果解析</h3>

<p>上面的运行结果得到了如图所示的输出，打开这个文档，可以看到命令行的使用介绍，翻译成中文：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">magic-pdf --<span class="built_in">help</span></span><br><span class="line">用法：magic-pdf [选项]</span><br><span class="line"></span><br><span class="line">选项：</span><br><span class="line">  -v, --version                显示版本号并退出</span><br><span class="line">  -p, --path 路径              本地文件路径或目录。支持 PDF、PPT、PPTX、DOC、DOCX、PNG、JPG 文件  [必填]</span><br><span class="line">  -o, --output-dir 路径        输出到本地目录  [必填]</span><br><span class="line">  -m, --method [ocr|txt|auto]  解析 PDF 的方法。ocr：使用 OCR 技术从 PDF 中提取信息；</span><br><span class="line">                               txt：仅适用于基于文本的 PDF，效果优于 OCR；</span><br><span class="line">                               auto：自动从 ocr 和 txt 中选择最佳解析方式。</span><br><span class="line">                               如果未指定方法，默认使用 auto。</span><br><span class="line">  -l, --lang 文本              输入 PDF 中包含的语言（如果已知）以提高 OCR 的准确性。可选项。</span><br><span class="line">                               语言应使用缩写，参考链接：</span><br><span class="line">                               https://paddlepaddle.github.io/PaddleOCR/en/ppocr</span><br><span class="line">                               /blog/multi_languages.html#5-support-languages-</span><br><span class="line">                               and-abbreviations</span><br><span class="line">  -d, --debug 布尔值           启用详细的调试信息，以便在执行 CLI 命令时查看过程。</span><br><span class="line">  -s, --start 整数             解析 PDF 时的起始页码，从 0 开始。</span><br><span class="line">  -e, --end 整数               解析 PDF 时的结束页码，从 0 开始。</span><br><span class="line">  --<span class="built_in">help</span>                       显示此帮助信息并退出。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 显示版本</span></span><br><span class="line">magic-pdf -v</span><br><span class="line"></span><br><span class="line"><span class="comment">## 命令行示例</span></span><br><span class="line">magic-pdf -p &#123;some_pdf&#125; -o &#123;some_output_dir&#125; -m auto</span><br></pre></td></tr></table></figure>

<blockquote>
<p>文件必须以以下后缀结尾：<br>.pdf .png .jpg .ppt .pptx .doc .docx.</p>
</blockquote>
<p>{some_pdf} 可以是单个 PDF 文件，也可以是包含多个 PDF 的目录。结果将保存在 {some_output_dir} 目录中。输出文件列表如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">├── some_pdf.md                          <span class="comment"># Markdown 文件  </span></span><br><span class="line">├── images                               <span class="comment"># 用于存储图片的目录  </span></span><br><span class="line">├── some_pdf_layout.pdf                  <span class="comment"># 页面布局图  </span></span><br><span class="line">├── some_pdf_middle.json                 <span class="comment"># MinerU 中间处理结果  </span></span><br><span class="line">├── some_pdf_model.json                  <span class="comment"># 模型推理结果  </span></span><br><span class="line">├── some_pdf_origin.pdf                  <span class="comment"># 原始 PDF 文件  </span></span><br><span class="line">├── some_pdf_spans.pdf                   <span class="comment"># 最小粒度的边界框位置信息图  </span></span><br><span class="line">└── some_pdf_content_list.json           <span class="comment"># 按阅读顺序排列的富文本 JSON  </span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>有关输出文件的更多信息，请参考 Inference Result 或 Pipe Result。</p>
</blockquote>
<p>对于我们的命令行命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">magic-pdf -p small_ocr.pdf -o ./output</span><br></pre></td></tr></table></figure>

<p>输入的是<code>small_ocr.pdf</code>，输出的是：</p>
<table>
<thead>
<tr>
<th>文件名</th>
<th>内容</th>
</tr>
</thead>
<tbody><tr>
<td>small_ocr_origin.pdf</td>
<td>原始pdf文件</td>
</tr>
<tr>
<td>small_ocr.md</td>
<td>将small_ocr.pdf转化为small_ocr.md</td>
</tr>
<tr>
<td>small_ocr_content_list.json</td>
<td>正文的按阅读顺序的json，包含四个字段（type:数据类型，text:文本内容，page_idx:页数，text_level:几级标题），如果一段既在第1页，有在第二页，那么内容合并在text中，page_idx&#x3D;1）</td>
</tr>
<tr>
<td>small_ocr_layout.pdf</td>
<td>页面布局图，分三种颜色表示（粉红色：正文，灰色：页眉页脚页序，淡紫色：标题）</td>
</tr>
<tr>
<td>small_ocr_spans.pdf</td>
<td>最小粒度的边界框位置信息图 ，正文的最小单位是行框</td>
</tr>
<tr>
<td>small_ocr_middle.json</td>
<td>感觉是将框出来的信息解析出来，包含解析块(para_blocks)，丢弃块(discarded)，段序，页序，框位置，内容等</td>
</tr>
<tr>
<td>small_ocr_model.json</td>
<td>模型推理结果，只取解析块中的内容，按行json化，包含位置信息</td>
</tr>
<tr>
<td>iamges</td>
<td>存储图片的文件夹，这里是空的</td>
</tr>
</tbody></table>
<h4 id="Inference-Result"><a href="#Inference-Result" class="headerlink" title="Inference Result"></a>Inference Result</h4><p> <a href="https://mineru.readthedocs.io/en/latest/user_guide/inference_result.html">见这里</a></p>
<h4 id="Pipe-Result"><a href="#Pipe-Result" class="headerlink" title="Pipe Result"></a>Pipe Result</h4><p><a href="https://mineru.readthedocs.io/en/latest/user_guide/pipe_result.html">见这里</a></p>
<hr>
<h3 id="第二次运行"><a href="#第二次运行" class="headerlink" title="第二次运行"></a>第二次运行</h3><p>我们调研pdf解析工具的契机就是招投标项目，所以还是以招标文件来进行实际测试，运行：</p>
<blockquote>
<p>注意：招标文件中有大量的长篇幅的表格。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">magic-pdf -p 招标文件修订-1.pdf -o ./output</span><br></pre></td></tr></table></figure>

<h4 id="发现的问题"><a href="#发现的问题" class="headerlink" title="发现的问题"></a>发现的问题</h4><ol>
<li>表格中的识别串行</li>
<li>表格中的识别可能会丢失行</li>
</ol>
<p>在<a href="https://mineru.readthedocs.io/en/latest/additional_notes/known_issues.html">known_issues</a>中，官方也提到了：Table recognition may result in row&#x2F;column recognition errors in complex tables.</p>
<blockquote>
<p>但我用的这表格也不复杂？😶</p>
</blockquote>
<p>在Issues中搜索表格，发现有很多人提问题，目前官方回复是这属于rapidtable的问题，mineru不对第三方库进行优化。</p>
<h3 id="Dolphin"><a href="#Dolphin" class="headerlink" title="Dolphin"></a>Dolphin</h3><p>这个文档图像解析库是2025.5.20开源的，简单的看了下，首先一看是字节开源的，emmmm，然后直接看Issues吧，发现很多人说幻觉问题啊，不可用问题啊什么的，蒜鸟蒜鸟不部署尝试了。</p>
<hr>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文主要介绍了MinerU工具的安装和简单使用，本人重点关注表格数据的解析，发现该工具使用的rapidtable在表格解析方面有较大缺陷，比如串行问题和行缺失问题，遂暂时认为在多表格场景，该工具可能暂不可用，最后又简单看了下Dolphin工具的issues，并未实际部署体验。</p>
<hr>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://github.com/opendatalab/MinerU/blob/master/docs/README_Ubuntu_CUDA_Acceleration_zh_CN.md">https://github.com/opendatalab/MinerU/blob/master/docs/README_Ubuntu_CUDA_Acceleration_zh_CN.md</a></li>
<li><a href="https://github.com/opendatalab/MinerU/blob/master/docs/how_to_download_models_zh_cn.md">https://github.com/opendatalab/MinerU/blob/master/docs/how_to_download_models_zh_cn.md</a></li>
<li><a href="https://mineru.readthedocs.io/en/latest/user_guide/usage/command_line.html">https://mineru.readthedocs.io/en/latest/user_guide/usage/command_line.html</a></li>
<li><a href="https://mineru.readthedocs.io/en/latest/user_guide/inference_result.html">https://mineru.readthedocs.io/en/latest/user_guide/inference_result.html</a></li>
<li><a href="https://mineru.readthedocs.io/en/latest/user_guide/pipe_result.html">https://mineru.readthedocs.io/en/latest/user_guide/pipe_result.html</a></li>
<li><a href="https://mineru.readthedocs.io/en/latest/user_guide/tutorial/pipeline.html">https://mineru.readthedocs.io/en/latest/user_guide/tutorial/pipeline.html</a></li>
<li><a href="https://mineru.readthedocs.io/en/latest/">https://mineru.readthedocs.io/en/latest/</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>pdf</tag>
        <tag>mineru</tag>
      </tags>
  </entry>
  <entry>
    <title>Python备忘录：高频易忘技巧速查</title>
    <url>/2025/06/12/Python%E5%A4%87%E5%BF%98%E5%BD%95%EF%BC%9A%E9%AB%98%E9%A2%91%E6%98%93%E5%BF%98%E6%8A%80%E5%B7%A7%E9%80%9F%E6%9F%A5/</url>
    <content><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul>
<li><a href="#f1">列表推导式</a></li>
<li><a href="#f2">sort</a></li>
<li><a href="#f3">filter</a></li>
<li><a href="#f4">map</a></li>
<li><a href="#f5">lambda 表达式</a></li>
</ul>
<span id="more"></span>

<hr>
<p><a name="f1"></a></p>
<h3 id="1-列表推导式"><a href="#1-列表推导式" class="headerlink" title="1. 列表推导式"></a>1. 列表推导式</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[表达式 <span class="keyword">for</span> 变量 <span class="keyword">in</span> 可迭代对象 <span class="keyword">if</span> 条件]</span><br></pre></td></tr></table></figure>

<ul>
<li><code>表达式</code>：对每个元素进行的操作（可以是原样、处理或运算）</li>
<li><code>变量</code>：表示从可迭代对象中取出的每个元素</li>
<li><code>可迭代对象</code>：比如 <code>list</code>、<code>range</code>、<code>str</code></li>
<li><code>if 条件</code>（可选）：过滤条件</li>
</ul>
<p><strong>示例1：平方列表</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">squares = [x * x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>)]</span><br><span class="line"><span class="comment"># 相当于：</span></span><br><span class="line"><span class="comment"># squares = []</span></span><br><span class="line"><span class="comment"># for x in range(5):</span></span><br><span class="line"><span class="comment">#     squares.append(x * x)</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(squares)  <span class="comment"># [0, 1, 4, 9, 16]</span></span><br></pre></td></tr></table></figure>

<p><strong>示例2：过滤偶数</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">numbers = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>]</span><br><span class="line">evens = [x <span class="keyword">for</span> x <span class="keyword">in</span> numbers <span class="keyword">if</span> x % <span class="number">2</span> == <span class="number">0</span>]</span><br><span class="line"><span class="comment"># 相当于:</span></span><br><span class="line"><span class="comment"># evens = []</span></span><br><span class="line"><span class="comment"># for x in numbers:</span></span><br><span class="line"><span class="comment">#	  if x % 2 == 0:</span></span><br><span class="line"><span class="comment"># 		  evens.append(x)</span></span><br><span class="line"><span class="built_in">print</span>(evens)</span><br></pre></td></tr></table></figure>



<p><a name="f5"></a></p>
<h3 id="2-lambda表达式"><a href="#2-lambda表达式" class="headerlink" title="2. lambda表达式"></a>2. lambda表达式</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">lambda</span> 参数<span class="number">1</span>, 参数<span class="number">2</span>, ... : 表达式</span><br></pre></td></tr></table></figure>

<ul>
<li><code>lambda</code> 后面是参数</li>
<li>冒号 <code>:</code> 后面是<strong>表达式</strong>（只能是一行，不能写多条语句）</li>
<li><code>lambda</code> 表达式本身<strong>返回这个表达式的值</strong></li>
</ul>
<p><strong>示例1：平方函数</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">square = <span class="keyword">lambda</span> x: x * x</span><br><span class="line"><span class="comment"># 相当于</span></span><br><span class="line"><span class="comment"># def square(x):</span></span><br><span class="line"><span class="comment">#    return x * x</span></span><br><span class="line"><span class="built_in">print</span>(square(<span class="number">5</span>))  <span class="comment"># 输出 25</span></span><br></pre></td></tr></table></figure>

<p><strong>示例2：两个数相加</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">add = <span class="keyword">lambda</span> x, y: x + y</span><br><span class="line"><span class="built_in">print</span>(add(<span class="number">3</span>, <span class="number">4</span>))  <span class="comment"># 输出 7</span></span><br></pre></td></tr></table></figure>



<p><strong>示例 3：配合 <code>sorted</code> 使用</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">students = [(<span class="string">&quot;Alice&quot;</span>, <span class="number">88</span>), (<span class="string">&quot;Bob&quot;</span>, <span class="number">75</span>), (<span class="string">&quot;Charlie&quot;</span>, <span class="number">90</span>)]</span><br><span class="line">students_sorted = <span class="built_in">sorted</span>(students, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(students_sorted)</span><br></pre></td></tr></table></figure>

<p><strong>相当于：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_score</span>(<span class="params">student</span>):</span><br><span class="line">    <span class="keyword">return</span> student[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">students = [(<span class="string">&quot;Alice&quot;</span>, <span class="number">88</span>), (<span class="string">&quot;Bob&quot;</span>, <span class="number">75</span>), (<span class="string">&quot;Charlie&quot;</span>, <span class="number">90</span>)]</span><br><span class="line">students_sorted = <span class="built_in">sorted</span>(students, key=get_score)</span><br><span class="line"><span class="built_in">print</span>(students_sorted)</span><br></pre></td></tr></table></figure>



<p><strong>示例 4：配合 <code>filter</code> 使用（筛选偶数）</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nums = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">evens = <span class="built_in">list</span>(<span class="built_in">filter</span>(<span class="keyword">lambda</span> x: x % <span class="number">2</span> == <span class="number">0</span>, nums))</span><br><span class="line"><span class="built_in">print</span>(evens)</span><br></pre></td></tr></table></figure>

<p><strong>相当于：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">is_even</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> x % <span class="number">2</span> == <span class="number">0</span></span><br><span class="line"></span><br><span class="line">nums = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">evens = <span class="built_in">list</span>(<span class="built_in">filter</span>(is_even, nums))</span><br><span class="line"><span class="built_in">print</span>(evens)</span><br></pre></td></tr></table></figure>



<p><strong>示例 5：配合 <code>map</code> 使用（每个数平方）</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">nums = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">squares = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x ** <span class="number">2</span>, nums))</span><br><span class="line"><span class="built_in">print</span>(squares)</span><br></pre></td></tr></table></figure>

<p><strong>相当于：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">square</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> x ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line">nums = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">squares = <span class="built_in">list</span>(<span class="built_in">map</span>(square, nums))</span><br><span class="line"><span class="built_in">print</span>(squares)</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>PDF解析库：pdfplumber基础用法</title>
    <url>/2025/06/04/PDF%E8%A7%A3%E6%9E%90%E5%BA%93%EF%BC%9Apdfplumber%E5%9F%BA%E7%A1%80%E7%94%A8%E6%B3%95/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在<a href="https://caihaoran-00.github.io/2025/05/29/LLM%E5%BA%94%E7%94%A8%EF%BC%9A%E7%BB%93%E6%9E%84%E5%8C%96%E6%8F%90%E5%8F%96%E5%8F%8A%E5%90%8E%E7%BB%AD%E6%80%9D%E8%B7%AF/#more">LLM应用：结构化提取及后续思路</a>一文中，我们使用<code>pdfplumber</code>的<code>.extract_text</code>方法，但这个方法会将全文（尤其指表格部分）当做普通文本按行读取，会完全丢失表格的格式，察觉<code>pdfplumber</code>库的用法有些学问，遂准备本文记录下<code>pdfplumber</code>的基础用法，目的是自动化的判别是普通文本还是表格，表格数据用表格提取的方式，普通文本用文本提取的方法。</p>
<span id="more"></span>

<hr>
<h2 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h2><h3 id="一-Page-chars"><a href="#一-Page-chars" class="headerlink" title="一 Page.chars"></a>一 Page.chars</h3><p>我们从官方给的基本示例开始看起，打印第一页的第一个字符：</p>
<figure class="highlight python"><figcaption><span>pdfplumber_basic_chars.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pdfplumber</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(<span class="string">&quot;../../招标文件修订-1.pdf&quot;</span>) <span class="keyword">as</span> pdf:</span><br><span class="line">    first_page = pdf.pages[<span class="number">0</span>]</span><br><span class="line">    <span class="built_in">print</span>(first_page.chars[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="string">&#x27;matrix&#x27;</span>: (1, 0, 0, 1, 303.75000763, 37.94699858999995), </span><br><span class="line"><span class="string">&#x27;fontname&#x27;</span>: <span class="string">&#x27;FAAAAH+TimesNewRomanPSMT&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;adv&#x27;</span>: 4.5,</span><br><span class="line"><span class="string">&#x27;upright&#x27;</span>: True,</span><br><span class="line"><span class="string">&#x27;x0&#x27;</span>: 303.75000763,</span><br><span class="line"><span class="string">&#x27;y0&#x27;</span>: 36.00299858999995,</span><br><span class="line"><span class="string">&#x27;x1&#x27;</span>: 308.25000763,</span><br><span class="line"><span class="string">&#x27;y1&#x27;</span>: 45.00299858999995,</span><br><span class="line"><span class="string">&#x27;width&#x27;</span>: 4.5,</span><br><span class="line"><span class="string">&#x27;height&#x27;</span>: 9.0,</span><br><span class="line"><span class="string">&#x27;size&#x27;</span>: 9.0,</span><br><span class="line"><span class="string">&#x27;mcid&#x27;</span>: None,</span><br><span class="line"><span class="string">&#x27;tag&#x27;</span>: None,</span><br><span class="line"><span class="string">&#x27;object_type&#x27;</span>: <span class="string">&#x27;char&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;page_number&#x27;</span>: 1, </span><br><span class="line"><span class="string">&#x27;ncs&#x27;</span>: <span class="string">&#x27;DeviceGray&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;text&#x27;</span>: <span class="string">&#x27;1&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;stroking_color&#x27;</span>: None,</span><br><span class="line"><span class="string">&#x27;stroking_pattern&#x27;</span>: None,</span><br><span class="line"><span class="string">&#x27;non_stroking_color&#x27;</span>: (0,), </span><br><span class="line"><span class="string">&#x27;non_stroking_pattern&#x27;</span>: None,</span><br><span class="line"><span class="string">&#x27;top&#x27;</span>: 746.99700141,</span><br><span class="line"><span class="string">&#x27;bottom&#x27;</span>: 755.99700141,</span><br><span class="line"><span class="string">&#x27;doctop&#x27;</span>: 746.99700141</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>各字段&#x2F;属性名的说明如下：</strong></p>
<table>
<thead>
<tr>
<th align="center">属性名</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">matrix</td>
<td align="center">字符的当前变换矩阵（Current Transformation Matrix）</td>
</tr>
<tr>
<td align="center">fontname</td>
<td align="center">字体名称</td>
</tr>
<tr>
<td align="center">adv</td>
<td align="center">文字宽度 × 字体大小 × 缩放因子</td>
</tr>
<tr>
<td align="center">upright</td>
<td align="center">字符是否直立</td>
</tr>
<tr>
<td align="center">x0</td>
<td align="center">字符左边到页面左边的距离</td>
</tr>
<tr>
<td align="center">y0</td>
<td align="center">字符底部到页面底部的距离</td>
</tr>
<tr>
<td align="center">x1</td>
<td align="center">字符右边到页面左边的距离</td>
</tr>
<tr>
<td align="center">y1</td>
<td align="center">字符顶部到页面底部的距离</td>
</tr>
<tr>
<td align="center">width</td>
<td align="center">字符宽度</td>
</tr>
<tr>
<td align="center">height</td>
<td align="center">字符高度</td>
</tr>
<tr>
<td align="center">size</td>
<td align="center">字体大小</td>
</tr>
<tr>
<td align="center">mcid</td>
<td align="center">字符所属的标记内容段 ID（如果有，否则为 None），实验性属性</td>
</tr>
<tr>
<td align="center">tag</td>
<td align="center">字符所属的标记内容段标签（如果有，否则为 None），实验性属性</td>
</tr>
<tr>
<td align="center">object_type</td>
<td align="center">对象类型，固定为 “char”</td>
</tr>
<tr>
<td align="center">page_number</td>
<td align="center">字符所在的页码</td>
</tr>
<tr>
<td align="center">ncs</td>
<td align="center">TKTK（待补充）</td>
</tr>
<tr>
<td align="center">text</td>
<td align="center">字符本身，例如：”z”、”Z” 或空格</td>
</tr>
<tr>
<td align="center">stroking_color</td>
<td align="center">字符轮廓颜色（描边色），详见 docs&#x2F;colors.md</td>
</tr>
<tr>
<td align="center">stroking_pattern</td>
<td align="center">TKTK（待补充）</td>
</tr>
<tr>
<td align="center">non_stroking_color</td>
<td align="center">字符内部颜色（填充色），详见 docs&#x2F;colors.md</td>
</tr>
<tr>
<td align="center">non_stroking_pattern</td>
<td align="center">TKTK（待补充）</td>
</tr>
<tr>
<td align="center">top</td>
<td align="center">字符顶部到页面顶部的距离</td>
</tr>
<tr>
<td align="center">bottom</td>
<td align="center">字符底部到页面顶部的距离</td>
</tr>
<tr>
<td align="center">doctop</td>
<td align="center">字符顶部到整个文档顶部的距离</td>
</tr>
</tbody></table>
<p>好的，话说回来，<code>&#39;text&#39;: &#39;1&#39;?</code>哪里有1😳</p>


<p>不会是页面最下面中间的那个像0和1重叠的页码吧？不行，我要把这页的所有字符都打印出来看一下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(<span class="string">&quot;../../招标文件修订-1.pdf&quot;</span>) <span class="keyword">as</span> pdf:</span><br><span class="line">    first_page = pdf.pages[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> i, char <span class="keyword">in</span> <span class="built_in">enumerate</span>(first_page.chars):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;字符 <span class="subst">&#123;i&#125;</span>: 文本=&#x27;<span class="subst">&#123;char[<span class="string">&#x27;text&#x27;</span>]&#125;</span>&#x27;, 位置=(x0=<span class="subst">&#123;char[<span class="string">&#x27;x0&#x27;</span>]&#125;</span>, y0=<span class="subst">&#123;char[<span class="string">&#x27;y0&#x27;</span>]&#125;</span>, x1=<span class="subst">&#123;char[<span class="string">&#x27;x1&#x27;</span>]&#125;</span>, y1=<span class="subst">&#123;char[<span class="string">&#x27;y1&#x27;</span>]&#125;</span>)&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">字符 0: 文本=<span class="string">&#x27;1&#x27;</span>, 位置=(x0=303.75000763, y0=36.00299858999995, x1=308.25000763, y1=45.00299858999995)</span><br><span class="line">字符 1: 文本=<span class="string">&#x27;0&#x27;</span>, 位置=(x0=303.75, y0=36.00299858999995, x1=308.25, y1=45.00299858999995)</span><br><span class="line">字符 2: 文本=<span class="string">&#x27;杭&#x27;</span>, 位置=(x0=113.23200226, y0=606.64799768, x1=137.23200226, y1=630.64799768)</span><br><span class="line">字符 3: 文本=<span class="string">&#x27;州&#x27;</span>, 位置=(x0=137.32800226, y0=606.64799768, x1=161.32800226, y1=630.64799768)</span><br><span class="line">字符 4: 文本=<span class="string">&#x27;市&#x27;</span>, 位置=(x0=161.42400226, y0=606.64799768, x1=185.42400226, y1=630.64799768)</span><br><span class="line">字符 5: 文本=<span class="string">&#x27;房&#x27;</span>, 位置=(x0=185.52000226, y0=606.64799768, x1=209.52000226, y1=630.64799768)</span><br><span class="line">字符 6: 文本=<span class="string">&#x27;屋&#x27;</span>, 位置=(x0=209.61600226000002, y0=606.64799768, x1=233.61600226000002, y1=630.64799768)</span><br><span class="line">字符 7: 文本=<span class="string">&#x27;建&#x27;</span>, 位置=(x0=233.71200226000002, y0=606.64799768, x1=257.71200226, y1=630.64799768)</span><br><span class="line">字符 8: 文本=<span class="string">&#x27;筑&#x27;</span>, 位置=(x0=257.80800226, y0=606.64799768, x1=281.80800226, y1=630.64799768)</span><br><span class="line">字符 9: 文本=<span class="string">&#x27;和&#x27;</span>, 位置=(x0=281.90400226, y0=606.64799768, x1=305.90400226, y1=630.64799768)</span><br><span class="line">字符 10: 文本=<span class="string">&#x27;市&#x27;</span>, 位置=(x0=306.00000226000003, y0=606.64799768, x1=330.00000226000003, y1=630.64799768)</span><br><span class="line">字符 11: 文本=<span class="string">&#x27;政&#x27;</span>, 位置=(x0=330.09600226000003, y0=606.64799768, x1=354.09600226000003, y1=630.64799768)</span><br><span class="line">字符 12: 文本=<span class="string">&#x27;基&#x27;</span>, 位置=(x0=354.19200226000004, y0=606.64799768, x1=378.19200226000004, y1=630.64799768)</span><br><span class="line">字符 13: 文本=<span class="string">&#x27;础&#x27;</span>, 位置=(x0=378.28800226000004, y0=606.64799768, x1=402.28800226000004, y1=630.64799768)</span><br><span class="line">字符 14: 文本=<span class="string">&#x27;设&#x27;</span>, 位置=(x0=402.38400226000005, y0=606.64799768, x1=426.38400226000005, y1=630.64799768)</span><br><span class="line">字符 15: 文本=<span class="string">&#x27;施&#x27;</span>, 位置=(x0=426.48000226000005, y0=606.64799768, x1=450.48000226000005, y1=630.64799768)</span><br><span class="line">字符 16: 文本=<span class="string">&#x27;项&#x27;</span>, 位置=(x0=450.57600226000005, y0=606.64799768, x1=474.57600226000005, y1=630.64799768)</span><br><span class="line">字符 17: 文本=<span class="string">&#x27;目&#x27;</span>, 位置=(x0=474.67200226000006, y0=606.64799768, x1=498.67200226000006, y1=630.64799768)</span><br><span class="line">字符 18: 文本=<span class="string">&#x27; &#x27;</span>, 位置=(x0=498.76800226000006, y0=606.64799768, x1=510.76800226000006, y1=630.64799768)</span><br><span class="line">字符 19: 文本=<span class="string">&#x27;设&#x27;</span>, 位置=(x0=185.51999665, y0=544.39799768, x1=209.51999665, y1=568.39799768)</span><br><span class="line">字符 20: 文本=<span class="string">&#x27;计&#x27;</span>, 位置=(x0=209.61599665, y0=544.39799768, x1=233.61599665, y1=568.39799768)</span><br><span class="line">字符 21: 文本=<span class="string">&#x27;招&#x27;</span>, 位置=(x0=233.71199665, y0=544.39799768, x1=257.71199665, y1=568.39799768)</span><br><span class="line">字符 22: 文本=<span class="string">&#x27;标&#x27;</span>, 位置=(x0=257.80799665, y0=544.39799768, x1=281.80799665, y1=568.39799768)</span><br><span class="line">字符 23: 文本=<span class="string">&#x27;文&#x27;</span>, 位置=(x0=281.90399665, y0=544.39799768, x1=305.90399665, y1=568.39799768)</span><br><span class="line">字符 24: 文本=<span class="string">&#x27;件&#x27;</span>, 位置=(x0=305.99999665, y0=544.39799768, x1=329.99999665, y1=568.39799768)</span><br><span class="line">字符 25: 文本=<span class="string">&#x27;示&#x27;</span>, 位置=(x0=330.09599665, y0=544.39799768, x1=354.09599665, y1=568.39799768)</span><br><span class="line">字符 26: 文本=<span class="string">&#x27;范&#x27;</span>, 位置=(x0=354.19199665, y0=544.39799768, x1=378.19199665, y1=568.39799768)</span><br><span class="line">字符 27: 文本=<span class="string">&#x27;文&#x27;</span>, 位置=(x0=378.28799665, y0=544.39799768, x1=402.28799665, y1=568.39799768)</span><br><span class="line">字符 28: 文本=<span class="string">&#x27;本&#x27;</span>, 位置=(x0=402.38399665000003, y0=544.39799768, x1=426.38399665000003, y1=568.39799768)</span><br><span class="line">字符 29: 文本=<span class="string">&#x27;（&#x27;</span>, 位置=(x0=251.78400421999999, y0=496.86800394999995, x1=269.78400422, y1=514.86800395)</span><br><span class="line">字符 30: 文本=<span class="string">&#x27;资&#x27;</span>, 位置=(x0=269.85600422, y0=496.86800394999995, x1=287.85600422, y1=514.86800395)</span><br><span class="line">字符 31: 文本=<span class="string">&#x27;格&#x27;</span>, 位置=(x0=287.92800422, y0=496.86800394999995, x1=305.92800422, y1=514.86800395)</span><br><span class="line">字符 32: 文本=<span class="string">&#x27;后&#x27;</span>, 位置=(x0=306.00000422, y0=496.86800394999995, x1=324.00000422, y1=514.86800395)</span><br><span class="line">字符 33: 文本=<span class="string">&#x27;审&#x27;</span>, 位置=(x0=324.07200422, y0=496.86800394999995, x1=342.07200422, y1=514.86800395)</span><br><span class="line">字符 34: 文本=<span class="string">&#x27;）&#x27;</span>, 位置=(x0=342.14400422, y0=496.86800394999995, x1=360.14400422, y1=514.86800395)</span><br><span class="line">字符 35: 文本=<span class="string">&#x27;（&#x27;</span>, 位置=(x0=251.71199799, y0=453.12900554, x1=269.71199799, y1=471.12900554)</span><br><span class="line">字符 36: 文本=<span class="string">&#x27;2&#x27;</span>, 位置=(x0=269.78399799, y0=453.12900554, x1=278.78399799, y1=471.12900554)</span><br><span class="line">字符 37: 文本=<span class="string">&#x27;0&#x27;</span>, 位置=(x0=278.85599799, y0=453.12900554, x1=287.85599799, y1=471.12900554)</span><br><span class="line">字符 38: 文本=<span class="string">&#x27;1&#x27;</span>, 位置=(x0=287.92799799, y0=453.12900554, x1=296.92799799, y1=471.12900554)</span><br><span class="line">字符 39: 文本=<span class="string">&#x27;9&#x27;</span>, 位置=(x0=296.99999799, y0=453.12900554, x1=305.99999799, y1=471.12900554)</span><br><span class="line">字符 40: 文本=<span class="string">&#x27;年&#x27;</span>, 位置=(x0=306.07199799, y0=453.12900554, x1=324.07199799, y1=471.12900554)</span><br><span class="line">字符 41: 文本=<span class="string">&#x27;版&#x27;</span>, 位置=(x0=324.14399799, y0=453.12900554, x1=342.14399799, y1=471.12900554)</span><br><span class="line">字符 42: 文本=<span class="string">&#x27;）&#x27;</span>, 位置=(x0=342.21599799, y0=453.12900554, x1=360.21599799, y1=471.12900554)</span><br><span class="line">字符 43: 文本=<span class="string">&#x27;杭&#x27;</span>, 位置=(x0=206.60399628, y0=149.65998087999998, x1=224.60399628, y1=167.65998087999998)</span><br><span class="line">字符 44: 文本=<span class="string">&#x27;州&#x27;</span>, 位置=(x0=224.67599628, y0=149.65998087999998, x1=242.67599628, y1=167.65998087999998)</span><br><span class="line">字符 45: 文本=<span class="string">&#x27;市&#x27;</span>, 位置=(x0=242.74799628, y0=149.65998087999998, x1=260.74799628, y1=167.65998087999998)</span><br><span class="line">字符 46: 文本=<span class="string">&#x27;城&#x27;</span>, 位置=(x0=260.81999628, y0=149.65998087999998, x1=278.81999628, y1=167.65998087999998)</span><br><span class="line">字符 47: 文本=<span class="string">&#x27;乡&#x27;</span>, 位置=(x0=278.89199628, y0=149.65998087999998, x1=296.89199628, y1=167.65998087999998)</span><br><span class="line">字符 48: 文本=<span class="string">&#x27;建&#x27;</span>, 位置=(x0=296.96399628, y0=149.65998087999998, x1=314.96399628, y1=167.65998087999998)</span><br><span class="line">字符 49: 文本=<span class="string">&#x27;设&#x27;</span>, 位置=(x0=315.03599628, y0=149.65998087999998, x1=333.03599628, y1=167.65998087999998)</span><br><span class="line">字符 50: 文本=<span class="string">&#x27;委&#x27;</span>, 位置=(x0=333.10799628, y0=149.65998087999998, x1=351.10799628, y1=167.65998087999998)</span><br><span class="line">字符 51: 文本=<span class="string">&#x27;员&#x27;</span>, 位置=(x0=351.17999628, y0=149.65998087999998, x1=369.17999628, y1=167.65998087999998)</span><br><span class="line">字符 52: 文本=<span class="string">&#x27;会&#x27;</span>, 位置=(x0=369.25199628, y0=149.65998087999998, x1=387.25199628, y1=167.65998087999998)</span><br><span class="line">字符 53: 文本=<span class="string">&#x27;制&#x27;</span>, 位置=(x0=387.32399628, y0=149.65998087999998, x1=405.32399628, y1=167.65998087999998)</span><br><span class="line">字符 54: 文本=<span class="string">&#x27;二&#x27;</span>, 位置=(x0=247.24800873, y0=126.31598674000004, x1=265.24800873000004, y1=144.31598674000003)</span><br><span class="line">字符 55: 文本=<span class="string">&#x27;0&#x27;</span>, 位置=(x0=265.32000873, y0=126.31598674000004, x1=274.32000873, y1=144.31598674000003)</span><br><span class="line">字符 56: 文本=<span class="string">&#x27;二&#x27;</span>, 位置=(x0=274.39200873, y0=126.31598674000004, x1=292.39200873, y1=144.31598674000003)</span><br><span class="line">字符 57: 文本=<span class="string">&#x27;五&#x27;</span>, 位置=(x0=292.46400873, y0=126.31598674000004, x1=310.46400873, y1=144.31598674000003)</span><br><span class="line">字符 58: 文本=<span class="string">&#x27;年&#x27;</span>, 位置=(x0=310.53600873, y0=126.31598674000004, x1=328.53600873, y1=144.31598674000003)</span><br><span class="line">字符 59: 文本=<span class="string">&#x27;四&#x27;</span>, 位置=(x0=328.60800873000005, y0=126.31598674000004, x1=346.60800873000005, y1=144.31598674000003)</span><br><span class="line">字符 60: 文本=<span class="string">&#x27;月&#x27;</span>, 位置=(x0=346.68000873000005, y0=126.31598674000004, x1=364.68000873000005, y1=144.31598674000003)</span><br></pre></td></tr></table></figure>

<p>好像确实是那个页码，但为什么是先从最后读取呢，有些奇怪，不行，我想再确切的确认下到底是不是页码。</p>
<hr>
<h3 id="二-im-draw-rect-…"><a href="#二-im-draw-rect-…" class="headerlink" title="二 im.draw_rect(…)"></a>二 im.draw_rect(…)</h3><table>
<thead>
<tr>
<th align="center">单对象方法</th>
<th align="center">批量方法</th>
<th align="center">描述</th>
</tr>
</thead>
<tbody><tr>
<td align="center">im.draw_rect(<br />bbox_or_obj, <br />fill&#x3D;{color},<br /> stroke&#x3D;{color}, stroke_width&#x3D;1)</td>
<td align="center">im.draw_rects(list_of_rects, **kwargs)</td>
<td align="center">从矩形对象、字符对象等，或一个四元组形式的边界框中绘制矩形。</td>
</tr>
</tbody></table>
<p>解释：</p>
<ul>
<li><code>im.draw_rect(...)</code>：绘制单个矩形，可传入一个矩形对象或四元组边界框。</li>
<li><code>im.draw_rects(...)</code>：绘制多个矩形，参数为矩形列表。其他绘图参数可通过 <code>**kwargs</code> 传入，例如填充颜色、描边颜色和描边宽度。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pdfplumber</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(<span class="string">&quot;../../招标文件修订-1.pdf&quot;</span>) <span class="keyword">as</span> pdf:</span><br><span class="line">    first_page = pdf.pages[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 提取页面图像</span></span><br><span class="line">    im = first_page.to_image(resolution=<span class="number">150</span>)  <span class="comment"># 分辨率 150 DPI</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 标记前两个字符的位置</span></span><br><span class="line">    <span class="keyword">for</span> char <span class="keyword">in</span> first_page.chars[<span class="number">0</span>:<span class="number">2</span>]:</span><br><span class="line">        x0, y0, x1, y1 = char[<span class="string">&#x27;x0&#x27;</span>], char[<span class="string">&#x27;top&#x27;</span>], char[<span class="string">&#x27;x1&#x27;</span>], char[<span class="string">&#x27;bottom&#x27;</span>]</span><br><span class="line">        im.draw_rect((x0, y0, x1, y1), fill=(<span class="number">255</span>, <span class="number">255</span>, <span class="number">0</span>, <span class="number">50</span>), stroke=<span class="string">&quot;red&quot;</span>, stroke_width=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 显示图像</span></span><br><span class="line">    im.show()</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th align="center">变量名</th>
<th align="center">含义</th>
</tr>
</thead>
<tbody><tr>
<td align="center">fill</td>
<td align="center">填充色</td>
</tr>
<tr>
<td align="center">stoke</td>
<td align="center">框框的颜色</td>
</tr>
<tr>
<td align="center">stroke_width</td>
<td align="center">框框的宽度</td>
</tr>
</tbody></table>
<blockquote>
<p><code>fill=(255, 255, 0, 50)</code> 表示一种带透明度的填充颜色，具体含义是：</p>
<ul>
<li><code>(255, 255, 0)</code> 是 RGB 颜色值，对应纯黄色（红255，绿255，蓝0）</li>
<li><code>50</code> 是 alpha 通道值，表示透明度，范围通常是 0~255，50 表示比较透明（约 20% 不透明）</li>
</ul>
<p>所以这是一种半透明的黄色填充色，颜色比较浅，带有一定透明效果。</p>
</blockquote>
<p><strong>输出：</strong></p>


<p>可以看到，<code>0,1</code>确实是页码位置。</p>
<hr>
<p>回归正文，我们的目标是表格数据用表格提取的方式，普通文本用文本提取的方法，那我们就需要先单独体验下文本提取和表格提取的方法，先从文本提取开始吧：</p>
<h3 id="三-文本提取"><a href="#三-文本提取" class="headerlink" title="三 文本提取"></a>三 文本提取</h3><h4 id="1-Page-extract-text-…"><a href="#1-Page-extract-text-…" class="headerlink" title="1. Page.extract_text(…)"></a>1. Page.extract_text(…)</h4><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>.extract_text(x_tolerance=3, x_tolerance_ratio=None, y_tolerance=3, layout=False, x_density=7.25, y_density=13, line_dir_render=None, char_dir_render=None, **kwargs)</code></td>
<td>将页面上的所有字符对象整理为一个单一的字符串。<br><br><strong>当 <code>layout=False</code> 时：</strong><br>若前一个字符的 <code>x1</code> 与下一个字符的 <code>x0</code> 之间的差值大于 <code>x_tolerance</code>，则插入空格。（如果设置了 <code>x_tolerance_ratio</code>，则使用动态的 <code>x_tolerance</code>，其值为 <code>x_tolerance_ratio * 上一个字符的 size</code>。）若一个字符的 <code>doctop</code> 与下一个字符的 <code>doctop</code> 之间的差值大于 <code>y_tolerance</code>，则插入换行符。<br><br><strong>当 <code>layout=True</code> 时（实验性功能）：</strong><br>尝试模拟 PDF 页面上文本的结构布局。通过 <code>x_density</code> 和 <code>y_density</code> 来判断每个 PDF 坐标点（单位）上至少应有的字符数或换行数。<br>你可以传入 <code>line_dir_render=&quot;ttb&quot;/&quot;btt&quot;/&quot;ltr&quot;/&quot;rtl&quot;</code> 和&#x2F;或 <code>char_dir_render=&quot;ttb&quot;/&quot;btt&quot;/&quot;ltr&quot;/&quot;rtl&quot;</code> 来改变默认的行或字符输出方向（例如：从上到下、从右到左等）。<br>其余所有的 <code>**kwargs</code> 参数都会传递给 <code>.extract_words(...)</code> 方法（见下文），该方法是进行布局计算的第一步。</td>
</tr>
</tbody></table>
<blockquote>
<p><code>ttb</code>：top-to-bottom（从上到下）</p>
<p><code>btt</code>：bottom-to-top（从下到上）</p>
<p><code>ltr</code>：left-to-right（从左到右）</p>
<p><code>rtl</code>：right-to-left（从右到左）。</p>
</blockquote>
<p><strong>更详细的介绍请看附录1</strong>，使用<code>.extract_text</code>读取文件的前三页并打印：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pdfplumber</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换为你的 PDF 文件路径</span></span><br><span class="line">pdf_path = <span class="string">&quot;../../招标文件修订-1.pdf&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(pdf_path) <span class="keyword">as</span> pdf:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">min</span>(<span class="number">3</span>, <span class="built_in">len</span>(pdf.pages))):  <span class="comment"># 最多读取前三页</span></span><br><span class="line">        page = pdf.pages[i]</span><br><span class="line">        text = page.extract_text(</span><br><span class="line">            x_tolerance=<span class="number">3</span>,</span><br><span class="line">            y_tolerance=<span class="number">3</span>,</span><br><span class="line">            layout=<span class="literal">False</span>  <span class="comment"># 或设置为 True 以尝试还原排版结构</span></span><br><span class="line">        )</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;--- 第 <span class="subst">&#123;i+<span class="number">1</span>&#125;</span> 页 ---\n&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(text <span class="keyword">or</span> <span class="string">&quot;[该页无可提取文本]&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span> + <span class="string">&quot;-&quot;</span>*<span class="number">40</span> + <span class="string">&quot;\n&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>我觉得有必要把第二页和第三页也贴出来，为了不占用正文位置，贴在<strong>附录2</strong>了，有两点需要关注的：</p>
<ol>
<li>第三页是表格</li>
<li>页码有问题（均以1打底，看附录2你就明白了）</li>
</ol>
<p><strong>输出：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">--- 第 1 页 ---</span><br><span class="line"></span><br><span class="line">杭州市房屋建筑和市政基础设施项目</span><br><span class="line">设计招标文件示范文本</span><br><span class="line">（资格后审）</span><br><span class="line">（2019年版）</span><br><span class="line">杭州市城乡建设委员会制</span><br><span class="line">二0二五年四月</span><br><span class="line">01</span><br><span class="line"></span><br><span class="line">----------------------------------------</span><br><span class="line"></span><br><span class="line">--- 第 2 页 ---</span><br><span class="line"></span><br><span class="line">奥体街（扬帆路-养正巷）设计</span><br><span class="line">（招标编号：A3301080120526863001221）</span><br><span class="line">招标文件</span><br><span class="line">（☑资格后审□邀请招标）</span><br><span class="line">招标人：杭州滨江奥体博览城开发建设运营管理有限公司 （盖单位章）</span><br><span class="line">招标代理机构：浙江华耀建设咨询有限公司 （盖单位章）</span><br><span class="line">2025年05月15日</span><br><span class="line">11</span><br><span class="line"></span><br><span class="line">----------------------------------------</span><br><span class="line"></span><br><span class="line">--- 第 3 页 ---</span><br><span class="line"></span><br><span class="line">第二章 投标人须知</span><br><span class="line">投标人须知前附表</span><br><span class="line">条款号 条款名称 编列内容</span><br><span class="line">名称：杭州滨江奥体博览城开发建</span><br><span class="line">设运营管理有限公司</span><br><span class="line">地址：浙江省杭州市滨江区浦沿街</span><br><span class="line">1.1.2 招标人</span><br><span class="line">道滨安路1338号三楼</span><br><span class="line">联系人：翁栎超</span><br><span class="line">电话：13600511926</span><br><span class="line">名称： 浙江华耀建设咨询有限公司</span><br><span class="line">地址：杭州市上城区佰富时代中心3幢13楼</span><br><span class="line">1.1.3 招标代理机构</span><br><span class="line">联系人：潘正阳、陈瑶</span><br><span class="line">电话：13758171369、18757567243</span><br><span class="line">奥体街（扬帆路-养正巷）设计</span><br><span class="line">1.1.4 工程名称</span><br><span class="line">杭州市滨江区</span><br><span class="line">1.1.5 建设地点</span><br><span class="line">见招标公告</span><br><span class="line">1.1.6 建设规模</span><br><span class="line">本项目投资估算为22798万元</span><br><span class="line">1.1.7 投资估算</span><br><span class="line">国有100%</span><br><span class="line">1.2.1 资金来源及比例</span><br><span class="line">已落实</span><br><span class="line">1.2.2 资金落实情况</span><br><span class="line">☑方案设计、初步设计（含概算编制和调整）和施工图设计（☑BIM设计</span><br><span class="line">服务）</span><br><span class="line">招标内容具体包括:工程设计服务内容： 包括但不限于：</span><br><span class="line">（1）可研编制（含估算编制）、方案设计及深化、初步设计（含概算</span><br><span class="line">编制）、施工图设计【含BIM（若有）】、管线综合、交改设计（若</span><br><span class="line">有，含主体项目交改以及其他配套交改设计）、雨污水管线迁改（若</span><br><span class="line">有）、基坑设计、报批审查配合、按审查和招标人意见对整个设计过程</span><br><span class="line">的修改、深化整合等优化设计；</span><br><span class="line">1.3.1 招标范围</span><br><span class="line">（2）按招标文件要求提供纸质和电子图纸；</span><br><span class="line">（3）设计补图和工程施工阶段的变更联系单；</span><br><span class="line">（4）施工配合、验收配合、竣工图编制配合等相关服务；</span><br><span class="line">（5）根据工程实际需要提供现场服务等。</span><br><span class="line">各阶段设计成果应符合国家规定的图纸编制深度要求及相关出图标准要</span><br><span class="line">求且应满足发包人的相关要求，并应及时完成招标人和相关审查部门的</span><br><span class="line">阶段性审查意见所提出的修改工作等，特别是相关部门不计次数的优化</span><br><span class="line">修改要求等。阶段性审查包括方案评审、初步设计审查和施工图审查</span><br><span class="line">12</span><br><span class="line"></span><br><span class="line">----------------------------------------</span><br></pre></td></tr></table></figure>

<blockquote>
<p>layout&#x3D;True的贴在附录3了，感觉也没有格式信息（猛地一看像是有格式信息）。</p>
</blockquote>
<p>可以看出：</p>
<ol>
<li>每页的最后有一个数字，分别是01,11,12，为页码</li>
<li>第三页是表格，<code>extract_text</code>依旧会将其当做普通文本按行读取，即失去段落结构了</li>
</ol>
<hr>
<h4 id="2-extract-words-…"><a href="#2-extract-words-…" class="headerlink" title="2. extract_words(…)"></a>2. extract_words(…)</h4><p>关于<code>extract_words</code>参数的详细讲解见<strong>附录5</strong>，<strong>代码1（基础用法）：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pdfplumber</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开 PDF 文件</span></span><br><span class="line"><span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(<span class="string">&quot;../../招标文件修订-1.pdf&quot;</span>) <span class="keyword">as</span> pdf:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">min</span>(<span class="number">3</span>, <span class="built_in">len</span>(pdf.pages))):  <span class="comment"># 只解析前 3 页（或文件页数更少时自动适配）</span></span><br><span class="line">        page = pdf.pages[i]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;\n--- 第 <span class="subst">&#123;i+<span class="number">1</span>&#125;</span> 页 ---&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 提取单词列表（默认容差设置）</span></span><br><span class="line">        words = page.extract_words()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 打印前几个单词的信息（太多可以裁剪）</span></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> words[:<span class="number">10</span>]:  <span class="comment"># 每页前 10 个单词</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;词：<span class="subst">&#123;word[<span class="string">&#x27;text&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;  ↪ 坐标：(<span class="subst">&#123;word[<span class="string">&#x27;x0&#x27;</span>]&#125;</span>, <span class="subst">&#123;word[<span class="string">&#x27;top&#x27;</span>]&#125;</span>, <span class="subst">&#123;word[<span class="string">&#x27;x1&#x27;</span>]&#125;</span>, <span class="subst">&#123;word[<span class="string">&#x27;bottom&#x27;</span>]&#125;</span>)&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>可以看出，extract_words相当于在extract_text的基础上加上坐标输出（虽然[第二章 投标人须知]被分开为两份了）：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">--- 第 1 页 ---</span><br><span class="line">词：杭州市房屋建筑和市政基础设施项目</span><br><span class="line">  ↪ 坐标：(113.23200226, 161.35200232, 498.67200226000006, 185.35200232)</span><br><span class="line">词：设计招标文件示范文本</span><br><span class="line">  ↪ 坐标：(185.51999665, 223.60200232, 426.38399665000003, 247.60200232)</span><br><span class="line">词：（资格后审）</span><br><span class="line">  ↪ 坐标：(251.78400421999999, 277.13199605, 360.14400422, 295.13199605000005)</span><br><span class="line">词：（2019年版）</span><br><span class="line">  ↪ 坐标：(251.71199799, 320.87099446, 360.21599799, 338.87099446)</span><br><span class="line">词：杭州市城乡建设委员会制</span><br><span class="line">  ↪ 坐标：(206.60399628, 624.3400191200001, 405.32399628, 642.3400191200001)</span><br><span class="line">词：二0二五年四月</span><br><span class="line">  ↪ 坐标：(247.24800873, 647.68401326, 364.68000873000005, 665.6840132599999)</span><br><span class="line">词：01</span><br><span class="line">  ↪ 坐标：(303.75, 746.99700141, 308.25000763, 755.99700141)</span><br><span class="line"></span><br><span class="line">--- 第 2 页 ---</span><br><span class="line">词：奥体街（扬帆路-养正巷）设计</span><br><span class="line">  ↪ 坐标：(204.31200457999998, 95.86200049000013, 394.0400045800001, 109.86200049000013)</span><br><span class="line">词：（招标编号：A3301080120526863001221）</span><br><span class="line">  ↪ 坐标：(188.40000153, 129.73200037000004, 445.9440015299999, 143.73200037000004)</span><br><span class="line">词：招标文件</span><br><span class="line">  ↪ 坐标：(253.97500458999997, 219.91299402000004, 357.97500458999997, 245.91299402000004)</span><br><span class="line">词：（☑资格后审□邀请招标）</span><br><span class="line">  ↪ 坐标：(175.49999849, 259.70200610999996, 436.44199849, 284.12200611)</span><br><span class="line">词：招标人：杭州滨江奥体博览城开发建设运营管理有限公司</span><br><span class="line">  ↪ 坐标：(84.15000192, 524.49500181, 434.15000192, 538.49500181)</span><br><span class="line">词：（盖单位章）</span><br><span class="line">  ↪ 坐标：(444.00600192, 524.49500181, 528.00600192, 538.49500181)</span><br><span class="line">词：招标代理机构：浙江华耀建设咨询有限公司</span><br><span class="line">  ↪ 坐标：(120.15000001, 551.7290106, 386.15000001, 565.7290106)</span><br><span class="line">词：（盖单位章）</span><br><span class="line">  ↪ 坐标：(408.00400000999997, 551.7290106, 492.00400000999997, 565.7290106)</span><br><span class="line">词：2025年05月15日</span><br><span class="line">  ↪ 坐标：(310.00000763, 602.28399088, 408.00000763, 616.28399088)</span><br><span class="line">词：11</span><br><span class="line">  ↪ 坐标：(303.75, 746.99700141, 308.25000763, 755.99700141)</span><br><span class="line"></span><br><span class="line">--- 第 3 页 ---</span><br><span class="line">词：第二章</span><br><span class="line">  ↪ 坐标：(228.69999695, 92.72899985999993, 294.87599695, 114.72899985999993)</span><br><span class="line">词：投标人须知</span><br><span class="line">  ↪ 坐标：(306.05199695, 92.72899985999993, 416.40399694999996, 114.72899985999993)</span><br><span class="line">词：投标人须知前附表</span><br><span class="line">  ↪ 坐标：(238.89399719, 126.88100191000001, 367.34199719, 142.88100191)</span><br><span class="line">词：条款号</span><br><span class="line">  ↪ 坐标：(64.62499905, 171.73550296999997, 96.20899905, 182.23550296999997)</span><br><span class="line">词：条款名称</span><br><span class="line">  ↪ 坐标：(147.31599999, 171.73550296999997, 189.44199999, 182.23550296999997)</span><br><span class="line">词：编列内容</span><br><span class="line">  ↪ 坐标：(358.14099653999995, 171.73550296999997, 400.2669965399999, 182.23550296999997)</span><br><span class="line">词：名称：杭州滨江奥体博览城开发建</span><br><span class="line">  ↪ 坐标：(219.87500239, 193.33550335999996, 377.37500238999996, 203.83550335999996)</span><br><span class="line">词：设运营管理有限公司</span><br><span class="line">  ↪ 坐标：(219.87500239, 208.93550374000006, 314.37500238999996, 219.43550374000006)</span><br><span class="line">词：地址：浙江省杭州市滨江区浦沿街</span><br><span class="line">  ↪ 坐标：(220.02200238999998, 230.03550411999993, 377.52200239, 240.53550411999993)</span><br><span class="line">词：1.1.2</span><br><span class="line">  ↪ 坐标：(73.75, 236.08550145000004, 100.0, 246.58550145000004)</span><br></pre></td></tr></table></figure>

<p><strong>代码二（指定return_chars&#x3D;True）</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pdfplumber</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开 PDF 文件</span></span><br><span class="line"><span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(<span class="string">&quot;../../招标文件修订-1.pdf&quot;</span>) <span class="keyword">as</span> pdf:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">min</span>(<span class="number">3</span>, <span class="built_in">len</span>(pdf.pages))):  <span class="comment"># 只解析前 3 页（或文件页数更少时自动适配）</span></span><br><span class="line">        page = pdf.pages[i]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;\n--- 第 <span class="subst">&#123;i+<span class="number">1</span>&#125;</span> 页 ---&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 提取单词列表，并包含组成每个单词的字符详情</span></span><br><span class="line">        words = page.extract_words(return_chars=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 打印前几个单词的信息（太多可以裁剪）</span></span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> words[:<span class="number">10</span>]:  <span class="comment"># 每页前 10 个单词</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;词：<span class="subst">&#123;word[<span class="string">&#x27;text&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;  ↪ 坐标：(<span class="subst">&#123;word[<span class="string">&#x27;x0&#x27;</span>]&#125;</span>, <span class="subst">&#123;word[<span class="string">&#x27;top&#x27;</span>]&#125;</span>, <span class="subst">&#123;word[<span class="string">&#x27;x1&#x27;</span>]&#125;</span>, <span class="subst">&#123;word[<span class="string">&#x27;bottom&#x27;</span>]&#125;</span>)&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;  ↪ 字符组成：&quot;</span>)</span><br><span class="line">            <span class="keyword">for</span> char <span class="keyword">in</span> word[<span class="string">&quot;chars&quot;</span>]:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;    - 字符：<span class="subst">&#123;char[<span class="string">&#x27;text&#x27;</span>]&#125;</span>, 坐标：(<span class="subst">&#123;char[<span class="string">&#x27;x0&#x27;</span>]&#125;</span>, <span class="subst">&#123;char[<span class="string">&#x27;top&#x27;</span>]&#125;</span>, <span class="subst">&#123;char[<span class="string">&#x27;x1&#x27;</span>]&#125;</span>, <span class="subst">&#123;char[<span class="string">&#x27;bottom&#x27;</span>]&#125;</span>), 字体：<span class="subst">&#123;char.get(<span class="string">&#x27;fontname&#x27;</span>)&#125;</span>, 大小：<span class="subst">&#123;char.get(<span class="string">&#x27;size&#x27;</span>)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>内容太长，这里仅展示第一页，可以看出指定return_chars&#x3D;True后就相当于在不指定的基础上加上.chars方法：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"> --- 第 1 页 ---</span><br><span class="line">词：杭州市房屋建筑和市政基础设施项目</span><br><span class="line">  ↪ 坐标：(113.23200226, 161.35200232, 498.67200226000006, 185.35200232)</span><br><span class="line">  ↪ 字符组成：</span><br><span class="line">    - 字符：杭, 坐标：(113.23200226, 161.35200232, 137.23200226, 185.35200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">    - 字符：州, 坐标：(137.32800226, 161.35200232, 161.32800226, 185.35200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">    - 字符：市, 坐标：(161.42400226, 161.35200232, 185.42400226, 185.35200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">    - 字符：房, 坐标：(185.52000226, 161.35200232, 209.52000226, 185.35200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">    - 字符：屋, 坐标：(209.61600226000002, 161.35200232, 233.61600226000002, 185.35200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">    - 字符：建, 坐标：(233.71200226000002, 161.35200232, 257.71200226, 185.35200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">    - 字符：筑, 坐标：(257.80800226, 161.35200232, 281.80800226, 185.35200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">    - 字符：和, 坐标：(281.90400226, 161.35200232, 305.90400226, 185.35200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">    - 字符：市, 坐标：(306.00000226000003, 161.35200232, 330.00000226000003, 185.35200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">    - 字符：政, 坐标：(330.09600226000003, 161.35200232, 354.09600226000003, 185.35200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">    - 字符：基, 坐标：(354.19200226000004, 161.35200232, 378.19200226000004, 185.35200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">    - 字符：础, 坐标：(378.28800226000004, 161.35200232, 402.28800226000004, 185.35200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">    - 字符：设, 坐标：(402.38400226000005, 161.35200232, 426.38400226000005, 185.35200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">    - 字符：施, 坐标：(426.48000226000005, 161.35200232, 450.48000226000005, 185.35200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">    - 字符：项, 坐标：(450.57600226000005, 161.35200232, 474.57600226000005, 185.35200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">    - 字符：目, 坐标：(474.67200226000006, 161.35200232, 498.67200226000006, 185.35200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">词：设计招标文件示范文本</span><br><span class="line">  ↪ 坐标：(185.51999665, 223.60200232, 426.38399665000003, 247.60200232)</span><br><span class="line">  ↪ 字符组成：</span><br><span class="line">    - 字符：设, 坐标：(185.51999665, 223.60200232, 209.51999665, 247.60200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">    - 字符：计, 坐标：(209.61599665, 223.60200232, 233.61599665, 247.60200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">    - 字符：招, 坐标：(233.71199665, 223.60200232, 257.71199665, 247.60200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">    - 字符：标, 坐标：(257.80799665, 223.60200232, 281.80799665, 247.60200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">    - 字符：文, 坐标：(281.90399665, 223.60200232, 305.90399665, 247.60200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">    - 字符：件, 坐标：(305.99999665, 223.60200232, 329.99999665, 247.60200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">    - 字符：示, 坐标：(330.09599665, 223.60200232, 354.09599665, 247.60200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">    - 字符：范, 坐标：(354.19199665, 223.60200232, 378.19199665, 247.60200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">    - 字符：文, 坐标：(378.28799665, 223.60200232, 402.28799665, 247.60200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">    - 字符：本, 坐标：(402.38399665000003, 223.60200232, 426.38399665000003, 247.60200232), 字体：FAAABA+SimSun,Bold, 大小：24.0</span><br><span class="line">词：（资格后审）</span><br><span class="line">  ↪ 坐标：(251.78400421999999, 277.13199605, 360.14400422, 295.13199605000005)</span><br><span class="line">  ↪ 字符组成：</span><br><span class="line">    - 字符：（, 坐标：(251.78400421999999, 277.13199605, 269.78400422, 295.13199605000005), 字体：FAAABA+SimSun,Bold, 大小：18.000000000000057</span><br><span class="line">    - 字符：资, 坐标：(269.85600422, 277.13199605, 287.85600422, 295.13199605000005), 字体：FAAABA+SimSun,Bold, 大小：18.000000000000057</span><br><span class="line">    - 字符：格, 坐标：(287.92800422, 277.13199605, 305.92800422, 295.13199605000005), 字体：FAAABA+SimSun,Bold, 大小：18.000000000000057</span><br><span class="line">    - 字符：后, 坐标：(306.00000422, 277.13199605, 324.00000422, 295.13199605000005), 字体：FAAABA+SimSun,Bold, 大小：18.000000000000057</span><br><span class="line">    - 字符：审, 坐标：(324.07200422, 277.13199605, 342.07200422, 295.13199605000005), 字体：FAAABA+SimSun,Bold, 大小：18.000000000000057</span><br><span class="line">    - 字符：）, 坐标：(342.14400422, 277.13199605, 360.14400422, 295.13199605000005), 字体：FAAABA+SimSun,Bold, 大小：18.000000000000057</span><br><span class="line">词：（2019年版）</span><br><span class="line">  ↪ 坐标：(251.71199799, 320.87099446, 360.21599799, 338.87099446)</span><br><span class="line">  ↪ 字符组成：</span><br><span class="line">    - 字符：（, 坐标：(251.71199799, 320.87099446, 269.71199799, 338.87099446), 字体：FAAABA+SimSun,Bold, 大小：18.0</span><br><span class="line">    - 字符：2, 坐标：(269.78399799, 320.87099446, 278.78399799, 338.87099446), 字体：FAAABE+SimSun,Bold, 大小：18.0</span><br><span class="line">    - 字符：0, 坐标：(278.85599799, 320.87099446, 287.85599799, 338.87099446), 字体：FAAABE+SimSun,Bold, 大小：18.0</span><br><span class="line">    - 字符：1, 坐标：(287.92799799, 320.87099446, 296.92799799, 338.87099446), 字体：FAAABE+SimSun,Bold, 大小：18.0</span><br><span class="line">    - 字符：9, 坐标：(296.99999799, 320.87099446, 305.99999799, 338.87099446), 字体：FAAABE+SimSun,Bold, 大小：18.0</span><br><span class="line">    - 字符：年, 坐标：(306.07199799, 320.87099446, 324.07199799, 338.87099446), 字体：FAAABA+SimSun,Bold, 大小：18.0</span><br><span class="line">    - 字符：版, 坐标：(324.14399799, 320.87099446, 342.14399799, 338.87099446), 字体：FAAABA+SimSun,Bold, 大小：18.0</span><br><span class="line">    - 字符：）, 坐标：(342.21599799, 320.87099446, 360.21599799, 338.87099446), 字体：FAAABA+SimSun,Bold, 大小：18.0</span><br><span class="line">词：杭州市城乡建设委员会制</span><br><span class="line">  ↪ 坐标：(206.60399628, 624.3400191200001, 405.32399628, 642.3400191200001)</span><br><span class="line">  ↪ 字符组成：</span><br><span class="line">    - 字符：杭, 坐标：(206.60399628, 624.3400191200001, 224.60399628, 642.3400191200001), 字体：FAAABA+SimSun,Bold, 大小：18.0</span><br><span class="line">    - 字符：州, 坐标：(224.67599628, 624.3400191200001, 242.67599628, 642.3400191200001), 字体：FAAABA+SimSun,Bold, 大小：18.0</span><br><span class="line">    - 字符：市, 坐标：(242.74799628, 624.3400191200001, 260.74799628, 642.3400191200001), 字体：FAAABA+SimSun,Bold, 大小：18.0</span><br><span class="line">    - 字符：城, 坐标：(260.81999628, 624.3400191200001, 278.81999628, 642.3400191200001), 字体：FAAABA+SimSun,Bold, 大小：18.0</span><br><span class="line">    - 字符：乡, 坐标：(278.89199628, 624.3400191200001, 296.89199628, 642.3400191200001), 字体：FAAABA+SimSun,Bold, 大小：18.0</span><br><span class="line">    - 字符：建, 坐标：(296.96399628, 624.3400191200001, 314.96399628, 642.3400191200001), 字体：FAAABA+SimSun,Bold, 大小：18.0</span><br><span class="line">    - 字符：设, 坐标：(315.03599628, 624.3400191200001, 333.03599628, 642.3400191200001), 字体：FAAABA+SimSun,Bold, 大小：18.0</span><br><span class="line">    - 字符：委, 坐标：(333.10799628, 624.3400191200001, 351.10799628, 642.3400191200001), 字体：FAAABA+SimSun,Bold, 大小：18.0</span><br><span class="line">    - 字符：员, 坐标：(351.17999628, 624.3400191200001, 369.17999628, 642.3400191200001), 字体：FAAABA+SimSun,Bold, 大小：18.0</span><br><span class="line">    - 字符：会, 坐标：(369.25199628, 624.3400191200001, 387.25199628, 642.3400191200001), 字体：FAAABA+SimSun,Bold, 大小：18.0</span><br><span class="line">    - 字符：制, 坐标：(387.32399628, 624.3400191200001, 405.32399628, 642.3400191200001), 字体：FAAABA+SimSun,Bold, 大小：18.0</span><br><span class="line">词：二0二五年四月</span><br><span class="line">  ↪ 坐标：(247.24800873, 647.68401326, 364.68000873000005, 665.6840132599999)</span><br><span class="line">  ↪ 字符组成：</span><br><span class="line">    - 字符：二, 坐标：(247.24800873, 647.68401326, 265.24800873000004, 665.6840132599999), 字体：FAAABA+SimSun,Bold, 大小：17.999999999999986</span><br><span class="line">    - 字符：0, 坐标：(265.32000873, 647.68401326, 274.32000873, 665.6840132599999), 字体：FAAABE+SimSun,Bold, 大小：17.999999999999986</span><br><span class="line">    - 字符：二, 坐标：(274.39200873, 647.68401326, 292.39200873, 665.6840132599999), 字体：FAAABA+SimSun,Bold, 大小：17.999999999999986</span><br><span class="line">    - 字符：五, 坐标：(292.46400873, 647.68401326, 310.46400873, 665.6840132599999), 字体：FAAABA+SimSun,Bold, 大小：17.999999999999986</span><br><span class="line">    - 字符：年, 坐标：(310.53600873, 647.68401326, 328.53600873, 665.6840132599999), 字体：FAAABA+SimSun,Bold, 大小：17.999999999999986</span><br><span class="line">    - 字符：四, 坐标：(328.60800873000005, 647.68401326, 346.60800873000005, 665.6840132599999), 字体：FAAABA+SimSun,Bold, 大小：17.999999999999986</span><br><span class="line">    - 字符：月, 坐标：(346.68000873000005, 647.68401326, 364.68000873000005, 665.6840132599999), 字体：FAAABA+SimSun,Bold, 大小：17.999999999999986</span><br><span class="line">词：01</span><br><span class="line">  ↪ 坐标：(303.75, 746.99700141, 308.25000763, 755.99700141)</span><br><span class="line">  ↪ 字符组成：</span><br><span class="line">    - 字符：0, 坐标：(303.75, 746.99700141, 308.25, 755.99700141), 字体：FAAAAH+TimesNewRomanPSMT, 大小：9.0</span><br><span class="line">    - 字符：1, 坐标：(303.75000763, 746.99700141, 308.25000763, 755.99700141), 字体：FAAAAH+TimesNewRomanPSMT, 大小：9.0</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="3-extract-text-lines-…"><a href="#3-extract-text-lines-…" class="headerlink" title="3. extract_text_lines(…)"></a>3. extract_text_lines(…)</h4><p>那如果不想使用<code>extract_words</code>这种细粒度的方法，只想按行去提取文本怎么办呢，可以用<code>extract_text_lines</code>方法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pdfplumber</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开 PDF 文件</span></span><br><span class="line"><span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(<span class="string">&quot;../../招标文件修订-1.pdf&quot;</span>) <span class="keyword">as</span> pdf:</span><br><span class="line">    page = pdf.pages[<span class="number">2</span>]  <span class="comment"># 读取第1页</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 提取文本行（实验功能）</span></span><br><span class="line">    lines = page.extract_text_lines(return_chars=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打印前几行的内容和位置</span></span><br><span class="line">    <span class="keyword">for</span> i, line <span class="keyword">in</span> <span class="built_in">enumerate</span>(lines[:<span class="number">5</span>]):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;\n🔹 第 <span class="subst">&#123;i+<span class="number">1</span>&#125;</span> 行：<span class="subst">&#123;line[<span class="string">&#x27;text&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;   ➤ 边界框：(<span class="subst">&#123;line[<span class="string">&#x27;x0&#x27;</span>]&#125;</span>, <span class="subst">&#123;line[<span class="string">&#x27;top&#x27;</span>]&#125;</span>, <span class="subst">&#123;line[<span class="string">&#x27;x1&#x27;</span>]&#125;</span>, <span class="subst">&#123;line[<span class="string">&#x27;bottom&#x27;</span>]&#125;</span>)&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;   ➤ 字符数：<span class="subst">&#123;<span class="built_in">len</span>(line[<span class="string">&#x27;chars&#x27;</span>])&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> char <span class="keyword">in</span> line[<span class="string">&#x27;chars&#x27;</span>][:<span class="number">3</span>]:  <span class="comment"># 显示前三个字符</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;     - 字符：<span class="subst">&#123;char[<span class="string">&#x27;text&#x27;</span>]&#125;</span>，位置：(<span class="subst">&#123;char[<span class="string">&#x27;x0&#x27;</span>]&#125;</span>, <span class="subst">&#123;char[<span class="string">&#x27;top&#x27;</span>]&#125;</span>，<span class="subst">&#123;char[<span class="string">&#x27;x1&#x27;</span>]&#125;</span>, <span class="subst">&#123;char[<span class="string">&#x27;bottom&#x27;</span>]&#125;</span>)&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">🔹 第 1 行：第二章 投标人须知</span><br><span class="line">   ➤ 边界框：(228.69999695, 92.72899985999993, 416.40399694999996, 114.72899985999993)</span><br><span class="line">   ➤ 字符数：8</span><br><span class="line">     - 字符：第，位置：(228.69999695, 92.72899985999993，250.69999695, 114.72899985999993)</span><br><span class="line">     - 字符：二，位置：(250.78799695, 92.72899985999993，272.78799695, 114.72899985999993)</span><br><span class="line">     - 字符：章，位置：(272.87599695, 92.72899985999993，294.87599695, 114.72899985999993)</span><br><span class="line"></span><br><span class="line">🔹 第 2 行：投标人须知前附表</span><br><span class="line">   ➤ 边界框：(238.89399719, 126.88100191000001, 367.34199719, 142.88100191)</span><br><span class="line">   ➤ 字符数：8</span><br><span class="line">     - 字符：投，位置：(238.89399719, 126.88100191000001，254.89399719, 142.88100191)</span><br><span class="line">     - 字符：标，位置：(254.95799719, 126.88100191000001，270.95799719, 142.88100191)</span><br><span class="line">     - 字符：人，位置：(271.02199719, 126.88100191000001，287.02199719, 142.88100191)</span><br><span class="line"></span><br><span class="line">🔹 第 3 行：条款号 条款名称 编列内容</span><br><span class="line">   ➤ 边界框：(64.62499905, 171.73550296999997, 400.2669965399999, 182.23550296999997)</span><br><span class="line">   ➤ 字符数：11</span><br><span class="line">     - 字符：条，位置：(64.62499905, 171.73550296999997，75.12499905, 182.23550296999997)</span><br><span class="line">     - 字符：款，位置：(75.16699905, 171.73550296999997，85.66699905, 182.23550296999997)</span><br><span class="line">     - 字符：号，位置：(85.70899905, 171.73550296999997，96.20899905, 182.23550296999997)</span><br><span class="line"></span><br><span class="line">🔹 第 4 行：名称：杭州滨江奥体博览城开发建</span><br><span class="line">   ➤ 边界框：(219.87500239, 193.33550335999996, 377.37500238999996, 203.83550335999996)</span><br><span class="line">   ➤ 字符数：15</span><br><span class="line">     - 字符：名，位置：(219.87500239, 193.33550335999996，230.37500239, 203.83550335999996)</span><br><span class="line">     - 字符：称，位置：(230.37500239, 193.33550335999996，240.87500239, 203.83550335999996)</span><br><span class="line">     - 字符：：，位置：(240.87500239, 193.33550335999996，251.37500239, 203.83550335999996)</span><br><span class="line"></span><br><span class="line">🔹 第 5 行：设运营管理有限公司</span><br><span class="line">   ➤ 边界框：(219.87500239, 208.93550374000006, 314.37500238999996, 219.43550374000006)</span><br><span class="line">   ➤ 字符数：9</span><br><span class="line">     - 字符：设，位置：(219.87500239, 208.93550374000006，230.37500239, 219.43550374000006)</span><br><span class="line">     - 字符：运，位置：(230.37500239, 208.93550374000006，240.87500239, 219.43550374000006)</span><br><span class="line">     - 字符：营，位置：(240.87500239, 208.93550374000006，251.37500239, 219.43550374000006)</span><br></pre></td></tr></table></figure>

<p><strong>关于extract_words与extract_text_lines的比较见附录6。</strong></p>
<hr>
<h4 id="4-search-…"><a href="#4-search-…" class="headerlink" title="4. search(…)"></a>4. search(…)</h4><p>高亮第三页的<strong>招标人：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pdfplumber</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开 PDF 文件</span></span><br><span class="line"><span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(<span class="string">&quot;../../招标文件修订-1.pdf&quot;</span>) <span class="keyword">as</span> pdf:</span><br><span class="line">    page = pdf.pages[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 搜索关键词“招标人”，并包含字符对象</span></span><br><span class="line">    matches = page.search(<span class="string">&quot;招标人&quot;</span>, return_chars=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 生成页面图像对象</span></span><br><span class="line">    im = page.to_image(resolution=<span class="number">300</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 高亮每一个匹配到的文本区域</span></span><br><span class="line">    <span class="keyword">for</span> <span class="keyword">match</span> <span class="keyword">in</span> matches:</span><br><span class="line">        bbox = (<span class="keyword">match</span>[<span class="string">&quot;x0&quot;</span>], <span class="keyword">match</span>[<span class="string">&quot;top&quot;</span>], <span class="keyword">match</span>[<span class="string">&quot;x1&quot;</span>], <span class="keyword">match</span>[<span class="string">&quot;bottom&quot;</span>])</span><br><span class="line">        im.draw_rect(bbox, stroke=<span class="string">&quot;red&quot;</span>, stroke_width=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 展示图像</span></span><br><span class="line">    im.show()</span><br></pre></td></tr></table></figure>



<hr>
<h3 id="四-表格提取"><a href="#四-表格提取" class="headerlink" title="四 表格提取"></a>四 表格提取</h3><table>
<thead>
<tr>
<th>方法</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>.find_tables(table_settings=&#123;&#125;)</code></td>
<td>返回多个 <code>Table</code> 对象。<code>Table</code> 对象提供 <code>.cells</code>, <code>.rows</code>, <code>.columns</code>, <code>.bbox</code> 属性以及 <code>.extract(x_tolerance=3, y_tolerance=3)</code> 方法。</td>
</tr>
<tr>
<td><code>.find_table(table_settings=&#123;&#125;)</code></td>
<td>类似于 <code>.find_tables(...)</code>，但只返回页面中<strong>最大的表格</strong>（按单元格数量衡量）。如果多个表格大小相同，则返回离页面顶部最近的一个。</td>
</tr>
<tr>
<td><code>.extract_tables(table_settings=&#123;&#125;)</code></td>
<td>返回页面中所有表格的文本内容，格式为列表嵌套列表嵌套列表：<code>表格 -&gt; 行 -&gt; 单元格</code>。</td>
</tr>
<tr>
<td><code>.extract_table(table_settings=&#123;&#125;)</code></td>
<td>返回页面中最大表格的文本内容，格式为：<code>行 -&gt; 单元格</code>。</td>
</tr>
<tr>
<td><code>.debug_tablefinder(table_settings=&#123;&#125;)</code></td>
<td>返回 <code>TableFinder</code> 类实例，可访问 <code>.edges</code>, <code>.intersections</code>, <code>.cells</code>, <code>.tables</code> 属性。</td>
</tr>
</tbody></table>
<blockquote>
<p>默认情况下，<code>.extract_tables()</code> 使用页面的水平与垂直线（包括矩形边）作为单元格边界。但你可以通过 <code>table_settings</code> 自定义策略和阈值。详细介绍见附录4。</p>
</blockquote>
<h4 id="1-extract-tables-…"><a href="#1-extract-tables-…" class="headerlink" title="1. extract_tables(…)"></a>1. extract_tables(…)</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pdfplumber</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开 PDF 文件</span></span><br><span class="line"><span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(<span class="string">&quot;../../招标文件修订-1.pdf&quot;</span>) <span class="keyword">as</span> pdf:</span><br><span class="line">    <span class="comment"># 设置要提取的页码（注意：pdfplumber 的页码从 0 开始）</span></span><br><span class="line">    pages_to_extract = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">0</span>, <span class="number">3</span>)) + <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">14</span>, <span class="number">17</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历选中的页面</span></span><br><span class="line">    <span class="keyword">for</span> page_number <span class="keyword">in</span> pages_to_extract:</span><br><span class="line">        page = pdf.pages[page_number]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;\n🔹 第 <span class="subst">&#123;page_number + <span class="number">1</span>&#125;</span> 页的表格内容：&quot;</span>)</span><br><span class="line"></span><br><span class="line">        tables = page.extract_tables()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果有表格</span></span><br><span class="line">        <span class="keyword">if</span> tables:</span><br><span class="line">            <span class="keyword">for</span> table_index, table <span class="keyword">in</span> <span class="built_in">enumerate</span>(tables):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;\n  ➤ 表格 <span class="subst">&#123;table_index + <span class="number">1</span>&#125;</span>:&quot;</span>)</span><br><span class="line">                <span class="keyword">for</span> row <span class="keyword">in</span> table:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&quot;    &quot;</span>, row)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;  ❌ 没有找到表格。&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">🔹 第 1 页的表格内容：</span><br><span class="line">  ❌ 没有找到表格。</span><br><span class="line"></span><br><span class="line">🔹 第 2 页的表格内容：</span><br><span class="line">  ❌ 没有找到表格。</span><br><span class="line"></span><br><span class="line">🔹 第 3 页的表格内容：</span><br><span class="line"></span><br><span class="line">  ➤ 表格 1:</span><br><span class="line">     [<span class="string">&#x27;条款号&#x27;</span>, <span class="string">&#x27;条款名称&#x27;</span>, <span class="string">&#x27;编列内容&#x27;</span>]</span><br><span class="line">     [<span class="string">&#x27;1.1.2&#x27;</span>, <span class="string">&#x27;招标人&#x27;</span>, <span class="string">&#x27;名称：杭州滨江奥体博览城开发建\n设运营管理有限公司\n地址：浙江省杭州市滨江区浦沿街\n道滨安路1338号三楼\n联系人：翁栎超\n电话：13600511926&#x27;</span>]</span><br><span class="line">     [<span class="string">&#x27;1.1.3&#x27;</span>, <span class="string">&#x27;招标代理机构&#x27;</span>, <span class="string">&#x27;名称： 浙江华耀建设咨询有限公司\n地址：杭州市上城区佰富时代中心3幢13楼\n联系人：潘正阳、陈瑶\n电话：13758171369、18757567243&#x27;</span>]</span><br><span class="line">     [<span class="string">&#x27;1.1.4&#x27;</span>, <span class="string">&#x27;工程名称&#x27;</span>, <span class="string">&#x27;奥体街（扬帆路-养正巷）设计&#x27;</span>]</span><br><span class="line">     [<span class="string">&#x27;1.1.5&#x27;</span>, <span class="string">&#x27;建设地点&#x27;</span>, <span class="string">&#x27;杭州市滨江区&#x27;</span>]</span><br><span class="line">     [<span class="string">&#x27;1.1.6&#x27;</span>, <span class="string">&#x27;建设规模&#x27;</span>, <span class="string">&#x27;见招标公告&#x27;</span>]</span><br><span class="line">     [<span class="string">&#x27;1.1.7&#x27;</span>, <span class="string">&#x27;投资估算&#x27;</span>, <span class="string">&#x27;本项目投资估算为22798万元&#x27;</span>]</span><br><span class="line">     [<span class="string">&#x27;1.2.1&#x27;</span>, <span class="string">&#x27;资金来源及比例&#x27;</span>, <span class="string">&#x27;国有100%&#x27;</span>]</span><br><span class="line">     [<span class="string">&#x27;1.2.2&#x27;</span>, <span class="string">&#x27;资金落实情况&#x27;</span>, <span class="string">&#x27;已落实&#x27;</span>]</span><br><span class="line">     [<span class="string">&#x27;1.3.1&#x27;</span>, <span class="string">&#x27;招标范围&#x27;</span>, <span class="string">&#x27;☑方案设计、初步设计（含概算编制和调整）和施工图设计（☑BIM设计\n服务）\n招标内容具体包括:工程设计服务内容： 包括但不限于：\n（1）可研编制（含估算编制）、方案设计及深化、初步设计（含概算\n编制）、施工图设计【含BIM（若有）】、管线综合、交改设计（若\n有，含主体项目交改以及其他配套交改设计）、雨污水管线迁改（若\n有）、基坑设计、报批审查配合、按审查和招标人意见对整个设计过程\n的修改、深化整合等优化设计；\n（2）按招标文件要求提供纸质和电子图纸；\n（3）设计补图和工程施工阶段的变更联系单；\n（4）施工配合、验收配合、竣工图编制配合等相关服务；\n（5）根据工程实际需要提供现场服务等。\n各阶段设计成果应符合国家规定的图纸编制深度要求及相关出图标准要\n求且应满足发包人的相关要求，并应及时完成招标人和相关审查部门的\n阶段性审查意见所提出的修改工作等，特别是相关部门不计次数的优化\n修改要求等。阶段性审查包括方案评审、初步设计审查和施工图审查&#x27;</span>]</span><br><span class="line"></span><br><span class="line">🔹 第 15 页的表格内容：</span><br><span class="line"></span><br><span class="line">  ➤ 表格 1:</span><br><span class="line">     [<span class="string">&#x27;评审因素&#x27;</span>, <span class="string">&#x27;评审内容&#x27;</span>, <span class="string">&#x27;分值&#x27;</span>]</span><br><span class="line"></span><br><span class="line">🔹 第 16 页的表格内容：</span><br><span class="line"></span><br><span class="line">  ➤ 表格 1:</span><br><span class="line">     [<span class="string">&#x27;类似工程业\n绩&#x27;</span>, <span class="string">&#x27;企业业绩：投标人自投标截止日之前5年（含）内（以合\n同签订时间为准）承接过的类似业绩：\n①单个设计合同金额260万元（含）以上的市政道路工程\n设计合同业绩，每一个得1.5分，本项最多得1.5分；\n②单个设计合同包含长度200米（含）以上城市隧道(隧\n道长度含U型槽段)的市政道路工程设计合同业绩，每一\n个得1.5分，本项最多得1.5分。\n（证明材料：设计合同、中标通知书复印件加盖公章，合\n同中必须体现项目属性、时间等项目特征表述；如不能体\n现，不得分。）&#x27;</span>, <span class="string">&#x27;0-3分&#x27;</span>]</span><br><span class="line">     [None, <span class="string">&#x27;项目负责人业绩：投标人自投标截止日之前5年（含）内\n（以合同签订时间为准），拟派项目负责人以项目负责人\n身份负责过的类似业绩：\n①单个设计合同金额260万元（含）以上的市政道路工程\n设计合同业绩，每一个得2分，本项最多得2分；\n② 单个设计合同金额200（含）-260万元市政道路工程\n设计合同业绩，每一个得1分，本项最多得2分。\n（证明材料：设计合同、中标通知书复印件加盖公章，合\n同中必须体现项目属性、时间、项目负责人名字等项目特\n征表述；如不能体现，不得分。）&#x27;</span>, <span class="string">&#x27;0-2分&#x27;</span>]</span><br><span class="line">     [<span class="string">&#x27;信用评价&#x27;</span>, <span class="string">&#x27;建设行政主管部门信用评价&#x27;</span>, <span class="string">&#x27;0-2分&#x27;</span>]</span><br><span class="line">     [<span class="string">&#x27;团队配备&#x27;</span>, <span class="string">&#x27;（1）项目班子人员全部满足招标文件人员配备要求（具\n体要求见《附表：项目负责人及人员配备表》）得2分，\n每有一项不满足扣0.5分（最少0分）。\n（2）道路、隧道、给排水、电气专业设计师，具有对应\n专业注册执业资格【如注册土木工程师（岩土）资格、注\n册公用设备工程师（给排水）资格、注册电气工程师（供\n配电）资格】的，提供一个得0.3分，两个得0.6分，三\n个得1分，最高得1分。\n注：项目设计团队中各专业不可兼任。\n(有效证明材料：提供执业资格证书，职称证书，本单位\n近三个月的社保证明（至投标截止时间上溯6个月中任意\n连续3个月的社保缴纳证明），复印件加盖公章。如职称\n证书无法证明专业，以毕业证专业为准。)&#x27;</span>, <span class="string">&#x27;0-3分&#x27;</span>]</span><br><span class="line"></span><br><span class="line">  ➤ 表格 2:</span><br><span class="line">     [<span class="string">&#x27;序号&#x27;</span>, <span class="string">&#x27;职务名称&#x27;</span>, <span class="string">&#x27;最少配备\n数量\n（人）&#x27;</span>, <span class="string">&#x27;职称或职业资格&#x27;</span>, <span class="string">&#x27;备注&#x27;</span>]</span><br><span class="line">     [<span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;项目负责人&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;具有市政公用工程或隧道工程&#x27;</span>, <span class="string">&#x27;全过程&#x27;</span>]</span><br><span class="line"></span><br><span class="line">🔹 第 17 页的表格内容：</span><br><span class="line"></span><br><span class="line">  ➤ 表格 1:</span><br><span class="line">     [<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;类高级工程师及以上职称&#x27;</span>, <span class="string">&#x27;&#x27;</span>]</span><br><span class="line">     [<span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;道路专业设计师&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;具有工程师及以上职称&#x27;</span>, <span class="string">&#x27;全过程&#x27;</span>]</span><br><span class="line">     [<span class="string">&#x27;3&#x27;</span>, <span class="string">&#x27;隧道专业设计师&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;具有工程师及以上职称&#x27;</span>, <span class="string">&#x27;全过程&#x27;</span>]</span><br><span class="line">     [<span class="string">&#x27;4&#x27;</span>, <span class="string">&#x27;给排水专业设计师&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;具有工程师及以上职称&#x27;</span>, <span class="string">&#x27;全过程&#x27;</span>]</span><br><span class="line">     [<span class="string">&#x27;5&#x27;</span>, <span class="string">&#x27;电气专业设计师&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;具有工程师及以上职称&#x27;</span>, <span class="string">&#x27;全过程&#x27;</span>]</span><br><span class="line">     [<span class="string">&#x27;6&#x27;</span>, <span class="string">&#x27;园林专业设计师&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;具有工程师及以上职称&#x27;</span>, <span class="string">&#x27;全过程&#x27;</span>]</span><br><span class="line">     [<span class="string">&#x27;7&#x27;</span>, <span class="string">&#x27;造价专业负责人&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;具有注册一级造价师资格&#x27;</span>, <span class="string">&#x27;全过程&#x27;</span>]</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="2-find-tables-…"><a href="#2-find-tables-…" class="headerlink" title="2. find_tables(…)"></a>2. find_tables(…)</h4><p><strong>直接上代码：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pdfplumber</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开 PDF 文件</span></span><br><span class="line"><span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(<span class="string">&quot;../../招标文件修订-1.pdf&quot;</span>) <span class="keyword">as</span> pdf:</span><br><span class="line">    <span class="comment"># 定义页码范围（注意：页码从 0 开始）</span></span><br><span class="line">    target_pages = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">0</span>, <span class="number">3</span>)) + <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">14</span>, <span class="number">17</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> page_num <span class="keyword">in</span> target_pages:</span><br><span class="line">        <span class="keyword">if</span> page_num &gt;= <span class="built_in">len</span>(pdf.pages):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;⚠️ 页码 <span class="subst">&#123;page_num + <span class="number">1</span>&#125;</span> 超出 PDF 页数范围。&quot;</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;\n================ 📄 第 <span class="subst">&#123;page_num + <span class="number">1</span>&#125;</span> 页 ================&quot;</span>)</span><br><span class="line">        page = pdf.pages[page_num]</span><br><span class="line">        tables = page.find_tables()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> tables:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;❌ 没有找到表格。&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> i, table <span class="keyword">in</span> <span class="built_in">enumerate</span>(tables):</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;\n🔹 表格 <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>:&quot;</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 1. 表格边界框</span></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;📏 bbox 边界框:&quot;</span>, table.bbox)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 2. 单元格</span></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;🧱 cells（共 <span class="subst">&#123;<span class="built_in">len</span>(table.cells)&#125;</span> 个单元格）:&quot;</span>)</span><br><span class="line">                <span class="comment"># 获取前两个和最后两个</span></span><br><span class="line">                cells_to_show = table.cells[:<span class="number">2</span>] + table.cells[-<span class="number">2</span>:] <span class="keyword">if</span> <span class="built_in">len</span>(table.cells) &gt; <span class="number">4</span> <span class="keyword">else</span> table.cells</span><br><span class="line">                <span class="keyword">for</span> idx, cell <span class="keyword">in</span> <span class="built_in">enumerate</span>(cells_to_show, <span class="number">1</span>):</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;  → 第 <span class="subst">&#123;idx&#125;</span> 个单元格: <span class="subst">&#123;cell&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 3. 行（完整打印每个单元格）</span></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;📋 rows（共 <span class="subst">&#123;<span class="built_in">len</span>(table.rows)&#125;</span> 行）:&quot;</span>)</span><br><span class="line">                <span class="keyword">for</span> row_idx, row <span class="keyword">in</span> <span class="built_in">enumerate</span>(table.rows):</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;  ⬇ 第 <span class="subst">&#123;row_idx + <span class="number">1</span>&#125;</span> 行:&quot;</span>)</span><br><span class="line">                    <span class="keyword">for</span> col_idx, cell <span class="keyword">in</span> <span class="built_in">enumerate</span>(row.cells):</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">f&quot;     → 第 <span class="subst">&#123;col_idx + <span class="number">1</span>&#125;</span> 列单元格内容: <span class="subst">&#123;cell&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 4. 列（完整打印每个单元格）</span></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;📊 columns（共 <span class="subst">&#123;<span class="built_in">len</span>(table.columns)&#125;</span> 列）:&quot;</span>)</span><br><span class="line">                <span class="keyword">for</span> col_idx, col <span class="keyword">in</span> <span class="built_in">enumerate</span>(table.columns):</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;  ⬅ 第 <span class="subst">&#123;col_idx + <span class="number">1</span>&#125;</span> 列:&quot;</span>)</span><br><span class="line">                    <span class="keyword">for</span> row_idx, cell <span class="keyword">in</span> <span class="built_in">enumerate</span>(col.cells):</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">f&quot;     → 第 <span class="subst">&#123;row_idx + <span class="number">1</span>&#125;</span> 行单元格内容: <span class="subst">&#123;cell&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 5. 提取文本形式的表格</span></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;📄 表格内容（使用 extract 提取）:&quot;</span>)</span><br><span class="line">                extracted = table.extract(x_tolerance=<span class="number">3</span>, y_tolerance=<span class="number">3</span>)</span><br><span class="line">                <span class="keyword">for</span> row <span class="keyword">in</span> extracted:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&quot;   &quot;</span>, row)</span><br></pre></td></tr></table></figure>

<p><strong>输出（这里仅以前三页为例进行说明）：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">================ 📄 第 1 页 ================</span><br><span class="line">❌ 没有找到表格。</span><br><span class="line"></span><br><span class="line">================ 📄 第 2 页 ================</span><br><span class="line">❌ 没有找到表格。</span><br><span class="line"></span><br><span class="line">================ 📄 第 3 页 ================</span><br><span class="line"></span><br><span class="line">🔹 表格 1:</span><br><span class="line">📏 bbox 边界框: (51.42499924, 166.80000305, 543.87501145, 761.84999084)</span><br><span class="line">🧱 cells（共 30 个单元格）:</span><br><span class="line">  → 第 1 个单元格: (51.42499924, 166.80000305, 122.32500077, 184.95000267)</span><br><span class="line">  → 第 2 个单元格: (51.42499924, 184.95000267, 122.32500077, 297.55000305)</span><br><span class="line">  → 第 3 个单元格: (214.47500228999996, 487.84999084, 543.87501145, 511.74998474)</span><br><span class="line">  → 第 4 个单元格: (214.47500228999996, 511.74998474, 543.87501145, 761.84999084)</span><br><span class="line">📋 rows（共 10 行）:</span><br><span class="line">  ⬇ 第 1 行:</span><br><span class="line">     → 第 1 列单元格内容: (51.42499924, 166.80000305, 122.32500077, 184.95000267)</span><br><span class="line">     → 第 2 列单元格内容: (122.32500077, 166.80000305, 214.47500228999996, 184.95000267)</span><br><span class="line">     → 第 3 列单元格内容: (214.47500228999996, 166.80000305, 543.87501145, 184.95000267)</span><br><span class="line">  ⬇ 第 2 行:</span><br><span class="line">     → 第 1 列单元格内容: (51.42499924, 184.95000267, 122.32500077, 297.55000305)</span><br><span class="line">     → 第 2 列单元格内容: (122.32500077, 184.95000267, 214.47500228999996, 297.55000305)</span><br><span class="line">     → 第 3 列单元格内容: (214.47500228999996, 184.95000267, 543.87501145, 297.55000305)</span><br><span class="line">  ⬇ 第 3 行:</span><br><span class="line">     → 第 1 列单元格内容: (51.42499924, 297.55000305, 122.32500077, 368.05000305)</span><br><span class="line">     → 第 2 列单元格内容: (122.32500077, 297.55000305, 214.47500228999996, 368.05000305)</span><br><span class="line">     → 第 3 列单元格内容: (214.47500228999996, 297.55000305, 543.87501145, 368.05000305)</span><br><span class="line">  ⬇ 第 4 行:</span><br><span class="line">     → 第 1 列单元格内容: (51.42499924, 368.05000305, 122.32500077, 392.1000061)</span><br><span class="line">     → 第 2 列单元格内容: (122.32500077, 368.05000305, 214.47500228999996, 392.1000061)</span><br><span class="line">     → 第 3 列单元格内容: (214.47500228999996, 368.05000305, 543.87501145, 392.1000061)</span><br><span class="line">  ⬇ 第 5 行:</span><br><span class="line">     → 第 1 列单元格内容: (51.42499924, 392.1000061, 122.32500077, 416.0)</span><br><span class="line">     → 第 2 列单元格内容: (122.32500077, 392.1000061, 214.47500228999996, 416.0)</span><br><span class="line">     → 第 3 列单元格内容: (214.47500228999996, 392.1000061, 543.87501145, 416.0)</span><br><span class="line">  ⬇ 第 6 行:</span><br><span class="line">     → 第 1 列单元格内容: (51.42499924, 416.0, 122.32500077, 439.90000914999996)</span><br><span class="line">     → 第 2 列单元格内容: (122.32500077, 416.0, 214.47500228999996, 439.90000914999996)</span><br><span class="line">     → 第 3 列单元格内容: (214.47500228999996, 416.0, 543.87501145, 439.90000914999996)</span><br><span class="line">  ⬇ 第 7 行:</span><br><span class="line">     → 第 1 列单元格内容: (51.42499924, 439.90000914999996, 122.32500077, 463.80000305)</span><br><span class="line">     → 第 2 列单元格内容: (122.32500077, 439.90000914999996, 214.47500228999996, 463.80000305)</span><br><span class="line">     → 第 3 列单元格内容: (214.47500228999996, 439.90000914999996, 543.87501145, 463.80000305)</span><br><span class="line">  ⬇ 第 8 行:</span><br><span class="line">     → 第 1 列单元格内容: (51.42499924, 463.80000305, 122.32500077, 487.84999084)</span><br><span class="line">     → 第 2 列单元格内容: (122.32500077, 463.80000305, 214.47500228999996, 487.84999084)</span><br><span class="line">     → 第 3 列单元格内容: (214.47500228999996, 463.80000305, 543.87501145, 487.84999084)</span><br><span class="line">  ⬇ 第 9 行:</span><br><span class="line">     → 第 1 列单元格内容: (51.42499924, 487.84999084, 122.32500077, 511.74998474)</span><br><span class="line">     → 第 2 列单元格内容: (122.32500077, 487.84999084, 214.47500228999996, 511.74998474)</span><br><span class="line">     → 第 3 列单元格内容: (214.47500228999996, 487.84999084, 543.87501145, 511.74998474)</span><br><span class="line">  ⬇ 第 10 行:</span><br><span class="line">     → 第 1 列单元格内容: (51.42499924, 511.74998474, 122.32500077, 761.84999084)</span><br><span class="line">     → 第 2 列单元格内容: (122.32500077, 511.74998474, 214.47500228999996, 761.84999084)</span><br><span class="line">     → 第 3 列单元格内容: (214.47500228999996, 511.74998474, 543.87501145, 761.84999084)</span><br><span class="line">📊 columns（共 3 列）:</span><br><span class="line">  ⬅ 第 1 列:</span><br><span class="line">     → 第 1 行单元格内容: (51.42499924, 166.80000305, 122.32500077, 184.95000267)</span><br><span class="line">     → 第 2 行单元格内容: (51.42499924, 184.95000267, 122.32500077, 297.55000305)</span><br><span class="line">     → 第 3 行单元格内容: (51.42499924, 297.55000305, 122.32500077, 368.05000305)</span><br><span class="line">     → 第 4 行单元格内容: (51.42499924, 368.05000305, 122.32500077, 392.1000061)</span><br><span class="line">     → 第 5 行单元格内容: (51.42499924, 392.1000061, 122.32500077, 416.0)</span><br><span class="line">     → 第 6 行单元格内容: (51.42499924, 416.0, 122.32500077, 439.90000914999996)</span><br><span class="line">     → 第 7 行单元格内容: (51.42499924, 439.90000914999996, 122.32500077, 463.80000305)</span><br><span class="line">     → 第 8 行单元格内容: (51.42499924, 463.80000305, 122.32500077, 487.84999084)</span><br><span class="line">     → 第 9 行单元格内容: (51.42499924, 487.84999084, 122.32500077, 511.74998474)</span><br><span class="line">     → 第 10 行单元格内容: (51.42499924, 511.74998474, 122.32500077, 761.84999084)</span><br><span class="line">  ⬅ 第 2 列:</span><br><span class="line">     → 第 1 行单元格内容: (122.32500077, 166.80000305, 214.47500228999996, 184.95000267)</span><br><span class="line">     → 第 2 行单元格内容: (122.32500077, 184.95000267, 214.47500228999996, 297.55000305)</span><br><span class="line">     → 第 3 行单元格内容: (122.32500077, 297.55000305, 214.47500228999996, 368.05000305)</span><br><span class="line">     → 第 4 行单元格内容: (122.32500077, 368.05000305, 214.47500228999996, 392.1000061)</span><br><span class="line">     → 第 5 行单元格内容: (122.32500077, 392.1000061, 214.47500228999996, 416.0)</span><br><span class="line">     → 第 6 行单元格内容: (122.32500077, 416.0, 214.47500228999996, 439.90000914999996)</span><br><span class="line">     → 第 7 行单元格内容: (122.32500077, 439.90000914999996, 214.47500228999996, 463.80000305)</span><br><span class="line">     → 第 8 行单元格内容: (122.32500077, 463.80000305, 214.47500228999996, 487.84999084)</span><br><span class="line">     → 第 9 行单元格内容: (122.32500077, 487.84999084, 214.47500228999996, 511.74998474)</span><br><span class="line">     → 第 10 行单元格内容: (122.32500077, 511.74998474, 214.47500228999996, 761.84999084)</span><br><span class="line">  ⬅ 第 3 列:</span><br><span class="line">     → 第 1 行单元格内容: (214.47500228999996, 166.80000305, 543.87501145, 184.95000267)</span><br><span class="line">     → 第 2 行单元格内容: (214.47500228999996, 184.95000267, 543.87501145, 297.55000305)</span><br><span class="line">     → 第 3 行单元格内容: (214.47500228999996, 297.55000305, 543.87501145, 368.05000305)</span><br><span class="line">     → 第 4 行单元格内容: (214.47500228999996, 368.05000305, 543.87501145, 392.1000061)</span><br><span class="line">     → 第 5 行单元格内容: (214.47500228999996, 392.1000061, 543.87501145, 416.0)</span><br><span class="line">     → 第 6 行单元格内容: (214.47500228999996, 416.0, 543.87501145, 439.90000914999996)</span><br><span class="line">     → 第 7 行单元格内容: (214.47500228999996, 439.90000914999996, 543.87501145, 463.80000305)</span><br><span class="line">     → 第 8 行单元格内容: (214.47500228999996, 463.80000305, 543.87501145, 487.84999084)</span><br><span class="line">     → 第 9 行单元格内容: (214.47500228999996, 487.84999084, 543.87501145, 511.74998474)</span><br><span class="line">     → 第 10 行单元格内容: (214.47500228999996, 511.74998474, 543.87501145, 761.84999084)</span><br><span class="line">📄 表格内容（使用 extract 提取）:</span><br><span class="line">    [<span class="string">&#x27;条款号&#x27;</span>, <span class="string">&#x27;条款名称&#x27;</span>, <span class="string">&#x27;编列内容&#x27;</span>]</span><br><span class="line">    [<span class="string">&#x27;1.1.2&#x27;</span>, <span class="string">&#x27;招标人&#x27;</span>, <span class="string">&#x27;名称：杭州滨江奥体博览城开发建\n设运营管理有限公司\n地址：浙江省杭州市滨江区浦沿街\n道滨安路1338号三楼\n联系人：翁栎超\n电话：13600511926&#x27;</span>]</span><br><span class="line">    [<span class="string">&#x27;1.1.3&#x27;</span>, <span class="string">&#x27;招标代理机构&#x27;</span>, <span class="string">&#x27;名称： 浙江华耀建设咨询有限公司\n地址：杭州市上城区佰富时代中心3幢13楼\n联系人：潘正阳、陈瑶\n电话：13758171369、18757567243&#x27;</span>]</span><br><span class="line">    [<span class="string">&#x27;1.1.4&#x27;</span>, <span class="string">&#x27;工程名称&#x27;</span>, <span class="string">&#x27;奥体街（扬帆路-养正巷）设计&#x27;</span>]</span><br><span class="line">    [<span class="string">&#x27;1.1.5&#x27;</span>, <span class="string">&#x27;建设地点&#x27;</span>, <span class="string">&#x27;杭州市滨江区&#x27;</span>]</span><br><span class="line">    [<span class="string">&#x27;1.1.6&#x27;</span>, <span class="string">&#x27;建设规模&#x27;</span>, <span class="string">&#x27;见招标公告&#x27;</span>]</span><br><span class="line">    [<span class="string">&#x27;1.1.7&#x27;</span>, <span class="string">&#x27;投资估算&#x27;</span>, <span class="string">&#x27;本项目投资估算为22798万元&#x27;</span>]</span><br><span class="line">    [<span class="string">&#x27;1.2.1&#x27;</span>, <span class="string">&#x27;资金来源及比例&#x27;</span>, <span class="string">&#x27;国有100%&#x27;</span>]</span><br><span class="line">    [<span class="string">&#x27;1.2.2&#x27;</span>, <span class="string">&#x27;资金落实情况&#x27;</span>, <span class="string">&#x27;已落实&#x27;</span>]</span><br><span class="line">    [<span class="string">&#x27;1.3.1&#x27;</span>, <span class="string">&#x27;招标范围&#x27;</span>, <span class="string">&#x27;☑方案设计、初步设计（含概算编制和调整）和施工图设计（☑BIM设计\n服务）\n招标内容具体包括:工程设计服务内容： 包括但不限于：\n（1）可研编制（含估算编制）、方案设计及深化、初步设计（含概算\n编制）、施工图设计【含BIM（若有）】、管线综合、交改设计（若\n有，含主体项目交改以及其他配套交改设计）、雨污水管线迁改（若\n有）、基坑设计、报批审查配合、按审查和招标人意见对整个设计过程\n的修改、深化整合等优化设计；\n（2）按招标文件要求提供纸质和电子图纸；\n（3）设计补图和工程施工阶段的变更联系单；\n（4）施工配合、验收配合、竣工图编制配合等相关服务；\n（5）根据工程实际需要提供现场服务等。\n各阶段设计成果应符合国家规定的图纸编制深度要求及相关出图标准要\n求且应满足发包人的相关要求，并应及时完成招标人和相关审查部门的\n阶段性审查意见所提出的修改工作等，特别是相关部门不计次数的优化\n修改要求等。阶段性审查包括方案评审、初步设计审查和施工图审查&#x27;</span>]</span><br></pre></td></tr></table></figure>

<p><strong>说明：</strong></p>
<ol>
<li><p>上方的坐标单位是”points”(pt)，也叫PDF单位。</p>
<blockquote>
<p>1 point &#x3D; 1&#x2F;72 inch，72 pt &#x3D; 1 英寸 ≈ 2.54 cm</p>
</blockquote>
</li>
<li><p>上方的四个坐标均为(x0, top, x1, bottom)</p>
<table>
<thead>
<tr>
<th align="center">标志</th>
<th align="center">含义</th>
</tr>
</thead>
<tbody><tr>
<td align="center">x0</td>
<td align="center">左边框到页面左边框距离</td>
</tr>
<tr>
<td align="center">top</td>
<td align="center">上边框到页面上边框的距离</td>
</tr>
<tr>
<td align="center">x1</td>
<td align="center">右边框到页面左边框的距离</td>
</tr>
<tr>
<td align="center">bottom</td>
<td align="center">下边框到页面上边框的距离</td>
</tr>
</tbody></table>
</li>
<li><p>bbox 边界框: (51.42499924, 166.80000305, 543.87501145, 761.84999084)表示当前整个表格的坐标位置，左边框距离页面左边缘51.42 pt，上边框距离页面上边缘166.80 pt，右边框距离页面左边缘543.88 pt，下边框距离页面上边缘761.85 pt。</p>
</li>
<li><p>cells表示当前表格有多少各单元格，顺序为从上到下，从左到右，这里只打印出了前两个和最后两个，可以看出第一个单元格的前两位与最后一个单元格的后两位组合即为bbox边界框。</p>
</li>
<li><p>row表示按行读取，可以看出对于同一行来说，top和bottom是一样的。</p>
</li>
<li><p>columns表示按列读取，可以看出对于同一列，x0和x1是一样的。</p>
</li>
<li><p>最终extract提取的内容和extract_tables()提取的内容一样。</p>
</li>
</ol>
<h4 id="3-对比"><a href="#3-对比" class="headerlink" title="3. 对比"></a>3. 对比</h4><p>比较下上面提到的两种方式：</p>
<ul>
<li><code>.find_tables()</code> ➕ <code>.extract()</code></li>
<li><code>.extract_tables()</code></li>
</ul>
<p>本质上都是为了提取表格内容，但它们在使用方式和控制粒度上<strong>有所区别</strong>。下面是详细解释：</p>
<p>✅ <code>.find_tables() + .extract()</code> 的特点</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tables = page.find_tables()</span><br><span class="line"><span class="keyword">for</span> table <span class="keyword">in</span> tables:</span><br><span class="line">    data = table.extract()</span><br></pre></td></tr></table></figure>

<p><strong>优势</strong>：</p>
<ul>
<li>返回的是 <code>Table</code> 对象，可以访问更多属性：<ul>
<li><code>.cells</code>: 表格所有单元格（包含位置和内容）</li>
<li><code>.bbox</code>: 表格边界框</li>
<li><code>.rows</code>, <code>.columns</code>: 每行每列的单元格</li>
</ul>
</li>
<li>更适合<strong>需要对表格结构进行进一步分析或可视化</strong>的场景。</li>
<li>可以在提取前对每个表格单独处理，例如筛选特定大小或位置的表格。</li>
</ul>
<p><strong>劣势</strong>：</p>
<ul>
<li>稍微复杂一些，不适合只想快速提取文本的简单场景。</li>
</ul>
<p>✅ <code>.extract_tables()</code> 的特点</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tables = page.extract_tables()</span><br></pre></td></tr></table></figure>

<p><strong>优势</strong>：</p>
<ul>
<li>更<strong>快速、直接</strong>，返回的是一个<strong>嵌套列表结构</strong>：<ul>
<li>结构：<code>[table1, table2, ...]</code>，每个 table 是一个 <code>[[cell1, cell2, ...], [...], ...]</code></li>
</ul>
</li>
<li>更适合<strong>快速获取纯文本表格</strong>内容并打印或导出。</li>
<li>实际内部就是调用了 <code>find_tables(...).extract()</code> 的封装。</li>
</ul>
<p><strong>劣势</strong>：</p>
<ul>
<li>不返回 <code>Table</code> 对象，因此<strong>无法访问单元格位置、表格边界等高级信息</strong>。</li>
<li>无法对表格结构进行更多控制。</li>
</ul>
<p>📌 总结对比表</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>返回类型</th>
<th>能访问结构信息</th>
<th>操作复杂度</th>
<th>适合场景</th>
</tr>
</thead>
<tbody><tr>
<td><code>.find_tables() + .extract()</code></td>
<td><code>Table</code> 对象 + 列表</td>
<td>✅ 是</td>
<td>稍复杂</td>
<td>表格结构分析、自定义过滤</td>
</tr>
<tr>
<td><code>.extract_tables()</code></td>
<td>嵌套列表</td>
<td>❌ 否</td>
<td>简单</td>
<td>快速提取所有表格纯文本内容</td>
</tr>
</tbody></table>
<p>✅ 建议使用方式</p>
<ul>
<li><strong>只想提取表格内容文本</strong> → <code>extract_tables()</code> 更快更方便；</li>
<li><strong>想进一步分析表格结构、位置或可视化</strong> → 使用 <code>find_tables()</code> 和 <code>.extract()</code> 更灵活。</li>
</ul>
<hr>
<h3 id="五-Page-crop-…"><a href="#五-Page-crop-…" class="headerlink" title="五 Page.crop(…)"></a>五 Page.crop(…)</h3><table>
<thead>
<tr>
<th>方法</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>.crop(bounding_box, relative&#x3D;False, strict&#x3D;True)</td>
<td>返回一个<strong>裁剪到指定边界框</strong>（bounding box）的页面版本。边界框应表示为一个 4 元组，格式为 <code>(x0, top, x1, bottom)</code>。裁剪后的页面<strong>保留那些至少部分位于边界框内的对象</strong>。如果某个对象<strong>只有一部分位于边界框内</strong>，那么它的尺寸将被截取以适应这个边界框。如果设置 <code>relative=True</code>，则边界框的坐标将<strong>相对于页面左上角进行偏移计算</strong>（而不是使用绝对位置）。（详见 <a href="https://github.com/jsvine/pdfplumber/issues/245">Issue #245</a> 以获取图示和解释。）当 <code>strict=True</code>（默认值）时，要求<strong>裁剪边界框必须完全位于页面边界框之内</strong>，否则将引发错误。</td>
</tr>
</tbody></table>
<p>按上面<code>find_tables</code>一节中第17页输出的<code>bbox</code>坐标信息提取表格并保存下来：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pdfplumber</span><br><span class="line"></span><br><span class="line"><span class="comment"># PDF 路径和裁剪区域（bbox）</span></span><br><span class="line">pdf_path = <span class="string">&quot;../../招标文件修订-1.pdf&quot;</span></span><br><span class="line">page_number = <span class="number">16</span>  <span class="comment"># 第17业</span></span><br><span class="line">crop_bbox = (<span class="number">88.1</span>, <span class="number">72.25</span>, <span class="number">516.05</span>, <span class="number">226.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开 PDF 并处理指定页面</span></span><br><span class="line"><span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(pdf_path) <span class="keyword">as</span> pdf:</span><br><span class="line">    page = pdf.pages[page_number]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 裁剪指定区域</span></span><br><span class="line">    cropped_page = page.crop(crop_bbox)</span><br><span class="line">    tables = cropped_page.extract_tables()</span><br><span class="line">    <span class="comment"># 如果有表格</span></span><br><span class="line">    <span class="keyword">if</span> tables:</span><br><span class="line">        <span class="keyword">for</span> table_index, table <span class="keyword">in</span> <span class="built_in">enumerate</span>(tables):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;\n  ➤ 表格 <span class="subst">&#123;table_index + <span class="number">1</span>&#125;</span>:&quot;</span>)</span><br><span class="line">            <span class="keyword">for</span> row <span class="keyword">in</span> table:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;    &quot;</span>, row)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;  ❌ 没有找到表格。&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 渲染为图像（默认 resolution=72 dpi，可调高提升清晰度）</span></span><br><span class="line">    image = cropped_page.to_image(resolution=<span class="number">150</span>)  <span class="comment"># 150 或 200 更清晰</span></span><br><span class="line"></span><br><span class="line">    image.save(<span class="string">&quot;table.png&quot;</span>, <span class="built_in">format</span>=<span class="string">&quot;PNG&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">➤ 表格 1:</span><br><span class="line">   [<span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;类高级工程师及以上职称&#x27;</span>]</span><br><span class="line">   [<span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;道路专业设计师&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;具有工程师及以上职称&#x27;</span>]</span><br><span class="line">   [<span class="string">&#x27;3&#x27;</span>, <span class="string">&#x27;隧道专业设计师&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;具有工程师及以上职称&#x27;</span>]</span><br><span class="line">   [<span class="string">&#x27;4&#x27;</span>, <span class="string">&#x27;给排水专业设计师&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;具有工程师及以上职称&#x27;</span>]</span><br><span class="line">   [<span class="string">&#x27;5&#x27;</span>, <span class="string">&#x27;电气专业设计师&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;具有工程师及以上职称&#x27;</span>]</span><br><span class="line">   [<span class="string">&#x27;6&#x27;</span>, <span class="string">&#x27;园林专业设计师&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;具有工程师及以上职称&#x27;</span>]</span><br><span class="line">   [<span class="string">&#x27;7&#x27;</span>, <span class="string">&#x27;造价专业负责人&#x27;</span>, <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;具有注册一级造价师资格&#x27;</span>]</span><br></pre></td></tr></table></figure>



<hr>
<h2 id="✅正文"><a href="#✅正文" class="headerlink" title="✅正文"></a>✅正文</h2><h3 id="混合表格-文本"><a href="#混合表格-文本" class="headerlink" title="混合表格&#x2F;文本"></a>混合表格&#x2F;文本</h3><p>如果使用<code>extract_text_line()</code>会将所有内容按行读取，会丢失表格的结构，故表格需用<code>find_tables()+extract()</code>提取（因为单纯的<code>extract_tables()</code>拿不到坐标信息）,合理运用<code>extract_text_line</code>+<code>find_tables+extract</code>+<code>crop</code>是解析混合表格+普通文本的PDF文件的关键。</p>
<p>思路：</p>
<ul>
<li>先提取所有表格，记录他们的<code>bounding boxes</code></li>
<li>再提取所有文本行，排除那些出现在表格中的行</li>
</ul>
<p><strong>万丈高楼平地起，咱们一个问题一个问题的解决，先从最基本的代码来看：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pdfplumber</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_pdf_text_and_tables</span>(<span class="params">pdf_path, max_pages=<span class="literal">None</span></span>):</span><br><span class="line">    result = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(pdf_path) <span class="keyword">as</span> pdf:</span><br><span class="line">        <span class="keyword">for</span> i, page <span class="keyword">in</span> <span class="built_in">enumerate</span>(pdf.pages):</span><br><span class="line">            <span class="keyword">if</span> max_pages <span class="keyword">and</span> i &gt;= max_pages:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 提取文本行（按视觉顺序）</span></span><br><span class="line">            lines = page.extract_text_lines()</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">                result.append(&#123;</span><br><span class="line">                    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;text&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;content&quot;</span>: line[<span class="string">&quot;text&quot;</span>]</span><br><span class="line">                &#125;)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 提取表格（按每页顺序）</span></span><br><span class="line">            <span class="keyword">for</span> table <span class="keyword">in</span> page.find_tables():</span><br><span class="line">                table_data = table.extract()</span><br><span class="line">                <span class="keyword">if</span> table_data:</span><br><span class="line">                    result.append(&#123;</span><br><span class="line">                        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;table&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;content&quot;</span>: table_data</span><br><span class="line">                    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 使用示例</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    pdf_path = <span class="string">&quot;../../招标文件修订-1.pdf&quot;</span></span><br><span class="line">    output_path = <span class="string">&quot;mixed_content_output.json&quot;</span></span><br><span class="line"></span><br><span class="line">    content = extract_pdf_text_and_tables(pdf_path, max_pages=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(output_path, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        json.dump(content, f, ensure_ascii=<span class="literal">False</span>, indent=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;已完成提取并保存至：<span class="subst">&#123;output_path&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>此时的问题：表格内容读取两次，解决方式：通过坐标判断text是否属于table范围</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pdfplumber</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">is_in_any_table</span>(<span class="params">line, table_bboxes</span>):</span><br><span class="line">    y = line[<span class="string">&quot;top&quot;</span>]</span><br><span class="line">    <span class="keyword">for</span> x0, top, x1, bottom <span class="keyword">in</span> table_bboxes:</span><br><span class="line">        <span class="keyword">if</span> top &lt;= y &lt;= bottom:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_pdf_text_and_tables</span>(<span class="params">pdf_path, max_pages=<span class="literal">None</span></span>):</span><br><span class="line">    result = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(pdf_path) <span class="keyword">as</span> pdf:</span><br><span class="line">        <span class="keyword">for</span> i, page <span class="keyword">in</span> <span class="built_in">enumerate</span>(pdf.pages):</span><br><span class="line">            <span class="keyword">if</span> max_pages <span class="keyword">and</span> i &gt;= max_pages:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Step 1: 提取表格及其位置</span></span><br><span class="line">            tables = page.find_tables()</span><br><span class="line">            table_bboxes = [t.bbox <span class="keyword">for</span> t <span class="keyword">in</span> tables]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> table <span class="keyword">in</span> tables:</span><br><span class="line">                table_data = table.extract()</span><br><span class="line">                <span class="keyword">if</span> table_data:</span><br><span class="line">                    result.append(&#123;</span><br><span class="line">                        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;table&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;content&quot;</span>: table_data</span><br><span class="line">                    &#125;)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Step 2: 提取非表格文本行</span></span><br><span class="line">            lines = page.extract_text_lines()</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> is_in_any_table(line, table_bboxes):</span><br><span class="line">                    result.append(&#123;</span><br><span class="line">                        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;text&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;content&quot;</span>: line[<span class="string">&quot;text&quot;</span>]</span><br><span class="line">                    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 使用示例</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    pdf_path = <span class="string">&quot;../../招标文件修订-1.pdf&quot;</span></span><br><span class="line">    output_path = <span class="string">&quot;mixed_content_clean.json&quot;</span></span><br><span class="line"></span><br><span class="line">    content = extract_pdf_text_and_tables(pdf_path, max_pages=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(output_path, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        json.dump(content, f, ensure_ascii=<span class="literal">False</span>, indent=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;提取完成，结果已保存至：<span class="subst">&#123;output_path&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>此时的问题：虽然表格只读取一次了，但顺序不对，总是先写入table内容再写入text内容，解决办法：写入到result之前先按坐标排序</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pdfplumber</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">is_in_any_table</span>(<span class="params">line, table_bboxes</span>):</span><br><span class="line">    y = line[<span class="string">&quot;top&quot;</span>]</span><br><span class="line">    <span class="keyword">for</span> x0, top, x1, bottom <span class="keyword">in</span> table_bboxes:</span><br><span class="line">        <span class="keyword">if</span> top &lt;= y &lt;= bottom:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_pdf_ordered_content</span>(<span class="params">pdf_path, max_pages=<span class="literal">None</span></span>):</span><br><span class="line">    result = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(pdf_path) <span class="keyword">as</span> pdf:</span><br><span class="line">        <span class="keyword">for</span> i, page <span class="keyword">in</span> <span class="built_in">enumerate</span>(pdf.pages):</span><br><span class="line">            <span class="keyword">if</span> max_pages <span class="keyword">and</span> i &gt;= max_pages:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            items_on_page = []</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Step 1: 提取表格及其bbox</span></span><br><span class="line">            tables = page.find_tables()</span><br><span class="line">            table_bboxes = [t.bbox <span class="keyword">for</span> t <span class="keyword">in</span> tables]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> table <span class="keyword">in</span> tables:</span><br><span class="line">                table_data = table.extract()</span><br><span class="line">                <span class="keyword">if</span> table_data:</span><br><span class="line">                    <span class="comment"># 使用表格的 bbox.top 作为排序依据</span></span><br><span class="line">                    items_on_page.append(&#123;</span><br><span class="line">                        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;table&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;top&quot;</span>: table.bbox[<span class="number">1</span>],  <span class="comment"># bbox = (x0, top, x1, bottom)</span></span><br><span class="line">                        <span class="string">&quot;content&quot;</span>: table_data</span><br><span class="line">                    &#125;)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Step 2: 提取非表格文本行</span></span><br><span class="line">            lines = page.extract_text_lines()</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> is_in_any_table(line, table_bboxes):</span><br><span class="line">                    items_on_page.append(&#123;</span><br><span class="line">                        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;text&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;top&quot;</span>: line[<span class="string">&quot;top&quot;</span>],</span><br><span class="line">                        <span class="string">&quot;content&quot;</span>: line[<span class="string">&quot;text&quot;</span>]</span><br><span class="line">                    &#125;)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Step 3: 按 top 坐标排序，模拟阅读顺序</span></span><br><span class="line">            items_on_page.sort(key=<span class="keyword">lambda</span> x: x[<span class="string">&quot;top&quot;</span>])</span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> items_on_page:</span><br><span class="line">                <span class="keyword">del</span> item[<span class="string">&quot;top&quot;</span>]  <span class="comment"># 删除坐标，只保留内容</span></span><br><span class="line">                result.append(item)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 使用示例</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    pdf_path = <span class="string">&quot;../../招标文件修订-1.pdf&quot;</span></span><br><span class="line">    output_path = <span class="string">&quot;mixed_content_ordered.json&quot;</span></span><br><span class="line"></span><br><span class="line">    content = extract_pdf_ordered_content(pdf_path, max_pages=<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(output_path, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        json.dump(content, f, ensure_ascii=<span class="literal">False</span>, indent=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;提取完成，顺序已处理，结果已保存至：<span class="subst">&#123;output_path&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>现在顺序对了，但是需对续表增加一点处理，对于下面的续表，应将内容附加到上一页对应位置的末尾</strong></p>




<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pdfplumber</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">is_in_any_table</span>(<span class="params">line, table_bboxes</span>):</span><br><span class="line">    y = line[<span class="string">&quot;top&quot;</span>]</span><br><span class="line">    <span class="keyword">for</span> x0, top, x1, bottom <span class="keyword">in</span> table_bboxes:</span><br><span class="line">        <span class="keyword">if</span> top &lt;= y &lt;= bottom:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_pdf_ordered_content_merged</span>(<span class="params">pdf_path, max_pages=<span class="literal">None</span></span>):</span><br><span class="line">    result = []</span><br><span class="line">    last_table_ref = <span class="literal">None</span>  <span class="comment"># 用于存储上一页的表格引用</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(pdf_path) <span class="keyword">as</span> pdf:</span><br><span class="line">        <span class="keyword">for</span> i, page <span class="keyword">in</span> <span class="built_in">enumerate</span>(pdf.pages):</span><br><span class="line">            <span class="keyword">if</span> max_pages <span class="keyword">and</span> i &gt;= max_pages:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            items_on_page = []</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Step 1: 提取表格及其bbox</span></span><br><span class="line">            tables = page.find_tables()</span><br><span class="line">            table_bboxes = [t.bbox <span class="keyword">for</span> t <span class="keyword">in</span> tables]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> table <span class="keyword">in</span> tables:</span><br><span class="line">                table_data = table.extract()</span><br><span class="line">                <span class="keyword">if</span> table_data:</span><br><span class="line">                    <span class="comment"># 检查是否为续表的首行（第一列为空字符串）</span></span><br><span class="line">                    <span class="keyword">if</span> table_data <span class="keyword">and</span> table_data[<span class="number">0</span>] <span class="keyword">and</span> table_data[<span class="number">0</span>][<span class="number">0</span>].strip() == <span class="string">&quot;&quot;</span> <span class="keyword">and</span> last_table_ref:</span><br><span class="line">                        <span class="comment"># 合并到上一页的最后一行</span></span><br><span class="line">                        last_row = last_table_ref[-<span class="number">1</span>]</span><br><span class="line">                        new_row = table_data[<span class="number">0</span>]</span><br><span class="line">                        <span class="comment"># 将续表行的每个非空单元格合并到 last_row</span></span><br><span class="line">                        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(new_row)):</span><br><span class="line">                            <span class="keyword">if</span> j &lt; <span class="built_in">len</span>(last_row) <span class="keyword">and</span> new_row[j].strip():</span><br><span class="line">                                last_row[j] += new_row[j]</span><br><span class="line">                        <span class="comment"># 删除首行</span></span><br><span class="line">                        table_data = table_data[<span class="number">1</span>:]</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 添加当前表格</span></span><br><span class="line">                    items_on_page.append(&#123;</span><br><span class="line">                        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;table&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;top&quot;</span>: table.bbox[<span class="number">1</span>],</span><br><span class="line">                        <span class="string">&quot;content&quot;</span>: table_data</span><br><span class="line">                    &#125;)</span><br><span class="line"></span><br><span class="line">                    <span class="comment"># 更新 last_table_ref（只存储表格数据部分）</span></span><br><span class="line">                    last_table_ref = table_data</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Step 2: 提取非表格文本行</span></span><br><span class="line">            lines = page.extract_text_lines()</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> is_in_any_table(line, table_bboxes):</span><br><span class="line">                    items_on_page.append(&#123;</span><br><span class="line">                        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;text&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;top&quot;</span>: line[<span class="string">&quot;top&quot;</span>],</span><br><span class="line">                        <span class="string">&quot;content&quot;</span>: line[<span class="string">&quot;text&quot;</span>]</span><br><span class="line">                    &#125;)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Step 3: 排序并清理</span></span><br><span class="line">            items_on_page.sort(key=<span class="keyword">lambda</span> x: x[<span class="string">&quot;top&quot;</span>])</span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> items_on_page:</span><br><span class="line">                <span class="keyword">del</span> item[<span class="string">&quot;top&quot;</span>]</span><br><span class="line">                result.append(item)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ✅ 使用示例</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    pdf_path = <span class="string">&quot;../../招标文件修订-1.pdf&quot;</span></span><br><span class="line">    output_path = <span class="string">&quot;mixed_content_ordered.json&quot;</span></span><br><span class="line"></span><br><span class="line">    content = extract_pdf_ordered_content_merged(pdf_path, max_pages=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(output_path, <span class="string">&quot;w&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        json.dump(content, f, ensure_ascii=<span class="literal">False</span>, indent=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;提取完成，顺序已处理，结果已保存至：<span class="subst">&#123;output_path&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>到这里完成了基本的表格&#x2F;文本混合格式的pdf文件的解析，这里展示下第三页的解析结果：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">   <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;text&quot;</span><span class="punctuation">,</span></span><br><span class="line">   <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;第二章 投标人须知&quot;</span></span><br><span class="line"> <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"> <span class="punctuation">&#123;</span></span><br><span class="line">   <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;text&quot;</span><span class="punctuation">,</span></span><br><span class="line">   <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;投标人须知前附表&quot;</span></span><br><span class="line"> <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"> <span class="punctuation">&#123;</span></span><br><span class="line">   <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;table&quot;</span><span class="punctuation">,</span></span><br><span class="line">   <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">     <span class="punctuation">[</span></span><br><span class="line">       <span class="string">&quot;条款号&quot;</span><span class="punctuation">,</span></span><br><span class="line">       <span class="string">&quot;条款名称&quot;</span><span class="punctuation">,</span></span><br><span class="line">       <span class="string">&quot;编列内容&quot;</span></span><br><span class="line">     <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">     <span class="punctuation">[</span></span><br><span class="line">       <span class="string">&quot;1.1.2&quot;</span><span class="punctuation">,</span></span><br><span class="line">       <span class="string">&quot;招标人&quot;</span><span class="punctuation">,</span></span><br><span class="line">       <span class="string">&quot;名称：杭州滨江奥体博览城开发建\n设运营管理有限公司\n地址：浙江省杭州市滨江区浦沿街\n道滨安路1338号三楼\n联系人：翁栎超\n电话：13600511926&quot;</span></span><br><span class="line">     <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">     <span class="punctuation">[</span></span><br><span class="line">       <span class="string">&quot;1.1.3&quot;</span><span class="punctuation">,</span></span><br><span class="line">       <span class="string">&quot;招标代理机构&quot;</span><span class="punctuation">,</span></span><br><span class="line">       <span class="string">&quot;名称： 浙江华耀建设咨询有限公司\n地址：杭州市上城区佰富时代中心3幢13楼\n联系人：潘正阳、陈瑶\n电话：13758171369、18757567243&quot;</span></span><br><span class="line">     <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">     <span class="punctuation">[</span></span><br><span class="line">       <span class="string">&quot;1.1.4&quot;</span><span class="punctuation">,</span></span><br><span class="line">       <span class="string">&quot;工程名称&quot;</span><span class="punctuation">,</span></span><br><span class="line">       <span class="string">&quot;奥体街（扬帆路-养正巷）设计&quot;</span></span><br><span class="line">     <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">     <span class="punctuation">[</span></span><br><span class="line">       <span class="string">&quot;1.1.5&quot;</span><span class="punctuation">,</span></span><br><span class="line">       <span class="string">&quot;建设地点&quot;</span><span class="punctuation">,</span></span><br><span class="line">       <span class="string">&quot;杭州市滨江区&quot;</span></span><br><span class="line">     <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">     <span class="punctuation">[</span></span><br><span class="line">       <span class="string">&quot;1.1.6&quot;</span><span class="punctuation">,</span></span><br><span class="line">       <span class="string">&quot;建设规模&quot;</span><span class="punctuation">,</span></span><br><span class="line">       <span class="string">&quot;见招标公告&quot;</span></span><br><span class="line">     <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">     <span class="punctuation">[</span></span><br><span class="line">       <span class="string">&quot;1.1.7&quot;</span><span class="punctuation">,</span></span><br><span class="line">       <span class="string">&quot;投资估算&quot;</span><span class="punctuation">,</span></span><br><span class="line">       <span class="string">&quot;本项目投资估算为22798万元&quot;</span></span><br><span class="line">     <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">     <span class="punctuation">[</span></span><br><span class="line">       <span class="string">&quot;1.2.1&quot;</span><span class="punctuation">,</span></span><br><span class="line">       <span class="string">&quot;资金来源及比例&quot;</span><span class="punctuation">,</span></span><br><span class="line">       <span class="string">&quot;国有100%&quot;</span></span><br><span class="line">     <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">     <span class="punctuation">[</span></span><br><span class="line">       <span class="string">&quot;1.2.2&quot;</span><span class="punctuation">,</span></span><br><span class="line">       <span class="string">&quot;资金落实情况&quot;</span><span class="punctuation">,</span></span><br><span class="line">       <span class="string">&quot;已落实&quot;</span></span><br><span class="line">     <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">     <span class="punctuation">[</span></span><br><span class="line">       <span class="string">&quot;1.3.1&quot;</span><span class="punctuation">,</span></span><br><span class="line">       <span class="string">&quot;招标范围&quot;</span><span class="punctuation">,</span></span><br><span class="line">       <span class="string">&quot;☑方案设计、初步设计（含概算编制和调整）和施工图设计（☑BIM设计\n服务）\n招标内容具体包括:工程设计服务内容： 包括但不限于：\n（1）可研编制（含估算编制）、方案设计及深化、初步设计（含概算\n编制）、施工图设计【含BIM（若有）】、管线综合、交改设计（若\n有，含主体项目交改以及其他配套交改设计）、雨污水管线迁改（若\n有）、基坑设计、报批审查配合、按审查和招标人意见对整个设计过程\n的修改、深化整合等优化设计；\n（2）按招标文件要求提供纸质和电子图纸；\n（3）设计补图和工程施工阶段的变更联系单；\n（4）施工配合、验收配合、竣工图编制配合等相关服务；\n（5）根据工程实际需要提供现场服务等。\n各阶段设计成果应符合国家规定的图纸编制深度要求及相关出图标准要\n求且应满足发包人的相关要求，并应及时完成招标人和相关审查部门的\n阶段性审查意见所提出的修改工作等，特别是相关部门不计次数的优化\n修改要求等。阶段性审查包括方案评审、初步设计审查和施工图审查等。设计单位提供给招标人的设计成果必须保证其完整性和准确性。&quot;</span></span><br><span class="line">     <span class="punctuation">]</span></span><br><span class="line">   <span class="punctuation">]</span></span><br><span class="line"> <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"> <span class="punctuation">&#123;</span></span><br><span class="line">   <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;text&quot;</span><span class="punctuation">,</span></span><br><span class="line">   <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;12&quot;</span></span><br><span class="line"> <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure>

<h3 id="✅留坑"><a href="#✅留坑" class="headerlink" title="✅留坑"></a>✅留坑</h3><p>留个坑，下面的优化方向是更好的格式化，比如以章节分类，表格内容中将表头信息写进去等等…现在先去玩下clip(另一个项目可能要用)。</p>
<hr>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h3 id="1-page-extract-text"><a href="#1-page-extract-text" class="headerlink" title="1 page.extract_text"></a>1 page.extract_text</h3><p>设想你有一页 PDF，其内容如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Hello   world!</span><br><span class="line">This    is   a    <span class="built_in">test</span>.</span><br></pre></td></tr></table></figure>

<p>PDF 中字符的位置是精确坐标排布的，字符之间<strong>不一定有真正的空格字符</strong>，它们可能只是间隔了一段距离。在这种情况下，你希望把字符<strong>正确拼接成有空格、有换行</strong>的文本，就需要依赖 <code>.extract_text()</code> 的各个参数来帮你控制提取逻辑。</p>
<p>✅ 示例：如何作用的？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">page.extract_text(</span><br><span class="line">    x_tolerance=<span class="number">3</span>,</span><br><span class="line">    y_tolerance=<span class="number">3</span>,</span><br><span class="line">    layout=<span class="literal">False</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>x_tolerance=3</code></td>
<td>两个字符之间水平距离（下一个字符的 <code>x0</code> - 当前字符的 <code>x1</code>）超过 3，就认为它们之间有空格。太小会漏掉空格，太大可能乱加空格。</td>
</tr>
<tr>
<td><code>y_tolerance=3</code></td>
<td>两个字符的垂直位置（<code>doctop</code>）相差超过 3，就认为要换行。</td>
</tr>
<tr>
<td><code>layout=False</code></td>
<td>不考虑页面的原始排版，只按字符间距和垂直差距插入空格或换行。</td>
</tr>
</tbody></table>
<p>🔁 加入 <code>x_tolerance_ratio</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">page.extract_text(</span><br><span class="line">    x_tolerance=<span class="literal">None</span>,</span><br><span class="line">    x_tolerance_ratio=<span class="number">0.4</span>,</span><br><span class="line">    layout=<span class="literal">False</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>x_tolerance_ratio=0.4</code></td>
<td>设置一个相对间隔阈值。比如当前字符字体大小是 <code>10</code>，那只要两个字符横向间距 &gt; <code>10 * 0.4 = 4</code> 就认为它们之间应该加空格。用于应对不同字号的情况。</td>
</tr>
</tbody></table>
<p>🧱 使用 <code>layout=True</code> 模拟原始排版</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">page.extract_text(</span><br><span class="line">    layout=<span class="literal">True</span>,</span><br><span class="line">    x_density=<span class="number">5</span>,</span><br><span class="line">    y_density=<span class="number">10</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>layout=True</code></td>
<td>按页面结构提取文本，不只是纯拼接字符，会尝试还原换行、列、段落。适合有表格或双栏内容的 PDF。</td>
</tr>
<tr>
<td><code>x_density=5</code></td>
<td>控制水平方向密度。值越小，认为字符间隔“正常”的阈值越小，字符更容易被断开成不同“列”。</td>
</tr>
<tr>
<td><code>y_density=10</code></td>
<td>控制垂直方向密度。值越小，换行更频繁。</td>
</tr>
</tbody></table>
<p>↕️ 字符&#x2F;行方向控制</p>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">python复制编辑page.extract_text(</span><br><span class="line">    <span class="attribute">layout</span>=<span class="literal">True</span>,</span><br><span class="line">    <span class="attribute">line_dir_render</span>=<span class="string">&quot;ttb&quot;</span>,      # 行从上到下</span><br><span class="line">    <span class="attribute">char_dir_render</span>=<span class="string">&quot;ltr&quot;</span>       # 字从左到右</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>这两个参数用于控制输出文本的方向，适用于例如竖排日文、繁体中文文档的布局解析。</p>
<hr>
<h3 id="2-第二页-第三页"><a href="#2-第二页-第三页" class="headerlink" title="2 第二页+第三页"></a>2 第二页+第三页</h3><p><strong>第二页：</strong></p>


<p><strong>第三页：</strong></p>


<hr>
<h3 id="3-layout-True"><a href="#3-layout-True" class="headerlink" title="3 layout&#x3D;True"></a>3 layout&#x3D;True</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">--- 第 1 页 ---</span><br><span class="line"></span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                杭州市房屋建筑和市政基础设施项目                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                          设计招标文件示范文本                                                </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                   （资格后审）                                           </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                   （2019年版）                                         </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                            杭州市城乡建设委员会制                                             </span><br><span class="line">                                                                                    </span><br><span class="line">                                  二0二五年四月                                           </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                          01                                        </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line"></span><br><span class="line">----------------------------------------</span><br><span class="line"></span><br><span class="line">--- 第 2 页 ---</span><br><span class="line"></span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                            奥体街（扬帆路-养正巷）设计                                          </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                          （招标编号：A3301080120526863001221）                            </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                   招标文件                                             </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                        （☑资格后审□邀请招标）                                                </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">            招标人：杭州滨江奥体博览城开发建设运营管理有限公司                        （盖单位章）                 </span><br><span class="line">                                                                                    </span><br><span class="line">                 招标代理机构：浙江华耀建设咨询有限公司                    （盖单位章）                      </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                           2025年05月15日                              </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line">                                          11                                        </span><br><span class="line">                                                                                    </span><br><span class="line">                                                                                    </span><br><span class="line"></span><br><span class="line">----------------------------------------</span><br><span class="line"></span><br><span class="line">--- 第 3 页 ---</span><br><span class="line"></span><br><span class="line">                                                                                  </span><br><span class="line">                                                                                  </span><br><span class="line">                                                                                  </span><br><span class="line">                                                                                  </span><br><span class="line">                                                                                  </span><br><span class="line">                                                                                  </span><br><span class="line">                                                                                  </span><br><span class="line">                                第二章       投标人须知                                   </span><br><span class="line">                                                                                  </span><br><span class="line">                                                                                  </span><br><span class="line">                                 投标人须知前附表                                         </span><br><span class="line">                                                                                  </span><br><span class="line">                                                                                  </span><br><span class="line">         条款号        条款名称                         编列内容                             </span><br><span class="line">                                                                                  </span><br><span class="line">                              名称：杭州滨江奥体博览城开发建                                     </span><br><span class="line">                              设运营管理有限公司                                           </span><br><span class="line">                                                                                  </span><br><span class="line">                              地址：浙江省杭州市滨江区浦沿街                                     </span><br><span class="line">          1.1.2      招标人                                                          </span><br><span class="line">                              道滨安路1338号三楼                                         </span><br><span class="line">                              联系人：翁栎超                                             </span><br><span class="line">                              电话：13600511926                                      </span><br><span class="line">                              名称：  浙江华耀建设咨询有限公司                                   </span><br><span class="line">                                                                                  </span><br><span class="line">                              地址：杭州市上城区佰富时代中心3幢13楼                                </span><br><span class="line">          1.1.3    招标代理机构                                                         </span><br><span class="line">                               联系人：潘正阳、陈瑶                                         </span><br><span class="line">                              电话：13758171369、18757567243                          </span><br><span class="line">                                  奥体街（扬帆路-养正巷）设计                                  </span><br><span class="line">          1.1.4     工程名称                                                          </span><br><span class="line">                              杭州市滨江区                                              </span><br><span class="line">          1.1.5     建设地点                                                          </span><br><span class="line">                              见招标公告                                               </span><br><span class="line">          1.1.6     建设规模                                                          </span><br><span class="line">                              本项目投资估算为22798万元                                     </span><br><span class="line">          1.1.7     投资估算                                                          </span><br><span class="line">                              国有100%                                              </span><br><span class="line">          1.2.1   资金来源及比例                                                         </span><br><span class="line">                              已落实                                                 </span><br><span class="line">          1.2.2    资金落实情况                                                         </span><br><span class="line">                              ☑方案设计、初步设计（含概算编制和调整）和施工图设计（☑BIM设计                   </span><br><span class="line">                              服务）                                                 </span><br><span class="line">                              招标内容具体包括:工程设计服务内容：        包括但不限于：                   </span><br><span class="line">                              （1）可研编制（含估算编制）、方案设计及深化、初步设计（含概算                     </span><br><span class="line">                              编制）、施工图设计【含BIM（若有）】、管线综合、交改设计（若                     </span><br><span class="line">                              有，含主体项目交改以及其他配套交改设计）、雨污水管线迁改（若                      </span><br><span class="line">                              有）、基坑设计、报批审查配合、按审查和招标人意见对整个设计过程                     </span><br><span class="line">                              的修改、深化整合等优化设计；                                      </span><br><span class="line">          1.3.1     招标范围                                                          </span><br><span class="line">                              （2）按招标文件要求提供纸质和电子图纸；                                </span><br><span class="line">                              （3）设计补图和工程施工阶段的变更联系单；                               </span><br><span class="line">                              （4）施工配合、验收配合、竣工图编制配合等相关服务；                          </span><br><span class="line">                              （5）根据工程实际需要提供现场服务等。                                 </span><br><span class="line">                              各阶段设计成果应符合国家规定的图纸编制深度要求及相关出图标准要                     </span><br><span class="line">                              求且应满足发包人的相关要求，并应及时完成招标人和相关审查部门的                     </span><br><span class="line">                              阶段性审查意见所提出的修改工作等，特别是相关部门不计次数的优化                     </span><br><span class="line">                                                                                  </span><br><span class="line">                              修改要求等。阶段性审查包括方案评审、初步设计审查和施工图审查                      </span><br><span class="line">                                                                                  </span><br><span class="line">                                                                                  </span><br><span class="line">                                         12                                       </span><br><span class="line">                                                                                  </span><br><span class="line">                                                                                  </span><br><span class="line"></span><br><span class="line">----------------------------------------</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="4-table-settings"><a href="#4-table-settings" class="headerlink" title="4 table_settings"></a>4 table_settings</h3><p><strong>⚙️ 表格提取设置（<code>table_settings</code>）</strong></p>
<p>默认情况下，<code>.extract_tables()</code> 使用页面的水平与垂直线（包括矩形边）作为单元格边界。但你可以通过 <code>table_settings</code> 自定义策略和阈值。示例设置及默认值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;vertical_strategy&quot;</span>: <span class="string">&quot;lines&quot;</span>,</span><br><span class="line">  <span class="string">&quot;horizontal_strategy&quot;</span>: <span class="string">&quot;lines&quot;</span>,</span><br><span class="line">  <span class="string">&quot;explicit_vertical_lines&quot;</span>: [],</span><br><span class="line">  <span class="string">&quot;explicit_horizontal_lines&quot;</span>: [],</span><br><span class="line">  <span class="string">&quot;snap_tolerance&quot;</span>: <span class="number">3</span>,</span><br><span class="line">  <span class="string">&quot;snap_x_tolerance&quot;</span>: <span class="number">3</span>,</span><br><span class="line">  <span class="string">&quot;snap_y_tolerance&quot;</span>: <span class="number">3</span>,</span><br><span class="line">  <span class="string">&quot;join_tolerance&quot;</span>: <span class="number">3</span>,</span><br><span class="line">  <span class="string">&quot;join_x_tolerance&quot;</span>: <span class="number">3</span>,</span><br><span class="line">  <span class="string">&quot;join_y_tolerance&quot;</span>: <span class="number">3</span>,</span><br><span class="line">  <span class="string">&quot;edge_min_length&quot;</span>: <span class="number">3</span>,</span><br><span class="line">  <span class="string">&quot;min_words_vertical&quot;</span>: <span class="number">3</span>,</span><br><span class="line">  <span class="string">&quot;min_words_horizontal&quot;</span>: <span class="number">1</span>,</span><br><span class="line">  <span class="string">&quot;intersection_tolerance&quot;</span>: <span class="number">3</span>,</span><br><span class="line">  <span class="string">&quot;intersection_x_tolerance&quot;</span>: <span class="number">3</span>,</span><br><span class="line">  <span class="string">&quot;intersection_y_tolerance&quot;</span>: <span class="number">3</span>,</span><br><span class="line">  <span class="string">&quot;text_tolerance&quot;</span>: <span class="number">3</span>,</span><br><span class="line">  <span class="string">&quot;text_x_tolerance&quot;</span>: <span class="number">3</span>,</span><br><span class="line">  <span class="string">&quot;text_y_tolerance&quot;</span>: <span class="number">3</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>🧾 每个参数说明：</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>vertical_strategy</code>, <code>horizontal_strategy</code></td>
<td>可选：<code>&quot;lines&quot;</code>, <code>&quot;lines_strict&quot;</code>, <code>&quot;text&quot;</code>, <code>&quot;explicit&quot;</code>，见下文策略解释。</td>
</tr>
<tr>
<td><code>explicit_vertical_lines</code>, <code>explicit_horizontal_lines</code></td>
<td>显式指定用于表格的垂直&#x2F;水平线列表，可为数字或线条对象。</td>
</tr>
<tr>
<td><code>snap_*_tolerance</code></td>
<td>平行线在该范围内将被“吸附”到相同位置。</td>
</tr>
<tr>
<td><code>join_*_tolerance</code></td>
<td>共线线段若端点间距小于此值将被合并为一条线段。</td>
</tr>
<tr>
<td><code>edge_min_length</code></td>
<td>忽略短于此值的线段。</td>
</tr>
<tr>
<td><code>min_words_vertical</code>, <code>min_words_horizontal</code></td>
<td>使用 <code>&quot;text&quot;</code> 策略时，需有多少单词对齐才能推断出线。</td>
</tr>
<tr>
<td><code>intersection_*_tolerance</code></td>
<td>组合边成单元格时，判断是否交叉的容差范围。</td>
</tr>
<tr>
<td><code>text_*</code></td>
<td>控制从表格中提取文字的参数，支持所有 <code>.extract_text(...)</code> 中的参数。</td>
</tr>
</tbody></table>
<p>🧠 表格提取策略解释：</p>
<table>
<thead>
<tr>
<th>策略</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>&quot;lines&quot;</code></td>
<td>使用图形线条（包括矩形边）作为单元格边界。</td>
</tr>
<tr>
<td><code>&quot;lines_strict&quot;</code></td>
<td>使用图形线条（不包括矩形边）作为单元格边界。</td>
</tr>
<tr>
<td><code>&quot;text&quot;</code></td>
<td>根据文字的左&#x2F;中&#x2F;右对齐（垂直策略）或顶部对齐（水平策略）推断出虚拟线条作为单元格边界。</td>
</tr>
<tr>
<td><code>&quot;explicit&quot;</code></td>
<td>仅使用显式定义的线条（<code>explicit_*_lines</code> 参数提供）。</td>
</tr>
</tbody></table>
<p>📝 说明</p>
<ul>
<li>在提取表格前使用 <code>Page.crop(...)</code> 裁剪页面，往往可以提高精度。</li>
</ul>
<hr>
<h3 id="5-extract-words-…"><a href="#5-extract-words-…" class="headerlink" title="5 extract_words(…)"></a>5 extract_words(…)</h3><p><code>.extract_words()</code> 方法说明</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">.extract_words(</span><br><span class="line">    x_tolerance=<span class="number">3</span>,</span><br><span class="line">    x_tolerance_ratio=<span class="literal">None</span>,</span><br><span class="line">    y_tolerance=<span class="number">3</span>,</span><br><span class="line">    keep_blank_chars=<span class="literal">False</span>,</span><br><span class="line">    use_text_flow=<span class="literal">False</span>,</span><br><span class="line">    line_dir=<span class="string">&quot;ttb&quot;</span>,</span><br><span class="line">    char_dir=<span class="string">&quot;ltr&quot;</span>,</span><br><span class="line">    line_dir_rotated=<span class="string">&quot;ttb&quot;</span>,</span><br><span class="line">    char_dir_rotated=<span class="string">&quot;ltr&quot;</span>,</span><br><span class="line">    extra_attrs=[],</span><br><span class="line">    split_at_punctuation=<span class="literal">False</span>,</span><br><span class="line">    expand_ligatures=<span class="literal">True</span>,</span><br><span class="line">    return_chars=<span class="literal">False</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>该方法返回一个 <strong>所有“看起来像单词”的文本及其边界框</strong> 的列表。</p>
<p>🔍 单词识别逻辑</p>
<ul>
<li><strong>通常字符（upright）</strong>：若一个字符的 <code>x1</code> 与下一个字符的 <code>x0</code> 之间的距离 ≤ <code>x_tolerance</code>，且两者的 <code>doctop</code> 差值 ≤ <code>y_tolerance</code>，则被视为同一个单词的一部分。</li>
<li><strong>若设置了 <code>x_tolerance_ratio</code></strong>，则 <code>x_tolerance</code> 会根据字符尺寸动态调整：<br> <code>x_tolerance = x_tolerance_ratio * previous_character[&quot;size&quot;]</code></li>
<li><strong>非正立字符</strong>（例如旋转过的文字）：采用垂直距离而非水平距离进行判断。</li>
</ul>
<p>⚙️ 参数说明</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>x_tolerance</code></td>
<td>同一行字符在水平方向上间距的容差。</td>
</tr>
<tr>
<td><code>x_tolerance_ratio</code></td>
<td>动态容差比值，基于字符大小计算。若不为 None，则覆盖 <code>x_tolerance</code>。</td>
</tr>
<tr>
<td><code>y_tolerance</code></td>
<td>判断字符是否在同一行的垂直容差。</td>
</tr>
<tr>
<td><code>keep_blank_chars</code></td>
<td>是否保留空格字符为单词的一部分（默认否）。设为 <code>True</code> 表示空格也视为字符，不将其作为单词分隔符。</td>
</tr>
<tr>
<td><code>use_text_flow</code></td>
<td>是否依据 PDF 内部的字符流顺序排列与分组文本（模拟文本拖选效果），而不是按坐标位置排序。</td>
</tr>
<tr>
<td><code>line_dir</code></td>
<td>期望的行排列方向： <code>&quot;ttb&quot;</code>（上到下）、<code>&quot;btt&quot;</code>（下到上）。</td>
</tr>
<tr>
<td><code>char_dir</code></td>
<td>期望的字符排列方向： <code>&quot;ltr&quot;</code>（左到右）、<code>&quot;rtl&quot;</code>（右到左）。</td>
</tr>
<tr>
<td><code>line_dir_rotated</code></td>
<td>旋转文本的行排列方向。</td>
</tr>
<tr>
<td><code>char_dir_rotated</code></td>
<td>旋转文本的字符排列方向。</td>
</tr>
<tr>
<td><code>extra_attrs</code></td>
<td>限定单词必须由具有完全相同属性的字符组成，如 <code>[&quot;fontname&quot;, &quot;size&quot;]</code>。提取结果中会包含这些属性。</td>
</tr>
<tr>
<td><code>split_at_punctuation</code></td>
<td>是否在标点处分词，设为 <code>True</code> 表示在标点处强制切词。也可传入一个字符串，如 <code>&#39;!.,;&#39;</code> 自定义标点。</td>
</tr>
<tr>
<td><code>expand_ligatures</code></td>
<td>是否将连字（如 <code>ﬁ</code>）拆为其组成字母（如 <code>f</code> 和 <code>i</code>）。默认 <code>True</code>。</td>
</tr>
<tr>
<td><code>return_chars</code></td>
<td>是否在每个单词字典中添加构成它的字符列表（作为 <code>&quot;chars&quot;</code> 字段）。</td>
</tr>
</tbody></table>
<p>📦 返回值结构（列表中的每个元素是一个字典）</p>
<p>每个“单词”包含如下字段：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;text&quot;</span>: <span class="string">&quot;单词内容&quot;</span>,</span><br><span class="line">  <span class="string">&quot;x0&quot;</span>: 100.0,</span><br><span class="line">  <span class="string">&quot;x1&quot;</span>: 130.5,</span><br><span class="line">  <span class="string">&quot;top&quot;</span>: 90.2,</span><br><span class="line">  <span class="string">&quot;bottom&quot;</span>: 103.6,</span><br><span class="line">  <span class="string">&quot;doctop&quot;</span>: 290.2,</span><br><span class="line">  <span class="string">&quot;chars&quot;</span>: [ &#123;...&#125;, &#123;...&#125; ]  <span class="comment"># 仅当 return_chars=True 时提供</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>✅ 示例用法</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pdfplumber</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(<span class="string">&quot;example.pdf&quot;</span>) <span class="keyword">as</span> pdf:</span><br><span class="line">    page = pdf.pages[<span class="number">0</span>]</span><br><span class="line">    words = page.extract_words(x_tolerance=<span class="number">2</span>, y_tolerance=<span class="number">2</span>, return_chars=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;单词: <span class="subst">&#123;word[<span class="string">&#x27;text&#x27;</span>]&#125;</span>, 位置: (<span class="subst">&#123;word[<span class="string">&#x27;x0&#x27;</span>]&#125;</span>, <span class="subst">&#123;word[<span class="string">&#x27;top&#x27;</span>]&#125;</span>) - (<span class="subst">&#123;word[<span class="string">&#x27;x1&#x27;</span>]&#125;</span>, <span class="subst">&#123;word[<span class="string">&#x27;bottom&#x27;</span>]&#125;</span>)&quot;</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="6-extract-words-vs-extract-text-lines"><a href="#6-extract-words-vs-extract-text-lines" class="headerlink" title="6 extract_words() vs extract_text_lines()"></a>6 extract_words() vs extract_text_lines()</h3><p><code>.extract_text_lines()</code> 和 <code>.extract_words()</code> <strong>在输出结构上有相似之处</strong>，但它们关注的<strong>粒度和应用场景不同</strong>：</p>
<p>🆚 <code>.extract_words()</code> vs <code>.extract_text_lines()</code></p>
<table>
<thead>
<tr>
<th>特性</th>
<th><code>.extract_words()</code></th>
<th><code>.extract_text_lines()</code></th>
</tr>
</thead>
<tbody><tr>
<td>📦 粒度</td>
<td><strong>按单词</strong>划分</td>
<td><strong>按文本行</strong>划分</td>
</tr>
<tr>
<td>📐 坐标</td>
<td>每个词的 <code>x0, top, x1, bottom</code></td>
<td>每行文本的 <code>x0, top, x1, bottom</code></td>
</tr>
<tr>
<td>🔠 内容组织</td>
<td>每个词是一个独立对象</td>
<td>每行是一个整体（包含多个字符或词）</td>
</tr>
<tr>
<td>🔍 可选内容</td>
<td>可加 <code>return_chars=True</code> 返回组成词的字符</td>
<td>默认可返回每行字符（同样用 <code>return_chars=True</code>）</td>
</tr>
<tr>
<td>🧭 排序依据</td>
<td>主要靠字符之间的水平&#x2F;垂直距离（默认 <code>x/y_tolerance</code>）</td>
<td>可选择 layout 方式，依赖版式流（<code>layout=True</code>）</td>
</tr>
<tr>
<td>🧩 应用场景</td>
<td>提取关键字段、词级处理、搜索</td>
<td>精准还原行结构、逐行处理、OCR 后处理</td>
</tr>
</tbody></table>
<p>✅ 举例说明差别</p>
<p>假设你有一页 PDF 内容是：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">项目名称：XX工程项目</span><br><span class="line">招标人：YY公司</span><br></pre></td></tr></table></figure>

<p>用 <code>.extract_words()</code> 输出（指定<code>split_at_punctuation=True</code>）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[</span><br><span class="line">  &#123;<span class="string">&#x27;text&#x27;</span>: <span class="string">&#x27;项目名称&#x27;</span>, <span class="string">&#x27;x0&#x27;</span>:..., <span class="string">&#x27;top&#x27;</span>:..., ...&#125;,</span><br><span class="line">  &#123;<span class="string">&#x27;text&#x27;</span>: <span class="string">&#x27;：&#x27;</span>, <span class="string">&#x27;x0&#x27;</span>:..., ...&#125;,</span><br><span class="line">  &#123;<span class="string">&#x27;text&#x27;</span>: <span class="string">&#x27;XX工程项目&#x27;</span>, <span class="string">&#x27;x0&#x27;</span>:..., ...&#125;,</span><br><span class="line">  &#123;<span class="string">&#x27;text&#x27;</span>: <span class="string">&#x27;招标人&#x27;</span>, <span class="string">&#x27;x0&#x27;</span>:..., ...&#125;,</span><br><span class="line">  &#123;<span class="string">&#x27;text&#x27;</span>: <span class="string">&#x27;：&#x27;</span>, <span class="string">&#x27;x0&#x27;</span>:..., ...&#125;,</span><br><span class="line">  &#123;<span class="string">&#x27;text&#x27;</span>: <span class="string">&#x27;YY公司&#x27;</span>, <span class="string">&#x27;x0&#x27;</span>:..., ...&#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p>👉 你得到的是<strong>词级</strong>切分，适合做关键词匹配或结构化提取。</p>
<p>用 <code>.extract_text_lines()</code> 输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="string">&#x27;text&#x27;</span>: <span class="string">&#x27;项目名称：XX工程项目&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;chars&#x27;</span>: [...],  <span class="comment"># 所有字符详细位置</span></span><br><span class="line">    <span class="string">&#x27;x0&#x27;</span>: ..., <span class="string">&#x27;top&#x27;</span>: ..., ...</span><br><span class="line">  &#125;,</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="string">&#x27;text&#x27;</span>: <span class="string">&#x27;招标人：YY公司&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;chars&#x27;</span>: [...],</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p>👉 你得到的是<strong>整行信息</strong>，非常适合做：</p>
<ul>
<li>OCR结果还原</li>
<li>按行分组处理（比如”招标人”是 key，”YY公司”是 value）</li>
</ul>
<p>🎯 总结建议</p>
<table>
<thead>
<tr>
<th>目标</th>
<th>推荐方法</th>
</tr>
</thead>
<tbody><tr>
<td>关键词定位、字段抽取</td>
<td><code>.extract_words()</code></td>
</tr>
<tr>
<td>保持 PDF 原有排版顺序、行级处理</td>
<td><code>.extract_text_lines()</code></td>
</tr>
<tr>
<td>精细字符位置分析</td>
<td>任意方法 + <code>return_chars=True</code></td>
</tr>
</tbody></table>
<hr>
<h3 id="7-search"><a href="#7-search" class="headerlink" title="7 search"></a>7 search</h3><p>📘 <code>.search()</code> 方法说明</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">page.search(pattern, regex=<span class="literal">True</span>, <span class="keyword">case</span>=<span class="literal">True</span>, main_group=<span class="number">0</span>,</span><br><span class="line">            return_groups=<span class="literal">True</span>, return_chars=<span class="literal">True</span>,</span><br><span class="line">            layout=<span class="literal">False</span>, **kwargs)</span><br></pre></td></tr></table></figure>

<p>这是一个<strong>实验性功能</strong>，用于在页面中搜索匹配的文本，返回所有匹配项的列表。</p>
<p>📌 参数说明：</p>
<table>
<thead>
<tr>
<th>参数</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><code>pattern</code></td>
<td>查询字符串或正则表达式，可以是编译或未编译的 regex，也可以是普通字符串</td>
</tr>
<tr>
<td><code>regex</code></td>
<td>如果为 <code>False</code>，则 <code>pattern</code> 被当作普通字符串处理（非正则表达式）</td>
</tr>
<tr>
<td><code>case</code></td>
<td>为 <code>False</code> 时忽略大小写</td>
</tr>
<tr>
<td><code>main_group</code></td>
<td>指定主返回的正则分组（默认 <code>0</code> 表示整体匹配）</td>
</tr>
<tr>
<td><code>return_groups</code></td>
<td>如果设为 <code>False</code>，将不返回正则分组匹配结果</td>
</tr>
<tr>
<td><code>return_chars</code></td>
<td>如果设为 <code>False</code>，不返回匹配字符的字符对象列表</td>
</tr>
<tr>
<td><code>layout</code></td>
<td>与 <code>.extract_text()</code> 的 layout 参数相同，是否按布局方式分析文本</td>
</tr>
<tr>
<td><code>**kwargs</code></td>
<td>其他传给 <code>.extract_text(layout=True, ...)</code> 的参数</td>
</tr>
</tbody></table>
<blockquote>
<p>⚠️ 注意：<strong>匹配为空字符串或全空格的结果会被自动忽略</strong>，因为它们通常没有实际的页面位置（bbox）。</p>
</blockquote>
<p>✅ 使用示例（搜索“招标人”并输出其位置信息）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pdfplumber</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开 PDF 文件</span></span><br><span class="line"><span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(<span class="string">&quot;example.pdf&quot;</span>) <span class="keyword">as</span> pdf:</span><br><span class="line">    page = pdf.pages[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 搜索关键词“招标人”</span></span><br><span class="line">    results = page.search(<span class="string">&quot;招标人&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, <span class="keyword">match</span> <span class="keyword">in</span> <span class="built_in">enumerate</span>(results):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;第 <span class="subst">&#123;i+<span class="number">1</span>&#125;</span> 个匹配：&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot; - 匹配文本：&quot;</span>, <span class="keyword">match</span>[<span class="string">&quot;text&quot;</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot; - 位置：&quot;</span>, <span class="keyword">match</span>[<span class="string">&quot;x0&quot;</span>], <span class="keyword">match</span>[<span class="string">&quot;top&quot;</span>], <span class="keyword">match</span>[<span class="string">&quot;x1&quot;</span>], <span class="keyword">match</span>[<span class="string">&quot;bottom&quot;</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot; - 所含字符数量：&quot;</span>, <span class="built_in">len</span>(<span class="keyword">match</span>[<span class="string">&quot;chars&quot;</span>]))</span><br></pre></td></tr></table></figure>

<p>✅ 使用正则表达式进行复杂匹配（如提取“项目名称：XXX”）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">pattern = re.<span class="built_in">compile</span>(<span class="string">r&quot;项目名称[：:]?\s*(\S+)&quot;</span>)</span><br><span class="line">results = page.search(pattern)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> r <span class="keyword">in</span> results:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;主匹配文本：&quot;</span>, r[<span class="string">&quot;text&quot;</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;正则分组（项目名）：&quot;</span>, r[<span class="string">&quot;groups&quot;</span>][<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;位置：&quot;</span>, r[<span class="string">&quot;x0&quot;</span>], r[<span class="string">&quot;top&quot;</span>], r[<span class="string">&quot;x1&quot;</span>], r[<span class="string">&quot;bottom&quot;</span>])</span><br></pre></td></tr></table></figure>

<p>💡 常见用途场景：</p>
<ul>
<li>精确定位关键词在页面中的位置（比如“开标时间”、“联系人”）</li>
<li>做结构化信息提取（使用正则提取“键：值”结构）</li>
<li>做表单&#x2F;模板字段匹配（比如识别“税号：123456”）</li>
</ul>
<hr>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>pdf</tag>
        <tag>pdfplumber</tag>
      </tags>
  </entry>
  <entry>
    <title>PDF解析库：速度与效果对比</title>
    <url>/2025/05/20/PDF%E8%A7%A3%E6%9E%90%E5%BA%93%EF%BC%9A%E9%80%9F%E5%BA%A6%E4%B8%8E%E6%95%88%E6%9E%9C%E5%AF%B9%E6%AF%94/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近在做从pdf中解析内容（给<a href="https://caihaoran-00.github.io/2025/04/28/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B0%83%E7%A0%94%EF%BC%9A%E6%8B%9B%E6%A0%87%E6%99%BA%E8%83%BD%E4%BD%93/#more">这个项目</a>做的demo），然后扔给LLM，让LLM从中针对想要的字段提取结构化数据，简单做了个demo，思想是使用<code>pdfplumber</code>从pdf中解析内容，然后将内容扔给大模型，写好system_prompt让其去提取，再说仔细点就是让LLM1去提取招标文件的内容，LLM2提取招标公告的内容，LLM3将前两个LLM提取的结构化内容合并保存，目前只是简单做了一下，有一些需要细化的点：</p>
<p><code>pdf</code>解析器方面：</p>
<ul>
<li><code>pdfplumber</code>解析出来的内容（尤其是表格）是什么样子的，解析速度怎么样</li>
<li>这个场景下<code>pdfplumber</code>是最优选择吗，其他<code>pdf</code>解析器的效果和速度怎么样</li>
</ul>
<p><code>LLM</code>方面：</p>
<ul>
<li>是选长下文（≥128 k）LLM，一把梭哈将数据扔进去让其去抽取信息还是切分数据使用普通上下文（32K）模型去抽取（现在是一把梭哈）</li>
<li>不同模型的表现怎么量化</li>
</ul>
<span id="more"></span>

<p>本文先只关注PDF解析库的速度和效果对比，对比的库包括：</p>
<ul>
<li><code>pdfplumber</code></li>
<li><code>pypdf/PyPDF2</code></li>
<li><code>PDFMiner.six</code></li>
<li><code>PyMuPDF(fitz)</code></li>
</ul>
<ol>
<li>参与公司</li>
<li>公司报价</li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>pdf</tag>
      </tags>
  </entry>
  <entry>
    <title>Qwen2.5VL 7B安装与官方玩法体验</title>
    <url>/2025/03/18/Qwen2-5VL%E5%AE%89%E8%A3%85%E4%B8%8E%E5%AE%98%E6%96%B9%E7%8E%A9%E6%B3%95%E4%BD%93%E9%AA%8C/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前面直接简单的使用LLamaFactory微调了Qwen2.5 VL 7B（其实和视觉能力没关系，只简单微调了文本），但转念一想，还没体验过Qwen2.5 VL的官方玩法，本文即记录下官方玩法以及记录一下占用情况。</p>
<span id="more"></span>

<hr>
<h2 id="安装与使用"><a href="#安装与使用" class="headerlink" title="安装与使用"></a>安装与使用</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 克隆项目</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/QwenLM/Qwen2.5-VL</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切换到项目工作目录</span></span><br><span class="line"><span class="built_in">cd</span> /Qwen2.5-VL</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个名为 Qwen2_5_VL 的新虚拟环境，并指定 Python 版本为 3.12</span></span><br><span class="line">conda create --name Qwen2_5_VL python=3.12 -y</span><br><span class="line"></span><br><span class="line"><span class="comment"># 激活虚拟环境</span></span><br><span class="line">conda activate Qwen2_5_VL</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装依赖</span></span><br><span class="line">pip install git+https://github.com/huggingface/transformers accelerate</span><br><span class="line">pip install -U flash-attn --no-build-isolation</span><br><span class="line">pip install -r requirements_web_demo.txt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载预训练权重</span></span><br><span class="line">git lfs install</span><br><span class="line">git <span class="built_in">clone</span> https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct</span><br><span class="line"></span><br><span class="line">or</span><br><span class="line"></span><br><span class="line">git <span class="built_in">clone</span> https://www.modelscope.cn/Qwen/Qwen2.5-VL-7B-Instruct.git</span><br></pre></td></tr></table></figure>

<p>然后打开<code>web_demo_mm.py</code>，看下<code>DEFAULT_CKPT_PATH</code>的路径：<code>Qwen/Qwen2.5-VL-7B-Instruct</code>，那么我们需要把下载的<code>Qwen2.5-VL-7B-Instruct</code>放在<code>Qwen</code>文件夹下，运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python web_demo_mm.py --flash-attn2</span><br></pre></td></tr></table></figure>

<p>吼，报错了，那再试试：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python web_demo_mm.py</span><br></pre></td></tr></table></figure>

<p>还是报错：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">RuntimeError: Failed to import transformers.models.qwen2_5_vl.modeling_qwen2_5_vl because of the following error (look up to see its traceback):</span><br><span class="line">/home/chr/anaconda3/envs/Qwen2_5_VL/lib/python3.12/site-packages/flash_attn_2_cuda.cpython-312-x86_64-linux-gnu.so: undefined symbol: _ZNK3c1011StorageImpl27throw_data_ptr_access_errorEv</span><br></pre></td></tr></table></figure>

<img src="/2025/03/18/Qwen2-5VL%E5%AE%89%E8%A3%85%E4%B8%8E%E5%AE%98%E6%96%B9%E7%8E%A9%E6%B3%95%E4%BD%93%E9%AA%8C/17bf15268ec70aa64a1f7d2fddbfb9a.png" class="" title="17bf15268ec70aa64a1f7d2fddbfb9a">

<hr>
<h3 id="Web-UI方式使用"><a href="#Web-UI方式使用" class="headerlink" title="Web UI方式使用"></a>Web UI方式使用</h3><p>参考<a href="https://blog.csdn.net/a61022706/article/details/141570792">链接2</a>的步骤，然后继续运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python web_demo_mm.py --flash-attn2</span><br></pre></td></tr></table></figure>

<p>好的，运行起来了！！！</p>
<img src="/2025/03/18/Qwen2-5VL%E5%AE%89%E8%A3%85%E4%B8%8E%E5%AE%98%E6%96%B9%E7%8E%A9%E6%B3%95%E4%BD%93%E9%AA%8C/b8024758c9d0ab160260fd9d80d8b6b.png" class="" title="b8024758c9d0ab160260fd9d80d8b6b">

<p>但是吧，目前发现两类主要问题：</p>
<ol>
<li>让模型框出某个位置，得到的回答有点奇怪（见上图）</li>
<li>4s的720P视频都爆显存</li>
</ol>
<p>还是用3B的模型玩玩吧，将<code>DEFAULT_CKPT_PATH</code>的路径改为<code>Qwen/Qwen2.5-VL-3B-Instruct</code>，运行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">python web_demo_mm.py --flash-attn2</span><br></pre></td></tr></table></figure>

<p>漫长的等待….，铛铛铛铛：</p>
<img src="/2025/03/18/Qwen2-5VL%E5%AE%89%E8%A3%85%E4%B8%8E%E5%AE%98%E6%96%B9%E7%8E%A9%E6%B3%95%E4%BD%93%E9%AA%8C/0ce74c805c2f3a274ca8996b29cc88a.png" class="" title="0ce74c805c2f3a274ca8996b29cc88a">

<p>翻译：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">视频显示了一个户外游乐场的嬉戏场景。一个人坐在一把黄色腿的彩色圆形橙色椅子上。他们穿着紫色无檐便帽、深色夹克和浅色裤子。另一个看起来像孩子的人站在附近，与坐着的人互动。这孩子穿着黑色夹克和红色鞋子。</span><br><span class="line">坐着的人正在进行一项有趣的活动，可能会假装成一个角色或表演一个舞蹈动作。他们有力地移动着胳膊和腿，营造出一种活泼的氛围。孩子似乎很享受这种互动，为场景增添了欢乐的气氛。</span><br><span class="line">在背景中，还有其他游乐场设备和结构，包括一个大型的彩色滑梯。地面覆盖着典型的游乐场橡胶表面，确保了孩子们玩耍的安全。整体环境明亮晴朗，表明可能是白天。</span><br></pre></td></tr></table></figure>

<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">十分我能打几分：<span class="number">5</span>分</span><br><span class="line"></span><br><span class="line">背景：<span class="number">3</span>B模型部署在<span class="number">4090</span>单卡上，ubuntu系统；</span><br><span class="line">速度方面：<span class="number">49</span> S的<span class="number">1080</span>P视频（用我手机之前在游乐场录得）用时<span class="number">10</span> S；</span><br><span class="line">占用：</span><br><span class="line">不部署模型，仅正常开了几个网页：显存占用<span class="number">1275</span> MB</span><br><span class="line">仅部署，不使用模型回答任何问题：显存占用<span class="number">10370</span> MB</span><br><span class="line">使用模型回答视频问题：显存占用<span class="number">23007</span> MB</span><br><span class="line"></span><br><span class="line">开两个网页使用模型回答相同的视频问题：后发送问题的那个网页会爆显存，然后待会又回答了（看服务后台像是串行回答的，即第一个网页的问题回复完毕才去问第二个网页的问题）</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="vLLM方式运行"><a href="#vLLM方式运行" class="headerlink" title="vLLM方式运行"></a>vLLM方式运行</h3><p>由于我上面已经缓存了3B模型，所以只需要：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install <span class="string">&#x27;vllm&gt;0.7.2&#x27;</span></span><br><span class="line"></span><br><span class="line">vllm serve Qwen/Qwen2.5-VL-3B-Instruct --port 8000 --host 0.0.0.0 --dtype bfloat16 --limit-mm-per-prompt image=5,video=5</span><br></pre></td></tr></table></figure>

<p>但是，一个3B大模型把我现存占满了？</p>
<img src="/2025/03/18/Qwen2-5VL%E5%AE%89%E8%A3%85%E4%B8%8E%E5%AE%98%E6%96%B9%E7%8E%A9%E6%B3%95%E4%BD%93%E9%AA%8C/image-20250319101903786.png" class="" title="image-20250319101903786">



<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://zhuanlan.zhihu.com/p/23296553864">https://zhuanlan.zhihu.com/p/23296553864</a></li>
<li><a href="https://blog.csdn.net/a61022706/article/details/141570792">https://blog.csdn.net/a61022706/article/details/141570792</a></li>
</ol>
<p><strong>AI视觉认知引擎升级方案</strong><br> <em>基于Qwen2.5-VL-72B的多模态领域专精化训练</em></p>
<p>▍技术架构<br> <code>72B参数视觉语言基座</code> × <code>垂直领域知识注入</code><br> • <strong>基座模型</strong>: Qwen2.5-VL-72B多模态大模型（视觉-语言跨模态预训练架构）​<br> • <strong>微调策略</strong>: 双模态联合训练范式（文本语料+视频帧序列）​<br> • <strong>增强组件</strong>: 动态梯度裁剪 + 混合精度训练引擎​<br> • <strong>优化策略</strong>: 渐进式解冻 + 层级学习率调度（非全参数训练)</p>
<p>▍领域适应技术<br> <code>结构化知识蒸馏</code> | <code>时序特征对齐</code> | <code>跨模态语义桥接</code><br> • <strong>文本增强</strong>: 专业术语向量空间重构​<br> • <strong>视频解析</strong>: ViT时空特征提取 + 关键帧语义标注​<br> • <strong>对齐机制</strong>: CLIP风格的跨模态对比学习损失函数​<br> • <strong>加速方案</strong>: FlashAttention优化 + 动态计算图编译</p>
<p>▍实测性能优势</p>
<p> • <strong>跨模态检索</strong>: 图像-文本匹配准确率提升28.6%（相较于原始版本）</p>
<p> • <strong>细粒度解析</strong>: 图像区域语义识别准确率达到91.2%</p>
<p> • <strong>推理加速</strong>: 高分辨率图像处理速度提升3.1倍</p>
<p> • <strong>训练效率</strong>: 微调成本降低67%（参数冻结策略）</p>
<p>▍商业价值锚点 </p>
<p> ✓ 构建图像-语言联动的领域认知系统<br> ✓ 实现像素级视觉理解与业务知识融合​<br> ✓ 支持复杂场景的即时推理与决策闭环</p>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>llm</tag>
        <tag>qwen2.5 vl</tag>
      </tags>
  </entry>
  <entry>
    <title>论文：Qwen2.5VL</title>
    <url>/2025/03/11/Qwen2-5VL%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%E4%B8%8E%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>说来惭愧，玩了这么久LLM，还没正经看过LLM的论文，最近要好好玩玩Qwen2.5 VL，目的是探索能基于它做什么应用（主要看能不能做到实时检测），这里先看一下论文，有个原理上的认识，再去微调Qwen2.5 VL。</p>
<p><strong>论文名：Qwen2.5-VL Technical Report</strong></p>
<p><strong>作者：Qwen Team, Alibaba Group</strong></p>
<p><strong>论文地址：</strong> <a href="https://arxiv.org/abs/2502.13923">https://arxiv.org/abs/2502.13923</a></p>
<p><strong>Qwen Chat:</strong> <a href="https://chat.qwenlm.ai/">https://chat.Qwenlm.ai</a></p>
<p><strong>Hugging face:</strong> <a href="https://huggingface.co/Qwen">https://huggingface.co/Qwen</a></p>
<p><strong>ModelScope:</strong> <a href="https://modelscope.cn/organization/Qwen">https://modelscope.cn/organization/Qwen</a></p>
<p><strong>Github:</strong> <a href="https://github.com/QwenLM/Qwen2.5-VL">https://github.com/QwenLM/Qwen2.5-VL</a></p>
<p><em><strong>年份：2025</strong></em></p>
<span id="more"></span>

<hr>
<h2 id="摘要（Abstract）"><a href="#摘要（Abstract）" class="headerlink" title="摘要（Abstract）"></a>摘要（Abstract）</h2><p>我们介绍了Qwen2.5-VL，Qwen视觉语言系列的最新旗舰模型，它展示了在基础功能和创新功能方面的重大进步。Qwen2.5-VL通过增强的视觉识别、精确的对象定位、稳健的文档解析和长视频理解，实现了在理解和与世界交互方面的重大飞跃。Qwen2.5-VL通过增强的视觉识别、精确的对象定位、鲁棒的文档解析和长视频理解，实现了在理解世界和互动方面的重大飞跃。Qwen2.5-VL的一个突出的特点是它能够使用边界框或点精确地定位对象。它提供了从发票、表单和表格中提取的健壮的结构化数据，以及对图表和布局的详细分析。为了处理复杂的输入，Qwen2.5- VL引入了动态分辨率处理和绝对时间编码，使其能够通过二级事件定位来处理不同大小的图像和延长持续时间（长达数小时）的视频。这使得模型能够原生地感知空间尺度和时间动态，而无需依赖传统的归一化技术。通过从零开始训练一个原生的动态分辨率视觉 Transformer (ViT)，并结合窗口注意力 (Window Attention)，我们显著降低了计算开销，同时保持了原生分辨率。因此，Qwen2.5-VL 不仅在静态图像和文档理解方面表现出色，还能作为一个交互式视觉智能体，在现实世界场景中执行推理、工具使用和任务操作，例如操作计算机和移动设备。</p>
<p>该模型在各个领域都具备强大的泛化能力，无需针对特定任务进行微调。Qwen2.5-VL 提供三种尺寸，满足从边缘 AI 到高性能计算的多样化需求。其中，旗舰版 Qwen2.5-VL-72B 在文档和图表理解方面表现突出，能够与 GPT-4o 和 Claude 3.5 Sonnet 等最新顶尖模型相媲美。较小的 Qwen2.5-VL-7B 和 Qwen2.5-VL-3B 也超越了同类竞争对手，即使在资源受限的环境下仍然具备强大的能力。此外，Qwen2.5-VL 还保持了稳健的语言能力，继承了 Qwen2.5 大语言模型 (LLM) 的核心语言能力。</p>
<img src="/2025/03/11/Qwen2-5VL%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%E4%B8%8E%E6%80%BB%E7%BB%93/image-20250311144619136.png" class="" title="image-20250311144619136">

<h2 id="1-介绍（Introduction）"><a href="#1-介绍（Introduction）" class="headerlink" title="1. 介绍（Introduction）"></a>1. 介绍（Introduction）</h2><p>大型视觉语言模型（LVLMs, Large vision-language models）是人工智能的关键突破，标志着多模式理解和交互的变革性方法。通过将视觉感知与自然语言处理无缝集成，这些高级模型从根本上重塑了机器解释和分析跨不同领域的复杂信息的方式。尽管多模态大型语言模型取得了重大进步，但这些模型目前的功能可以被比作三明治饼干的中间层——能够胜任各种任务，但却缺乏出色的性能。精细粒度视觉任务构成了这个类比的基础层。在Qwen2.5-VL的这次迭代中，我们致力于探索细粒度的感知能力，旨在为LVLMS建立一个坚实的基础，并为现实世界的应用创建一个代理放大器。该框架的顶层是多模态推理，它通过利用最新的Qwen2.5 LLM和使用多模态QA数据构建而得到增强。</p>
<p>一系列的作品促进了多模态大型模型的发展，其特点是架构设计、视觉输入处理和数据管理。LVLMs进步的主要驱动力之一是体系结构的持续创新。（Alayrac等，2022年；李等，2022a；2023b；Liu等，2023b；a；王等，2024i；张等，2024b；王等，2023）逐步塑造了当前范式，通常由视觉编码器、跨模态投影仪和LLM组成。细粒度感知模型已经成为另一个关键领域。模型如（Xiao等人，2023年；刘等人，2023年；任等人，2024年；张等人，2024a；d；彭等人，2023；Deitke等人，2024）突破了详细视觉理解方面可能的边界。Omni（Li等人，2024g；2025b；Ye等人，2024）和MoE（Riquelme等人，2021；Lee等人，2024；Li等人，2024h；c；Wu等人，2024b）的架构也激发了LVLMs的未来发展。视觉编码器的增强（Chen等，2023；Liu等，2024b；Liang等，2025）和分辨率缩放（李等，2023c；叶等人，2023；李等人，2023a)在提高实际视觉理解质量方面发挥了关键作用。管理更多样化的场景和更高质量的数据是训练高级LVLMS的必要步骤。（郭等，2024年；2024年陈等，2024d；刘等，2024a；陈等，2024a；唐等，2024；李等，2024a)对这项努力具有非常有价值的贡献。</p>
<p>然而，尽管视觉语言模型取得了显著的进展，但它们目前仍面临着发展瓶颈，包括计算复杂性、有限的上下文理解、糟糕的细粒度视觉感知，以及在不同序列长度上不一致的表现。</p>
<p>在本报告中，我们介绍了最新的工作Qwen2.5-VL，它延续了Qwen系列的开源哲学，在各种基准测试上实现甚至超越了顶级的闭源代码模型。从技术上讲，我们的贡献有四方面： </p>
<ol>
<li>在视觉编码器中实现窗口注意力，以优化推理效率；</li>
<li>我们引入了动态FPS采样，将动态分辨率扩展到时间维度，并能够在不同的采样率下实现全面的视频理解；</li>
<li>我们通过对齐绝对时间来升级时间域中的MRoPE，从而促进了更复杂的时间序列学习；</li>
<li>我们在管理训练前和监督微调的高质量数据方面做了重大努力，进一步将训练前语料库从1.2万亿标记扩展到4.1万亿个tokens。</li>
</ol>
<p>Qwen2.5-VL的突出特点是：</p>
<ul>
<li>强大的文档解析功能： Qwen2.5-VL将文本识别升级到完整解析，在处理多场景、多语言和各种内置的（手写、表格、图表、化学公式和音乐表）文档方面表现出色。</li>
<li>跨格式的精确对象接地： Qwen2.5-VL解锁提高了检测、指向和计数对象的精度，适应了绝对坐标和JSON格式的高级空间推理。</li>
<li>超长视频理解和细粒度视频接地：我们的模型将原生动态分辨率扩展到时间维度，增强了理解持续数小时的视频的能力，同时在秒内提取事件片段。</li>
<li>增强的计算机和移动设备的代理(agent)功能：针对计算机和移动设备的增强代理功能：利用先进的基础、推理和决策能力，在智能手机和计算机上使用优越的代理功能来增强模型。</li>
</ul>
<img src="/2025/03/11/Qwen2-5VL%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%E4%B8%8E%E6%80%BB%E7%BB%93/image-20250311152513173.png" class="" title="image-20250311152513173">

<p>图片1：Qwen2.5-VL框架演示了一个视觉编码器和一个语言模型解码器的集成来处理多模态输入，包括图像和视频。视觉编码器被设计用来处理其本地分辨率的输入，并支持动态FPS采样。不同大小的图像和具有不同FPS速率的视频帧被动态地映射到不同长度的token序列上。值得注意的是，MRoPE将时间id与时间维度上的绝对时间对齐，使模型能够更好地理解时间动态，比如事件的节奏和精确的时刻定位。处理后的视觉数据随后被输入Qwen2.5 LM解码器。我们重新设计了视觉transformer（ViT）架构，结合了先进的组件，如带有SwiGLU激活函数的FFN，RMSNorm用于标准化，以及基于窗口的注意机制来提高性能和效率。</p>
<h2 id="2-方法（Approach）"><a href="#2-方法（Approach）" class="headerlink" title="2. 方法（Approach）"></a>2. 方法（Approach）</h2><p>在本节中，我们首先概述了Qwen2.5-VL系列模型的体系结构更新，并提供了数据和训练细节的概述。</p>
<h3 id="2-1-模型架构"><a href="#2-1-模型架构" class="headerlink" title="2.1 模型架构"></a>2.1 模型架构</h3><p>Qwen2.5-VL的整体模型体系结构由三个部分组成：</p>
<p><strong>大语言模型（Large Language Model）：</strong> Qwen2.5-VL系列采用大型语言模型作为其基本部分。该模型用Qwen2.5 LLM中预先训练的权重进行初始化。为了更好地满足多模态理解的要求，我们将一维RoPE（Rotary Position Embedding, 旋转位置嵌入）修改为我们的与绝对时间对齐的多模态旋转位置嵌入。</p>
<p><strong>视觉编码器：</strong> Qwen2.5-VL的视觉编码器采用了重新设计的视觉Transformer（ViT）架构。在结构上，我们结合了2D-RoPE和窗口注意力来支持原生输入分辨率，同时加速了整个视觉编码器的计算。在训练和推理过程中，输入图像的高度和宽度被调整到28的倍数，然后被输入ViT。视觉编码器通过将图像分割成步长为14的块来处理图像，生成一组图像特征。我们在第2.1.1节中提供了对视觉编码器的更详细的介绍。</p>
<p><strong>基于MLP的视觉语言合并：</strong> 为了解决长图像特征序列带来的效率挑战，我们采用一种简单而有效的方法来压缩特征序列，然后将其输入大型语言模型（LLM）。具体来说，我们不是直接使用ViT提取的原始块特征，而是首先将四个块特征的空间相邻集进行分组。然后，将这些分组的特征连接起来，并通过一个两级多层感知器（MLP），将它们投射到一个与LLM中使用的文本嵌入对齐的维度中。该方法不仅降低了计算成本，而且为动态压缩不同长度的图像特征序列提供了一种灵活的方法。</p>
<img src="/2025/03/11/Qwen2-5VL%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%E4%B8%8E%E6%80%BB%E7%BB%93/image-20250311161912268.png" class="" title="image-20250311161912268">

<h4 id="2-1-1-快速和高效的视觉编码器"><a href="#2-1-1-快速和高效的视觉编码器" class="headerlink" title="2.1.1 快速和高效的视觉编码器"></a>2.1.1 快速和高效的视觉编码器</h4><p>视觉编码器在多模态大语言模型（MLLMs）中起着关键的作用。为了解决由于原生分辨率输入而导致的训练和推理过程中的计算负载不平衡所带来的挑战，我们重新设计了视觉变压器（ViT）架构。一个关键的问题来自于与处理不同大小的图像相关的二次计算复杂度。为了缓解这种情况，我们在大多数层中引入了窗口注意力，以确保计算成本与块的数量呈线性扩展，而不是二次方。在我们的架构中，只有四个层采用了完全的自我注意，而其余的层利用了窗口注意力，最大窗口大小为112×112（对应于8个×8块）。对小于112×112的区域不进行填充，保持其原始分辨率。这种设计允许模型在原生输入分辨率下进行，避免了不必要的缩放或失真。</p>
<p>对于位置编码，我们采用二维旋转位置嵌入（RoPE）来有效地捕获二维空间中的空间关系。此外，为了更好地处理视频输入，我们将我们的方法扩展到3D块分区。具体来说，我们使用14个×14个图像块作为基本单元，与传统的静态图像ViTs相一致。对于视频数据，两个连续的帧被分组在一起，显著减少了输入到语言模型中的token的数量。这种设计不仅保持了与现有架构的兼容性，而且提高了处理顺序视频数据的效率。</p>
<p>为了简化整体的网络结构，我们将ViT体系结构与大型语言模型（LLMs）的设计原则更紧密地对齐。具体来说，我们采用RMSNorm（Zhang &amp;Sennrich，2019）进行归一化，并采用SwiGLU（Dauphin et al.，2017）作为激活函数。这些选择提高了计算效率和模型的视觉和语言组件之间的兼容性。</p>
<p>在训练方面，我们从头开始训练重新设计的ViT。培训过程包括几个阶段，包括CLIP预训练、视觉-语言对齐和端到端微调。为了确保在不同的输入分辨率之间的鲁棒性，我们在训练阶段采用了原生分辨率的动态采样。图像根据其原始的纵横比进行随机采样，使模型能够有效地推广到不同分辨率的输入。这种方法不仅提高了模型的适应性，而且确保了跨不同大小的视觉数据的稳定和有效的训练。</p>
<h4 id="2-1-2-原生动态分辨率和帧率"><a href="#2-1-2-原生动态分辨率和帧率" class="headerlink" title="2.1.2 原生动态分辨率和帧率"></a>2.1.2 原生动态分辨率和帧率</h4><p>Qwen2.5-VL在空间和时间维度上都引入了进步，以有效地处理不同的多模态输入。</p>
<p>在空间域中，Qwen2.5-VL动态地将不同大小的图像转换为具有相应长度的标记序列。与传统的坐标规格化方法不同，我们的模型直接使用输入图像的实际尺寸来表示边界框、点和其他空间特征。这允许模型固有地学习比例信息，提高其处理不同分辨率图像的能力。</p>
<p>对于视频输入，Qwen2.5-VL结合了动态帧率（FPS）训练和绝对时间编码。通过适应可变帧率，该模型可以更好地捕捉视频内容的时间动态。不同于其他方法通过引入文本时间戳或使用额外的头部来实现时间对齐，我们提出了一种新颖且高效的策略，直接将 MRoPE ID 与时间戳对齐。这种方法允许模型通过时间维度id之间的间隔来理解时间的节奏，而不需要任何额外的计算。</p>
<h4 id="2-1-3-多模态旋转位置嵌入与绝对时间对齐"><a href="#2-1-3-多模态旋转位置嵌入与绝对时间对齐" class="headerlink" title="2.1.3 多模态旋转位置嵌入与绝对时间对齐"></a>2.1.3 多模态旋转位置嵌入与绝对时间对齐</h4><p>位置嵌入对于在视觉和语言模式中建模顺序数据都是至关重要的。基于Qwen2-VL中引入的多模态旋转位置嵌入（MRoPE），我们扩展了其功能，以更好地处理视频中的时间信息。</p>
<p>Qwen2-VL中的MRoPE将位置嵌入分解为三个不同的分量：时间、高度和宽度，以有效地建模多模态输入。对于文本输入，所有三个组件都使用相同的位置id，使得MRoPE在功能上等同于传统的1D RoPE（Su et al.，2024）。对于图像，时间ID在视觉token之间保持不变，而唯一的ID则根据每个token在图像中的空间位置分配给高度和宽度组件。当处理被视为帧序列的视频时，每一帧的时间ID都有增量，而高度和宽度组件遵循与静态图像相同的分配模式。</p>
<p>然而，在Qwen2-VL中，MRoPE中的时间位置id与输入帧数联系在一起，这并没有解释内容变化的速度或视频内事件的绝对时间。为了解决这一限制，Qwen2.5-VL引入了一个关键的改进：将MRoPE的时间组件与绝对时间对齐。如图1所示，通过利用时间id之间的间隔，该模型能够学习具有不同FPS采样率的视频之间一致的时间对齐。</p>
<h3 id="2-2-预训练"><a href="#2-2-预训练" class="headerlink" title="2.2 预训练"></a>2.2 预训练</h3><p>在本节中，我们首先描述了预训练数据集的构建，然后概述了整个训练管道和配置。</p>
<h4 id="2-2-1预训练数据集"><a href="#2-2-1预训练数据集" class="headerlink" title="2.2.1预训练数据集"></a>2.2.1预训练数据集</h4><p>与Qwen2-VL相比，我们显著增加了预训练数据的数量，从1.2万亿tokens增加到大约4万亿tokens。我们的预训练数据集是通过多种方法的组合来构建的，包括原始的网络数据，合成数据等。该数据集包括各种各样的多模态数据，如图像标题、交错图像-文本数据、光学字符识别（OCR）数据、视觉知识（如名人、地标、植物和动物识别）、多模态学术问题、位置数据、文档解析数据、视频描述、视频定位和基于代理的交互数据。在整个训练过程中，我们在不同的阶段仔细调整了这些数据类型的组成和比例，以优化学习结果。</p>
<p><strong>交错图像文本数据：</strong> 交错图像文本数据对多模式学习至关重要，提供三个关键的好处： </p>
<ol>
<li>使上下文学习同时视觉和文本线索（Alayrac等，2022）；</li>
<li>当没有图像时保持强大的文本功能（Lin et al.，2024）；</li>
<li>包含广泛的一般信息。</li>
</ol>
<p>然而，许多可用的交错数据缺乏有意义的文本-图像关联，而且往往是嘈杂的，限制了它在复杂推理和创造性生成方面的有用性。</p>
<p>为了解决这些挑战，我们开发了一个用于评分和清洗数据的管道，确保只使用高质量的、相关的交错数据。我们的过程包括两个步骤：标准数据清洗（Li et al.，2024e），然后是使用内部评估模型的四阶段评分系统。评分标准包括：</p>
<ol>
<li>纯文本质量，</li>
<li>图像文本相关性，</li>
<li>图像文本互补性，</li>
<li>信息密度平衡。</li>
</ol>
<p>这种细致的方法提高了模型执行复杂推理和生成连贯的多模态内容的能力。</p>
<p>以下是对这些图像-文本评分标准的描述：</p>
<p>图像-文本相关性：得分越高表示图像和文本之间的联系更强，图像有意义地补充、解释或扩展文本，而不仅仅是装饰它。</p>
<p>信息互补性：得分越高，表示图像和文本之间的互补性信息越大。每一个都应该提供独特的细节，共同创造一个完整的叙述。</p>
<p>信息密度的平衡：得分越高，意味着图像和文本之间的信息分布越平衡，避免过多的文本或图像信息，确保两者之间的适当平衡。</p>
<p><strong>具有绝对位置坐标的对齐数据：</strong> 我们采用具有绝对位置坐标的原生分辨率训练，目的是实现更准确的感知世界。相反，相对坐标不能有效地表示图像中物体的原始大小和位置。为了解决这个限制，Qwen2.5-VL在训练过程中使用基于输入图像的实际尺寸的坐标值来表示边界框和点。该方法确保了模型能够更好地捕捉目标的真实尺度和空间关系，从而提高了目标检测和定位等任务的性能。</p>
<p>为了提升模型的泛化对齐能力，我们构建了一个综合数据集，其中包含带有指代表达的边界框（bounding boxes）和关键点（points），数据来源包括公开数据集和专有数据。我们的方法涉及将数据合成为多种格式，包括 XML，JSON 以及自定义格式，并采用了一系列技术，例如 Copy-Paste 增强（Ghiasi 等，2021），以及利用现成的模型（off-the-shelf models）进行数据合成，如 Grounding DINO（Liu 等，2023c）和 SAM（Kirillov 等，2023）。这种方法有助于更稳健地评估和提升模型的对齐能力（grounding abilities）。</p>
<p>为了提高模型在开放词汇表检测方面的性能，我们将训练数据集扩展到包括超过10,000个对象类别。此外，为了提高模型在极端目标检测场景中的有效性，我们在查询中合成了不存在的对象类别，并为每个对象构建了包含多个实例的图像数据。</p>
<p>为了确保优越的基于点的对象对齐能力，我们构建了一个包含公开可用数据和合成数据的综合点数据集。具体来说，数据来源包括来自 PixMo（Deitke 等，2024）的公开指示和计数数据、公开可访问的物体对齐数据（来自物体检测和实例分割任务），以及通过自动化管道合成的精确指向特定图像细节的指示数据。</p>
<p><strong>文档全方位解析数据：</strong> 为了训练Qwen2.5-VL，我们合成了大量的文档数据语料库。解析文档内容的传统方法通常依赖于单独的模型来处理布局分析、文本提取、图表解释和插图处理。相比之下，Qwen2.5- VL的设计旨在使通用模型具有解析、理解和转换文档格式的全面功能。具体来说，我们在文档中加入了多种多样的元素，如表格、图表、方程式、自然或合成图像、乐谱和化学公式。这些元素统一采用HTML格式，它将布局框信息和插图描述集成到HTML标签结构中。我们还根据典型的阅读顺序丰富了文档布局，并在基于HTML的标注真值中包含了与每个模块（如段落和图表）对应的坐标。这种创新方法使得任何文档的完整信息，包括其布局、文本、图表和插图，都能够以标准化和统一的方式进行表示。因此，Qwen2.5-VL 实现了多模态文档元素的无缝集成，从而促进了更高效和准确的文档理解与转化。</p>
<p>下面是Qwen VL HTML格式：</p>
<figure class="highlight html"><figcaption><span>Qwen VL HTML Format</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"># paragraph</span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">data-bbox</span>=<span class="string">&quot;x1 y1 x2 y2&quot;</span>&gt;</span> content <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"># table</span><br><span class="line"><span class="tag">&lt;<span class="name">style</span>&gt;</span><span class="language-css"><span class="selector-tag">table</span>&#123;id&#125; style</span><span class="tag">&lt;/<span class="name">style</span>&gt;</span><span class="tag">&lt;<span class="name">table</span> <span class="attr">data-bbox</span>=<span class="string">&quot;x1 y1 x2 y2&quot;</span> <span class="attr">class</span>=<span class="string">&quot;table&#123;id&#125;&quot;</span>&gt;</span> table content</span><br><span class="line"><span class="tag">&lt;/<span class="name">table</span>&gt;</span></span><br><span class="line"># chart</span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;chart&quot;</span> <span class="attr">data-bbox</span>=<span class="string">&quot;x1 y1 x2 y2&quot;</span>&gt;</span> <span class="tag">&lt;<span class="name">img</span> <span class="attr">data-bbox</span>=<span class="string">&quot;x1 y1 x2 y2&quot;</span> /&gt;</span><span class="tag">&lt;<span class="name">table</span>&gt;</span> chart content</span><br><span class="line"><span class="tag">&lt;/<span class="name">table</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"># formula</span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;formula&quot;</span> <span class="attr">data-bbox</span>=<span class="string">&quot;x1 y1 x2 y2&quot;</span>&gt;</span> <span class="tag">&lt;<span class="name">img</span> <span class="attr">data-bbox</span>=<span class="string">&quot;x1 y1 x2 y2&quot;</span> /&gt;</span> <span class="tag">&lt;<span class="name">div</span>&gt;</span> formula</span><br><span class="line">content <span class="tag">&lt;/<span class="name">div</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"># image caption</span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;image caption&quot;</span> <span class="attr">data-bbox</span>=<span class="string">&quot;x1 y1 x2 y2&quot;</span>&gt;</span> <span class="tag">&lt;<span class="name">img</span> <span class="attr">data-bbox</span>=<span class="string">&quot;x1 y1 x2 y2&quot;</span> /&gt;</span><span class="tag">&lt;<span class="name">p</span>&gt;</span> image</span><br><span class="line">caption <span class="tag">&lt;/<span class="name">p</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"># image ocr</span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;image ocr&quot;</span> <span class="attr">data-bbox</span>=<span class="string">&quot;x1 y1 x2 y2&quot;</span>&gt;</span> <span class="tag">&lt;<span class="name">img</span> <span class="attr">data-bbox</span>=<span class="string">&quot;x1 y1 x2 y2&quot;</span> /&gt;</span><span class="tag">&lt;<span class="name">p</span>&gt;</span> image ocr</span><br><span class="line"><span class="tag">&lt;/<span class="name">p</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"># music sheet</span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;music sheet&quot;</span> <span class="attr">format</span>=<span class="string">&quot;abc notation&quot;</span> <span class="attr">data-bbox</span>=<span class="string">&quot;x1 y1 x2 y2&quot;</span>&gt;</span> <span class="tag">&lt;<span class="name">img</span> <span class="attr">data-bbox</span>=<span class="string">&quot;x1 y1</span></span></span><br><span class="line"><span class="string"><span class="tag">x2 y2&quot;</span> /&gt;</span> <span class="tag">&lt;<span class="name">div</span>&gt;</span> music sheet content <span class="tag">&lt;/<span class="name">div</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"># chemical formula content</span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;chemical formula&quot;</span> <span class="attr">format</span>=<span class="string">&quot;smile&quot;</span> <span class="attr">data-bbox</span>=<span class="string">&quot;x1 y1 x2 y2&quot;</span>&gt;</span> <span class="tag">&lt;<span class="name">img</span> <span class="attr">data-bbox</span>=<span class="string">&quot;x1 y1</span></span></span><br><span class="line"><span class="string"><span class="tag">x2 y2&quot;</span> /&gt;</span> <span class="tag">&lt;<span class="name">div</span>&gt;</span> chemical formula content <span class="tag">&lt;/<span class="name">div</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>这种格式确保所有文档元素都以结构化和可访问的方式表示，使Qwen2.5-VL能够高效地处理和理解。</p>
<p><strong>OCR 数据：<strong>我们收集并整理了来自不同来源的数据，以提升 OCR（光学字符识别）性能，其中包括</strong>合成数据、开源数据和内部收集的数据</strong>。</p>
<ul>
<li><strong>合成数据</strong> 由视觉文本生成引擎生成，能够模拟真实环境中的高质量文本图像。</li>
<li><strong>多语言支持</strong>：为了支持更广泛的语言并增强多语言能力，我们引入了一个大规模的<strong>多语言 OCR 数据集</strong>，涵盖<strong>法语、德语、意大利语、西班牙语、葡萄牙语、阿拉伯语、俄语、日语、韩语和越南语</strong>等多种语言。</li>
<li><strong>数据多样性与质量控制</strong>：数据集经过精心筛选，确保多样性和高质量，结合了<strong>高质量的合成图像</strong>和<strong>真实世界的自然场景图像</strong>，从而提升模型在不同语言环境中的适应性，并增强其对不同文本外观和环境条件的鲁棒性。</li>
</ul>
<p><strong>图表类数据：<strong>我们使用 <strong>matplotlib、seaborn 和 plotly</strong> 等可视化库合成了 <strong>100 万个样本</strong>，涵盖</strong>柱状图、关系图和热图</strong>等多种图表类型。</p>
<p><strong>表格类数据：<strong>我们利用离线端到端表格识别模型</strong>处理了 600 万个真实世界的表格样本</strong>，并进一步筛选出高质量数据，<strong>剔除低置信度表格、重叠表格以及单元格密度不足的表格</strong>。</p>
<p><strong>视频数据：</strong></p>
<ul>
<li><strong>FPS 适配</strong>：为了增强对不同帧率（FPS）视频数据的理解能力，我们在训练过程中<strong>动态采样 FPS</strong>，以确保训练数据集中 FPS 分布更加均衡。</li>
<li><strong>长视频字幕生成</strong>：对于<strong>时长超过半小时</strong>的视频，我们<strong>专门构建了一套长视频字幕数据集</strong>，通过<strong>目标合成管道</strong>生成<strong>多帧字幕</strong>，以提高模型对长视频内容的理解能力。</li>
<li><strong>视频对齐数据</strong>：针对视频数据的时间对齐问题，我们提供了<strong>秒级格式（second-based format）<strong>和</strong>时-分-秒-帧（hmsf）格式</strong>的时间戳，以确保模型能够准确理解和输出不同格式的时间信息。</li>
</ul>
<p><strong>智能体数据（Agent Data）：<strong>我们增强了 <strong>Qwen2.5-VL</strong> 的</strong>感知和决策能力</strong>，以构建其智能体（Agent）能力。</p>
<p><strong>感知能力（Perception）：</strong></p>
<ul>
<li>我们收集了<strong>移动端、网页端和桌面端</strong>的截图数据。</li>
<li>通过<strong>合成数据引擎</strong>生成<strong>截图描述（captions）<strong>和</strong>UI 元素对齐标注（grounding annotations）</strong>。</li>
<li><strong>截图描述任务</strong>（Caption Task）：帮助 Qwen2.5-VL 理解<strong>图形界面</strong>。</li>
<li><strong>对齐任务</strong>（Grounding Task）：帮助 Qwen2.5-VL <strong>关联 UI 元素的外观和功能</strong>。</li>
</ul>
<p><strong>决策能力（Decision-Making）：</strong></p>
<ul>
<li><strong>操作格式统一</strong>：我们将<strong>移动端、网页端和桌面端的操作</strong>统一为<strong>函数调用格式</strong>，并构建一个共享的<strong>操作空间（Action Space）</strong>。</li>
<li>多步操作数据：<ul>
<li>收集<strong>开源数据</strong>和<strong>基于虚拟环境的智能体框架（Wang et al., 2025; 2024b;c）合成的多步操作轨迹</strong>，并将其<strong>转换为函数格式</strong>。</li>
<li>通过<strong>人工和模型标注（Xu et al., 2024）</strong>，为每一步操作生成<strong>推理过程</strong>。</li>
</ul>
</li>
<li>推理数据构建流程：<ol>
<li><strong>给定一个真实操作（Ground-Truth Operation）</strong>，我们在截图上<strong>高亮显示</strong>该操作。</li>
<li><strong>提供全局查询信息</strong>，以及<strong>操作前后的截图</strong>，要求标注人员<strong>编写推理内容</strong>，解释该操作的意图。</li>
<li><strong>使用基于模型的筛选器</strong>，剔除低质量的推理内容。</li>
</ol>
</li>
</ul>
<p>这一推理内容的加入，能够防止 <strong>Qwen2.5-VL</strong> <strong>过拟合</strong>于<strong>真实操作数据</strong>，并使其在<strong>真实世界场景中更加鲁棒（robust）</strong>。</p>
<img src="/2025/03/11/Qwen2-5VL%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%E4%B8%8E%E6%80%BB%E7%BB%93/image-20250312104636009.png" class="" title="image-20250312104636009">

<h4 id="2-2-2-训练方案（Training-Recipe）"><a href="#2-2-2-训练方案（Training-Recipe）" class="headerlink" title="2.2.2 训练方案（Training Recipe）"></a>2.2.2 训练方案（Training Recipe）</h4><p>我们从零开始训练了一个 <strong>Vision Transformer (ViT)</strong>，其中<strong>视觉编码器</strong>（Vision Encoder）使用 <strong>DataComp（Gadre et al., 2023）</strong> 和部分<strong>自有数据集</strong>进行初始化，而<strong>语言模型组件</strong>（LLM）则基于<strong>预训练的 Qwen2.5 大语言模型（Yang et al., 2024a）</strong> 进行初始化。</p>
<p>如表 2 所示，<strong>预训练过程分为三个阶段</strong>，每个阶段采用不同的数据配置和训练策略，以<strong>逐步增强模型能力</strong>。</p>
<p><strong>第一阶段：ViT 预训练，增强视觉-语言对齐能力</strong></p>
<ul>
<li>仅训练 <strong>Vision Transformer (ViT)</strong>，使其更好地与<strong>语言模型（LLM）对齐</strong>，为多模态理解奠定基础。</li>
<li>主要数据来源：<ul>
<li><strong>图像字幕数据（Image Captions）</strong></li>
<li><strong>视觉知识数据（Visual Knowledge）</strong></li>
<li><strong>OCR 数据（光学字符识别数据）</strong></li>
</ul>
</li>
<li>这些数据经过精心选择，以提升 ViT <strong>提取有意义视觉表征</strong>的能力，并确保其能<strong>有效融入文本信息</strong>。</li>
</ul>
<p><strong>第二阶段：解冻所有参数，训练多模态数据，提升复杂视觉处理能力</strong></p>
<ul>
<li><strong>解冻全部模型参数</strong>，在更<strong>丰富的多模态数据</strong>上训练，增强模型处理复杂视觉信息的能力。</li>
<li>引入更加复杂、需要推理能力的数据集，包括：<ul>
<li><strong>交错数据（Interleaved Data）</strong></li>
<li><strong>多任务学习数据集（Multi-task Learning Datasets）</strong></li>
<li><strong>视觉问答（VQA，Visual Question Answering）</strong></li>
<li><strong>多模态数学（Multimodal Mathematics）</strong></li>
<li><strong>基于智能体的任务（Agent-based Tasks）</strong></li>
<li><strong>视频理解数据（Video Understanding）</strong></li>
<li><strong>纯文本数据（Pure-text Datasets）</strong></li>
</ul>
</li>
<li>这一阶段旨在<strong>强化模型视觉与语言的深层次联系</strong>，使其能够处理<strong>更加复杂的多模态任务</strong>。</li>
</ul>
<p><strong>第三阶段：增强长序列推理能力，加入视频与智能体数据</strong></p>
<ul>
<li>进一步增强模型在<strong>长序列推理、视频和智能体任务</strong>上的能力。</li>
<li>在训练中<strong>增加序列长度</strong>，使模型能<strong>处理更长的上下文</strong>，特别是涉及<strong>长距离依赖和复杂推理的任务</strong>。</li>
</ul>
<p><strong>优化训练效率的策略</strong></p>
<p>由于训练过程中<strong>图像大小和文本长度的变化</strong>会导致<strong>计算负载不均衡</strong>，我们采取了<strong>优化策略</strong>来提升训练效率：</p>
<ul>
<li><strong>主要计算负载</strong>来自于 <strong>LLM（语言模型）和 Vision Encoder（视觉编码器）</strong>。</li>
<li>由于 <strong>视觉编码器的参数较少</strong>，并且我们引入了 <strong>窗口注意力（Window Attention）</strong> 来进一步<strong>降低计算需求</strong>，所以主要优化点是<strong>均衡 LLM 计算负载</strong>。</li>
<li>具体方法：<ul>
<li><strong>动态打包（Dynamically Packed）</strong> 数据样本，根据输入的<strong>序列长度</strong>分配给 LLM，确保计算负载均衡。</li>
<li><strong>第一、二阶段</strong>：数据序列长度<strong>统一设定为 8,192</strong>。</li>
<li><strong>第三阶段</strong>：序列长度<strong>提升至 32,768</strong>，以适应模型<strong>处理长序列任务的能力</strong>。</li>
</ul>
</li>
</ul>
<h3 id="2-3-后训练（Post-training）"><a href="#2-3-后训练（Post-training）" class="headerlink" title="2.3 后训练（Post-training）"></a>2.3 后训练（Post-training）</h3><p>Qwen2.5-VL 的后训练对齐框架采用 <strong>双阶段优化范式</strong>，包括 <strong>监督微调（Supervised Fine-Tuning, SFT）</strong> 和 <strong>直接偏好优化（Direct Preference Optimization, DPO）</strong>（Rafailov 等，2023）。这种<strong>分层对齐策略</strong>结合了<strong>参数高效的领域自适应</strong>和<strong>人类偏好蒸馏</strong>，分别针对<strong>表征对齐（representational grounding）</strong> 和<strong>行为优化（behavioral refinement）</strong> 进行优化，以满足不同的训练目标。</p>
<p><strong>监督微调（SFT）</strong></p>
<p>SFT 旨在通过<strong>针对性的指令优化</strong>，弥合<strong>预训练表征</strong>与<strong>下游任务需求</strong>之间的差距。在这一阶段，我们采用 <strong>ChatML 格式</strong>（OpenAI，2024）来构造指令跟随数据，这种格式<strong>有意区别于预训练数据模式</strong>，但仍保持与 Qwen2-VL（Wang 等，2024e）的架构一致性。这种格式转换实现了三个关键调整：</p>
<ol>
<li><strong>显式对话角色标注</strong>，支持多模态回合式交互；</li>
<li><strong>在文本指令中结构化地注入视觉嵌入</strong>，确保模型能够结合视觉信息理解任务；</li>
<li><strong>通过格式感知的数据打包，保持跨模态的位置信息关系</strong>，使模型能够理解视觉元素与文本之间的对应关系。</li>
</ol>
<p>通过在这种增强格式下，向模型提供<strong>精心挑选的多模态指令-响应对（instruction-response pairs）</strong>，SFT <strong>可以高效地传递知识，同时保持预训练特征的完整性</strong>。</p>
<h4 id="2-3-1-指令数据"><a href="#2-3-1-指令数据" class="headerlink" title="2.3.1 指令数据"></a>2.3.1 指令数据</h4><p>在<strong>监督微调（SFT）阶段，使用精心构建的数据集来提升模型在不同模态下的指令跟随能力。该数据集包含约200万条数据</strong>，其中<strong>纯文本数据占比50%</strong>，<strong>多模态数据占比50%</strong>，后者包括<strong>图文和视频文本</strong>的组合。多模态数据的引入使模型能够有效处理复杂输入。需要注意的是，虽然<strong>纯文本数据和多模态数据的数量相等</strong>，但由于多模态数据<strong>包含视觉和时间信息</strong>，其在训练过程中会消耗<strong>显著更多的 token 和计算资源</strong>。</p>
<p>该数据集主要由<strong>中英文数据</strong>组成，并补充了一定量的<strong>多语言数据</strong>，以支持更广泛的语言多样性。数据集结构设计涵盖不同层次的<strong>对话复杂度</strong>，包括<strong>单轮对话</strong>和<strong>多轮对话</strong>。这些对话进一步结合了从<strong>单张图片输入到多张图片序列</strong>的各种场景，以模拟真实的对话动态。</p>
<p>数据来源主要包括<strong>开源数据集</strong>，并辅以<strong>购买的精选数据</strong>和<strong>在线查询数据</strong>，从而确保数据集的<strong>广泛覆盖性</strong>和<strong>代表性</strong>。</p>
<p>为了适应多种应用场景，数据集中包含多个<strong>专门子集</strong>，如：</p>
<ul>
<li><strong>通用视觉问答（VQA）</strong></li>
<li><strong>图像描述（Image Captioning）</strong></li>
<li><strong>数学问题求解</strong></li>
<li><strong>编程任务</strong></li>
<li><strong>安全相关查询</strong></li>
</ul>
<p>此外，还构建了专门的数据集，以提升模型在<strong>文档与光学字符识别（Doc &amp; OCR）</strong>、<strong>目标定位（Grounding）</strong>、<strong>视频分析</strong>和<strong>智能体交互（Agent Interactions）</strong> 等领域的能力。有关数据的详细信息可在论文的相关章节中找到。</p>
<p>这种<strong>结构化且多样化</strong>的数据集设计，确保 SFT 阶段能够<strong>有效对齐预训练表示</strong>，使模型能够更好地适应<strong>多模态下游任务</strong>的需求，从而具备更强的<strong>上下文理解</strong>和<strong>任务执行</strong>能力。</p>
<h4 id="2-3-2-数据过滤流水线"><a href="#2-3-2-数据过滤流水线" class="headerlink" title="2.3.2 数据过滤流水线"></a>2.3.2 数据过滤流水线</h4><p>训练数据的质量是影响<strong>视觉-语言模型</strong>性能的关键因素。<strong>开源数据集</strong>和<strong>合成数据集</strong>通常存在较大的<strong>变异性</strong>，其中可能包含<strong>噪声数据、冗余数据或低质量样本</strong>。因此，必须进行严格的数据清理和过滤，以解决这些问题。<strong>低质量数据</strong>可能导致<strong>预训练表示</strong>与下游任务的要求无法良好对齐，从而降低模型处理复杂多模态任务的能力。因此，确保数据质量至关重要，以实现<strong>稳健</strong>且<strong>可靠</strong>的模型性能。</p>
<p><strong>两阶段数据过滤流水线：<strong>为了解决这些挑战，我们构建了一条</strong>两阶段数据过滤流水线</strong>，以系统性地提升<strong>监督微调（SFT）</strong> 数据集的质量。该流水线包括以下两个阶段：</p>
<p><strong>第一阶段：领域特定分类</strong>，在第一阶段，我们使用<strong>Qwen2-VL-Instag</strong>（由<strong>Qwen2-VL-72B</strong>衍生而来的<strong>专业分类模型</strong>）对<strong>问答（QA）对</strong>进行<strong>分层分类</strong>。该模型将 QA 对划分为<strong>八个主要领域</strong>（如<strong>编程</strong>和<strong>规划</strong>），并进一步细分为<strong>30个子类别</strong>。</p>
<p>例如，<strong>编程（Coding）</strong> 这一主要领域下包含以下子类别：</p>
<ul>
<li><strong>Code_Debugging（代码调试）</strong></li>
<li><strong>Code_Generation（代码生成）</strong></li>
<li><strong>Code_Translation（代码翻译）</strong></li>
<li><strong>Code_Understanding（代码理解）</strong></li>
</ul>
<p>这种<strong>分层结构</strong>有助于<strong>领域感知</strong>和<strong>子领域感知</strong>的过滤策略，使流水线能够针对不同类别的数据<strong>优化数据清理流程</strong>。从而<strong>提高 SFT 数据集的质量和相关性</strong>。</p>
<p><strong>第二阶段：领域定制化过滤，<strong>在第二阶段，我们实施</strong>领域定制化过滤</strong>，结合<strong>基于规则</strong>和<strong>基于模型</strong>的方法，以全面提升数据质量。由于<strong>文档处理、光学字符识别（OCR）、视觉目标定位（Visual Grounding）<strong>等领域的多样性，每个领域可能需要</strong>独特的过滤策略</strong>。以下是这些领域中采用的通用过滤策略概述：</p>
<p><strong>1. 基于规则的过滤（Rule-Based Filtering）</strong></p>
<ul>
<li>采用<strong>预定义的启发式规则</strong>来<strong>剔除低质量或存在问题的数据</strong>。</li>
<li>针对<strong>文档处理、OCR、视觉目标定位</strong>等任务，识别并移除<strong>重复模式</strong>，以防止模型学习过程受损，并确保最优性能。</li>
<li>剔除<strong>不完整、被截断或格式错误</strong>的响应，这些问题在<strong>合成数据集</strong>和<strong>多模态任务</strong>中较为常见。</li>
<li>为了保持<strong>数据的相关性</strong>并符合<strong>伦理标准</strong>，会移除<strong>无关或可能导致有害输出</strong>的查询和答案。</li>
<li>这种<strong>结构化方法</strong>确保数据集符合<strong>伦理准则</strong>，并满足<strong>特定任务的要求</strong>。</li>
</ul>
<p><strong>2. 基于模型的过滤（Model-Based Filtering）</strong></p>
<ul>
<li>进一步利用<strong>Qwen2.5-VL 系列</strong>训练的<strong>奖励模型（Reward Models）</strong> 对数据集进行精细筛选。</li>
<li>对多模态 QA 对进行多维度评估，其中：<ul>
<li><strong>查询（Query）<strong>会被评估其</strong>复杂度和相关性</strong>，确保保留<strong>适当具有挑战性且上下文相关的示例</strong>。</li>
<li><strong>答案（Answer）<strong>则依据</strong>正确性、完整性、清晰度、相关性和有用性</strong>等指标进行筛选。</li>
<li>在<strong>视觉相关任务</strong>中，会特别关注<strong>视觉信息的准确解读与应用</strong>，确保答案能够<strong>正确利用视觉信息</strong>。</li>
</ul>
</li>
</ul>
<p>这种<strong>多维评分机制</strong>确保<strong>只有高质量的数据</strong>才会进入 SFT 阶段，从而进一步提升模型的性能和泛化能力。</p>
<h4 id="2-3-3-基于拒绝采样的增强推理"><a href="#2-3-3-基于拒绝采样的增强推理" class="headerlink" title="2.3.3 基于拒绝采样的增强推理"></a>2.3.3 <strong>基于拒绝采样的增强推理</strong></h4><p>为了<strong>补充结构化数据过滤流水线</strong>，我们采用<strong>拒绝采样（Rejection Sampling）<strong>策略来优化数据集，并提升</strong>视觉-语言模型（VLM）<strong>的推理能力。该方法在</strong>需要复杂推理</strong>的任务中尤为关键，例如<strong>数学问题求解、代码生成</strong>以及<strong>特定领域的视觉问答（VQA）</strong>。</p>
<p>研究表明，<strong>链式思维（Chain-of-Thought, CoT）推理（Wei et al., 2022）能显著提升模型的推理能力</strong>（DeepSeek-AI et al., 2024）。我们的<strong>后训练实验</strong>也证实了这一点，进一步凸显了<strong>结构化推理过程</strong>对<strong>高质量推理结果</strong>的重要性。</p>
<p><strong>拒绝采样流程：<strong>该过程始于</strong>带有标准答案的高质量数据集</strong>，其中包含需要<strong>多步推理</strong>的任务，例如<strong>数学问题求解、代码生成和特定领域的 VQA</strong>。然后，我们使用<strong>Qwen2.5-VL 模型的中间版本</strong>对<strong>模型生成的回答</strong>与<strong>标准答案</strong>进行比对，<strong>仅保留</strong>模型输出与期望答案<strong>匹配</strong>的样本，从而确保数据集仅由<strong>高质量、准确的示例</strong>组成。</p>
<p>为了进一步提高数据质量，我们施加<strong>额外约束</strong>，以过滤掉不理想的输出，具体包括：</p>
<ul>
<li><strong>避免代码混用（code-switching）</strong>：排除含有不同语言混杂的回答，确保语言一致性。</li>
<li><strong>控制输出长度</strong>：去除<strong>过长</strong>的回答，避免冗余信息影响推理质量。</li>
<li><strong>剔除重复模式</strong>：移除<strong>重复句式</strong>或<strong>模式化表达</strong>，保证回答的<strong>清晰性</strong>和<strong>连贯性</strong>。</li>
</ul>
<p>这些标准有助于确保<strong>CoT 推理过程的清晰度和连贯性</strong>，从而提高下游任务的性能。</p>
<p><strong>视觉-语言模型中的 CoT 挑战与优化：<strong>在视觉-语言模型中应用</strong>CoT 推理</strong>存在一项核心挑战：模型必须<strong>同时依赖文本和视觉模态</strong>，但<strong>中间推理步骤可能无法充分整合视觉信息</strong>，具体表现为：</p>
<ul>
<li><strong>忽略关键视觉线索</strong>（例如没有参考图片中的关键信息）。</li>
<li><strong>错误解读视觉内容</strong>（例如误判图像中的物体或文字）。</li>
</ul>
<p>为了解决这些问题，我们开发了<strong>基于规则</strong>和<strong>基于模型</strong>的过滤策略，以<strong>验证中间推理步骤的准确性</strong>。这些机制确保<strong>每一步推理过程都能有效结合视觉和文本信息</strong>。然而，实现<strong>最佳的模态对齐</strong>仍是一个<strong>持续优化的挑战</strong>，需要进一步的技术突破。</p>
<p><strong>拒绝采样对模型推理能力的提升：<strong>通过</strong>迭代优化数据集</strong>并<strong>移除低质量或错误样本</strong>，拒绝采样显著提升了模型的<strong>推理能力</strong>。该方法确保模型学习<strong>高质量、高保真度</strong>的示例，使其能够在<strong>复杂任务</strong>中表现得更加<strong>准确</strong>和<strong>连贯</strong>。</p>
<p>这种方法不仅<strong>增强了模型对多步推理任务的处理能力</strong>，还<strong>为未来的视觉-语言建模改进奠定了基础</strong>。</p>
<h4 id="2-3-4-训练方案"><a href="#2-3-4-训练方案" class="headerlink" title="2.3.4 训练方案"></a>2.3.4 <strong>训练方案</strong></h4><p>Qwen2.5-VL 的<strong>后训练过程</strong>包括两个阶段：</p>
<ol>
<li><strong>监督微调（Supervised Fine-Tuning, SFT）</strong></li>
<li><strong>直接偏好优化（Direct Preference Optimization, DPO）</strong></li>
</ol>
<p>在这两个阶段中，<strong>视觉变换器（Vision Transformer, ViT）参数保持冻结</strong>。</p>
<p><strong>SFT 阶段（监督微调）：<strong>在 SFT 阶段，模型在</strong>多样化的多模态数据</strong>上进行<strong>微调</strong>，这些数据包括：</p>
<ul>
<li><strong>图文数据对（image-text pairs）</strong></li>
<li><strong>视频数据（video）</strong></li>
<li><strong>纯文本数据（pure text）</strong></li>
</ul>
<p>数据来源涵盖：</p>
<ul>
<li><strong>通用 VQA 数据</strong>（General Visual Question Answering）</li>
<li><strong>拒绝采样数据（Rejection Sampling）</strong></li>
<li><strong>专业领域数据集</strong>（如<strong>文档识别（Document and OCR）</strong>、<strong>目标定位（Grounding）</strong>、<strong>视频分析（Video）<strong>和</strong>智能体相关任务（Agent-related tasks）</strong>）</li>
</ul>
<p><strong>DPO 阶段（直接偏好优化）：<strong>DPO 阶段专注于</strong>图文数据</strong>和<strong>纯文本数据</strong>，主要使用<strong>偏好数据（Preference Data）<strong>来优化模型，使其更加符合</strong>人类偏好</strong>。</p>
<ul>
<li><strong>每个样本仅处理一次</strong>，确保优化过程高效。</li>
<li>该阶段的目标：<ul>
<li>提升<strong>跨模态推理能力</strong></li>
<li><strong>优化特定任务表现</strong></li>
<li><strong>对齐用户意图</strong>，使模型生成的答案更符合用户需求</li>
</ul>
</li>
</ul>
<p>这种<strong>高效的训练流程</strong>在<strong>提升模型能力</strong>的同时，确保其与<strong>人类偏好保持一致</strong>。</p>
<hr>
<h2 id="3-实验"><a href="#3-实验" class="headerlink" title="3 实验"></a>3 实验</h2><p>在本节中，我们首先介绍整体模型，并将其与当前最先进（SoTA）模型进行比较。随后，我们评估该模型在各个子能力上的表现。</p>
<h3 id="3-1-与先进模型比较"><a href="#3-1-与先进模型比较" class="headerlink" title="3.1 与先进模型比较"></a>3.1 与先进模型比较</h3><img src="/2025/03/11/Qwen2-5VL%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%E4%B8%8E%E6%80%BB%E7%BB%93/image-20250314140802625.png" class="" title="image-20250314140802625">

<p>本实验部分评估了 Qwen2.5-VL 在多个数据集上的表现，并将其与当前最先进（SoTA）模型进行比较，包括 <strong>Claude-3.5-Sonnet-0620</strong>（Anthropic, 2024a）、<strong>GPT-4o-0513</strong>（OpenAI, 2024）、<strong>InternVL2.5</strong>（Chen et al., 2024d），以及不同规模的 <strong>Qwen2-VL</strong>（Wang et al., 2024e）。</p>
<p><strong>大学水平任务：</strong> 在大学水平的问题上，<strong>Qwen2.5-VL-72B</strong> 在 <strong>MMMU</strong>（Yue et al., 2023）上取得了 <strong>70.2</strong> 分。<br> 在更高难度的 <strong>MMMU-Pro</strong>（Yue et al., 2024）上，该模型得分 <strong>51.1</strong>，超越了此前的开源 SoTA 模型，并达到了 <strong>接近 GPT-4o 的性能</strong>。</p>
<p><strong>数学相关任务：</strong></p>
<ul>
<li>在 <strong>MathVista</strong>（Lu et al., 2024）上，Qwen2.5-VL-72B <strong>得分 74.8</strong>，超越了此前开源 SoTA 记录（72.3）。</li>
<li>在 <strong>MATH-Vision</strong>（Wang et al., 2024d）上，该模型 <strong>得分 38.1</strong>。</li>
<li>在 <strong>MathVerse</strong>（Zhang et al., 2024c）上，Qwen2.5-VL-72B <strong>得分 57.6</strong>，表现与其他领先模型具有竞争力。</li>
</ul>
<p><strong>通用视觉问答（VQA）任务：</strong></p>
<ul>
<li>在 <strong>MMBench-EN</strong>（Liu et al., 2023d）上，该模型 <strong>得分 88.6</strong>，略微超越了此前最高分 <strong>88.3</strong>。</li>
<li>在 <strong>MuirBench</strong>（Wang et al., 2024a）上 <strong>得分 70.7</strong>，在 <strong>BLINK</strong>（Fu et al., 2024c）上 <strong>得分 64.4</strong>，均表现优异。</li>
<li>在多语言视觉问答任务 <strong>MTVQA</strong>（Tang et al., 2024）中，Qwen2.5-VL-72B <strong>得分 31.7</strong>，展现出强大的多语言文本识别能力。</li>
<li>在主观评测任务中：<ul>
<li><strong>MMVet</strong>（Yu et al., 2024）上得分 <strong>76.2</strong></li>
<li><strong>MM-MT-Bench</strong>（Agrawal et al., 2024）上得分 <strong>7.6</strong><br> 这表明 Qwen2.5-VL-72B 在<strong>自然对话体验和用户满意度</strong>方面表现出色。</li>
</ul>
</li>
</ul>
<h3 id="3-2-纯文本任务的表现"><a href="#3-2-纯文本任务的表现" class="headerlink" title="3.2 纯文本任务的表现"></a>3.2 纯文本任务的表现</h3><p>为了全面评估指令微调模型在 <strong>纯文本任务</strong> 上的表现，我们选取了多个具有代表性的基准测试（详见 <strong>表 4</strong>），涵盖以下领域：</p>
<ul>
<li><strong>通用任务</strong>（Wang et al., 2024j; Gema et al., 2024; White et al., 2024）</li>
<li><strong>数学与科学任务</strong>（Rein et al., 2023; Hendrycks et al., 2021; Cobbe et al., 2021）</li>
<li><strong>编程任务</strong>（Chen et al., 2021; Cassano et al., 2023）</li>
<li><strong>对齐任务</strong>（Zhou et al., 2023）</li>
</ul>
<p>我们将 <strong>Qwen2.5-VL</strong> 与 <strong>多种同规模的大型语言模型（LLMs）</strong> 进行了对比。结果表明，<strong>Qwen2.5-VL 不仅在多模态任务上达到了最先进（SoTA）水平，同时在纯文本任务上也展现出了领先的性能</strong>，证明了其在<strong>多种评测标准下的多功能性和稳健性</strong>。</p>
<img src="/2025/03/11/Qwen2-5VL%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%E4%B8%8E%E6%80%BB%E7%BB%93/image-20250314142212215.png" class="" title="image-20250314142212215">

<hr>
<h3 id="3-3-定量结果"><a href="#3-3-定量结果" class="headerlink" title="3.3 定量结果"></a>3.3 定量结果</h3><h4 id="3-3-1-通用视觉问答（VQA）"><a href="#3-3-1-通用视觉问答（VQA）" class="headerlink" title="3.3.1 通用视觉问答（VQA）"></a>3.3.1 通用视觉问答（VQA）</h4><p>为了全面评估模型在 <strong>通用视觉问答（VQA）</strong> 和 <strong>对话</strong> 方面的能力，我们在多个 <strong>多样化数据集</strong> 上进行了广泛实验。<strong>如表 3 所示</strong>，Qwen2.5-VL 在 <strong>VQA 任务、主观评测、多语言场景和多图像问题</strong> 上均展现出 <strong>最先进（SoTA）</strong> 的表现。</p>
<p>具体而言，该模型在以下 <strong>基准数据集</strong> 上表现卓越：</p>
<ul>
<li><strong>MMBench 系列</strong>（Liu et al., 2023d）</li>
<li><strong>MMStar</strong>（Chen et al., 2024c）</li>
<li><strong>MME</strong>（Fu et al., 2023）</li>
<li><strong>MuirBench</strong>（Wang et al., 2024a）</li>
<li><strong>BLINK</strong>（Fu et al., 2024c）</li>
<li><strong>CRPE</strong>（Wang et al., 2024h）</li>
<li><strong>HallBench</strong>（Guan et al., 2023）</li>
<li><strong>MTVQA</strong>（Tang et al., 2024）</li>
<li><strong>MME-RealWorld</strong>（Zhang et al., 2024f）</li>
<li><strong>MMVet</strong>（Yu et al., 2024）</li>
<li><strong>MM-MT-Bench</strong>（Agrawal et al., 2024）</li>
</ul>
<p><strong>视觉细节理解与推理能力：</strong></p>
<ul>
<li>在 <strong>MMBench-EN-V1.1</strong> 数据集上，<strong>Qwen2.5-VL-72B</strong> 取得 <strong>88.4%</strong> 的准确率，超越了 <strong>InternVL2.5（78B）</strong> 和 <strong>Claude-3.5 Sonnet-0620</strong> 等 <strong>最先进模型</strong>。</li>
<li>在 <strong>MMStar</strong> 数据集上，Qwen2.5-VL 得分 <strong>70.8%</strong>，领先于其他主流模型。</li>
</ul>
<p>这些结果表明，<strong>Qwen2.5-VL 具有强大的适应性，能够在多种语言环境下保持高性能</strong>。</p>
<p><strong>高分辨率真实场景适应能力：</strong></p>
<ul>
<li>在 <strong>MME-RealWorld</strong> 基准测试中，Qwen2.5-VL 取得 <strong>63.2</strong> 分，展现出<strong>卓越的现实环境适应能力</strong>。</li>
<li>在 <strong>MuirBench</strong> 数据集中，该模型在 <strong>多图像理解任务</strong> 上得分 <strong>70.7</strong>，进一步证明其 <strong>优越的泛化能力</strong>。</li>
</ul>
<p>综合来看，这些结果表明，Qwen2.5-VL 在 <strong>通用视觉问答（VQA）任务</strong> 中 <strong>表现出极强的多功能性和高效性</strong>。</p>
<p><strong>小规模模型的竞争力：</strong></p>
<p>值得注意的是，即使是<strong>较小规模</strong> 的 <strong>Qwen2.5-VL-7B</strong> 和 <strong>Qwen2.5-VL-3B</strong> 也表现出 <strong>极具竞争力的性能</strong>：</p>
<ul>
<li><strong>Qwen2.5-VL-7B</strong> 在 <strong>MMStar</strong> 数据集上取得 <strong>63.9%</strong> 的得分。</li>
<li><strong>Qwen2.5-VL-3B</strong> 在 <strong>MMStar</strong> 数据集上得分 <strong>55.9%</strong>。</li>
</ul>
<p>这表明 <strong>Qwen2.5-VL 的架构不仅强大，而且具有良好的可扩展性，在减少参数的情况下依然能保持出色性能</strong>。</p>
<h4 id="3-3-2-文档理解与-OCR"><a href="#3-3-2-文档理解与-OCR" class="headerlink" title="3.3.2 文档理解与 OCR"></a>3.3.2 文档理解与 OCR</h4><p>我们在 <strong>OCR、图表和文档理解</strong> 相关的多个基准数据集上评估了 Qwen2.5-VL 模型的性能。<strong>表 5</strong> 展示了 Qwen2.5-VL 各版本与最先进（SoTA）模型在以下 <strong>OCR 相关基准</strong> 上的对比：</p>
<ul>
<li><strong>AI2D</strong>（Kembhavi et al., 2016）</li>
<li><strong>TextVQA</strong>（Singh et al., 2019）</li>
<li><strong>DocVQA</strong>（Mathew et al., 2021b）</li>
<li><strong>InfoVQA</strong>（Mathew et al., 2021a）</li>
<li><strong>ChartQA</strong>（Masry et al., 2022）</li>
<li><strong>CharXiv</strong>（Wang et al., 2024k）</li>
<li><strong>SEED-Bench-2-Plus</strong>（Li et al., 2024b）</li>
<li><strong>OCRBench</strong>（Liu et al., 2023e）</li>
<li><strong>OCRBench_v2</strong>（Fu et al., 2024b）</li>
<li><strong>CC-OCR</strong>（Yang et al., 2024b）</li>
<li><strong>OmniDocBench</strong>（Ouyang et al., 2024）</li>
<li><strong>VCR</strong>（Zhang et al., 2024e）</li>
</ul>
<p><strong>OCR 解析任务：</strong></p>
<p>对于 <strong>多场景、多语言以及不同类型文档（如手写文本、表格、图表、化学公式、数学表达式）</strong> 的 OCR 解析任务，Qwen2.5-VL-72B <strong>在 CC-OCR 和 OmniDocBench 数据集上刷新了最先进记录（SoTA）</strong>。这一成果得益于<strong>精心挑选的训练数据</strong> 和 <strong>LLM 强大的文本解析能力</strong>。</p>
<p><strong>OCR 相关理解任务：</strong></p>
<p>在 <strong>场景文本、图表、示意图及文档理解</strong>相关的基准测试中，Qwen2.5-VL 取得了<strong>卓越的性能</strong>，展现出 <strong>出色的文档理解能力</strong>。</p>
<ul>
<li>在 <strong>综合 OCR 理解基准</strong>（如 OCRBench和InfoVQA）上，Qwen2.5-VL-72B取得了<strong>显著领先的成绩</strong>，远超 <strong>InternVL2.5-78B</strong> 等强劲对手。</li>
<li>在<strong>涵盖图表、地图、网页等文本密集型场景</strong> 的 <strong>SEED-Bench-2-Plus</strong> 数据集中，Qwen2.5-VL-72B <strong>表现出色</strong>，进一步验证了其卓越的文档处理能力。</li>
</ul>
<p><strong>OCR 综合基准测试：</strong></p>
<p>在 <strong>OCRBench_v2</strong> 这一涵盖 <strong>OCR 解析与理解</strong> 任务的综合基准上，Qwen2.5-VL <strong>同样实现了领先的性能</strong>。值得注意的是，相较于 <strong>Gemini 1.5-Pro</strong>，Qwen2.5-VL 在 <strong>英文 OCR 任务上提升了 9.6%</strong>，在 <strong>中文 OCR 任务上更是提升了 20.6%</strong>，大幅超越当前最先进模型。</p>
<p>这些结果表明，Qwen2.5-VL <strong>在文档理解和 OCR 任务上达到了行业领先水平</strong>，具备强大的<strong>跨语言文档解析和文本理解能力</strong>。</p>
<img src="/2025/03/11/Qwen2-5VL%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%E4%B8%8E%E6%80%BB%E7%BB%93/image-20250314143316009.png" class="" title="image-20250314143316009">

<h4 id="3-3-3-空间理解"><a href="#3-3-3-空间理解" class="headerlink" title="3.3.3 空间理解"></a><strong>3.3.3 空间理解</strong></h4><p>理解空间关系对于开发能够像人类一样 <strong>解释和交互世界</strong> 的 AI 模型至关重要。在<strong>大规模视觉-语言模型（LVLMs）</strong> 中，<strong>视觉定位（visual grounding）</strong> 使 AI 能够根据 <strong>自然语言查询或描述</strong>在图像中<strong>精确地定位和识别</strong>特定的 <strong>物体、区域或元素</strong>。这一能力超越了传统的目标检测，不仅能够检测物体，还能在 <strong>视觉内容与语言上下文之间建立语义关系</strong>，从而实现更<strong>细粒度和上下文感知的视觉推理</strong>。</p>
<p>我们评估了 Qwen2.5-VL 在以下<strong>视觉定位基准</strong>上的表现：</p>
<ul>
<li><strong>指代表达理解基准（Referring Expression Comprehension）</strong>（Kazemzadeh et al., 2014; Mao et al., 2016）</li>
<li><strong>自然环境中的目标检测（Object Detection in the Wild, ODinW）</strong>（Li et al., 2022b）</li>
<li><strong>自构建的点定位基准（Point Grounding Benchmark）</strong></li>
<li><strong>物体计数基准（CountBench）</strong>（Paiss et al., 2023）</li>
</ul>
<p>我们将 <strong>Qwen2.5-VL</strong> 的 <strong>视觉定位能力</strong>与其他先进的<strong>大规模视觉-语言模型（LVLMs）</strong> 进行了比较，包括：</p>
<ul>
<li><strong>Gemini</strong></li>
<li><strong>Grounding-DINO</strong>（Liu et al., 2023c）</li>
<li><strong>Molmo</strong>（Deitke et al., 2024）</li>
<li><strong>InternVL2.5</strong></li>
</ul>
<p><strong>领先的视觉定位能力：</strong></p>
<p>Qwen2.5-VL 在 <strong>框定位（box-grounding）、点定位（point-grounding）和物体计数（counting）</strong> 任务上均取得 <strong>领先成绩</strong>。</p>
<ul>
<li><strong>双重定位能力（框+点）</strong><br> Qwen2.5-VL <strong>同时具备框定位和点定位能力</strong>，可以理解、定位并推理图像中特定部分的<strong>细节信息</strong>。</li>
<li><strong>开放词汇目标检测（Open-Vocabulary Object Detection）</strong><br> 在 <strong>ODinW-13 数据集</strong> 上，Qwen2.5-VL 取得了 <strong>43.1 mAP</strong> 的优异成绩，<strong>超过了大多数 LVLMs</strong>，并<strong>迅速缩小了通用模型与专业模型之间的差距</strong>。</li>
<li><strong>点定位能力突破</strong><br> 传统的 <strong>目标检测</strong> 主要依赖 <strong>边界框（bounding box）</strong>，但有些物体的 <strong>细节</strong> 很难用 <strong>矩形框表示</strong>。Qwen2.5-VL <strong>解锁了点定位能力</strong>，可以<strong>精准地定位</strong> 物体的<strong>特定细节</strong>，这一点在过去的检测方法中是 <strong>难以实现的</strong>。</li>
<li><strong>强大的计数能力</strong><br> 在 <strong>CountBench</strong> 基准测试中，Qwen2.5-VL <strong>采用“先检测再计数”（detect then count）的提示方式</strong>，Qwen2.5-VL-72B <strong>取得了 93.6% 的领先准确率</strong>，展现了出色的 <strong>目标计数能力</strong>。</li>
</ul>
<h4 id="3-3-4-视频理解与定位"><a href="#3-3-4-视频理解与定位" class="headerlink" title="3.3.4 视频理解与定位"></a>3.3.4 视频理解与定位</h4><p>我们对Qwen2.5-VL模型在<strong>视频理解与定位</strong>任务上的表现进行了全面评估，采用的基准测试涵盖<strong>时长从数秒到数小时</strong>的视频。<strong>表 8</strong>展示了 <strong>Qwen2.5-VL 系列模型</strong>与<strong>顶级商业模型</strong>在以下<strong>视频基准测试</strong>上的性能对比：</p>
<ul>
<li><strong>Video-MME</strong>（Fu et al., 2024a）</li>
<li><strong>Video-MMMU</strong>（Hu et al., 2025）</li>
<li><strong>MMVU</strong>（Zhao et al., 2025）</li>
<li><strong>MVBench</strong>（Li et al., 2024d）</li>
<li><strong>MMBench-Video</strong>（Fang et al., 2024）</li>
<li><strong>LongVideoBench</strong>（Wu et al., 2024a）</li>
<li><strong>EgoSchema</strong>（Mangalam et al., 2023）</li>
<li><strong>PerceptionTest</strong>（Patraucean et al., 2024）</li>
<li><strong>MLVU</strong>（Zhou et al., 2024）</li>
<li><strong>LVBench</strong>（Wang et al., 2024g）</li>
<li><strong>TempCompass</strong>（Liu et al., 2024c）</li>
<li><strong>Charades-STA</strong>（Gao et al., 2017）</li>
</ul>
<img src="/2025/03/11/Qwen2-5VL%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%E4%B8%8E%E6%80%BB%E7%BB%93/image-20250314144415902.png" class="" title="image-20250314144415902">

<p><strong>领先的长视频理解能力：</strong></p>
<p>在评估<strong>长视频理解</strong>的LVBench和MLVU基准测试中，Qwen2.5-VL-72B <strong>显著超越 GPT-4o</strong>，表现出<strong>卓越的长时视频推理和问答能力</strong>。</p>
<p><strong>时间敏感视频理解的突破：</strong></p>
<p>Qwen2.5-VL 采用 <strong>同步MRoPE（Synchronized MRoPE）</strong> 技术，增强了模型在<strong>时间敏感视频理解</strong>方面的能力，包括：</p>
<ul>
<li><strong>时间戳引用（timestamp referencing）</strong></li>
<li><strong>时间定位（temporal grounding）</strong></li>
<li><strong>密集字幕生成（dense captioning）</strong></li>
<li><strong>其他视频推理功能</strong></li>
</ul>
<p><strong>精准的视频事件定位能力：</strong></p>
<p>在 <strong>Charades-STA 数据集</strong>（用于评估 AI <strong>准确定位视频中的事件或活动</strong>的能力）上，Qwen2.5-VL-72B 取得了 <strong>50.9 mIoU</strong> 的优秀成绩，<strong>超越 GPT-4o</strong>。</p>
<p><strong>视频处理限制：</strong></p>
<p>在所有基准测试中，我们限制 <strong>每个视频的最大分析帧数为768</strong>，并确保<strong>视频 token总数不超过 24,576</strong>，以保证高效计算。</p>
<img src="/2025/03/11/Qwen2-5VL%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%E4%B8%8E%E6%80%BB%E7%BB%93/image-20250314144806604.png" class="" title="image-20250314144806604">

<h4 id="3-3-5-智能体（Agent）"><a href="#3-3-5-智能体（Agent）" class="headerlink" title="3.3.5 智能体（Agent）"></a>3.3.5 智能体（Agent）</h4><p>多模态模型的 <strong>智能体能力</strong>（Agent Capabilities）至关重要，它使模型能够 <strong>有效地与现实世界设备交互</strong>。我们从多个方面评估了 <strong>Qwen2.5-VL 的智能体能力</strong>。</p>
<p><strong>GUI 元素定位能力评估</strong></p>
<ul>
<li><strong>ScreenSpot（Cheng et al., 2024）</strong></li>
<li><strong>ScreenSpot Pro（Li et al., 2025a）</strong></li>
</ul>
<p><strong>离线评估（Offline Evaluation）</strong></p>
<ul>
<li><strong>Android Control（Li et al., 2024f）</strong></li>
</ul>
<p><strong>在线评估（Online Evaluation）</strong></p>
<ul>
<li><strong>AndroidWorld（Rawles et al., 2024）</strong></li>
<li><strong>MobileMiniWob++（Rawles et al., 2024）</strong></li>
<li><strong>OSWorld（Xie et al., 2025）</strong></li>
</ul>
<p><strong>模型对比</strong></p>
<p>我们将 <strong>Qwen2.5-VL-72B</strong> 与 <strong>其他顶级模型</strong> 进行了对比，包括：</p>
<ul>
<li><strong>GPT-4o（OpenAI, 2024）</strong></li>
<li><strong>Gemini 2.0（Deepmind, 2024）</strong></li>
<li><strong>Claude（Anthropic, 2024b）</strong></li>
<li><strong>Aguvis-72B（Xu et al., 2024）</strong></li>
<li><strong>Qwen2-VL-72B（Wang et al., 2024e）</strong></li>
</ul>
<p>评估结果见<strong>表 9</strong>。</p>
<p><strong>Qwen2.5-VL-72B 在 GUI 定位基准测试中的卓越表现</strong></p>
<ul>
<li>在 <strong>ScreenSpot 基准测试</strong> 中，Qwen2.5-VL-72B <strong>达到了 87.1% 的准确率</strong>，显著领先 <strong>Gemini 2.0（84.0%）和 Claude（83.0%）</strong>。</li>
<li>在 <strong>ScreenSpot Pro 基准测试</strong> 中，Qwen2.5-VL-72B <strong>达到了 43.6% 的准确率</strong>，<strong>远超</strong> Aguvis-72B（23.6%）和其前代 Qwen2-VL-72B（1.6%）。</li>
</ul>
<p>这些出色的 <strong>GUI 元素定位能力</strong> 使得 <strong>Qwen2.5-VL-72B</strong> 在 <strong>所有离线评估任务</strong> 中都 <strong>大幅领先</strong> 其他基线模型。</p>
<p><strong>在线评估中的出色表现：</strong></p>
<p>在 <strong>AndroidWorld 和 MobileMiniWob++</strong> 任务中，<strong>部分基线模型</strong> 由于 <strong>有限的 GUI 定位能力</strong>，难以完成任务。因此，我们采用 <strong>Set-of-Mark（SoM）</strong> 方法为这些模型提供辅助标记输入。</p>
<p><strong>主要发现：</strong></p>
<ul>
<li><strong>Qwen2.5-VL-72B 在 AndroidWorld 和 MobileMiniWob++ 任务中显著超越基线模型</strong>。</li>
<li><strong>在 OSWorld 任务中，即使不借助辅助标记，Qwen2.5-VL-72B 也能达到与基线模型相当的性能</strong>。</li>
</ul>
<p>这一结果表明：<br>  <strong>Qwen2.5-VL-72B 具备强大的环境适应能力</strong>，可以在<strong>真实且动态的环境</strong>中作为<strong>智能体（Agent）执行任务</strong>，无需额外辅助信息。</p>
<img src="/2025/03/11/Qwen2-5VL%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%E4%B8%8E%E6%80%BB%E7%BB%93/image-20250314155533200.png" class="" title="image-20250314155533200">

<hr>
<h2 id="4-结论"><a href="#4-结论" class="headerlink" title="4 结论"></a>4 结论</h2><p>我们推出了 <strong>Qwen2.5-VL</strong>，这是一款 <strong>最先进的视觉-语言（Vision-Language）模型系列</strong>，在 <strong>多模态理解和交互方面</strong> 取得了 <strong>重大突破</strong>。</p>
<p>Qwen2.5-VL 具备 <strong>增强的视觉识别、目标定位、文档解析以及长视频理解能力</strong>，能够在 <strong>静态与动态任务</strong> 中均表现出色。</p>
<p><strong>核心技术创新</strong></p>
<p>✅ <strong>原生动态分辨率处理（Dynamic-Resolution Processing）</strong> 和 <strong>绝对时间编码（Absolute Time Encoding）</strong>，确保对多种输入类型的稳健处理。<br> ✅ <strong>Window Attention 机制</strong>，在 <strong>降低计算成本</strong> 的同时，仍 <strong>保持高分辨率的精准解析</strong>。</p>
<p><strong>广泛的应用场景</strong></p>
<p>Qwen2.5-VL 适用于 <strong>从边缘 AI 设备到高性能计算（HPC）等多种场景</strong>。</p>
<ul>
<li><strong>旗舰模型 Qwen2.5-VL-72B</strong>：<br> 📌 <strong>在文档和图表理解任务上匹敌甚至超越</strong> <strong>GPT-4o 和 Claude 3.5 Sonnet</strong>。<br> 📌 在 <strong>纯文本任务上仍保持强劲性能</strong>。</li>
<li><strong>小型模型 Qwen2.5-VL-7B 和 Qwen2.5-VL-3B</strong>：<br> 📌 在相同规模的竞争对手中表现更优，兼顾 <strong>高效性与多功能性</strong>。</li>
</ul>
<p><strong>设立新标杆，推动智能交互</strong></p>
<p>Qwen2.5-VL <strong>重新定义了视觉-语言模型的行业基准</strong>，在 <strong>泛化能力</strong> 和<strong>任务执行能力</strong>上均表现卓越。其 <strong>创新突破</strong>为<strong>更智能、更具交互性的 AI 系统</strong>奠定了基础，进一步<strong>拉近AI感知能力与真实世界应用之间的距离</strong>。</p>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h3 id="Vit"><a href="#Vit" class="headerlink" title="Vit"></a>Vit</h3><p><strong>Vision Transformer (ViT) 是具体算法还是一类算法？</strong></p>
<p>简单来说，<strong>Vision Transformer（ViT）</strong> 是 <strong>一种具体的算法</strong>，但它也代表了一类<strong>基于 Transformer 结构的视觉处理方法</strong>。</p>
<h4 id="ViT是什么？"><a href="#ViT是什么？" class="headerlink" title="ViT是什么？"></a><strong>ViT是什么？</strong></h4><p>ViT 是 <strong>一种用于处理图像的深度学习模型</strong>，它由 Google 在 2020 年提出（论文 “<a href="https://arxiv.org/abs/2010.11929">An Image is Worth 16x16 Words</a>“）。<br>它的核心思想是：<strong>用 Transformer 代替 CNN 进行图像处理</strong>，从而带来更强的全局信息建模能力。</p>
<blockquote>
<p><strong>类比</strong>：<br>传统的 CNN（卷积神经网络）就像<strong>看局部细节</strong>，一块一块地分析图片，而 ViT 更像<strong>从整体来看图</strong>，一次性理解整个画面。</p>
</blockquote>
<h4 id="ViT-的核心原理"><a href="#ViT-的核心原理" class="headerlink" title="ViT 的核心原理"></a><strong>ViT 的核心原理</strong></h4><p>ViT 其实借鉴了 NLP（自然语言处理）中的 Transformer 结构，但对图像数据做了一些特别的处理：</p>
<ol>
<li><strong>把图片切成小块（Patch Embedding）</strong><ul>
<li>假设输入图片是 <strong>256×256 像素</strong>，ViT 会把它<strong>切割成多个 16×16 小块</strong>，然后把这些小块转换成向量。</li>
<li><strong>类比</strong>：就像把一张照片分成多个拼图块。</li>
</ul>
</li>
<li><strong>用 Transformer 处理这些小块</strong><ul>
<li>这些小块的向量会输入 Transformer，经过<strong>自注意力（Self-Attention）</strong> 机制计算它们之间的关系。</li>
<li><strong>类比</strong>：就像在阅读一段文章时，每个词都可以和其他词有联系，ViT 也能理解每个图像块与其他块的关系。</li>
</ul>
</li>
<li><strong>最后做分类或其他任务</strong><ul>
<li>经过 Transformer 处理后，ViT 会输出一个结果，比如“这张图片里有一只猫”或者“这是某个人的照片”。</li>
</ul>
</li>
</ol>
<h4 id="ViT-和-CNN（传统卷积神经网络）的对比"><a href="#ViT-和-CNN（传统卷积神经网络）的对比" class="headerlink" title="ViT 和 CNN（传统卷积神经网络）的对比"></a><strong>ViT 和 CNN（传统卷积神经网络）的对比</strong></h4><table>
<thead>
<tr>
<th><strong>对比项</strong></th>
<th><strong>CNN（卷积神经网络）</strong></th>
<th><strong>ViT（视觉 Transformer）</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>处理方式</strong></td>
<td>逐层卷积提取局部特征</td>
<td>直接学习全局关系</td>
</tr>
<tr>
<td><strong>适合的任务</strong></td>
<td>小数据量、标准视觉任务</td>
<td>大数据量、复杂视觉任务</td>
</tr>
<tr>
<td><strong>计算量</strong></td>
<td>较小，训练快</td>
<td>计算量大，需要更强硬件</td>
</tr>
<tr>
<td><strong>依赖数据量</strong></td>
<td>小数据也能训练得不错</td>
<td>需要大量数据（如 ImageNet）</td>
</tr>
</tbody></table>
<p><strong>总结</strong>：</p>
<ul>
<li>CNN 适合<strong>小数据集</strong>，比如检测人脸、识别车牌等。</li>
<li>ViT 更适合<strong>大规模数据</strong>，比如理解复杂图片、自动驾驶等。</li>
</ul>
<h4 id="ViT-只是一种算法，还是一类算法？"><a href="#ViT-只是一种算法，还是一类算法？" class="headerlink" title="ViT 只是一种算法，还是一类算法？"></a><strong>ViT 只是一种算法，还是一类算法？</strong></h4><p>ViT 本身是<strong>一个具体的算法</strong>，但由于它的成功，现在很多变种都基于 ViT 改进，比如：</p>
<ul>
<li><strong>DeiT</strong>（Data-efficient ViT）：优化数据使用，减少训练需求</li>
<li><strong>Swin Transformer</strong>：增加层次结构，提高性能</li>
<li><strong>BEiT</strong>（BERT for images）：借鉴 NLP 预训练方法，提高效果</li>
</ul>
<p>因此，ViT <strong>既是一种具体的算法，也可以看作是 Transformer 视觉模型的代表</strong>。</p>
<h4 id="适合小白的总结"><a href="#适合小白的总结" class="headerlink" title="适合小白的总结"></a><strong>适合小白的总结</strong></h4><ul>
<li>ViT 是用 Transformer 来分析图像的模型，相比 CNN 能更好地理解全局信息。</li>
<li>但是它需要<strong>大量数据和计算资源</strong>，所以一般用于大规模视觉任务。</li>
<li>ViT 本身是<strong>一个具体的算法</strong>，但它的思想已经影响了一大类<strong>基于 Transformer 的视觉算法</strong>。</li>
</ul>
]]></content>
      <categories>
        <category>theory</category>
      </categories>
      <tags>
        <tag>llm</tag>
        <tag>qwen2.5</tag>
        <tag>qwen2.5 vl</tag>
      </tags>
  </entry>
  <entry>
    <title>Qwen3聊天模板(chat_template)解析</title>
    <url>/2025/05/07/Qwen3%E8%81%8A%E5%A4%A9%E6%A8%A1%E6%9D%BF-chat-template-%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><a href="https://github.com/QwenLM/Qwen3?tab=readme-ov-file">Qwen3</a>与2025.04.29发布，亮点包括：</p>
<ul>
<li><strong>各种尺寸的密集和混合专家 (MoE) 模型</strong>，有 0.6B、1.7B、4B、8B、14B、32B 和 30B-A3B、235B-A22B 可供选择。</li>
<li>思考模式（用于复杂的逻辑推理、数学和编码）和<strong>非思考模式</strong>（用于高效、通用的聊天）<strong>之间的无缝切换，确保在各种场景下实现最佳性能。</strong></li>
<li><strong>推理能力大幅增强</strong>，在数学、代码生成、常识逻辑推理等方面超越了之前的QwQ（思维模式）和Qwen2.5指令模型（非思维模式）。</li>
<li><strong>卓越的人类偏好一致性</strong>，擅长创意写作、角色扮演、多轮对话和指令遵循，提供更自然、更具吸引力和身临其境的对话体验。</li>
<li><strong>精通代理能力</strong>，能够以思考和非思考两种模式与外部工具精准集成，在基于代理的复杂任务中取得开源模型的领先性能。</li>
<li><strong>支持 100 多种语言和方言</strong>，具有强大的<strong>多语言指令跟踪和翻译</strong>能力。</li>
</ul>
<p>更多信息请见前两个参考链接。Qwen3我认为最亮眼的是思考模式和非思考模式之间的无缝切换，本文将基于目前（2025.05.07）能获得的信息摸索Qwen3是如何做到该点的。</p>
<span id="more"></span>

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="预训练（简单了解）"><a href="#预训练（简单了解）" class="headerlink" title="预训练（简单了解）"></a>预训练（简单了解）</h3><p>在预训练方面，Qwen3 的数据集相比 Qwen2.5 有了显著扩展。Qwen2.5是在 18 万亿个 token 上进行预训练的，而 Qwen3 使用的数据量几乎是其两倍，达到了约 36 万亿个 token，涵盖了 119 种语言和方言。为了构建这个庞大的数据集，我们不仅从网络上收集数据，还从 PDF 文档中提取信息。我们使用 Qwen2.5-VL 从这些文档中提取文本，并用 Qwen2.5 改进提取内容的质量。为了增加数学和代码数据的数量，我们利用 Qwen2.5-Math 和 Qwen2.5-Coder 这两个数学和代码领域的专家模型合成数据，合成了包括教科书、问答对以及代码片段等多种形式的数据。</p>
<p>预训练过程分为三个阶段。在第一阶段（S1），模型在超过 30 万亿个 token 上进行了预训练，上下文长度为 4K token。这一阶段为模型提供了基本的语言技能和通用知识。在第二阶段（S2），我们通过增加知识密集型数据（如 STEM、编程和推理任务）的比例来改进数据集，随后模型又在额外的 5 万亿个 token 上进行了预训练。在最后阶段，我们使用高质量的长上下文数据将上下文长度扩展到 32K token，确保模型能够有效地处理更长的输入。</p>
<p>由于模型架构的改进、训练数据的增加以及更有效的训练方法，Qwen3 Dense 基础模型的整体性能与参数更多的Qwen2.5基础模型相当。例如，Qwen3-1.7B&#x2F;4B&#x2F;8B&#x2F;14B&#x2F;32B-Base 分别与 Qwen2.5-3B&#x2F;7B&#x2F;14B&#x2F;32B&#x2F;72B-Base 表现相当。特别是在 STEM、编码和推理等领域，Qwen3 Dense 基础模型的表现甚至超过了更大规模的 Qwen2.5 模型。对于 Qwen3 MoE 基础模型，它们在仅使用 10% 激活参数的情况下达到了与 Qwen2.5 Dense 基础模型相似的性能。这带来了训练和推理成本的显著节省。</p>
<hr>
<h3 id="后训练（重点了解）"><a href="#后训练（重点了解）" class="headerlink" title="后训练（重点了解）"></a>后训练（重点了解）</h3><img src="/2025/05/07/Qwen3%E8%81%8A%E5%A4%A9%E6%A8%A1%E6%9D%BF-chat-template-%E8%A7%A3%E6%9E%90/image-20250507144020609.png" class="" title="image-20250507144020609">

<p>为了开发能够同时具备思考推理和快速响应能力的混合模型，我们实施了一个四阶段的训练流程。该流程包括</p>
<ol>
<li>长思维链冷启动</li>
<li>长思维链强化学习</li>
<li>思维模式融合</li>
<li>通用强化学习</li>
</ol>
<p>在第一阶段，我们使用多样的的长思维链数据对模型进行了微调，涵盖了数学、代码、逻辑推理和 STEM 问题等多种任务和领域。这一过程旨在为模型配备基本的推理能力。</p>
<p>第二阶段的重点是大规模强化学习，利用基于规则的奖励来增强模型的探索和钻研能力。</p>
<p>在第三阶段，我们在一份包括长思维链数据和常用的指令微调数据的组合数据上对模型进行微调，将非思考模式整合到思考模型中。确保了推理和快速响应能力的无缝结合。</p>
<p>最后，在第四阶段，我们在包括指令遵循、格式遵循和 Agent 能力等在内的 20 多个通用领域的任务上应用了强化学习，以进一步增强模型的通用能力并纠正不良行为。</p>
<p>总结下来就是，在预训练得到Base模型后，直接进行长思维链数据的微调，然后利用基于规则的奖励来增强模型的探索和钻研能力（deepseek-R1那种的GRPO？），再接着进行所谓思维模式融合，<strong>即此次微调让其不输出&lt;think&gt;…&lt;\think&gt;或&lt;think&gt;与&lt;\think&gt;内的内容是空的（暂不确定）</strong>，最后进行通用强化学习，主要用于使回答符合人类偏好并无害，就得到了<code>Qwen3-235B-A22B</code>和<code>Qwen3-32B</code>。<br>那么有 0.6B、1.7B、4B、8B、14B和 30B-A3B模型是怎么得到的呢，哦，是通过<code>Qwen3-235B-A22B</code>和<code>Qwen3-32B</code>蒸馏的，本人猜测0.6B、1.7B、4B、8B、14B是Qwen3-32B蒸馏得到的，30B-A3B是Qwen3-235B-A22B蒸馏得到的。</p>
<blockquote>
<p>顺便一提，Qwen3-235B-A22B指的是总参数量235B，使用时激活参数22B。</p>
</blockquote>
<hr>
<h3 id="chat-template-聊天模板"><a href="#chat-template-聊天模板" class="headerlink" title="chat-template(聊天模板)"></a>chat-template(聊天模板)</h3><p>通过上面的有限信息并不能确认所谓思维模式融合具体是怎么做的（主要因为论文&#x2F;技术方案还没出来），那么咱们还能获得什么信息呢？那就是聊天模板，打开<a href="https://huggingface.co/Qwen/Qwen3-235B-A22B/tree/main">这个网页</a>，下滑到最后找到<code>tokenizer_config.json</code>，下载并打开它，滑到最后你会看到<code>chat_template</code>字段，<strong>你发送给LLM的问题会先被该模板处理然后再进行token化</strong>：</p>
<img src="/2025/05/07/Qwen3%E8%81%8A%E5%A4%A9%E6%A8%A1%E6%9D%BF-chat-template-%E8%A7%A3%E6%9E%90/image-20250507150253162.png" class="" title="image-20250507150253162">

<p>格式化后：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot;chat_template&quot;: </span><br><span class="line">&quot;&#123;%- if tools %&#125;</span><br><span class="line">    &#123;&#123;- &#x27;&lt;|im_start|&gt;system\n&#x27; &#125;&#125;</span><br><span class="line">    </span><br><span class="line">    &#123;%- if messages[0].role == &#x27;system&#x27; %&#125;</span><br><span class="line">        &#123;&#123;- messages[0].content + &#x27;\n\n&#x27; &#125;&#125;</span><br><span class="line">    &#123;%- endif %&#125;</span><br><span class="line">    </span><br><span class="line">    &#123;&#123;- \&quot;# Tools\n\nYou may call one or more functions to assist with the user query.\n\nYou are provided with function signatures within &lt;tools&gt;&lt;/tools&gt; XML tags:\n&lt;tools&gt;\&quot; &#125;&#125;</span><br><span class="line">    </span><br><span class="line">    &#123;%- for tool in tools %&#125;</span><br><span class="line">        &#123;&#123;- \&quot;\n\&quot; &#125;&#125;</span><br><span class="line">        &#123;&#123;- tool | tojson &#125;&#125;</span><br><span class="line">    &#123;%- endfor %&#125;</span><br><span class="line">    </span><br><span class="line">    &#123;&#123;- \&quot;\n&lt;/tools&gt;\n\nFor each function call, return a json object with function name and arguments within &lt;tool_call&gt;&lt;/tool_call&gt; XML tags:\n&lt;tool_call&gt;\n&#123;\\\&quot;name\\\&quot;: &lt;function-name&gt;, \\\&quot;arguments\\\&quot;: &lt;args-json-object&gt;&#125;\n&lt;/tool_call&gt;&lt;|im_end|&gt;\n\&quot; &#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;%- else %&#125;</span><br><span class="line"></span><br><span class="line">    &#123;%- if messages[0].role == &#x27;system&#x27; %&#125;</span><br><span class="line">        &#123;&#123;- &#x27;&lt;|im_start|&gt;system\n&#x27; + messages[0].content + &#x27;&lt;|im_end|&gt;\n&#x27; &#125;&#125;</span><br><span class="line">    &#123;%- endif %&#125;</span><br><span class="line"></span><br><span class="line">&#123;%- endif %&#125;</span><br><span class="line"></span><br><span class="line">&#123;%- set ns = namespace(multi_step_tool=true, last_query_index=messages|length - 1) %&#125;</span><br><span class="line"></span><br><span class="line">&#123;%- for message in messages[::-1] %&#125;</span><br><span class="line">    &#123;%- set index = (messages|length - 1) - loop.index0 %&#125;</span><br><span class="line"></span><br><span class="line">&#123;%- if ns.multi_step_tool and message.role == \&quot;user\&quot; and not(message.content.startswith(&#x27;&lt;tool_response&gt;&#x27;) and message.content.endswith(&#x27;&lt;/tool_response&gt;&#x27;)) %&#125;</span><br><span class="line">        &#123;%- set ns.multi_step_tool = false %&#125;</span><br><span class="line">        &#123;%- set ns.last_query_index = index %&#125;</span><br><span class="line">    &#123;%- endif %&#125;</span><br><span class="line"></span><br><span class="line">&#123;%- endfor %&#125;</span><br><span class="line"></span><br><span class="line">&#123;%- for message in messages %&#125;</span><br><span class="line">    &#123;%- if (message.role == \&quot;user\&quot;) or (message.role == \&quot;system\&quot; and not loop.first) %&#125;</span><br><span class="line">        &#123;&#123;- &#x27;&lt;|im_start|&gt;&#x27; + message.role + &#x27;\n&#x27; + message.content + &#x27;&lt;|im_end|&gt;&#x27; + &#x27;\n&#x27; &#125;&#125;</span><br><span class="line">    &#123;%- elif message.role == \&quot;assistant\&quot; %&#125;</span><br><span class="line">        &#123;%- set content = message.content %&#125;</span><br><span class="line">        &#123;%- set reasoning_content = &#x27;&#x27; %&#125;</span><br><span class="line">        &#123;%- if message.reasoning_content is defined and message.reasoning_content is not none %&#125;</span><br><span class="line">            &#123;%- set reasoning_content = message.reasoning_content %&#125;</span><br><span class="line">        &#123;%- else %&#125;</span><br><span class="line">            &#123;%- if &#x27;&lt;/think&gt;&#x27; in message.content %&#125;</span><br><span class="line">                &#123;%- set content = message.content.split(&#x27;&lt;/think&gt;&#x27;)[-1].lstrip(&#x27;\n&#x27;) %&#125;</span><br><span class="line">                &#123;%- set reasoning_content = message.content.split(&#x27;&lt;/think&gt;&#x27;)[0].rstrip(&#x27;\n&#x27;).split(&#x27;&lt;think&gt;&#x27;)[-1].lstrip(&#x27;\n&#x27;) %&#125;</span><br><span class="line">            &#123;%- endif %&#125;</span><br><span class="line">        &#123;%- endif %&#125;</span><br><span class="line">        &#123;%- if loop.index0 &gt; ns.last_query_index %&#125;</span><br><span class="line">            &#123;%- if loop.last or (not loop.last and reasoning_content) %&#125;</span><br><span class="line">                &#123;&#123;- &#x27;&lt;|im_start|&gt;&#x27; + message.role + &#x27;\n&lt;think&gt;\n&#x27; + reasoning_content.strip(&#x27;\n&#x27;) + &#x27;\n&lt;/think&gt;\n\n&#x27; + content.lstrip(&#x27;\n&#x27;) &#125;&#125;</span><br><span class="line">            &#123;%- else %&#125;</span><br><span class="line">                &#123;&#123;- &#x27;&lt;|im_start|&gt;&#x27; + message.role + &#x27;\n&#x27; + content &#125;&#125;</span><br><span class="line">            &#123;%- endif %&#125;</span><br><span class="line">        &#123;%- else %&#125;</span><br><span class="line">            &#123;&#123;- &#x27;&lt;|im_start|&gt;&#x27; + message.role + &#x27;\n&#x27; + content &#125;&#125;</span><br><span class="line">        &#123;%- endif %&#125;</span><br><span class="line">        &#123;%- if message.tool_calls %&#125;</span><br><span class="line">            &#123;%- for tool_call in message.tool_calls %&#125;</span><br><span class="line">                &#123;%- if (loop.first and content) or (not loop.first) %&#125;</span><br><span class="line">                    &#123;&#123;- &#x27;\n&#x27; &#125;&#125;</span><br><span class="line">                &#123;%- endif %&#125;</span><br><span class="line">                &#123;%- if tool_call.function %&#125;</span><br><span class="line">                    &#123;%- set tool_call = tool_call.function %&#125;</span><br><span class="line">                &#123;%- endif %&#125;</span><br><span class="line">                &#123;&#123;- &#x27;&lt;tool_call&gt;\n&#123;\&quot;name\&quot;: \&quot;&#x27; &#125;&#125;</span><br><span class="line">                &#123;&#123;- tool_call.name &#125;&#125;</span><br><span class="line">                &#123;&#123;- &#x27;\&quot;, \&quot;arguments\&quot;: &#x27; &#125;&#125;</span><br><span class="line">                &#123;%- if tool_call.arguments is string %&#125;</span><br><span class="line">                    &#123;&#123;- tool_call.arguments &#125;&#125;</span><br><span class="line">                &#123;%- else %&#125;</span><br><span class="line">                    &#123;&#123;- tool_call.arguments | tojson &#125;&#125;</span><br><span class="line">                &#123;%- endif %&#125;</span><br><span class="line">                &#123;&#123;- &#x27;&#125;\n&lt;/tool_call&gt;&#x27; &#125;&#125;</span><br><span class="line">            &#123;%- endfor %&#125;</span><br><span class="line">        &#123;%- endif %&#125;</span><br><span class="line">        &#123;&#123;- &#x27;&lt;|im_end|&gt;\n&#x27; &#125;&#125;</span><br><span class="line">    &#123;%- elif message.role == \&quot;tool\&quot; %&#125;</span><br><span class="line">        &#123;%- if loop.first or (messages[loop.index0 - 1].role != \&quot;tool\&quot;) %&#125;</span><br><span class="line">            &#123;&#123;- &#x27;&lt;|im_start|&gt;user&#x27; &#125;&#125;</span><br><span class="line">        &#123;%- endif %&#125;</span><br><span class="line">        &#123;&#123;- &#x27;\n&lt;tool_response&gt;\n&#x27; &#125;&#125;</span><br><span class="line">        &#123;&#123;- message.content &#125;&#125;</span><br><span class="line">        &#123;&#123;- &#x27;\n&lt;/tool_response&gt;&#x27; &#125;&#125;</span><br><span class="line">        &#123;%- if loop.last or (messages[loop.index0 + 1].role != \&quot;tool\&quot;) %&#125;</span><br><span class="line">            &#123;&#123;- &#x27;&lt;|im_end|&gt;\n&#x27; &#125;&#125;</span><br><span class="line">        &#123;%- endif %&#125;</span><br><span class="line">    &#123;%- endif %&#125;</span><br><span class="line">&#123;%- endfor %&#125;</span><br><span class="line">&#123;%- if add_generation_prompt %&#125;</span><br><span class="line">    &#123;&#123;- &#x27;&lt;|im_start|&gt;assistant\n&#x27; &#125;&#125;</span><br><span class="line">    &#123;%- if enable_thinking is defined and enable_thinking is false %&#125;</span><br><span class="line">        &#123;&#123;- &#x27;&lt;think&gt;\n\n&lt;/think&gt;\n\n&#x27; &#125;&#125;</span><br><span class="line">    &#123;%- endif %&#125;</span><br><span class="line">&#123;%- endif %&#125;&quot;</span><br></pre></td></tr></table></figure>



<p>我觉得<strong>有必要</strong>先看看<code>Qwen2.5</code>的<code>chat-template</code>，一步一步来，来到<a href="https://huggingface.co/Qwen/Qwen2.5-72B-Instruct/tree/main">这个网页</a>，划到最后，下载并打开<code>tokenizer_config.json</code>：</p>
<p><strong>格式化后：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;%- if tools %&#125;</span><br><span class="line"></span><br><span class="line">    &#123;&#123;- &#x27;&lt;|im_start|&gt;system\n&#x27; &#125;&#125;</span><br><span class="line">    </span><br><span class="line">    &#123;%- if messages[0][&#x27;role&#x27;] == &#x27;system&#x27; %&#125;</span><br><span class="line">        &#123;&#123;- messages[0][&#x27;content&#x27;] &#125;&#125;</span><br><span class="line">    &#123;%- else %&#125;</span><br><span class="line">       &#123;&#123;- &#x27;You are Qwen, created by Alibaba Cloud. You are a helpful assistant.&#x27; &#125;&#125;</span><br><span class="line">    &#123;%- endif %&#125;</span><br><span class="line">    </span><br><span class="line">    &#123;&#123;- &quot;\n\n# Tools\n\nYou may call one or more functions to assist with the user query.\n\nYou are provided with function signatures within &lt;tools&gt;&lt;/tools&gt; XML tags:\n&lt;tools&gt;&quot; &#125;&#125;</span><br><span class="line">    </span><br><span class="line">    &#123;%- for tool in tools %&#125;</span><br><span class="line">        &#123;- &quot;\n&quot; &#125;&#125;</span><br><span class="line">        &#123;&#123;- tool | tojson &#125;&#125;</span><br><span class="line">    &#123;%- endfor %&#125;</span><br><span class="line">    </span><br><span class="line">    &#123;&#123;- &quot;\n&lt;/tools&gt;\n\nFor each function call, return a json object with function name and arguments within &lt;tool_call&gt;&lt;/tool_call&gt; XML tags:\n&lt;tool_call&gt;\n&#123;\&quot;name\&quot;: &lt;function-name&gt;, \&quot;arguments\&quot;: &lt;args-json-object&gt;&#125;\n&lt;/tool_call&gt;&lt;|im_end|&gt;\n&quot; &#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;%- else %&#125;</span><br><span class="line">    </span><br><span class="line">    &#123;%- if messages[0][&#x27;role&#x27;] == &#x27;system&#x27; %&#125;</span><br><span class="line">        &#123;&#123;- &#x27;&lt;|im_start|&gt;system\n&#x27; + messages[0][&#x27;content&#x27;] + &#x27;&lt;|im_end|&gt;\n&#x27; &#125;&#125;</span><br><span class="line">    &#123;%- else %&#125;</span><br><span class="line">        &#123;&#123;- &#x27;&lt;|im_start|&gt;system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.&lt;|im_end|&gt;\n&#x27; &#125;&#125;</span><br><span class="line">    &#123;%- endif %&#125;</span><br><span class="line"></span><br><span class="line">&#123;%- endif %&#125;</span><br><span class="line"></span><br><span class="line">&#123;%- for message in messages %&#125;</span><br><span class="line">    </span><br><span class="line">    &#123;%- if (message.role == &quot;user&quot;) or (message.role == &quot;system&quot; and not loop.first) or (message.role == &quot;assistant&quot; and not message.tool_calls) %&#125;  </span><br><span class="line">        &#123;&#123;- &#x27;&lt;|im_start|&gt;&#x27; + message.role + &#x27;\n&#x27; + message.content + &#x27;&lt;|im_end|&gt;\n&#x27; &#125;&#125;</span><br><span class="line">    &#123;%- elif message.role == &quot;assistant&quot; %&#125;</span><br><span class="line">        </span><br><span class="line">        &#123;&#123;- &#x27;&lt;|im_start|&gt;&#x27; + message.role &#125;&#125;</span><br><span class="line">        </span><br><span class="line">        &#123;%- if message.content %&#125;</span><br><span class="line">            </span><br><span class="line">            &#123;&#123;- &#x27;\n&#x27; + message.content &#125;&#125;</span><br><span class="line">        </span><br><span class="line">        &#123;%- endif %&#125;</span><br><span class="line">        </span><br><span class="line">        &#123;%- for tool_call in message.tool_calls %&#125;</span><br><span class="line">            </span><br><span class="line">            &#123;%- if tool_call.function is defined %&#125;</span><br><span class="line">                &#123;%- set tool_call = tool_call.function %&#125;</span><br><span class="line">            &#123;%- endif %&#125;</span><br><span class="line">            </span><br><span class="line">            &#123;&#123;- &#x27;\n&lt;tool_call&gt;\n&#123;\&quot;name\&quot;: \&quot;&#x27; &#125;&#125;</span><br><span class="line">            </span><br><span class="line">            &#123;&#123;- tool_call.name &#125;&#125;</span><br><span class="line">            </span><br><span class="line">            &#123;&#123;- &#x27;\&quot;, \&quot;arguments\&quot;: &#x27; &#125;&#125;</span><br><span class="line">            </span><br><span class="line">            &#123;&#123;- tool_call.arguments | tojson &#125;&#125;</span><br><span class="line">            </span><br><span class="line">            &#123;&#123;- &#x27;&#125;\n&lt;/tool_call&gt;&#x27; &#125;&#125;</span><br><span class="line">        </span><br><span class="line">        &#123;%- endfor %&#125;</span><br><span class="line">        </span><br><span class="line">        &#123;&#123;- &#x27;&lt;|im_end|&gt;\n&#x27; &#125;&#125;</span><br><span class="line">    </span><br><span class="line">    &#123;%- elif message.role == &quot;tool&quot; %&#125;</span><br><span class="line">        </span><br><span class="line">        &#123;%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != &quot;tool&quot;) %&#125;</span><br><span class="line">            &#123;&#123;- &#x27;&lt;|im_start|&gt;user&#x27; &#125;&#125;</span><br><span class="line">        &#123;%- endif %&#125;</span><br><span class="line">        </span><br><span class="line">        &#123;&#123;- &#x27;\n&lt;tool_response&gt;\n&#x27; &#125;&#125;</span><br><span class="line">        </span><br><span class="line">        &#123;&#123;- message.content &#125;&#125;</span><br><span class="line">        </span><br><span class="line">        &#123;&#123;- &#x27;\n&lt;/tool_response&gt;&#x27; &#125;&#125;</span><br><span class="line">        </span><br><span class="line">        &#123;%- if loop.last or (messages[loop.index0 + 1].role != &quot;tool&quot;) %&#125;        </span><br><span class="line">            &#123;&#123;- &#x27;&lt;|im_end|&gt;\n&#x27; &#125;&#125;</span><br><span class="line">        &#123;%- endif %&#125;</span><br><span class="line">        </span><br><span class="line">    &#123;%- endif %&#125;</span><br><span class="line">&#123;%- endfor %&#125;</span><br><span class="line"></span><br><span class="line">&#123;%- if add_generation_prompt %&#125;</span><br><span class="line">    &#123;&#123;- &#x27;&lt;|im_start|&gt;assistant\n&#x27; &#125;&#125;</span><br><span class="line">&#123;%- endif %&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>① 判断是否有工具 <code>if tools</code></strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;%- if tools %&#125;</span><br><span class="line">    &lt;|im_start|&gt;system\n</span><br><span class="line">    &#123;%- if messages[0][&#x27;role&#x27;] == &#x27;system&#x27; %&#125;</span><br><span class="line">        &#123;&#123;- messages[0][&#x27;content&#x27;] &#125;&#125;  &#123;# 插入第一条系统消息内容 #&#125;</span><br><span class="line">    &#123;%- else %&#125;</span><br><span class="line">        You are Qwen, created by Alibaba Cloud. You are a helpful assistant.  &#123;# 默认系统提示 #&#125;</span><br><span class="line">    &#123;%- endif %&#125;</span><br><span class="line">    \n\n# Tools\n\nYou may call one or more functions...  &#123;# 工具调用说明 #&#125;</span><br><span class="line">    &lt;tools&gt;</span><br><span class="line">    &#123;%- for tool in tools %&#125;</span><br><span class="line">        \n&#123;&#123;- tool | tojson &#125;&#125;  &#123;# 遍历工具列表，转为JSON格式 #&#125;</span><br><span class="line">    &#123;%- endfor %&#125;</span><br><span class="line">    \n&lt;/tools&gt;\n\nFor each function call...  &#123;# 工具调用格式要求 #&#125;</span><br><span class="line">    &lt;tool_call&gt;\n&#123;&quot;name&quot;: &lt;function-name&gt;, &quot;arguments&quot;: &lt;args-json-object&gt;&#125;\n&lt;/tool_call&gt;&lt;|im_end|&gt;\n</span><br><span class="line">&#123;%- else %&#125;</span><br><span class="line">    &#123;# 无工具时的系统消息处理 #&#125;</span><br><span class="line">    &#123;%- if messages[0][&#x27;role&#x27;] == &#x27;system&#x27; %&#125;</span><br><span class="line">        &lt;|im_start|&gt;system\n&#123;&#123; messages[0][&#x27;content&#x27;] &#125;&#125;&lt;|im_end|&gt;\n</span><br><span class="line">    &#123;%- else %&#125;</span><br><span class="line">        &lt;|im_start|&gt;system\nYou are Qwen...&lt;|im_end|&gt;\n  &#123;# 默认系统消息 #&#125;</span><br><span class="line">    &#123;%- endif %&#125;</span><br><span class="line">&#123;%- endif %&#125;</span><br></pre></td></tr></table></figure>

<p>如果有 tools（函数工具定义）：</p>
<ul>
<li><p>输出：</p>
<ul>
<li><code>&lt;|im_start|&gt;system\n</code> 表示 system 角色开头。</li>
<li>如果第一条消息是 system，输出它的内容。</li>
<li>否则，用默认系统提示：<br> <code>You are Qwen, created by Alibaba Cloud. You are a helpful assistant.</code></li>
</ul>
</li>
<li><p>接着输出：</p>
<ul>
<li><code># Tools</code>：人工标记，告诉模型后面是工具定义。</li>
<li><code>&lt;tools&gt;...&lt;/tools&gt;</code>：XML标签包住工具签名（函数定义）。</li>
<li>每个 tool 用 JSON 格式化进来。</li>
</ul>
</li>
<li><p>最后指示模型：</p>
<ul>
<li><p>对每个函数调用，需要用 <code>&lt;tool_call&gt;...&lt;/tool_call&gt;</code> 包住 JSON：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;tool_call&gt;</span><br><span class="line">&#123;&quot;name&quot;: &lt;function-name&gt;, &quot;arguments&quot;: &lt;args-json-object&gt;&#125;</span><br><span class="line">&lt;/tool_call&gt;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<p>如果没有 tools：</p>
<ul>
<li>仍然输出 <code>&lt;|im_start|&gt;system\n</code>。</li>
<li>输出首条 system 消息或默认 system 提示。</li>
<li>用 <code>&lt;|im_end|&gt;</code> 封住。</li>
</ul>
<hr>
<p><strong>② 遍历每条消息 <code>for message in messages</code></strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;%- for message in messages %&#125;</span><br><span class="line">    &#123;# 用户消息、非首条系统消息、无工具调用的助手消息 #&#125;</span><br><span class="line">    &#123;%- if (message.role == &quot;user&quot;) or (message.role == &quot;system&quot; and not loop.first) or (message.role == &quot;assistant&quot; and not message.tool_calls) %&#125;</span><br><span class="line">        &lt;|im_start|&gt;&#123;&#123; message.role &#125;&#125;\n&#123;&#123; message.content &#125;&#125;&lt;|im_end|&gt;\n</span><br></pre></td></tr></table></figure>

<p>遍历 <code>messages</code> 列表：</p>
<ul>
<li><p>如果是：</p>
<ul>
<li><p>用户 (<code>user</code>)</p>
</li>
<li><p>非首条的 system (<code>system</code>)</p>
</li>
<li><p>没调用工具的助手 (<code>assistant</code>)<br> → 直接输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;|im_start|&gt;role</span><br><span class="line">content</span><br><span class="line">&lt;|im_end|&gt;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;# 含工具调用的助手消息 #&#125;</span><br><span class="line">&#123;%- elif message.role == &quot;assistant&quot; %&#125;</span><br><span class="line">    &lt;|im_start|&gt;&#123;&#123; message.role &#125;&#125;</span><br><span class="line">    &#123;%- if message.content %&#125;</span><br><span class="line">        \n&#123;&#123; message.content &#125;&#125;  &#123;# 插入文本回复（可选） #&#125;</span><br><span class="line">    &#123;%- endif %&#125;</span><br><span class="line">    &#123;%- for tool_call in message.tool_calls %&#125;</span><br><span class="line">        \n&lt;tool_call&gt;\n&#123;&quot;name&quot;: &quot;&#123;&#123; tool_call.name &#125;&#125;&quot;, &quot;arguments&quot;: &#123;&#123; tool_call.arguments | tojson &#125;&#125;&#125;\n&lt;/tool_call&gt;</span><br><span class="line">    &#123;%- endfor %&#125;</span><br><span class="line">    &lt;|im_end|&gt;\n</span><br></pre></td></tr></table></figure>

<ul>
<li><p>如果是助手 (<code>assistant</code>) ：</p>
<ul>
<li><p>开始：</p>
<figure class="highlight coq"><table><tr><td class="code"><pre><span class="line">&lt;|<span class="type">im_start</span>|<span class="type">&gt;assistant</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>如果有 <code>content</code>，也加进来。</p>
</li>
<li><p>遍历 <code>tool_calls</code>：</p>
<ul>
<li><p>如果是 <code>&#123;function: &#123;...&#125;&#125;</code>，先解包。</p>
</li>
<li><p>用：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;tool_call&gt;</span><br><span class="line">&#123;&quot;name&quot;: &quot;...&quot;, &quot;arguments&quot;: ...&#125;</span><br><span class="line">&lt;/tool_call&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>每个调用序列化为 JSON。</p>
</li>
</ul>
</li>
<li><p>结束：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;|im_end|&gt;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">    &#123;# 工具返回消息 #&#125;</span><br><span class="line">    &#123;%- elif message.role == &quot;tool&quot; %&#125;</span><br><span class="line">        &#123;%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != &quot;tool&quot;) %&#125;</span><br><span class="line">            &lt;|im_start|&gt;user  &#123;# 工具消息合并为一条用户消息 #&#125;</span><br><span class="line">        &#123;%- endif %&#125;</span><br><span class="line">        \n&lt;tool_response&gt;\n&#123;&#123; message.content &#125;&#125;\n&lt;/tool_response&gt;</span><br><span class="line">        &#123;%- if loop.last or (messages[loop.index0 + 1].role != &quot;tool&quot;) %&#125;</span><br><span class="line">            &lt;|im_end|&gt;\n</span><br><span class="line">        &#123;%- endif %&#125;</span><br><span class="line">&#123;%- endfor %&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><p>如果是工具 (<code>tool</code>) 响应：</p>
<ul>
<li><p>如果第一条或前一条不是 tool：</p>
<ul>
<li><p>加上：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;|im_start|&gt;user</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>加：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;tool_response&gt;</span><br><span class="line">content</span><br><span class="line">&lt;/tool_response&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>如果最后一条或后一条不是 tool：</p>
<ul>
<li><p>加上：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;|im_end|&gt;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;%- if add_generation_prompt %&#125;</span><br><span class="line">    &lt;|im_start|&gt;assistant\n  &#123;# 提示模型开始生成回复 #&#125;</span><br><span class="line">&#123;%- endif %&#125;</span><br></pre></td></tr></table></figure>

<p>③ 生成助手提示 <code>if add_generation_prompt</code></p>
<p>如果 <code>add_generation_prompt</code> 被激活：</p>
<ul>
<li><p>最后再加上：</p>
<figure class="highlight coq"><table><tr><td class="code"><pre><span class="line">&lt;|<span class="type">im_start</span>|<span class="type">&gt;assistant</span>\n</span><br></pre></td></tr></table></figure></li>
</ul>
<hr>
<p>☯<strong>不懂jinja语法，让ChatGpt等LLM给咱们按段转成Python语句以便解释和学习jinja语法吧：</strong>☯</p>
<p>1️⃣ 工具提示部分：</p>
<p><strong>jinja</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;%- if tools %&#125; </span><br><span class="line">    &#123;&#123;- &#x27;&lt;|im_start|&gt;system\n&#x27; &#125;&#125;</span><br><span class="line">    &#123;%- if messages[0].role == &#x27;system&#x27; %&#125;</span><br><span class="line">        &#123;&#123;- messages[0].content + &#x27;\n\n&#x27; &#125;&#125;</span><br><span class="line">    &#123;%- endif %&#125;</span><br><span class="line">    &#123;&#123;- &quot;# Tools\n\nYou may call one or more functions to assist with the user query.\n\nYou are provided with function signatures within &lt;tools&gt;&lt;/tools&gt; XML tags:\n&lt;tools&gt;&quot; &#125;&#125;</span><br><span class="line">    &#123;%- for tool in tools %&#125;</span><br><span class="line">        &#123;&#123;- &quot;\n&quot; &#125;&#125;</span><br><span class="line">        &#123;&#123;- tool | tojson &#125;&#125;</span><br><span class="line">    &#123;%- endfor %&#125;</span><br><span class="line">    &#123;&#123;- &quot;\n&lt;/tools&gt;\n\nFor each function call, return a json object with function name and arguments within &lt;tool_call&gt;&lt;/tool_call&gt; XML tags:\n&lt;tool_call&gt;\n&#123;\&quot;name\&quot;: &lt;function-name&gt;, \&quot;arguments\&quot;: &lt;args-json-object&gt;&#125;\n&lt;/tool_call&gt;&lt;|im_end|&gt;\n&quot; &#125;&#125;</span><br><span class="line">&#123;%- else %&#125;</span><br><span class="line">    &#123;%- if messages[0].role == &#x27;system&#x27; %&#125;</span><br><span class="line">        &#123;&#123;- &#x27;&lt;|im_start|&gt;system\n&#x27; + messages[0].content + &#x27;&lt;|im_end|&gt;\n&#x27; &#125;&#125;</span><br><span class="line">    &#123;%- endif %&#125;</span><br><span class="line">&#123;%- endif %&#125;</span><br></pre></td></tr></table></figure>

<p><strong>python</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">output = <span class="string">&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> tools:</span><br><span class="line">    output += <span class="string">&quot;&lt;|im_start|&gt;system\n&quot;</span></span><br><span class="line">    <span class="keyword">if</span> messages[<span class="number">0</span>][<span class="string">&#x27;role&#x27;</span>] == <span class="string">&#x27;system&#x27;</span>:</span><br><span class="line">        output += messages[<span class="number">0</span>][<span class="string">&#x27;content&#x27;</span>] + <span class="string">&#x27;\n\n&#x27;</span></span><br><span class="line">    output += (</span><br><span class="line">        <span class="string">&quot;# Tools\n\n&quot;</span></span><br><span class="line">        <span class="string">&quot;You may call one or more functions to assist with the user query.\n\n&quot;</span></span><br><span class="line">        <span class="string">&quot;You are provided with function signatures within &lt;tools&gt;&lt;/tools&gt; XML tags:\n&quot;</span></span><br><span class="line">        <span class="string">&quot;&lt;tools&gt;&quot;</span></span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">for</span> tool <span class="keyword">in</span> tools:</span><br><span class="line">        output += <span class="string">&quot;\n&quot;</span> + json.dumps(tool)</span><br><span class="line">    output += (</span><br><span class="line">        <span class="string">&quot;\n&lt;/tools&gt;\n\n&quot;</span></span><br><span class="line">        <span class="string">&quot;For each function call, return a json object with function name and arguments within &lt;tool_call&gt;&lt;/tool_call&gt; XML tags:\n&quot;</span></span><br><span class="line">        <span class="string">&quot;&lt;tool_call&gt;\n&#123;\&quot;name\&quot;: &lt;function-name&gt;, \&quot;arguments\&quot;: &lt;args-json-object&gt;&#125;\n&lt;/tool_call&gt;&lt;|im_end|&gt;\n&quot;</span></span><br><span class="line">    )</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">if</span> messages[<span class="number">0</span>][<span class="string">&#x27;role&#x27;</span>] == <span class="string">&#x27;system&#x27;</span>:</span><br><span class="line">        output += <span class="string">f&quot;&lt;|im_start|&gt;system\n<span class="subst">&#123;messages[<span class="number">0</span>][<span class="string">&#x27;content&#x27;</span>]&#125;</span>&lt;|im_end|&gt;\n&quot;</span></span><br></pre></td></tr></table></figure>

<p>📌 <strong>作用：</strong></p>
<ul>
<li>检查当前是否有提供 tools（函数签名）。</li>
<li>如果有：<ul>
<li>开始 <code>&lt;|im_start|&gt;system</code> 块，附加工具声明。</li>
<li>列出每个工具（用 <code>&lt;tool&gt;&lt;/tool&gt;</code> XML 包裹，用 JSON 格式）。</li>
<li>提示模型：调用工具时需要用 <code>&lt;tool_call&gt;&lt;/tool_call&gt;</code> XML 包裹，内容是 JSON 格式的 <code>&#123;&quot;name&quot;: ..., &quot;arguments&quot;: ...&#125;</code>。</li>
</ul>
</li>
<li>如果没工具，仅输出 system 消息（如果有）。</li>
</ul>
<p>✅ <strong>这段属于“初始化模型上下文”，特别是开放工具调用时用。</strong></p>
<p>2️⃣ 定义多轮工具调用</p>
<p>jinja:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;%- set ns = namespace(multi_step_tool=true, last_query_index=messages|length - 1) %&#125;</span><br><span class="line">&#123;%- for message in messages[::-1] %&#125;</span><br><span class="line">    &#123;%- set index = (messages|length - 1) - loop.index0 %&#125;</span><br><span class="line">    &#123;%- if ns.multi_step_tool and message.role == &quot;user&quot; and not(message.content.startswith(&#x27;&lt;tool_response&gt;&#x27;) and message.content.endswith(&#x27;&lt;/tool_response&gt;&#x27;)) %&#125;</span><br><span class="line">        &#123;%- set ns.multi_step_tool = false %&#125;</span><br><span class="line">        &#123;%- set ns.last_query_index = index %&#125;</span><br><span class="line">    &#123;%- endif %&#125;</span><br><span class="line">&#123;%- endfor %&#125;</span><br></pre></td></tr></table></figure>

<p><strong>python:</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ns = &#123;</span><br><span class="line">    <span class="string">&#x27;multi_step_tool&#x27;</span>: <span class="literal">True</span>,</span><br><span class="line">    <span class="string">&#x27;last_query_index&#x27;</span>: <span class="built_in">len</span>(messages) - <span class="number">1</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, message <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">reversed</span>(messages)):</span><br><span class="line">    index = (<span class="built_in">len</span>(messages) - <span class="number">1</span>) - i</span><br><span class="line">    <span class="keyword">if</span> ns[<span class="string">&#x27;multi_step_tool&#x27;</span>] <span class="keyword">and</span> message[<span class="string">&#x27;role&#x27;</span>] == <span class="string">&#x27;user&#x27;</span> <span class="keyword">and</span> <span class="keyword">not</span> (message[<span class="string">&#x27;content&#x27;</span>].startswith(<span class="string">&#x27;&lt;tool_response&gt;&#x27;</span>) <span class="keyword">and</span> message[<span class="string">&#x27;content&#x27;</span>].endswith(<span class="string">&#x27;&lt;/tool_response&gt;&#x27;</span>)):</span><br><span class="line">        ns[<span class="string">&#x27;multi_step_tool&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">        ns[<span class="string">&#x27;last_query_index&#x27;</span>] = index</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>📌 <strong>作用：</strong></p>
<ul>
<li>创建一个内部 <code>namespace</code>，用于存储：<ul>
<li><code>multi_step_tool</code> → 作为条件退出的标志位（倒序找第一个符合条件的user角色）</li>
<li><code>last_query_index</code> → 最后一条非工具响应的 user 消息索引</li>
</ul>
</li>
<li>逆序扫描消息：<ul>
<li>还在未找到符号条件的user角色（<code>multi_step_tool</code> 是 true）</li>
<li>当前消息是用户发的（<code>message.role == &quot;user&quot;</code>）</li>
<li>并且内容不是工具响应（不是 <code>&lt;tool_response&gt; ... &lt;/tool_response&gt;</code>）<ul>
<li>标记：multi_step_tool标志位为false（找到最后真正提问的位置）</li>
<li>保存这个位置到 <code>last_query_index</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>✅ 目的：<br> 找到倒数第一个“有效用户提问”（不是工具响应的用户 message）</p>
<p>✅ 用在哪里？<br> 后面拼装 assistant 内容时，决定：</p>
<ul>
<li>哪些 assistant 消息是多步工具调用后的回应（要带 <code>&lt;think&gt;</code> 标签）</li>
<li>哪些是普通 assistant 回复</li>
</ul>
<p>✅ 为什么要特别处理？<br> 因为在多轮工具调用中，assistant 可能回应很多次，但你只希望把和最新一轮用户提问相关的 assistant 回复特殊标记。</p>
<p>✅ <strong>这段是为后续判断 assistant 消息是否属于最后一轮交互做准备。</strong></p>
<hr>
<p>3️⃣消息遍历与格式化（核心部分）</p>
<p>(a) <strong>用户&#x2F;系统消息</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;%- for message in messages %&#125;</span><br><span class="line">    &#123;%- if (message.role == &quot;user&quot;) or (message.role == &quot;system&quot; and not loop.first) %&#125;</span><br><span class="line">        &lt;|im_start|&gt;&#123;&#123; message.role &#125;&#125;\n&#123;&#123; message.content &#125;&#125;&lt;|im_end|&gt;\n</span><br></pre></td></tr></table></figure>

<p><strong>python:</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> idx, message <span class="keyword">in</span> <span class="built_in">enumerate</span>(messages):</span><br><span class="line">    <span class="keyword">if</span> message[<span class="string">&#x27;role&#x27;</span>] == <span class="string">&#x27;user&#x27;</span> <span class="keyword">or</span> (message[<span class="string">&#x27;role&#x27;</span>] == <span class="string">&#x27;system&#x27;</span> <span class="keyword">and</span> idx != <span class="number">0</span>):</span><br><span class="line">        output += <span class="string">f&quot;&lt;|im_start|&gt;<span class="subst">&#123;message[<span class="string">&#x27;role&#x27;</span>]&#125;</span>\n<span class="subst">&#123;message[<span class="string">&#x27;content&#x27;</span>]&#125;</span>&lt;|im_end|&gt;\n&quot;</span></span><br></pre></td></tr></table></figure>

<p>用户消息或非首条系统消息，直接包裹为 <code>&lt;|im_start|&gt;&#123;role&#125;\n&#123;content&#125;&lt;|im_end|&gt;\n</code>。</p>
<p>(b)  <strong>助手消息（含工具调用）</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;%- elif message.role == &quot;assistant&quot; %&#125;</span><br><span class="line">    &#123;%- set content = message.content %&#125;</span><br><span class="line">    &#123;%- set reasoning_content = &#x27;&#x27; %&#125;</span><br><span class="line">    &#123;%- if message.reasoning_content is defined %&#125;</span><br><span class="line">        &#123;%- set reasoning_content = message.reasoning_content %&#125;</span><br><span class="line">    &#123;%- elif &#x27;&lt;/think&gt;&#x27; in message.content %&#125;</span><br><span class="line">        &#123;%- set content = message.content.split(&#x27;&lt;/think&gt;&#x27;)[-1].lstrip(&#x27;\n&#x27;) %&#125;</span><br><span class="line">        &#123;%- set reasoning_content = message.content.split(&#x27;&lt;think&gt;&#x27;)[-1].split(&#x27;&lt;/think&gt;&#x27;)[0].strip() %&#125;</span><br><span class="line">    &#123;%- endif %&#125;</span><br></pre></td></tr></table></figure>

<p><strong>python:</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">elif</span> message[<span class="string">&#x27;role&#x27;</span>] == <span class="string">&#x27;assistant&#x27;</span>:</span><br><span class="line">    content = message[<span class="string">&#x27;content&#x27;</span>]</span><br><span class="line">    reasoning_content = <span class="string">&#x27;&#x27;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;reasoning_content&#x27;</span> <span class="keyword">in</span> message <span class="keyword">and</span> message[<span class="string">&#x27;reasoning_content&#x27;</span>] <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        reasoning_content = message[<span class="string">&#x27;reasoning_content&#x27;</span>]</span><br><span class="line">    <span class="keyword">elif</span> <span class="string">&#x27;&lt;/think&gt;&#x27;</span> <span class="keyword">in</span> message[<span class="string">&#x27;content&#x27;</span>]:</span><br><span class="line">        parts = message[<span class="string">&#x27;content&#x27;</span>].split(<span class="string">&#x27;&lt;/think&gt;&#x27;</span>)</span><br><span class="line">        content = parts[-<span class="number">1</span>].lstrip(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">        reasoning_content = parts[<span class="number">0</span>].rstrip(<span class="string">&#x27;\n&#x27;</span>).split(<span class="string">&#x27;&lt;think&gt;&#x27;</span>)[-<span class="number">1</span>].lstrip(<span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>提取 <code>content</code> 和 <code>reasoning_content</code>（推理内容）</li>
<li>若消息显式定义 <code>reasoning_content</code>，直接使用</li>
<li>否则从 <code>&lt;think&gt;</code> 标签中解析。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;%- if loop.index0 &gt; ns.last_query_index %&#125;</span><br><span class="line">    &#123;%- if loop.last or (not loop.last and reasoning_content) %&#125;</span><br><span class="line">        &lt;|im_start|&gt;&#123;&#123; message.role &#125;&#125;\n&lt;think&gt;\n&#123;&#123; reasoning_content &#125;&#125;\n&lt;/think&gt;\n\n&#123;&#123; content &#125;&#125;</span><br><span class="line">    &#123;%- else %&#125;</span><br><span class="line">        &lt;|im_start|&gt;&#123;&#123; message.role &#125;&#125;\n&#123;&#123; content &#125;&#125;</span><br><span class="line">    &#123;%- endif %&#125;</span><br><span class="line">&#123;%- else %&#125;</span><br><span class="line">    &lt;|im_start|&gt;&#123;&#123; message.role &#125;&#125;\n&#123;&#123; content &#125;&#125;</span><br><span class="line">&#123;%- endif %&#125;</span><br></pre></td></tr></table></figure>

<p><strong>python:</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> idx &gt; ns[<span class="string">&#x27;last_query_index&#x27;</span>]:</span><br><span class="line">    <span class="keyword">if</span> idx == <span class="built_in">len</span>(messages) - <span class="number">1</span> <span class="keyword">or</span> (idx != <span class="built_in">len</span>(messages) - <span class="number">1</span> <span class="keyword">and</span> reasoning_content):</span><br><span class="line">        output += <span class="string">f&quot;&lt;|im_start|&gt;assistant\n&lt;think&gt;\n<span class="subst">&#123;reasoning_content.strip()&#125;</span>\n&lt;/think&gt;\n\n<span class="subst">&#123;content.lstrip()&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        output += <span class="string">f&quot;&lt;|im_start|&gt;assistant\n<span class="subst">&#123;content&#125;</span>&quot;</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    output += <span class="string">f&quot;&lt;|im_start|&gt;assistant\n<span class="subst">&#123;content&#125;</span>&quot;</span></span><br></pre></td></tr></table></figure>

<ul>
<li>如果是最后一条消息或包含推理内容，插入 <code>&lt;think&gt;</code> 标签；</li>
<li>否则直接输出内容。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;%- if message.tool_calls %&#125;</span><br><span class="line">    &#123;%- for tool_call in message.tool_calls %&#125;</span><br><span class="line">        \n&lt;tool_call&gt;\n&#123;&quot;name&quot;: &quot;&#123;&#123; tool_call.name &#125;&#125;&quot;, &quot;arguments&quot;: &#123;&#123; tool_call.arguments | tojson &#125;&#125;&#125;\n&lt;/tool_call&gt;</span><br><span class="line">    &#123;%- endfor %&#125;</span><br><span class="line">&#123;%- endif %&#125;</span><br><span class="line">&lt;|im_end|&gt;\n</span><br></pre></td></tr></table></figure>

<p><strong>python:</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="string">&#x27;tool_calls&#x27;</span> <span class="keyword">in</span> message:</span><br><span class="line">        <span class="keyword">for</span> tool_call <span class="keyword">in</span> message[<span class="string">&#x27;tool_calls&#x27;</span>]:</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;function&#x27;</span> <span class="keyword">in</span> tool_call:</span><br><span class="line">                tool_call = tool_call[<span class="string">&#x27;function&#x27;</span>]</span><br><span class="line">            output += <span class="string">f&quot;\n&lt;tool_call&gt;\n&#123;&#123;\&quot;name\&quot;: \&quot;<span class="subst">&#123;tool_call[<span class="string">&#x27;name&#x27;</span>]&#125;</span>\&quot;, \&quot;arguments\&quot;: &quot;</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(tool_call[<span class="string">&#x27;arguments&#x27;</span>], <span class="built_in">str</span>):</span><br><span class="line">                output += tool_call[<span class="string">&#x27;arguments&#x27;</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                output += json.dumps(tool_call[<span class="string">&#x27;arguments&#x27;</span>])</span><br><span class="line">            output += <span class="string">&#x27;&#125;\n&lt;/tool_call&gt;&#x27;</span></span><br><span class="line">    output += <span class="string">&#x27;&lt;|im_end|&gt;\n&#x27;</span></span><br></pre></td></tr></table></figure>

<ul>
<li><strong>工具调用处理</strong>：<ul>
<li>每个 <code>tool_call</code> 格式化为 <code>&lt;tool_call&gt;</code> 包裹的 JSON 对象。</li>
</ul>
</li>
</ul>
<p>(c) 工具响应消息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;%- elif message.role == &quot;tool&quot; %&#125;</span><br><span class="line">    &#123;%- if loop.first or (messages[loop.index0 - 1].role != &quot;tool&quot;) %&#125;</span><br><span class="line">        &lt;|im_start|&gt;user</span><br><span class="line">    &#123;%- endif %&#125;</span><br><span class="line">    \n&lt;tool_response&gt;\n&#123;&#123; message.content &#125;&#125;\n&lt;/tool_response&gt;</span><br><span class="line">    &#123;%- if loop.last or (messages[loop.index0 + 1].role != &quot;tool&quot;) %&#125;</span><br><span class="line">        &lt;|im_end|&gt;\n</span><br><span class="line">    &#123;%- endif %&#125;</span><br></pre></td></tr></table></figure>

<p><strong>python:</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">elif</span> message[<span class="string">&#x27;role&#x27;</span>] == <span class="string">&#x27;tool&#x27;</span>:</span><br><span class="line">    <span class="keyword">if</span> idx == <span class="number">0</span> <span class="keyword">or</span> messages[idx - <span class="number">1</span>][<span class="string">&#x27;role&#x27;</span>] != <span class="string">&#x27;tool&#x27;</span>:</span><br><span class="line">        output += <span class="string">&#x27;&lt;|im_start|&gt;user&#x27;</span></span><br><span class="line">    output += <span class="string">f&quot;\n&lt;tool_response&gt;\n<span class="subst">&#123;message[<span class="string">&#x27;content&#x27;</span>]&#125;</span>\n&lt;/tool_response&gt;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> idx == <span class="built_in">len</span>(messages) - <span class="number">1</span> <span class="keyword">or</span> messages[idx + <span class="number">1</span>][<span class="string">&#x27;role&#x27;</span>] != <span class="string">&#x27;tool&#x27;</span>:</span><br><span class="line">        output += <span class="string">&#x27;&lt;|im_end|&gt;\n&#x27;</span></span><br></pre></td></tr></table></figure>

<p>连续的工具消息合并为一条用户消息，用 <code>&lt;tool_response&gt;</code> 包裹内容。</p>
<hr>
<p>4️⃣生成提示（结尾）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;%- if add_generation_prompt %&#125;</span><br><span class="line">    &lt;|im_start|&gt;assistant\n</span><br><span class="line">    &#123;%- if enable_thinking is defined and enable_thinking is false %&#125;</span><br><span class="line">        &lt;think&gt;\n\n&lt;/think&gt;\n\n</span><br><span class="line">    &#123;%- endif %&#125;</span><br><span class="line">&#123;%- endif %&#125;</span><br></pre></td></tr></table></figure>

<p><strong>python:</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> add_generation_prompt:</span><br><span class="line">    output += <span class="string">&#x27;&lt;|im_start|&gt;assistant\n&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;enable_thinking&#x27;</span> <span class="keyword">in</span> <span class="built_in">locals</span>() <span class="keyword">and</span> <span class="keyword">not</span> enable_thinking:</span><br><span class="line">        output += <span class="string">&#x27;&lt;think&gt;\n\n&lt;/think&gt;\n\n&#x27;</span></span><br></pre></td></tr></table></figure>

<p>提示模型开始生成回复，可选是否强制空推理步骤。</p>
<hr>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://qwenlm.github.io/zh/blog/qwen3/">https://qwenlm.github.io/zh/blog/qwen3/</a></li>
<li><a href="https://github.com/QwenLM/Qwen3?tab=readme-ov-file">https://github.com/QwenLM/Qwen3?tab=readme-ov-file</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>llm</tag>
        <tag>qwen3</tag>
      </tags>
  </entry>
  <entry>
    <title>TTS之GPT-Sovits介绍与使用</title>
    <url>/2025/03/06/TTS%E4%B9%8BGPT-Sovits%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前面已经使用了GPT-Sovits V2做了有趣的应用，但关于GPT-Sovits的介绍与使用教程并没有写，且目前遇到了一个问题，使用中文进行微调后（后面发现与使用中文语音微调关系不大，主要取决于参考音频），再使用中文作为参考音频，使用该微调模型说英语则会很别扭（中文口音），故在此补上实验过程，目的在于得到英语流畅的模型，且融合音色防止版权问题。</p>
<span id="more"></span>

<hr>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>GPT-SoVITS是<a href="https://space.bilibili.com/5760446/">花儿不哭</a>大佬研发的低成本AI音色克隆软件。目前只有TTS（文字转语音）功能，将来会更新变声功能。GPT-SoVITS的正确缩写应该是GSV（下文用该缩写代替），请不要用sovits来简称它，这会让人把它和So-VITS-SVC搞混，两者并没有什么关系。</p>
<p>目前（2025-3-6），GSV已经更新到V3版本，关于<strong>各版本的介绍</strong>：</p>
<p><code>GPT-SoVITS-V1</code>实现了：</p>
<ul>
<li>由参考音频的情感、音色、语速控制合成音频的情感、音色、语速</li>
<li>可以少量语音微调训练，也可不训练直接推理</li>
<li>可以跨语种生成，即参考音频（训练集）和推理文本的语种为不同语种</li>
</ul>
<p><code>GPT-SoVITS-V2</code>新增特点：</p>
<ul>
<li>对低音质参考音频合成出来音质更好</li>
<li>底模训练集增加到5k小时，zero shot性能更好音色更像，所需数据集更少</li>
<li>增加韩粤两种语言，中日英韩粤5个语种均可跨语种合成</li>
<li>更好的文本前端：持续迭代更新。V2中英文加入多音字优化。</li>
</ul>
<p><code>GPT-SoVITS-V3</code>新增特点：</p>
<ul>
<li>音色相似度更像，需要更少训练集来逼近本人（甚至不需要训练SoVITS）</li>
<li>GPT合成更稳定，重复漏字更少，也更容易跑出丰富情感</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>语种主持（可跨语种合成）</th>
<th>GPT训练集时长</th>
<th>SoVITS训练集时长</th>
<th>推理速度</th>
<th>参数量</th>
<th>文本前端</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td>V1（2024年1月发布）</td>
<td>中日英</td>
<td>2k小时</td>
<td>2k小时</td>
<td>baseline</td>
<td>90M+77M</td>
<td>baseline</td>
<td>baseline</td>
</tr>
<tr>
<td>V2（2024年8月更新）</td>
<td>中日英韩粤</td>
<td>2.5k小时</td>
<td>vq encoder2k小时，剩余5k小时</td>
<td>翻倍</td>
<td>90M+77M</td>
<td>中日英逻辑均有增强</td>
<td>新增语速调节，无参考文本模式，更好的混合语种切分，音色混合</td>
</tr>
<tr>
<td>V3（2025年2月更新）</td>
<td>中日英韩粤</td>
<td>7k小时</td>
<td>vq encoder2k小时，剩余7k小时</td>
<td>约等于v2</td>
<td>330M+77M</td>
<td>不变</td>
<td>大幅增加zero shot相似度；情绪表达、微调性能提升</td>
</tr>
</tbody></table>
<p>目前我使用的是V2版本，有用户体验了V3，<a href="https://github.com/RVC-Boss/GPT-SoVITS/issues/2136">反馈1</a>，<a href="https://github.com/RVC-Boss/GPT-SoVITS/issues/2053#issue-2852950651">反馈2</a>，主要提及的是存在不稳定问题（音色&#x2F;节奏不稳定），有人建议可以使用<strong>V3的GPT模型配V2的sovits模型</strong>。</p>
<hr>
<h2 id="Ubuntu环境下安装"><a href="#Ubuntu环境下安装" class="headerlink" title="Ubuntu环境下安装"></a>Ubuntu环境下安装</h2><p>克隆仓库：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/RVC-Boss/GPT-SoVITS.git</span><br></pre></td></tr></table></figure>

<p>创建并激活conda环境：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> GPT-SoVITS</span><br><span class="line">conda create -n GPTSoVits python=3.9</span><br><span class="line">conda activate GPTSoVits</span><br></pre></td></tr></table></figure>

<p>运行自动安装脚本：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bash install.sh</span><br></pre></td></tr></table></figure>

<p>下载预训练模型：<br><strong>中国地区的用户可以<a href="https://www.yuque.com/baicaigongchang1145haoyuangong/ib3g1e/dkxgpiy9zb96hob4#nVNhX">在此处下载这些模型</a>。</strong></p>
<ol>
<li><p>从 <a href="https://huggingface.co/lj1995/GPT-SoVITS">GPT-SoVITS Models</a> 下载预训练模型，并将其放置在 <code>./GPT_SoVITS/pretrained_models</code> 目录中。</p>
</li>
<li><p>从 <a href="https://paddlespeech.bj.bcebos.com/Parakeet/released_models/g2p/G2PWModel_1.1.zip">G2PWModel_1.1.zip</a> 下载模型，解压并重命名为 <code>G2PWModel</code>，然后将其放置在 <code>./GPT_SoVITS/text</code> 目录中。（仅限中文TTS）</p>
</li>
<li><p>对于 UVR5（人声&#x2F;伴奏分离和混响移除，额外功能），从 <a href="https://huggingface.co/lj1995/VoiceConversionWebUI/tree/main/uvr5_weights">UVR5 Weights</a> 下载模型，并将其放置在 <code>./tools/uvr5/uvr5_weights</code> 目录中。</p>
<ul>
<li>如果你在 UVR5 中使用 <code>bs_roformer</code> 或 <code>mel_band_roformer</code>模型，你可以手动下载模型和相应的配置文件，并将它们放在 <code>tools/UVR5/UVR5_weights</code> 中。<strong>重命名模型文件和配置文件，确保除后缀外</strong>，模型和配置文件具有相同且对应的名称。此外，模型和配置文件名<strong>必须包含“roformer”</strong>，才能被识别为 roformer 类的模型。</li>
<li>建议在模型名称和配置文件名中<strong>直接指定模型类型</strong>，例如<code>mel_mand_roformer</code>、<code>bs_roformer</code>。如果未指定，将从配置文中比对特征，以确定它是哪种类型的模型。例如，模型<code>bs_roformer_ep_368_sdr_12.9628.ckpt</code> 和对应的配置文件<code>bs_roformer_ep_368_sdr_12.9628.yaml</code> 是一对。<code>kim_mel_band_roformer.ckpt</code> 和 <code>kim_mel_band_roformer.yaml</code> 也是一对。</li>
</ul>
</li>
<li><p>对于中文 ASR（额外功能），从 <a href="https://modelscope.cn/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/files">Damo ASR Model</a>、<a href="https://modelscope.cn/models/damo/speech_fsmn_vad_zh-cn-16k-common-pytorch/files">Damo VAD Model</a> 和 <a href="https://modelscope.cn/models/damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch/files">Damo Punc Model</a> 下载模型，并将它们放置在 <code>tools/asr/models</code> 目录中。</p>
</li>
<li><p>对于英语或日语 ASR（额外功能），从 <a href="https://huggingface.co/Systran/faster-whisper-large-v3">Faster Whisper Large V3</a> 下载模型，并将其放置在 <code>tools/asr/models</code> 目录中。此外，<a href="https://huggingface.co/Systran">其他模型</a> 可能具有类似效果且占用更少的磁盘空间。</p>
</li>
<li><p>需要从<a href="https://huggingface.co/lj1995/GPT-SoVITS/tree/main/gsv-v2final-pretrained">huggingface</a> 下载预训练模型文件放到GPT_SoVITS\pretrained_models\gsv-v2final-pretrained下</p>
<p>中文额外需要下载<a href="https://paddlespeech.bj.bcebos.com/Parakeet/released_models/g2p/G2PWModel_1.1.zip">G2PWModel_1.1.zip</a>（下载G2PW模型,解压并重命名为<code>G2PWModel</code>,将其放到<code>GPT_SoVITS/text</code>目录下）。</p>
</li>
</ol>
<hr>
<h2 id="WebUI运行"><a href="#WebUI运行" class="headerlink" title="WebUI运行"></a>WebUI运行</h2><p>运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python webui.py</span><br></pre></td></tr></table></figure>

<img src="/2025/03/06/TTS%E4%B9%8BGPT-Sovits%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/image-20250307154422098.png" class="" title="image-20250307154422098">

<p>点击上图箭头所示，得到：</p>
<img src="/2025/03/06/TTS%E4%B9%8BGPT-Sovits%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/image-20250307154543851.png" class="" title="image-20250307154543851">

<p>再按顺序点击，得到下一个页面：</p>
<img src="/2025/03/06/TTS%E4%B9%8BGPT-Sovits%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/image-20250307160607494.png" class="" title="image-20250307160607494">

<p>该界面的必填（选）项为：</p>
<ul>
<li>3~10 S的参考音频</li>
<li>对应于参考音频的文本</li>
<li>参考音频的语种</li>
<li>需要合成的文本</li>
<li>需要合成的语种（对应于需要合成的文本的语种）</li>
</ul>
<hr>
<h3 id="单语言"><a href="#单语言" class="headerlink" title="单语言"></a>单语言</h3><p>以下做了一些实验（用的原神派蒙的音频，来自<a href="https://www.bilibili.com/opus/804258696892776484">Bili 红血球AE3803</a>）：</p>
<table>
<thead>
<tr>
<th>参考文本真实语种</th>
<th>选择</th>
<th>真实的需要合成的文本语种</th>
<th>选择</th>
<th>合成结果</th>
</tr>
</thead>
<tbody><tr>
<td>zh</td>
<td>zh</td>
<td>zh</td>
<td>zh</td>
<td>正常</td>
</tr>
<tr>
<td>zh</td>
<td>zh</td>
<td>zh</td>
<td>zh-en</td>
<td>正常</td>
</tr>
<tr>
<td>zh</td>
<td>zh</td>
<td>en</td>
<td>zh</td>
<td>读字母</td>
</tr>
<tr>
<td>zh</td>
<td>zh</td>
<td>zh-en</td>
<td>zh</td>
<td>zh正常，en读字母</td>
</tr>
<tr>
<td>zh</td>
<td>zh</td>
<td>zh-en</td>
<td>en</td>
<td>zh不读，en也不太正常</td>
</tr>
<tr>
<td>zh</td>
<td>zh</td>
<td>zh-en</td>
<td>zh-en</td>
<td>整体正常（吞了几个字）</td>
</tr>
<tr>
<td>zh</td>
<td>zh</td>
<td>en</td>
<td>en</td>
<td>中文口音明显</td>
</tr>
<tr>
<td>zh</td>
<td>zh</td>
<td>en</td>
<td>zh-en</td>
<td>中文口音明显</td>
</tr>
<tr>
<td>en</td>
<td>en</td>
<td>en</td>
<td>en</td>
<td>正常</td>
</tr>
<tr>
<td>en</td>
<td>zh</td>
<td>en</td>
<td>en</td>
<td>读字母</td>
</tr>
<tr>
<td>en</td>
<td>en</td>
<td>en</td>
<td>zh-en</td>
<td>正常</td>
</tr>
<tr>
<td>en</td>
<td>en</td>
<td>en</td>
<td>zh</td>
<td>读字母</td>
</tr>
<tr>
<td>en</td>
<td>en</td>
<td>zh-en</td>
<td>zh</td>
<td>读字母，英语口音严重</td>
</tr>
<tr>
<td>en</td>
<td>en</td>
<td>zh-en</td>
<td>en</td>
<td>zh不读，en正常</td>
</tr>
<tr>
<td>en</td>
<td>en</td>
<td>zh-en</td>
<td>zh-en</td>
<td>英语口音严重</td>
</tr>
<tr>
<td>en</td>
<td>zh-en</td>
<td>zh-en</td>
<td>zh-en</td>
<td>英语口音严重</td>
</tr>
</tbody></table>
<p>从上表可以看出：</p>
<ul>
<li>口音由参考文本决定，中文参考音频读英语会有中文口音，英语参考音频读中文会有英语口音</li>
<li>选择的语种需包含真实的语种</li>
</ul>
<hr>
<h3 id="中英混合"><a href="#中英混合" class="headerlink" title="中英混合"></a>中英混合</h3><p>那如果参考音频的真实语种是中英混合的，会不会合成的中文和英文均没有别捏的口音了呢？</p>
<p>这里选用同事录得一段话进行实验，旨在判断通过zh-en参考音频能不能得到中英文都不别扭的合成效果。</p>
<p><strong>参考音频1：</strong></p>
<p>问候与告别，Good morning! How are you? See you tomorrow!介绍与询问， What’s your name? How old are you?</p>
<p><strong>参考音频2：</strong></p>
<p>问候与告别，Good morning! How are you? See you tomorrow!</p>
<p><strong>合成文本:</strong></p>
<p>从前，有一只小狐狸，它住在一片茂密的森林里。小狐狸聪明又勇敢，总是喜欢探索森林的每个角落。一天，它听说森林深处有一朵神奇的蓝色花，据说只要找到它，就能实现一个愿望。</p>
<p>小狐狸踏上了寻找蓝色花的旅程。它翻过高山，越过小溪，遇到了善良的兔子、友好的松鼠，还有一只迷路的小鸟。小狐狸帮助了小鸟找到回家的路，小鸟感激地告诉它，蓝色花就藏在森林里最高的那棵橡树下。</p>
<p>The little fox ran towards the great oak tree, its heart filled with excitement. When it finally arrived, it saw the glowing blue flower, shining like a star in the night. Carefully, the little fox made a wish: “I wish for happiness and kindness to spread across the forest.”</p>
<p>As soon as it finished speaking, a gentle breeze carried golden light throughout the woods. The trees seemed greener, the flowers bloomed brighter, and laughter echoed among the animals. The little fox smiled, knowing that its wish had come true. From that day on, the forest was filled with joy, all because of one small fox’s big heart.</p>
<table>
<thead>
<tr>
<th>参考文本真实语种</th>
<th>选择</th>
<th>真实的需要合成的文本语种</th>
<th>选择</th>
<th>合成结果</th>
</tr>
</thead>
<tbody><tr>
<td>zh-en</td>
<td>zh-en</td>
<td>zh-en</td>
<td>zh-en</td>
<td>en正常，zh节奏有点奇怪，像中国人模仿外国人口音说中文（意会一下🎃）</td>
</tr>
</tbody></table>
<p><strong>好的吧，看来通过zh-en参考音频来让合成zh-en音频时没口音好像有难度（我暂时感觉这种方式做不到），可能是通过单一说话人的zh-en音频微调实现的？🤺</strong></p>
<p>铛铛铛铛（不要问我为什么铛铛铛铛，看到最后你就知道了，也希望小友能看到这里😁），在这里补一个实验，用同事的中文录音：</p>
<table>
<thead>
<tr>
<th>参考文本真实语种</th>
<th>选择</th>
<th>真实的需要合成的文本语种</th>
<th>选择</th>
<th>合成结果</th>
</tr>
</thead>
<tbody><tr>
<td>zh（同事）</td>
<td>zh</td>
<td>en</td>
<td>en</td>
<td>正常</td>
</tr>
<tr>
<td>zh（同事）</td>
<td>zh</td>
<td>en</td>
<td>zh-en</td>
<td>正常</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>zh（派蒙）</td>
<td>zh</td>
<td>en</td>
<td>en</td>
<td>中文口音</td>
</tr>
<tr>
<td>zh（派蒙）</td>
<td>zh</td>
<td>en</td>
<td>zh-en</td>
<td>中文口音</td>
</tr>
</tbody></table>
<p>奇了怪，难道是游戏语音那种卡通配音缺少了某些元素？以致于作为参考音频时导致口语严重？（<strong>暂且这样理解吧</strong>）</p>
<hr>
<h3 id="音色融合"><a href="#音色融合" class="headerlink" title="音色融合"></a>音色融合</h3><p>先不管了，留个坑吧。接下来先实验下音色融合：</p>
<h4 id="ESD数据集下载"><a href="#ESD数据集下载" class="headerlink" title="ESD数据集下载"></a>ESD数据集下载</h4><p>ESD（Emotion Speech  Data）数据集是一个专为语音合成与语音转换设计的公开资源，涵盖了350段平行语料，由10位母语为普通话的说话者以及10位英语母语者以5种不同的情感状态（中性、快乐、愤怒、悲伤、惊讶）录制。这一宝贵的数据库不仅包含了录音，还有配套的文字脚本，极大地方便了研究与开发。</p>
<p>点击<a href="https://drive.google.com/file/d/1scuFwqh8s7KIYAfZW1Eu6088ZAK2SI-v/view?usp=sharing">这个链接</a>下载ESD数据集，下载完成后解压得到：</p>
<img src="/2025/03/06/TTS%E4%B9%8BGPT-Sovits%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/image-20250310154717934.png" class="" title="image-20250310154717934">

<table>
<thead>
<tr>
<th>说话人编号</th>
<th>性别</th>
<th>语种</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>女</td>
<td>zh</td>
</tr>
<tr>
<td>2</td>
<td>女</td>
<td>zh</td>
</tr>
<tr>
<td>3</td>
<td>女</td>
<td>zh</td>
</tr>
<tr>
<td>4</td>
<td>男</td>
<td>zh</td>
</tr>
<tr>
<td>5</td>
<td>男</td>
<td>zh</td>
</tr>
<tr>
<td>6</td>
<td>男</td>
<td>zh</td>
</tr>
<tr>
<td>7</td>
<td>女</td>
<td>zh</td>
</tr>
<tr>
<td>8</td>
<td>男</td>
<td>zh</td>
</tr>
<tr>
<td>9</td>
<td>女</td>
<td>zh</td>
</tr>
<tr>
<td>10</td>
<td>男</td>
<td>zh</td>
</tr>
<tr>
<td>11</td>
<td>男</td>
<td>en</td>
</tr>
<tr>
<td>12</td>
<td>男</td>
<td>en</td>
</tr>
<tr>
<td>13</td>
<td>男</td>
<td>en</td>
</tr>
<tr>
<td>14</td>
<td>男</td>
<td>en</td>
</tr>
<tr>
<td>15</td>
<td>女</td>
<td>en</td>
</tr>
<tr>
<td>16</td>
<td>女</td>
<td>en</td>
</tr>
<tr>
<td>17</td>
<td>女</td>
<td>en</td>
</tr>
<tr>
<td>18</td>
<td>女</td>
<td>en</td>
</tr>
<tr>
<td>19</td>
<td>女</td>
<td>en</td>
</tr>
<tr>
<td>20</td>
<td>男</td>
<td>en</td>
</tr>
</tbody></table>
<p>前10位是普通话，后10位为英语，每位说话者以说话情感分类，并且给出的txt文件对应了不同音频的说话内容和情绪。</p>
<img src="/2025/03/06/TTS%E4%B9%8BGPT-Sovits%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/image-20250310154936536.png" class="" title="image-20250310154936536">

<hr>
<h3 id="融合"><a href="#融合" class="headerlink" title="融合"></a>融合</h3><p>选取第三位说话者的0003_000982.wav作为参考音频，选择第7和第9位说话者的000982.wav与001029.wav作为融合音频，</p>
<table>
<thead>
<tr>
<th>音频序号</th>
<th>音频内容</th>
</tr>
</thead>
<tbody><tr>
<td>982</td>
<td>有些人划船，有的人在进行花草活动。</td>
</tr>
<tr>
<td>1029</td>
<td>但是有时夏天比其它季节更迷人。</td>
</tr>
</tbody></table>
<p>这里发现了个神奇的现象（一切的神奇现象都源于认知不足🤪），上面的单语言与中英混合合成出来的音频都有奇怪之处，单语言合成不同语种时，使用汉语为参考音频来合成英语时，有中国人说蹩脚英语的感觉，与此类似，使用英语为参考音频来合成汉语时，有外国人说蹩脚中文的感觉，这里的单语言中的是原神中派蒙的游戏内语音；而在中英混合场景使用的是同事的录音，参考音频直接为zh-en，但合成出来的中文有一些奇怪，英文正常；在这一节，笔者发现使用ESD提供的音频来试验，结果中英文部分都正常了，奇了个怪，那中英混个部分是不是还需要补一个同事只说中文作为参考音频的实验？（已补）</p>
<p>此处实验发现，在右侧若只添加一条音频，则<strong>音色则会以该音色为准（与参考音频的音色没关系了）</strong>，如果<strong>添加两条及以上的音频，则会平均融合这两条及以上音色</strong>。</p>
<p>好的，本来这节只为了验证融合音色的有效性，却意外发现了一些别的东西，只差微调的教程了，用到的时候再补上（相信不久就会补上了，现在是2025-3-10）。</p>
<img src="/2025/03/06/TTS%E4%B9%8BGPT-Sovits%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/image-20250310171709253.png" class="" title="image-20250310171709253">

<p>这里再总结一下：</p>
<img src="/2025/03/06/TTS%E4%B9%8BGPT-Sovits%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/image-20250310191549529.png" class="" title="image-20250310191549529">

<p>这里的①我叫做参考音频，②我叫做融合音频（纯个人叫法，如有雷同纯属巧合，后续看论文的时候再矫正），这里我试验下来，感觉①控制情绪、语速、节奏等，②控制音色；只有②处不上传音频时，音色才由①处决定，否则音色与①处没有关系。</p>
<p>思考题：想获得儿童的音色，开心的情绪，怎么做？</p>
<p>答：①放开心的情绪，②放儿童的音色。</p>
<hr>
<h3 id="微调"><a href="#微调" class="headerlink" title="微调"></a>微调</h3><p>TODO….</p>
<hr>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://github.com/RVC-Boss/GPT-SoVITS">https://github.com/RVC-Boss/GPT-SoVITS</a></li>
<li><a href="https://www.yuque.com/baicaigongchang1145haoyuangong/ib3g1e">https://www.yuque.com/baicaigongchang1145haoyuangong/ib3g1e</a></li>
<li><a href="https://github.com/RVC-Boss/GPT-SoVITS/issues/2136">https://github.com/RVC-Boss/GPT-SoVITS/issues/2136</a></li>
<li><a href="https://github.com/RVC-Boss/GPT-SoVITS/issues/2053#issue-2852950651">https://github.com/RVC-Boss/GPT-SoVITS/issues/2053#issue-2852950651</a></li>
<li><a href="https://blog.csdn.net/gitblog_01104/article/details/141593574">https://blog.csdn.net/gitblog_01104/article/details/141593574</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>tts</tag>
        <tag>gsv</tag>
        <tag>gpt sovits</tag>
        <tag>esd</tag>
      </tags>
  </entry>
  <entry>
    <title>TTS之Spark-TTS介绍与使用</title>
    <url>/2025/03/07/TTS%E4%B9%8BSpark-TTS%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>近日（2025-3-7），香港科技大学、出门问问、西北工业大学、上海交通大学、南洋理工大学等研究机构，重磅推出新一代语音生成模型 Spark-TTS。该模型完全基于Qwen2.5架构，摒弃额外生成模型辅助，以单阶段、单流方式实现 TTS 生成，具备超自然的语音克隆与跨语种生成能力，还支持用户根据需求定制专属声音。目前，Spark-TTS已经在开源社区SparkAudio发布，迅速登上Hugging Face趋势榜TTS第二，目前仍在持续攀升中。</p>
<p><strong>论文题目：Spark-TTS: An Efficient LLM-Based Text-to-Speech Model with Single-Stream Decoupled Speech Tokens</strong></p>
<p><strong>论文链接：<a href="https://arxiv.org/pdf/2503.01710">https://arxiv.org/pdf/2503.01710</a></strong></p>
<p><strong>样例展示：<a href="https://sparkaudio.github.io/spark-tts/">https://sparkaudio.github.io/spark-tts/</a></strong></p>
<p><strong>项目地址：<a href="https://github.com/SparkAudio/Spark-TTS">https://github.com/SparkAudio/Spark-TTS</a></strong></p>
<p><strong>模型地址：<a href="https://huggingface.co/SparkAudio/Spark-TTS-0.5B">https://huggingface.co/SparkAudio/Spark-TTS-0.5B</a></strong></p>
<p><strong>试用地址：<a href="https://huggingface.co/spaces/Mobvoi/Offical-Spark-TTS">https://huggingface.co/spaces/Mobvoi/Offical-Spark-TTS</a></strong></p>
<span id="more"></span>

<hr>
<h2 id="Ubuntu环境安装"><a href="#Ubuntu环境安装" class="headerlink" title="Ubuntu环境安装"></a>Ubuntu环境安装</h2><h3 id="克隆仓库"><a href="#克隆仓库" class="headerlink" title="克隆仓库"></a>克隆仓库</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/SparkAudio/Spark-TTS.git</span><br><span class="line"><span class="built_in">cd</span> Spark-TTS</span><br></pre></td></tr></table></figure>

<h3 id="创建conda虚拟环境及环境配置"><a href="#创建conda虚拟环境及环境配置" class="headerlink" title="创建conda虚拟环境及环境配置"></a>创建conda虚拟环境及环境配置</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda create -n sparktts -y python=3.12</span><br><span class="line">conda activate sparktts</span><br><span class="line">pip install -r requirements.txt</span><br><span class="line"><span class="comment"># If you are in mainland China, you can set the mirror as follows:</span></span><br><span class="line">pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com</span><br></pre></td></tr></table></figure>

<h3 id="下载模型"><a href="#下载模型" class="headerlink" title="下载模型"></a>下载模型</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p pretrained_models</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make sure you have git-lfs installed (https://git-lfs.com)</span></span><br><span class="line">git lfs install</span><br><span class="line"></span><br><span class="line">git <span class="built_in">clone</span> https://huggingface.co/SparkAudio/Spark-TTS-0.5B pretrained_models/Spark-TTS-0.5B</span><br></pre></td></tr></table></figure>

<h3 id="WebUI启动"><a href="#WebUI启动" class="headerlink" title="WebUI启动"></a>WebUI启动</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python webui.py --device 0</span><br></pre></td></tr></table></figure>

<p>然后本机浏览器打开<code>localhost:7860</code>或<code>127.0.0.1:7860</code>，得到下面页面：<img src="/2025/03/07/TTS%E4%B9%8BSpark-TTS%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/image-20250308142628932.png" class="" title="image-20250308142628932"></p>
<p>其中：</p>
<ol>
<li><p>选择prompt音频文件，确保采样率不低于16kHz</p>
</li>
<li><p>对应prompt音频文件的文本，可选，<strong>建议克隆相同语种</strong></p>
<blockquote>
<p>根据GPT-Sovits的经验，能写上还是要写上，且跨语种大概率会有口音</p>
</blockquote>
</li>
<li><p>需要合成的文本</p>
</li>
<li><p>点击<code>Generate</code>就可以了</p>
</li>
</ol>
<hr>
<h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>这里初步体验了一下，发现速度比GSV要慢的多，且合成的长语音会有吞字吞句现象，但克隆的音色挺像的（感觉比GSV像），社区说通过vLLM部署会极大提速，后面有空再细致试试吧。</p>
<hr>
<h3 id="第二part"><a href="#第二part" class="headerlink" title="第二part"></a>第二part</h3><p>铛铛铛铛，我又回来了，为什么呢？因为我发现官方发布了<strong>Nvidia Triton Inference Serving</strong>，即英伟达Triton推理服务，用的docker方式启动。咱们一起来体验下吧：</p>
<img src="/2025/03/07/TTS%E4%B9%8BSpark-TTS%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/image-20250419114750750.png" class="" title="image-20250419114750750">

<h4 id="安装："><a href="#安装：" class="headerlink" title="安装："></a>安装：</h4><p>首先，由于我之前已经clone了代码仓库，现在需要更新下新仓库，直接进入<code>Spark-TTS</code>目录：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git pull</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> runtime/triton_trtllm</span><br></pre></td></tr></table></figure>

<p>在运行<code>docker compose up</code>之前，需要先做点前置步骤，你可以直接运行<code>docker compose up</code>也许没下述问题。</p>
<p><strong>错误1</strong></p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">Error response from daemon: could not select device driver &quot;nvidia&quot; with capabilities: [[gpu]]</span><br></pre></td></tr></table></figure>

<p>这是因为现在docker里面不能使用GPU资源，解决办法，安装<code>NVIDIA Container Toolkit</code>，<a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#setting-up-nvidia-container-toolkit">参考</a>：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 命令1</span></span><br><span class="line">curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | <span class="built_in">sudo</span> gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \</span><br><span class="line">  &amp;&amp; curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \</span><br><span class="line">    sed <span class="string">&#x27;s#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g&#x27;</span> | \</span><br><span class="line">    <span class="built_in">sudo</span> <span class="built_in">tee</span> /etc/apt/sources.list.d/nvidia-container-toolkit.list</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 命令2</span></span><br><span class="line">sed -i -e <span class="string">&#x27;/experimental/ s/^#//g&#x27;</span> /etc/apt/sources.list.d/nvidia-container-toolkit.list</span><br><span class="line"></span><br><span class="line"><span class="comment"># 命令3</span></span><br><span class="line"><span class="built_in">sudo</span> apt-get install -y nvidia-container-toolkit</span><br><span class="line"></span><br><span class="line"><span class="comment"># 命令4：重启Docker daemon</span></span><br><span class="line"><span class="built_in">sudo</span> systemctl restart docker</span><br></pre></td></tr></table></figure>

<p><strong>错误2</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">requests.exceptions.SSLError: (MaxRetryError(<span class="string">&quot;HTTPSConnectionPool(host=&#x27;huggingface.co&#x27;, port=443): Max retries exceeded with url: /api/models/SparkAudio/Spark-TTS-0.5B/revision/main (Caused by SSLError(SSLEOFError(8, &#x27;[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1000)&#x27;)))&quot;</span>), <span class="string">&#x27;(Request ID: 820893bb-79e3-484b-b700-b4ca77292efa)&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>这是因为现在docker里面不能使用代理访问hugging face，解决办法：</p>
<p>首先，docker-compose.yml中添加代理配置：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">environment:</span><br><span class="line">     - PYTHONIOENCODING=utf-8</span><br><span class="line">     - MODEL<span class="built_in">_</span>ID=<span class="built_in">$</span>&#123;MODEL<span class="built_in">_</span>ID&#125;</span><br><span class="line">     <span class="params">#</span> --- 添加代理配置 ---</span><br><span class="line">     - HTTP<span class="built_in">_</span>PROXY=http://192.168.0.138:7890  <span class="params">#</span> <span class="built_in">&amp;</span>lt;= 替换 7890 为你的 Clash HTTP 端口</span><br><span class="line">     - HTTPS<span class="built_in">_</span>PROXY=http://192.168.0.138:7890 <span class="params">#</span> <span class="built_in">&amp;</span>lt;= 替换 7890 为你的 Clash HTTP 端口</span><br><span class="line">     - NO<span class="built_in">_</span>PROXY=localhost,127.0.0.1                 <span class="params">#</span> 建议添加，避免本地通信走代理</span><br></pre></td></tr></table></figure>

<p>然后，clash的首页配置的<code>Allow LAN</code>打开:</p>
<img src="/2025/03/07/TTS%E4%B9%8BSpark-TTS%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/df3b6e13ce7f193fdfa4a41b3c252d03.png" class="" title="df3b6e13ce7f193fdfa4a41b3c252d03">

<p>好的，现在就可以运行<code>docker compose up</code>了，经过长久的等待：</p>
<img src="/2025/03/07/TTS%E4%B9%8BSpark-TTS%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/c289f10f0c90472b0dc6ef369e1d169a.png" class="" title="c289f10f0c90472b0dc6ef369e1d169a">

<p>然后就可以运行<code>client_http.py</code>体验效果了。</p>
<hr>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://mp.weixin.qq.com/s/iHU4ZqwIzMY1YGgHFfhOCw">https://mp.weixin.qq.com/s/iHU4ZqwIzMY1YGgHFfhOCw</a></li>
<li><a href="https://github.com/SparkAudio/Spark-TTS?tab=readme-ov-file">https://github.com/SparkAudio/Spark-TTS?tab=readme-ov-file</a></li>
<li><a href="https://github.com/SparkAudio/Spark-TTS/blob/main/runtime/triton_trtllm/README.md">https://github.com/SparkAudio/Spark-TTS/blob/main/runtime/triton_trtllm/README.md</a></li>
<li><a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#setting-up-nvidia-container-toolkit">https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#setting-up-nvidia-container-toolkit</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>tts</tag>
        <tag>spark-tts</tag>
      </tags>
  </entry>
  <entry>
    <title>TTS之fish-speech</title>
    <url>/2025/03/15/TTS%E4%B9%8Bfish-speech/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>碎碎念：之前一直使用的是GSV（GPT-Sovits） V2版本，主要是因为它能满足我的基本需求（速度快，模仿情绪的能力，而且有音色融合的功能，但0样本克隆的效果也就那样吧，真想音色像得微调），可是呢，之前没正经使用过音色融合的功能，昨天试了下，发现webui版本的音色融合是以右侧的参考音频（音色融合音频）为准（音色融合音频只放一个的情况下，放多个将会将多个音频的音色进行融合，无论放一个还是放多个，音色都与左侧的参考音频的音色无关，但是呢，我做实验的时候都是用webui进行的实验，再转移到api_v2上进行使用，当我实验好，转移到api_v2上发现，api_v2的效果与webui的不一样，api_v2会将左侧的参考音频的音色融合起来，我觉得这是个bug，待会提下issue吧）。所以，还是得多玩玩其他家的TTS，以备不时之需，看了下fish-speech和F5-TTS的github首页，决定先宠幸fish-speech😏。</p>
<p><strong>项目地址：<a href="https://github.com/fishaudio/fish-speech">https://github.com/fishaudio/fish-speech</a></strong></p>
<p><strong>在线Demo：<a href="https://fish.audio/zh-CN/">https://fish.audio/zh-CN/</a></strong></p>
<p><strong>文档：<a href="https://speech.fish.audio/">https://speech.fish.audio/</a></strong></p>
<p><strong>快速开始本地推理：<a href="https://github.com/fishaudio/fish-speech/blob/main/inference.ipynb">https://github.com/fishaudio/fish-speech/blob/main/inference.ipynb</a></strong></p>
<span id="more"></span>

<hr>
<h2 id="特征"><a href="#特征" class="headerlink" title="特征"></a>特征</h2><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://speech.fish.audio/">https://speech.fish.audio/</a></li>
<li><a href="https://github.com/fishaudio/fish-speech">https://github.com/fishaudio/fish-speech</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>tts</tag>
        <tag>fish-speech</tag>
      </tags>
  </entry>
  <entry>
    <title>TTS之index-tts介绍与使用</title>
    <url>/2025/05/21/TTS%E4%B9%8Bindex-tts%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>由于觉得GPT-SoVITS这个TTS的并发性没那么好，需调研下其他的可0样本克隆的TTS（cosyvoice2之前简单试了下，觉得肯定用不起来，所以不会对cosyvoice2进行测试），目前的打算是比较GPT-SoVITS、index-tts与F5-TTS的效果与并发，本文先讲index-tts，使用的是<a href="https://github.com/Ksuriuri/index-tts-vllm">index-tts-vllm</a>（目前132 Starred），而不是官网的<a href="https://github.com/index-tts/index-tts">index-tts</a>（目前1.8k Starred）。计划介绍部署，使用方式，并发性等方面。</p>
<span id="more"></span>

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="项目简介"><a href="#项目简介" class="headerlink" title="项目简介"></a>项目简介</h3><p>该项目在 <a href="https://github.com/index-tts/index-tts">index-tts</a> 的基础上使用 vllm 库重新实现了 gpt 模型的推理，加速了 index-tts 的推理过程。</p>
<p>推理速度在单卡 RTX 4090 上的提升为：</p>
<ul>
<li>单个请求的 RTF (Real-Time Factor)：≈0.3 -&gt; ≈0.1</li>
<li>单个请求的 gpt 模型 decode 速度：≈90 token &#x2F; s -&gt; ≈280 token &#x2F; s</li>
<li>并发量：gpu_memory_utilization设置为0.5（约12GB显存）的情况下，vllm 显示 <code>Maximum concurrency for 608 tokens per request: 237.18x</code>，两百多并发，man！当然考虑 TTFT 以及其他推理成本（bigvgan 等），实测 16 左右的并发无压力（测速脚本参考 <code>simple_test.py</code>）</li>
</ul>
<hr>
<h3 id="新特性"><a href="#新特性" class="headerlink" title="新特性"></a>新特性</h3><ul>
<li>支持多角色音频混合：可以传入多个参考音频，TTS 输出的角色声线为多个参考音频的混合版本（输入多个参考音频会导致输出的角色声线不稳定，可以抽卡抽到满意的声线再作为参考音频）</li>
</ul>
<hr>
<h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><p>Word Error Rate (WER) Results for IndexTTS and Baseline Models on the <a href="https://github.com/BytedanceSpeech/seed-tts-eval"><strong>seed-test</strong></a></p>
<table>
<thead>
<tr>
<th>model</th>
<th>zh</th>
<th>en</th>
</tr>
</thead>
<tbody><tr>
<td>Human</td>
<td>1.254</td>
<td>2.143</td>
</tr>
<tr>
<td>index-tts (num_beams&#x3D;3)</td>
<td>1.005</td>
<td>1.943</td>
</tr>
<tr>
<td>index-tts (num_beams&#x3D;1)</td>
<td>1.107</td>
<td>2.032</td>
</tr>
<tr>
<td>index-tts-vllm</td>
<td>1.12</td>
<td>1.987</td>
</tr>
</tbody></table>
<p>基本保持了原项目的性能。</p>
<hr>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/Ksuriuri/index-tts-vllm.git</span><br><span class="line"><span class="built_in">cd</span> index-tts-vllm</span><br><span class="line"></span><br><span class="line">conda create -n index-tts-vllm python=3.12</span><br><span class="line">conda activate index-tts-vllm</span><br><span class="line"></span><br><span class="line">conda install pytorch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 pytorch-cuda=12.1 -c pytorch -c nvidia</span><br><span class="line"></span><br><span class="line">pip install -r requirements.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载模型，这里下载IndexTTS-1.5</span></span><br><span class="line">git <span class="built_in">clone</span> https://www.modelscope.cn/IndexTeam/IndexTTS-1.5.git</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 convert_hf_format.sh 中的 MODEL_DIR 修改为模型权重下载路径，我改为./IndexTTS-1.5，然后运行下面代码</span></span><br><span class="line"><span class="comment"># 此操作会将官方的模型权重转换为 transformers 库兼容的版本，保存在模型权重路径下的 vllm 文件夹中，方便后续 vllm 库加载模型权重</span></span><br><span class="line">bash convert_hf_format.sh	</span><br></pre></td></tr></table></figure>

<h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><h4 id="服务端"><a href="#服务端" class="headerlink" title="服务端"></a>服务端</h4><p>(可选：定义几种角色&#x2F;音色)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mkdir assets</span><br><span class="line"></span><br><span class="line">touch speakers.json</span><br><span class="line"></span><br><span class="line"><span class="comment"># 向speakers.json中写入结构对应信息(根据自己的写)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">&quot;小女孩1&quot;</span>: [</span><br><span class="line">        <span class="string">&quot;/home/srtc/下载/GPT-SoVITS/now_top_increase.wav&quot;</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="string">&quot;小女孩2&quot;</span>: [</span><br><span class="line">        <span class="string">&quot;/home/srtc/下载/GPT-SoVITS/en_usagirl.wav&quot;</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="string">&quot;小男孩1&quot;</span>: [</span><br><span class="line">        <span class="string">&quot;/home/srtc/下载/GPT-SoVITS/en_boy1.wav&quot;</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="string">&quot;青年男子1&quot;</span>: [</span><br><span class="line">        <span class="string">&quot;/home/srtc/下载/GPT-SoVITS/en_usaman.wav&quot;</span></span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">cd ..</span><br></pre></td></tr></table></figure>

<p>然后就可以启动你的fastapi了（也可以启动webui，感兴趣的请看参考链接1）：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python api_server.py --model_dir IndexTTS-1.5 --port 11996 --gpu_memory_utilization 0.5</span><br></pre></td></tr></table></figure>

<p><strong>启动参数：</strong></p>
<ul>
<li><code>--model_dir</code>: 模型权重下载路径</li>
<li><code>--host</code>: 服务ip地址，默认0.0.0.0</li>
<li><code>--port</code>: 服务端口</li>
<li><code>--gpu_memory_utilization</code>: vllm 显存占用率，默认设置为 <code>0.25</code></li>
</ul>
<p><strong>可以看到下方设置的角色生效了。</strong></p>
<img src="/2025/05/21/TTS%E4%B9%8Bindex-tts%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/78e7edbc9d8a3fd125d25c2df8a7b6cd.png" class="" title="78e7edbc9d8a3fd125d25c2df8a7b6cd">

<h4 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h4><p><strong>使用方式1：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;http://0.0.0.0:11996/tts_url&quot;</span></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&quot;text&quot;</span>: <span class="string">&quot;还是会想你，还是想登你&quot;</span>,</span><br><span class="line">    <span class="string">&quot;audio_paths&quot;</span>: [  <span class="comment"># 支持多参考音频</span></span><br><span class="line">        <span class="string">&quot;audio1.wav&quot;</span>,</span><br><span class="line">        <span class="string">&quot;audio2.wav&quot;</span></span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response = requests.post(url, json=data)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;output.wav&quot;</span>, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(response.content)</span><br></pre></td></tr></table></figure>

<p><strong>使用方式2：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;http://0.0.0.0:11996/tts&quot;</span></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&quot;text&quot;</span>: <span class="string">&quot;还是会想你，还是想登你&quot;</span>,</span><br><span class="line">    <span class="string">&quot;character&quot;</span>: <span class="string">&quot;小女孩&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response = requests.post(url, json=data)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;output.wav&quot;</span>, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(response.content)</span><br></pre></td></tr></table></figure>

<p>现在整体就跑通了，下一步就是并发性测试（压力测试），大佬给了<a href="https://github.com/Ksuriuri/index-tts-vllm/blob/master/simple_test.py">并发测试</a>的代码，咱们先跑下效果，再借鉴下大佬并发测试代码的思想。</p>
<hr>
<h3 id="并发测试"><a href="#并发测试" class="headerlink" title="并发测试"></a>并发测试</h3><p>运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python simple_test.py --text <span class="string">&quot;今天是5月21号星期3，今天天气晴，晚上嗦粉很热 ，出了一身的汗&quot;</span> --character <span class="string">&quot;小女孩1&quot;</span> --concurrency 16 --requests 5 </span><br></pre></td></tr></table></figure>

<p><strong>启动参数：</strong></p>
<ul>
<li><code>--urls</code>: TTS服务地址列表（多个用空格分割）</li>
<li><code>--text</code>: 需要合成的文本内容</li>
<li><code>--character</code>:合成角色名称 </li>
<li><code>--concurrency</code>: 并发线程数</li>
<li><code>--requests</code>:每个线程的请求数</li>
</ul>
<p>当前参数模拟的是16路并发（可以理解成有16个客户端&#x2F;线程），每个线程需要发送的请求为5，结果如下：</p>
<img src="/2025/05/21/TTS%E4%B9%8Bindex-tts%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/9f7fa69acd000fb80628a91cc85f36bf.png" class="" title="9f7fa69acd000fb80628a91cc85f36bf">

<p>也可以将<code>--requests</code>提高到20：</p>
<img src="/2025/05/21/TTS%E4%B9%8Bindex-tts%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/770812fccc07e6ce208c0bee94591fa5.png" class="" title="770812fccc07e6ce208c0bee94591fa5">

<p>最关注的维度是吞吐量…</p>
<hr>
<h3 id="压测代码（逐行注释版）"><a href="#压测代码（逐行注释版）" class="headerlink" title="压测代码（逐行注释版）"></a>压测代码（逐行注释版）</h3><p>借鉴下大佬的代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse  <span class="comment"># 用于解析命令行参数</span></span><br><span class="line"><span class="keyword">import</span> threading  <span class="comment"># 用于创建多线程</span></span><br><span class="line"><span class="keyword">import</span> time  <span class="comment"># 用于记录时间</span></span><br><span class="line"><span class="keyword">import</span> requests  <span class="comment"># 用于发送 HTTP 请求</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict  <span class="comment"># 提供带默认值的字典</span></span><br><span class="line"><span class="keyword">import</span> random  <span class="comment"># 用于生成随机数字</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个 TTS 服务压力测试类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TTSStressTester</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, urls, data, concurrency, requests_per_thread</span>):</span><br><span class="line">        <span class="comment"># 初始化参数</span></span><br><span class="line">        <span class="variable language_">self</span>.urls = urls  <span class="comment"># TTS 服务地址列表</span></span><br><span class="line">        <span class="variable language_">self</span>.data = data  <span class="comment"># 请求数据（包含 text 和 character）</span></span><br><span class="line">        <span class="variable language_">self</span>.concurrency = concurrency  <span class="comment"># 并发线程数</span></span><br><span class="line">        <span class="variable language_">self</span>.requests_per_thread = requests_per_thread  <span class="comment"># 每个线程发送的请求数</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 初始化统计信息字典</span></span><br><span class="line">        <span class="variable language_">self</span>.stats = &#123;</span><br><span class="line">            <span class="string">&#x27;total&#x27;</span>: <span class="number">0</span>,  <span class="comment"># 总请求数</span></span><br><span class="line">            <span class="string">&#x27;success&#x27;</span>: <span class="number">0</span>,  <span class="comment"># 成功请求数（返回音频）</span></span><br><span class="line">            <span class="string">&#x27;fail&#x27;</span>: <span class="number">0</span>,  <span class="comment"># 失败请求数</span></span><br><span class="line">            <span class="string">&#x27;durations&#x27;</span>: [],  <span class="comment"># 每个请求的耗时</span></span><br><span class="line">            <span class="string">&#x27;status_codes&#x27;</span>: defaultdict(<span class="built_in">int</span>),  <span class="comment"># 各类状态码统计</span></span><br><span class="line">            <span class="string">&#x27;errors&#x27;</span>: defaultdict(<span class="built_in">int</span>)  <span class="comment"># 异常统计</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="variable language_">self</span>.lock = threading.Lock()  <span class="comment"># 用于多线程下保护共享数据的锁</span></span><br><span class="line">        <span class="variable language_">self</span>.current_url_index = <span class="number">0</span>  <span class="comment"># 当前使用的 URL 下标</span></span><br><span class="line">        <span class="variable language_">self</span>.url_lock = threading.Lock()  <span class="comment"># 控制 URL 轮询的锁</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取下一个 URL（轮询机制）</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_next_url</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="variable language_">self</span>.url_lock:  <span class="comment"># 保证线程安全</span></span><br><span class="line">            url = <span class="variable language_">self</span>.urls[<span class="variable language_">self</span>.current_url_index]</span><br><span class="line">            <span class="variable language_">self</span>.current_url_index = (<span class="variable language_">self</span>.current_url_index + <span class="number">1</span>) % <span class="built_in">len</span>(<span class="variable language_">self</span>.urls)</span><br><span class="line">        <span class="keyword">return</span> url</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 发送一次 POST 请求</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_send_request</span>(<span class="params">self</span>):</span><br><span class="line">        start_time = time.time()  <span class="comment"># 请求开始时间</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># 为避免 VLLM 缓存，生成随机文本（如 &quot;93456&quot;）</span></span><br><span class="line">            <span class="variable language_">self</span>.data[<span class="string">&quot;text&quot;</span>] = <span class="string">&quot;,&quot;</span>.join([<span class="string">&quot;&quot;</span>.join([<span class="built_in">str</span>(random.randint(<span class="number">0</span>, <span class="number">9</span>)) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>)]) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>)])</span><br><span class="line">            target_url = <span class="variable language_">self</span>._get_next_url()  <span class="comment"># 获取一个 URL</span></span><br><span class="line">            response = requests.post(target_url, json=<span class="variable language_">self</span>.data, timeout=<span class="number">10</span>)  <span class="comment"># 发送请求</span></span><br><span class="line">            elapsed = time.time() - start_time  <span class="comment"># 计算耗时</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">with</span> <span class="variable language_">self</span>.lock:</span><br><span class="line">                <span class="variable language_">self</span>.stats[<span class="string">&#x27;durations&#x27;</span>].append(elapsed)  <span class="comment"># 记录耗时</span></span><br><span class="line">                <span class="variable language_">self</span>.stats[<span class="string">&#x27;status_codes&#x27;</span>][response.status_code] += <span class="number">1</span>  <span class="comment"># 状态码计数</span></span><br><span class="line">                <span class="variable language_">self</span>.stats[<span class="string">&#x27;total&#x27;</span>] += <span class="number">1</span>  <span class="comment"># 总请求数 +1</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># 判断是否请求成功</span></span><br><span class="line">                <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">                    content_type = response.headers.get(<span class="string">&#x27;Content-Type&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">                    <span class="keyword">if</span> <span class="string">&#x27;audio&#x27;</span> <span class="keyword">in</span> content_type:</span><br><span class="line">                        <span class="variable language_">self</span>.stats[<span class="string">&#x27;success&#x27;</span>] += <span class="number">1</span>  <span class="comment"># 成功请求</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        <span class="variable language_">self</span>.stats[<span class="string">&#x27;fail&#x27;</span>] += <span class="number">1</span></span><br><span class="line">                        <span class="variable language_">self</span>.stats[<span class="string">&#x27;errors&#x27;</span>][<span class="string">&#x27;invalid_content_type&#x27;</span>] += <span class="number">1</span>  <span class="comment"># 内容类型错误</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="variable language_">self</span>.stats[<span class="string">&#x27;fail&#x27;</span>] += <span class="number">1</span>  <span class="comment"># 状态码不是 200，认为失败</span></span><br><span class="line">                    </span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="comment"># 捕获异常并记录</span></span><br><span class="line">            <span class="keyword">with</span> <span class="variable language_">self</span>.lock:</span><br><span class="line">                <span class="variable language_">self</span>.stats[<span class="string">&#x27;fail&#x27;</span>] += <span class="number">1</span></span><br><span class="line">                <span class="variable language_">self</span>.stats[<span class="string">&#x27;errors&#x27;</span>][<span class="built_in">str</span>(<span class="built_in">type</span>(e).__name__)] += <span class="number">1</span>  <span class="comment"># 异常类型计数</span></span><br><span class="line">                <span class="variable language_">self</span>.stats[<span class="string">&#x27;durations&#x27;</span>].append(time.time() - start_time)  <span class="comment"># 添加耗时</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 每个线程的执行逻辑</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_worker</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.requests_per_thread):</span><br><span class="line">            <span class="variable language_">self</span>._send_request()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 启动所有线程并等待完成</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):</span><br><span class="line">        threads = []</span><br><span class="line">        start_time = time.time()  <span class="comment"># 记录开始时间</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.concurrency):  <span class="comment"># 创建多个线程</span></span><br><span class="line">            thread = threading.Thread(target=<span class="variable language_">self</span>._worker)</span><br><span class="line">            thread.start()</span><br><span class="line">            threads.append(thread)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> thread <span class="keyword">in</span> threads:</span><br><span class="line">            thread.join()  <span class="comment"># 等待所有线程执行完毕</span></span><br><span class="line"></span><br><span class="line">        total_time = time.time() - start_time  <span class="comment"># 总耗时</span></span><br><span class="line">        <span class="variable language_">self</span>._generate_report(total_time)  <span class="comment"># 打印报告</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打印最终报告</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_generate_report</span>(<span class="params">self, total_time</span>):</span><br><span class="line">        durations = <span class="variable language_">self</span>.stats[<span class="string">&#x27;durations&#x27;</span>]</span><br><span class="line">        total_requests = <span class="variable language_">self</span>.stats[<span class="string">&#x27;total&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;\n<span class="subst">&#123;<span class="string">&#x27; 测试报告 &#x27;</span>:=^<span class="number">40</span>&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;总请求时间: <span class="subst">&#123;total_time:<span class="number">.2</span>f&#125;</span>秒&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;总请求量: <span class="subst">&#123;total_requests&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;成功请求: <span class="subst">&#123;self.stats[<span class="string">&#x27;success&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;失败请求: <span class="subst">&#123;self.stats[<span class="string">&#x27;fail&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> durations:</span><br><span class="line">            avg_duration = <span class="built_in">sum</span>(durations) / <span class="built_in">len</span>(durations)</span><br><span class="line">            max_duration = <span class="built_in">max</span>(durations)</span><br><span class="line">            min_duration = <span class="built_in">min</span>(durations)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;\n响应时间统计:&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;平均: <span class="subst">&#123;avg_duration:<span class="number">.3</span>f&#125;</span>秒&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;最大: <span class="subst">&#123;max_duration:<span class="number">.3</span>f&#125;</span>秒&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;最小: <span class="subst">&#123;min_duration:<span class="number">.3</span>f&#125;</span>秒&quot;</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 计算分位数 P50, P90, P95, P99</span></span><br><span class="line">            sorted_durations = <span class="built_in">sorted</span>(durations)</span><br><span class="line">            <span class="keyword">for</span> p <span class="keyword">in</span> [<span class="number">50</span>, <span class="number">90</span>, <span class="number">95</span>, <span class="number">99</span>]:</span><br><span class="line">                index = <span class="built_in">int</span>(p / <span class="number">100</span> * <span class="built_in">len</span>(sorted_durations))</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;P<span class="subst">&#123;p&#125;</span>: <span class="subst">&#123;sorted_durations[index]:<span class="number">.3</span>f&#125;</span>秒&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 状态码分布输出</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n状态码分布:&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> code, count <span class="keyword">in</span> <span class="variable language_">self</span>.stats[<span class="string">&#x27;status_codes&#x27;</span>].items():</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;HTTP <span class="subst">&#123;code&#125;</span>: <span class="subst">&#123;count&#125;</span>次&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 错误统计输出</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.stats[<span class="string">&#x27;errors&#x27;</span>]:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;\n错误统计:&quot;</span>)</span><br><span class="line">            <span class="keyword">for</span> error, count <span class="keyword">in</span> <span class="variable language_">self</span>.stats[<span class="string">&#x27;errors&#x27;</span>].items():</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;error&#125;</span>: <span class="subst">&#123;count&#125;</span>次&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 吞吐量（每秒请求数）</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;\n吞吐量: <span class="subst">&#123;total_requests / total_time:<span class="number">.2</span>f&#125;</span> 请求/秒&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 主程序入口</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 定义命令行参数解析器</span></span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">&#x27;TTS服务压力测试脚本&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--urls&#x27;</span>, nargs=<span class="string">&#x27;+&#x27;</span>, </span><br><span class="line">                        default=[<span class="string">&#x27;http://localhost:11996/tts&#x27;</span>],  <span class="comment"># 默认本地地址</span></span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;TTS服务地址列表（多个用空格分隔）&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--text&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;测试文本&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;需要合成的文本内容&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--character&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;lancy&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;合成角色名称&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--concurrency&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">16</span>, <span class="built_in">help</span>=<span class="string">&#x27;并发线程数&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--requests&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">5</span>, <span class="built_in">help</span>=<span class="string">&#x27;每个线程的请求数&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    args = parser.parse_args()  <span class="comment"># 解析参数</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 组装请求体</span></span><br><span class="line">    test_data = &#123;</span><br><span class="line">        <span class="string">&quot;text&quot;</span>: args.text,</span><br><span class="line">        <span class="string">&quot;character&quot;</span>: args.character</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 实例化测试器</span></span><br><span class="line">    tester = TTSStressTester(</span><br><span class="line">        urls=args.urls,</span><br><span class="line">        data=test_data,</span><br><span class="line">        concurrency=args.concurrency,</span><br><span class="line">        requests_per_thread=args.requests</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 打印启动信息</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;开始压力测试，配置参数：&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;目标服务: <span class="subst">&#123;<span class="string">&#x27;, &#x27;</span>.join(args.urls)&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;并发线程: <span class="subst">&#123;args.concurrency&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;单线程请求数: <span class="subst">&#123;args.requests&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;总预计请求量: <span class="subst">&#123;args.concurrency * args.requests&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;<span class="string">&#x27; 测试启动 &#x27;</span>:=^<span class="number">40</span>&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 执行测试</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        tester.run()</span><br><span class="line">    <span class="keyword">except</span> KeyboardInterrupt:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n测试被用户中断&quot;</span>)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="服务端代码（逐行注释版）"><a href="#服务端代码（逐行注释版）" class="headerlink" title="服务端代码（逐行注释版）"></a>服务端代码（逐行注释版）</h3><p>顺便也拜读下大佬的服务端代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="comment"># os.environ[&quot;CUDA_VISIBLE_DEVICES&quot;] = &quot;7&quot;  # 可选，指定使用哪块GPU，比如第7块。取消注释可生效。</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> asyncio  <span class="comment"># 异步编程支持库</span></span><br><span class="line"><span class="keyword">import</span> io  <span class="comment"># 处理内存中的字节流</span></span><br><span class="line"><span class="keyword">import</span> traceback  <span class="comment"># 用于捕获错误堆栈信息，方便调试</span></span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, Request, Response  <span class="comment"># FastAPI 是现代 Python Web 框架</span></span><br><span class="line"><span class="keyword">from</span> fastapi.responses <span class="keyword">import</span> JSONResponse, StreamingResponse  <span class="comment"># 返回 JSON 或流式响应</span></span><br><span class="line"><span class="keyword">from</span> contextlib <span class="keyword">import</span> asynccontextmanager  <span class="comment"># 用于创建异步上下文管理器</span></span><br><span class="line"><span class="keyword">import</span> uvicorn  <span class="comment"># 用于运行 FastAPI 应用的 ASGI 服务器</span></span><br><span class="line"><span class="keyword">import</span> argparse  <span class="comment"># 用于处理命令行参数</span></span><br><span class="line"><span class="keyword">import</span> json  <span class="comment"># JSON 库</span></span><br><span class="line"><span class="keyword">import</span> asyncio  <span class="comment"># 重复引入了，其实上面已经引入过一次</span></span><br><span class="line"><span class="keyword">import</span> time  <span class="comment"># 用于计时</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  <span class="comment"># 数组处理库</span></span><br><span class="line"><span class="keyword">import</span> soundfile <span class="keyword">as</span> sf  <span class="comment"># 用于保存 WAV 音频文件</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> indextts.infer_vllm <span class="keyword">import</span> IndexTTS  <span class="comment"># 引入你自己的 TTS 推理类</span></span><br><span class="line"></span><br><span class="line">tts = <span class="literal">None</span>  <span class="comment"># 全局变量，用于后续保存 TTS 实例</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 应用生命周期管理器：初始化模型</span></span><br><span class="line"><span class="meta">@asynccontextmanager</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">lifespan</span>(<span class="params">app: FastAPI</span>):</span><br><span class="line">    <span class="keyword">global</span> tts</span><br><span class="line">    <span class="comment"># 配置文件路径</span></span><br><span class="line">    cfg_path = os.path.join(args.model_dir, <span class="string">&quot;config.yaml&quot;</span>)</span><br><span class="line">    <span class="comment"># 创建 TTS 实例</span></span><br><span class="line">    tts = IndexTTS(model_dir=args.model_dir, cfg_path=cfg_path, gpu_memory_utilization=args.gpu_memory_utilization)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取当前脚本所在路径</span></span><br><span class="line">    current_file_path = os.path.abspath(__file__)</span><br><span class="line">    cur_dir = os.path.dirname(current_file_path)</span><br><span class="line">    <span class="comment"># 拼接 speaker.json 的路径（用来注册角色音色）</span></span><br><span class="line">    speaker_path = os.path.join(cur_dir, <span class="string">&quot;assets/speaker.json&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> os.path.exists(speaker_path):</span><br><span class="line">        speaker_dict = json.load(<span class="built_in">open</span>(speaker_path, <span class="string">&#x27;r&#x27;</span>))</span><br><span class="line">        <span class="keyword">for</span> speaker, audio_paths <span class="keyword">in</span> speaker_dict.items():</span><br><span class="line">            <span class="comment"># 为每个角色注册音色样本</span></span><br><span class="line">            tts.registry_speaker(speaker, audio_paths)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">yield</span>  <span class="comment"># 程序进入运行状态</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果有需要，这里可以添加模型清理释放代码</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">app = FastAPI(lifespan=lifespan)  <span class="comment"># 创建 FastAPI 应用，绑定生命周期函数</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一个 API：根据音频路径合成语音</span></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/tts_url&quot;</span>, responses=&#123;</span></span></span><br><span class="line"><span class="params"><span class="meta">    <span class="number">200</span>: &#123;<span class="string">&quot;content&quot;</span>: &#123;<span class="string">&quot;application/octet-stream&quot;</span>: &#123;&#125;&#125;&#125;,  <span class="comment"># 返回 audio/wav 数据</span></span></span></span><br><span class="line"><span class="params"><span class="meta">    <span class="number">500</span>: &#123;<span class="string">&quot;content&quot;</span>: &#123;<span class="string">&quot;application/json&quot;</span>: &#123;&#125;&#125;&#125;  <span class="comment"># 出错时返回 JSON</span></span></span></span><br><span class="line"><span class="params"><span class="meta">&#125;</span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">tts_api_url</span>(<span class="params">request: Request</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        data = <span class="keyword">await</span> request.json()</span><br><span class="line">        text = data[<span class="string">&quot;text&quot;</span>]</span><br><span class="line">        audio_paths = data[<span class="string">&quot;audio_paths&quot;</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">global</span> tts</span><br><span class="line">        sr, wav = <span class="keyword">await</span> tts.infer(audio_paths, text)  <span class="comment"># 根据音频路径合成语音</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 把音频写入内存中的 BytesIO 对象</span></span><br><span class="line">        <span class="keyword">with</span> io.BytesIO() <span class="keyword">as</span> wav_buffer:</span><br><span class="line">            sf.write(wav_buffer, wav, sr, <span class="built_in">format</span>=<span class="string">&#x27;WAV&#x27;</span>)</span><br><span class="line">            wav_bytes = wav_buffer.getvalue()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> Response(content=wav_bytes, media_type=<span class="string">&quot;audio/wav&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> ex:</span><br><span class="line">        tb_str = <span class="string">&#x27;&#x27;</span>.join(traceback.format_exception(<span class="built_in">type</span>(ex), ex, ex.__traceback__))</span><br><span class="line">        <span class="keyword">return</span> JSONResponse(</span><br><span class="line">            status_code=<span class="number">500</span>,</span><br><span class="line">            content=&#123;</span><br><span class="line">                <span class="string">&quot;status&quot;</span>: <span class="string">&quot;error&quot;</span>,</span><br><span class="line">                <span class="string">&quot;error&quot;</span>: <span class="built_in">str</span>(tb_str)</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二个 API：根据角色名合成语音</span></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/tts&quot;</span>, responses=&#123;</span></span></span><br><span class="line"><span class="params"><span class="meta">    <span class="number">200</span>: &#123;<span class="string">&quot;content&quot;</span>: &#123;<span class="string">&quot;application/octet-stream&quot;</span>: &#123;&#125;&#125;&#125;,</span></span></span><br><span class="line"><span class="params"><span class="meta">    <span class="number">500</span>: &#123;<span class="string">&quot;content&quot;</span>: &#123;<span class="string">&quot;application/json&quot;</span>: &#123;&#125;&#125;&#125;</span></span></span><br><span class="line"><span class="params"><span class="meta">&#125;</span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">tts_api</span>(<span class="params">request: Request</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        data = <span class="keyword">await</span> request.json()</span><br><span class="line">        text = data[<span class="string">&quot;text&quot;</span>]</span><br><span class="line">        character = data[<span class="string">&quot;character&quot;</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">global</span> tts</span><br><span class="line">        sr, wav = <span class="keyword">await</span> tts.infer_with_ref_audio_embed(character, text)  <span class="comment"># 根据角色名合成语音</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">with</span> io.BytesIO() <span class="keyword">as</span> wav_buffer:</span><br><span class="line">            sf.write(wav_buffer, wav, sr, <span class="built_in">format</span>=<span class="string">&#x27;WAV&#x27;</span>)</span><br><span class="line">            wav_bytes = wav_buffer.getvalue()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> Response(content=wav_bytes, media_type=<span class="string">&quot;audio/wav&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> ex:</span><br><span class="line">        tb_str = <span class="string">&#x27;&#x27;</span>.join(traceback.format_exception(<span class="built_in">type</span>(ex), ex, ex.__traceback__))</span><br><span class="line">        <span class="built_in">print</span>(tb_str)</span><br><span class="line">        <span class="keyword">return</span> JSONResponse(</span><br><span class="line">            status_code=<span class="number">500</span>,</span><br><span class="line">            content=&#123;</span><br><span class="line">                <span class="string">&quot;status&quot;</span>: <span class="string">&quot;error&quot;</span>,</span><br><span class="line">                <span class="string">&quot;error&quot;</span>: <span class="built_in">str</span>(tb_str)</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动服务（命令行参数支持）</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--host&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&quot;0.0.0.0&quot;</span>)  <span class="comment"># 监听地址</span></span><br><span class="line">    parser.add_argument(<span class="string">&quot;--port&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">11996</span>)  <span class="comment"># 端口号</span></span><br><span class="line">    parser.add_argument(<span class="string">&quot;--model_dir&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&quot;/path/to/IndexTeam/Index-TTS&quot;</span>)  <span class="comment"># 模型路径</span></span><br><span class="line">    parser.add_argument(<span class="string">&quot;--gpu_memory_utilization&quot;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.25</span>)  <span class="comment"># GPU使用率限制</span></span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 启动 FastAPI 服务</span></span><br><span class="line">    uvicorn.run(app=app, host=args.host, port=args.port)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>有几点需要注意：</p>
<ol>
<li><code>@asynccontextmanager</code> 是 Python 标准库 <code>contextlib</code> 提供的装饰器，用于<strong>定义异步上下文管理器</strong>。</li>
</ol>
<blockquote>
<p> 创建一个“支持异步生命周期”的上下文管理器。用于在 FastAPI 启动&#x2F;关闭时执行代码。以yield为分割。</p>
</blockquote>
<ol start="2">
<li><p><code>@asynccontextmanager</code>装饰器下方的函数需为异步函数（async def）。</p>
</li>
<li><p>注意TTS是发送文本，返回字节流，而ASR是发送字节流，返回文本；</p>
<ul>
<li>文本可以使用JSONResponse返回（标准），也可以直接return</li>
</ul>
</li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>tts</tag>
        <tag>index-tts</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu22.04更新NVIDIA驱动</title>
    <url>/2025/04/02/Ubuntu22-04%E6%9B%B4%E6%96%B0NVIDIA%E9%A9%B1%E5%8A%A8/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近在玩一个项目（microWakeWord，写在另一篇博客），发现该项目依赖项的<code>tensorflow2.16</code>需要<code>CUDA 12.3</code>支持，但是我的驱动目前最多只能支持到<code>CUDA12.0</code>(通过<code>nvidia-smi</code>看右上角的<code>CUDA_Version: 12.0</code>)，也很久没更新过驱动和cuda、cudnn了，借这个机会更新一下吧。</p>
<span id="more"></span>

<hr>
<h2 id="驱动更新"><a href="#驱动更新" class="headerlink" title="驱动更新"></a>驱动更新</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ubuntu-drivers devices  <span class="comment">#  查看 Ubuntu 推荐的驱动,后面带 recommended 的通常是最稳定的。</span></span><br><span class="line"><span class="built_in">sudo</span> apt install nvidia-driver-570-server-open  <span class="comment"># 安装推荐的驱动</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">sudo</span> reboot  <span class="comment"># 重启系统</span></span><br><span class="line"></span><br><span class="line">nvidia-smi  <span class="comment"># 即可看到第一行的版本号不一样了</span></span><br></pre></td></tr></table></figure>

<img src="/2025/04/02/Ubuntu22-04%E6%9B%B4%E6%96%B0NVIDIA%E9%A9%B1%E5%8A%A8/10d160ae7733a9bca06f138803af3263.png" class="" title="10d160ae7733a9bca06f138803af3263">

<hr>
<h2 id="CUDA更新"><a href="#CUDA更新" class="headerlink" title="CUDA更新"></a>CUDA更新</h2><p>打开<a href="https://developer.nvidia.com/cuda-toolkit-archive">官网</a>，我这里选择CUDA12.6.3，然后选择对应你本机的选项，如下图：</p>
<img src="/2025/04/02/Ubuntu22-04%E6%9B%B4%E6%96%B0NVIDIA%E9%A9%B1%E5%8A%A8/4f3ba006f7150786c0f231329cccdb57.png" class="" title="4f3ba006f7150786c0f231329cccdb57">

<p>将网站给的命令依次输入到终端：</p>
<p>第一条：</p>
<img src="/2025/04/02/Ubuntu22-04%E6%9B%B4%E6%96%B0NVIDIA%E9%A9%B1%E5%8A%A8/215b78656adcbf619a3a4da75a8c5f27.png" class="" title="215b78656adcbf619a3a4da75a8c5f27">

<p>第二条：</p>
<p>提示安装程序检测到你已经通过包管理器安装了NVIDIA驱动，强烈建议你先卸载它。一方面我不知道怎么卸载，另一方面即使知道，也不打算接收这个建议🙄，好的，选择继续：</p>
<img src="/2025/04/02/Ubuntu22-04%E6%9B%B4%E6%96%B0NVIDIA%E9%A9%B1%E5%8A%A8/c4354861d0b11ccb2dd59777e69f7bdf.png" class="" title="c4354861d0b11ccb2dd59777e69f7bdf">

<p>看不懂，但是肯定让你同意，打上<code>accept</code>，回车：</p>
<img src="/2025/04/02/Ubuntu22-04%E6%9B%B4%E6%96%B0NVIDIA%E9%A9%B1%E5%8A%A8/8966b812b0c31d23418c8682e75d0f42.jpg" class="" title="8966b812b0c31d23418c8682e75d0f42">

<p>因为我们已经安装过驱动了，所以需要把驱动前面的勾（❌，whatever）去掉：</p>
<img src="/2025/04/02/Ubuntu22-04%E6%9B%B4%E6%96%B0NVIDIA%E9%A9%B1%E5%8A%A8/e99c553b0b77817a6604df16414a5a66.png" class="" title="e99c553b0b77817a6604df16414a5a66">

<p>然后提示链接已存在，更新链接，选择是：</p>
<img src="/2025/04/02/Ubuntu22-04%E6%9B%B4%E6%96%B0NVIDIA%E9%A9%B1%E5%8A%A8/cee88543436a5fe63fc81d31bf9e40e6.png" class="" title="cee88543436a5fe63fc81d31bf9e40e6">

<p>好的，安装完成后：</p>
<img src="/2025/04/02/Ubuntu22-04%E6%9B%B4%E6%96%B0NVIDIA%E9%A9%B1%E5%8A%A8/dc2b86948ddb39b3fef8289de756c471.png" class="" title="dc2b86948ddb39b3fef8289de756c471">

<p>可以看到，这时候<code>cuda</code>还是显式11.8（原来的版本）的。</p>
<p>继续运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim ~/.bashrc</span><br></pre></td></tr></table></figure>

<p>更改前：</p>
<img src="/2025/04/02/Ubuntu22-04%E6%9B%B4%E6%96%B0NVIDIA%E9%A9%B1%E5%8A%A8/image-20250402174205715.png" class="" title="image-20250402174205715">

<p>更改后：</p>
<img src="/2025/04/02/Ubuntu22-04%E6%9B%B4%E6%96%B0NVIDIA%E9%A9%B1%E5%8A%A8/image-20250402174255948.png" class="" title="image-20250402174255948">

<p>好的，再依次运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br><span class="line">nvcc -V</span><br></pre></td></tr></table></figure>

<img src="/2025/04/02/Ubuntu22-04%E6%9B%B4%E6%96%B0NVIDIA%E9%A9%B1%E5%8A%A8/ce3b2a483ae3ba05e202feba439e8cb4.png" class="" title="ce3b2a483ae3ba05e202feba439e8cb4">

<p>好的，大功告成！（但是呢，以防万一，我还是去吧原来的cuda11.8文件夹删掉吧）。</p>
<hr>
<h2 id="CUDNN更新"><a href="#CUDNN更新" class="headerlink" title="CUDNN更新"></a>CUDNN更新</h2><p>打开<a href="https://developer.nvidia.com/cudnn-downloads">官网</a>，和cuda安装差不多，选择配置后，依次运行给的代码：</p>
<img src="/2025/04/02/Ubuntu22-04%E6%9B%B4%E6%96%B0NVIDIA%E9%A9%B1%E5%8A%A8/81e6a6b8db114c52b48e36729ff427e4.png" class="" title="81e6a6b8db114c52b48e36729ff427e4">

<p>然后：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt-get install libfreeimage3 libfreeimage-dev</span><br><span class="line"></span><br><span class="line"><span class="built_in">cp</span> -r /usr/src/cudnn_samples_v9/ <span class="variable">$HOME</span></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$HOME</span>/cudnn_samples_v9/mnistCUDNN</span><br><span class="line">make clean &amp;&amp; make</span><br><span class="line">./mnistCUDNN</span><br></pre></td></tr></table></figure>

<img src="/2025/04/02/Ubuntu22-04%E6%9B%B4%E6%96%B0NVIDIA%E9%A9%B1%E5%8A%A8/ebe7fe7a3b1bb816b780d4061e33b810.png" class="" title="ebe7fe7a3b1bb816b780d4061e33b810">

<p>就哦了（可以把刚复制的cudnn_samples_v9删除掉）。</p>
<hr>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://blog.csdn.net/takedachia/article/details/130375718">https://blog.csdn.net/takedachia/article/details/130375718</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>CUDA</tag>
      </tags>
  </entry>
  <entry>
    <title>Unsloth:Llama-3.2-3B-Instruct+GRPO将通用LLM微调成推理LLM</title>
    <url>/2025/04/14/Unsloth-Llama-3-2-3B-Instruct-GRPO%E5%B0%86%E9%80%9A%E7%94%A8LLM%E5%BE%AE%E8%B0%83%E6%88%90%E6%8E%A8%E7%90%86LLM/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><a href="https://caihaoran-00.github.io/2025/04/08/Unsloth-Phi-4-GRPO%E5%B0%86%E9%80%9A%E7%94%A8%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E6%88%90%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B/">前面</a>我们使用<code>Unsloth</code>将<code>Phi-4 14B</code>通过<code>GRPO</code>方法转化成了推理<code>LLM</code>，但示例中的两个奖励函数有些问题，官方也并未有改正的意向，只是给了另一个<a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb#scrollTo=vzOuSVCL_GA9">Llama-3.2-3B</a>的示例供开发者参考，那么本文就一起来看一下这个新示例吧，同时本文将深入的解析其中所使用的代码。</p>
<span id="more"></span>

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="第一块：模型加载与初始化"><a href="#第一块：模型加载与初始化" class="headerlink" title="第一块：模型加载与初始化"></a><strong>第一块：模型加载与初始化</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> unsloth <span class="keyword">import</span> FastLanguageModel</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">max_seq_length = <span class="number">2048</span> <span class="comment"># Can increase for longer reasoning traces</span></span><br><span class="line">lora_rank = <span class="number">64</span> <span class="comment"># Larger rank = smarter, but slower</span></span><br><span class="line"></span><br><span class="line">model, tokenizer = FastLanguageModel.from_pretrained(</span><br><span class="line">    model_name = <span class="string">&quot;meta-llama/Llama-3.2-3B-Instruct&quot;</span>,</span><br><span class="line">    max_seq_length = max_seq_length,</span><br><span class="line">    load_in_4bit = <span class="literal">False</span>, <span class="comment"># False for LoRA 16bit</span></span><br><span class="line">    fast_inference = <span class="literal">True</span>, <span class="comment"># Enable vLLM fast inference</span></span><br><span class="line">    max_lora_rank = lora_rank,</span><br><span class="line">    gpu_memory_utilization = <span class="number">0.8</span>, <span class="comment"># Reduce if out of memory</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model = FastLanguageModel.get_peft_model(</span><br><span class="line">    model,</span><br><span class="line">    r = lora_rank, <span class="comment"># Choose any number &gt; 0 ! Suggested 8, 16, 32, 64, 128</span></span><br><span class="line">    target_modules = [</span><br><span class="line">        <span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;k_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>, <span class="string">&quot;o_proj&quot;</span>,</span><br><span class="line">        <span class="string">&quot;gate_proj&quot;</span>, <span class="string">&quot;up_proj&quot;</span>, <span class="string">&quot;down_proj&quot;</span>,</span><br><span class="line">    ], <span class="comment"># Remove QKVO if out of memory</span></span><br><span class="line">    lora_alpha = lora_rank,</span><br><span class="line">    use_gradient_checkpointing = <span class="string">&quot;unsloth&quot;</span>, <span class="comment"># Enable long context finetuning</span></span><br><span class="line">    random_state = <span class="number">3407</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>与之前文章相似，但：</p>
<ul>
<li>使用的不是<code>4bit</code>量化版本（也许因为使用的是<code>3B</code>模型）</li>
<li><code>lora_rank</code>使用的是64，之前是16，代表微调的权重会比之前多一些</li>
</ul>
<h3 id="第二块：加载gsm8k数据集"><a href="#第二块：加载gsm8k数据集" class="headerlink" title="第二块：加载gsm8k数据集"></a><strong>第二块：加载gsm8k数据集</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line">dataset = load_dataset(<span class="string">&quot;openai/gsm8k&quot;</span>, <span class="string">&quot;main&quot;</span>, split = <span class="string">&quot;train&quot;</span>)</span><br><span class="line">dataset</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">Dataset(&#123;</span><br><span class="line">    features: [&#x27;question&#x27;, &#x27;answer&#x27;],</span><br><span class="line">    num<span class="built_in">_</span>rows: 7473</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>关于<code>GSM8k</code>数据集的详细内容见附录。</p>
</blockquote>
<p>这里使用<code>openai/gsm8k</code>的<code>main</code>分支的<code>train</code>部分，其包含<code>7473</code>对问答对（QA, question-answer）。</p>
<h3 id="第三块：打印第一条数据"><a href="#第三块：打印第一条数据" class="headerlink" title="第三块：打印第一条数据"></a><strong>第三块：打印第一条数据</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dataset[<span class="number">0</span>][<span class="string">&quot;question&quot;</span>]</span><br><span class="line">dataset[<span class="number">0</span>][<span class="string">&quot;answer&quot;</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?</span><br><span class="line"></span><br><span class="line">Natalia sold 48/2 = &lt;&lt;48/2=24&gt;&gt;24 clips in May.</span><br><span class="line">Natalia sold 48+24 = &lt;&lt;48+24=72&gt;&gt;72 clips altogether in April and May.</span><br><span class="line"><span class="params">####</span> 72</span><br></pre></td></tr></table></figure>

<p>这里分别打印数据集第一条的<code>question</code>和<code>answer</code>，值得注意的是：</p>
<ul>
<li><code>answer</code>先是思考过程，结果写在<code>####</code>后面，且是纯数字</li>
<li><code>&lt;&lt;48/2=24&gt;&gt;</code>用于指示计算器调用</li>
</ul>
<h3 id="第四块：提取答案"><a href="#第四块：提取答案" class="headerlink" title="第四块：提取答案"></a><strong>第四块：提取答案</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">extract_hash_answer</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;####&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> text: <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">return</span> text.split(<span class="string">&quot;####&quot;</span>)[<span class="number">1</span>].strip()</span><br><span class="line">extract_hash_answer(dataset[<span class="number">0</span>][<span class="string">&quot;answer&quot;</span>])</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">&#x27;72&#x27;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>这里的疑惑点是函数名中的<code>hash</code>，其实这个<code>hash</code>指的是<code>hash symbol</code>，即<code>#</code>。而不是文件完整性校验的那个哈希。</p>
</blockquote>
<p>用于从<code>gsm8k</code>数据集的<code>answer</code>字段中提取最终答案，即<code>####</code>后方的内容。<code>.split</code>用于将文本内容按切割方式（这里是<code>####</code>切割成两部分），这里取第二部分，最后去掉首尾的空格。</p>
<h3 id="第五块：定义系统提示词"><a href="#第五块：定义系统提示词" class="headerlink" title="第五块：定义系统提示词"></a><strong>第五块：定义系统提示词</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">reasoning_start = <span class="string">&quot;&lt;start_working_out&gt;&quot;</span></span><br><span class="line">reasoning_end   = <span class="string">&quot;&lt;end_working_out&gt;&quot;</span></span><br><span class="line">solution_start = <span class="string">&quot;&lt;SOLUTION&gt;&quot;</span></span><br><span class="line">solution_end = <span class="string">&quot;&lt;/SOLUTION&gt;&quot;</span></span><br><span class="line"></span><br><span class="line">system_prompt = \</span><br><span class="line"><span class="string">f&quot;&quot;&quot;You are given a problem.</span></span><br><span class="line"><span class="string">Think about the problem and provide your working out.</span></span><br><span class="line"><span class="string">Place it between <span class="subst">&#123;reasoning_start&#125;</span> and <span class="subst">&#123;reasoning_end&#125;</span>.</span></span><br><span class="line"><span class="string">Then, provide your solution between <span class="subst">&#123;solution_start&#125;</span><span class="subst">&#123;solution_end&#125;</span>&quot;&quot;&quot;</span></span><br><span class="line">system_prompt</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">You are given a problem.</span><br><span class="line">Think about the problem and provide your working out.</span><br><span class="line">Place it between &lt;start<span class="built_in">_</span>working<span class="built_in">_</span>out&gt; and &lt;end<span class="built_in">_</span>working<span class="built_in">_</span>out&gt;.</span><br><span class="line">Then, provide your solution between &lt;SOLUTION&gt;&lt;/SOLUTION&gt;</span><br></pre></td></tr></table></figure>

<p>这里首先定义推理（reasoning）和结果（solution）的开始和结束标志，然后用在系统提示词（system_prompt）中。</p>
<h3 id="第六块：制作训练数据集"><a href="#第六块：制作训练数据集" class="headerlink" title="第六块：制作训练数据集"></a><strong>第六块：制作训练数据集</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dataset = dataset.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: &#123;</span><br><span class="line">    <span class="string">&quot;prompt&quot;</span> : [</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: system_prompt&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>,   <span class="string">&quot;content&quot;</span>: x[<span class="string">&quot;question&quot;</span>]&#125;,</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">&quot;answer&quot;</span>: extract_hash_answer(x[<span class="string">&quot;answer&quot;</span>]),</span><br><span class="line">&#125;)</span><br><span class="line">dataset[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;question&#x27;: &#x27;Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?&#x27;,</span><br><span class="line"> &#x27;answer&#x27;: &#x27;72&#x27;,</span><br><span class="line"> &#x27;prompt&#x27;: [&#123;&#x27;content&#x27;: &#x27;You are given a problem.<span class="keyword">\nThink</span> about the problem and provide your working out.<span class="keyword">\nPlace</span> it between &lt;start<span class="built_in">_</span>working<span class="built_in">_</span>out&gt; and &lt;end<span class="built_in">_</span>working<span class="built_in">_</span>out&gt;.<span class="keyword">\nThen</span>, provide your solution between &lt;SOLUTION&gt;&lt;/SOLUTION&gt;&#x27;,</span><br><span class="line">   &#x27;role&#x27;: &#x27;system&#x27;&#125;,</span><br><span class="line">  &#123;&#x27;content&#x27;: &#x27;Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?&#x27;,</span><br><span class="line">   &#x27;role&#x27;: &#x27;user&#x27;&#125;]&#125;</span><br></pre></td></tr></table></figure>

<p>我们一起来看一下：</p>
<ol>
<li><code>map</code>函数遍历原始 <code>dataset</code> 中的每一条数据（我们称之为 <code>x</code>）。</li>
<li>对于每一条数据 <code>x</code>，都根据 <code>lambda</code> 函数的规则创建一个<strong>新的</strong>字典。</li>
<li>这个新的字典包含两个键：<ul>
<li><code>&quot;prompt&quot;</code>：其值是一个列表，包含了固定的系统提示和一个从 x 中提取的用户问题，构造成对话格式。</li>
<li><code>&quot;answer&quot;</code>：其值是使用 <code>extract_hash_answer</code> 函数从 <code>x</code> 的原始答案中提取出来的、<code>####</code> 标记后的最终答案。</li>
</ul>
</li>
<li><code>.map()</code> 方法收集所有这些新创建的字典，组成一个新的数据集。</li>
<li>最后，<code>dataset = ...</code> 将这个全新的、转换过的数据集<strong>合并</strong>回 <code>dataset</code> 变量，如果返回的字典中有<strong>与原来数据项相同的键</strong>（比如 <code>&quot;answer&quot;</code>），那么原来数据项中该键的值会被函数返回的值<strong>覆盖（overwrite）</strong>。原来数据项中<strong>没有被返回字典的键覆盖</strong>的其他键（比如 <code>&quot;question&quot;</code>），会<strong>保持不变</strong>。</li>
</ol>
<hr>
<h3 id="第七块：创建匹配模板"><a href="#第七块：创建匹配模板" class="headerlink" title="第七块：创建匹配模板"></a><strong>第七块：创建匹配模板</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">match_format = re.<span class="built_in">compile</span>(</span><br><span class="line">    <span class="string">rf&quot;^[\s]&#123;&#123;0,&#125;&#125;&quot;</span>\</span><br><span class="line">    <span class="string">rf&quot;<span class="subst">&#123;reasoning_start&#125;</span>.+?<span class="subst">&#123;reasoning_end&#125;</span>.*?&quot;</span>\</span><br><span class="line">    <span class="string">rf&quot;<span class="subst">&#123;solution_start&#125;</span>(.+?)<span class="subst">&#123;solution_end&#125;</span>&quot;</span>\</span><br><span class="line">    <span class="string">rf&quot;[\s]&#123;&#123;0,&#125;&#125;$&quot;</span>,</span><br><span class="line">    flags = re.MULTILINE | re.DOTALL</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>这段代码创建一个“<strong>搜索模板</strong>”（也就是正则表达式），用来模板匹配。</p>
<p><code>match_format = re.compile(...)</code></p>
<ul>
<li><code>re.compile(...):</code> 这是 <code>re</code> 工具箱里的一个函数，叫做 <code>compile</code>（编译）。</li>
<li><strong>作用</strong>：它接收一个定义好的“搜索模板”（就是括号里那一长串东西），然后把它**预先处理（编译）**一下，变成一个更高效的“模式对象”。</li>
</ul>
<p><strong><code>rf&quot;...&quot;</code> 多行字符串</strong></p>
<ul>
<li><code>r</code> 前缀：表示这是一个“<strong>原始字符串</strong> (raw string)”。在原始字符串里，反斜杠 <code>\</code> 就只是一个普通的反斜杠，不会被 <code>Python</code> 误解成特殊转义字符（比如 <code>\n</code> 代表换行）。这在写正则表达式时特别有用，因为正则表达式本身就大量使用 <code>\</code>。</li>
<li><code>f</code> 前缀：表示这是一个“<strong>格式化字符串</strong> (<code>f-string</code>)”。它允许你在字符串里面用大括号 <code>&#123;&#125;</code> 包裹变量名，<code>Python</code> 会自动把变量的值填进去。比如 {<code>reasoning_start</code>}。</li>
<li><code>rf&quot;...&quot;</code>: 两者结合，意味着这是一个<strong>原始的格式化字符串</strong>。它既能方便地处理反斜杠，又能方便地嵌入变量。</li>
<li>多行写法：用 <code>\</code> 连接多行，只是为了代码看起来更整洁，实际上它们组成了一个<strong>完整</strong>的字符串。</li>
</ul>
<p><strong>正则表达式模板本身（括号里的核心内容）</strong><br>这部分是最复杂的，我们把它拆开看，假设变量 <code>reasoning_start</code> 是 &lt;开始思考&gt;，<code>reasoning_end</code> 是 &lt;结束思考&gt;，<code>solution_start</code> 是 &lt;最终答案&gt;，<code>solution_end</code> 是 &lt;结束答案&gt;。</p>
<ul>
<li><code>^</code>:<ul>
<li><strong>含义</strong>：匹配<strong>字符串的开头</strong>，或者在 <code>re.MULTILINE</code> 模式下匹配<strong>行的开头</strong>。</li>
<li><strong>解释</strong>：规定要查找的模式必须从文本的开头（或者一行的开头）就开始匹配。</li>
</ul>
</li>
<li><code>[\s]&#123;0,&#125;</code>:<ul>
<li><code>\s</code>: 匹配任何<strong>空白字符</strong>（空格、制表符 <code>\t</code>、换行符 <code>\n</code> 等）。</li>
<li><code>[...]</code>: 表示匹配方括号内<strong>任意一个</strong>字符。这里 <code>[\s]</code> 其实就等同于 <code>\s</code>。</li>
<li><code>&#123;0,&#125;</code>: 表示前面的部分（<code>\s</code>）可以出现 <strong>0 次或任意多次</strong>。</li>
<li><strong>解释</strong>：允许在文本开头（或行开头）有零个或多个空白字符。这让模式更灵活，即使文本开头有缩进或空行也能匹配上。</li>
</ul>
</li>
<li><code>&#123;reasoning_start&#125;</code>:<ul>
<li><strong>含义</strong>：这里会被 <code>f-string</code> 替换成变量 <code>reasoning_start</code> 的实际值，比如 &lt;开始思考&gt;。</li>
<li><strong>解释</strong>：查找那个表示“思考过程开始”的标记。</li>
</ul>
</li>
<li><code>.+?</code>:<ul>
<li><code>.</code>: 匹配<strong>除了换行符以外的任何单个字符</strong>。但是因为后面我们用了 <code>re.DOTALL</code> 标志，这里的<code>.</code> <strong>也能匹配换行符</strong>。</li>
<li><code>+</code>: 表示前面的部分（<code>.</code>）必须出现 <strong>1 次或多次</strong>。</li>
<li><code>?</code>: 跟在 <code>+</code> 或 <code>*</code> 后面时，表示<strong>非贪婪匹配</strong>。</li>
<li><strong>解释</strong>：匹配从 &lt;开始思考&gt; 之后开始的、<strong>任意数量（至少一个）的任何字符</strong>（包括换行符），直到<strong>第一次</strong>遇到后面跟着的 &lt;结束思考&gt; 为止。“非贪婪”很重要，它确保只匹配到第一个 &lt;结束思考&gt; 就停下，而不是一直匹配到文章中最后一个 &lt;结束思考&gt;。</li>
</ul>
</li>
<li><code>&#123;reasoning_end&#125;</code>:<ul>
<li><strong>含义</strong>：被替换成变量 <code>reasoning_end</code> 的值，比如 &lt;结束思考&gt;。</li>
<li><strong>解释</strong>：找到那个表示“思考过程结束”的标记。</li>
</ul>
</li>
<li><code>.*?</code>:<ul>
<li><code>.</code>: 同样，匹配包括换行符在内的任何字符。</li>
<li><code>*</code>: 表示前面的部分（.）可以出现 <strong>0 次或多次</strong>。</li>
<li><code>?</code>: 同样，表示<strong>非贪婪匹配</strong>。</li>
<li><strong>解释</strong>：匹配 &lt;结束思考&gt; 和 &lt;最终答案&gt; 之间可能存在的<strong>任何字符（包括没有字符，或者跨越多行的字符）</strong>。非贪婪匹配确保它只匹配最短的可能部分。</li>
</ul>
</li>
<li><code>&#123;solution_start&#125;</code>:<ul>
<li><strong>含义</strong>：被替换成变量 <code>solution_start</code> 的值，比如 &lt;最终答案&gt;。</li>
<li><strong>解释</strong>：找到那个表示“最终答案开始”的标记。</li>
</ul>
</li>
<li><code>(.+?)</code>: <strong>（这是最关键的部分之一！）</strong><ul>
<li><code>(...)</code>: 圆括号表示一个“<strong>捕获组</strong> (<code>capturing group</code>)”。意思是，当整个模式匹配成功时，我特别<strong>想要提取出</strong>圆括号里面匹配到的这部分内容。</li>
<li><code>.+?</code>: 和前面一样，非贪婪地匹配至少一个任意字符（包括换行符）。</li>
<li><strong>解释</strong>：匹配 &lt;最终答案&gt; 之后，到第一个 &lt;结束答案&gt; 之前的所有内容，并且<strong>把这部分内容“捕获”起来</strong>，方便我们之后取出来。这就是我们要提取的“最终答案”本身！</li>
</ul>
</li>
<li><code>&#123;solution_end&#125;</code>:<ul>
<li><strong>含义</strong>：被替换成变量 <code>solution_end</code> 的值，比如 &lt;结束答案&gt;。</li>
<li><strong>解释</strong>：找到那个表示“最终答案结束”的标记。</li>
</ul>
</li>
<li><code>[\s]&#123;0,&#125;</code>:<ul>
<li><strong>解释</strong>：允许在 &lt;结束答案&gt; 标记后面有零个或多个空白字符。</li>
</ul>
</li>
<li><code>$</code>:<ul>
<li><strong>含义</strong>：匹配<strong>字符串的结尾</strong>，或者在 <code>re.MULTILINE</code> 模式下匹配<strong>行的结尾</strong>。</li>
<li><strong>解释</strong>：规定匹配必须一直持续到文本的末尾（或一行的末尾）。</li>
</ul>
</li>
</ul>
<p><strong><code>flags = re.MULTILINE | re.DOTALL</code></strong></p>
<ul>
<li><code>flags</code>: 这是 <code>re.compile</code> 函数的一个参数，用来改变正则表达式的行为模式。</li>
<li><code>re.MULTILINE </code>(简写 <code>re.M</code>):<ul>
<li><strong>作用</strong>：让 <code>^</code> 能匹配每一行的开头（不仅仅是整个字符串的开头），让 <code>$</code> 能匹配每一行的结尾（不仅仅是整个字符串的结尾）。</li>
<li><strong>解释</strong>：如果你的文本有多行，这个标志允许模式在每一行的开头和结尾进行匹配检查，而不是只看整个文本的最开头和最末尾。</li>
</ul>
</li>
<li><code>re.DOTALL</code> (简写 <code>re.S</code>):<ul>
<li><strong>作用</strong>：让特殊字符 . <strong>能够匹配包括换行符在内</strong>的任何字符。默认情况下，<code>.</code> 是不匹配换行符的。</li>
<li><strong>解释</strong>：因为我们的“思考过程”和“最终答案”很可能包含多行文字，我们需要 <code>.</code> 能够跨越换行符去匹配。这个标志就是干这个的。</li>
</ul>
</li>
<li><code>|</code>: 这是按位或运算符。在这里用来<strong>组合</strong>多个标志。<code>re.MULTILINE | re.DOTALL</code> 表示同时启用 <code>MULTILINE</code> 和 <code>DOTALL</code> 这两个行为模式。</li>
</ul>
<p><strong>总结一下:</strong></p>
<p>这整段代码定义并编译了一个强大的“<strong>搜索模板</strong>” (match_format)。这个模板被设计用来：</p>
<ol>
<li>在一大段可能跨越多行的文本中进行查找。</li>
<li>查找一个特定的结构：必须以可选的空白开头，然后是“思考过程”标记，接着是思考内容，然后是“思考过程结束”标记，之后可能有一些其他文字，然后是“最终答案开始”标记，接着是<strong>我们想要提取的答案内容</strong>，最后是“最终答案结束”标记，并以可选的空白结尾。</li>
<li>由于设置了 <code>MULTILINE</code> 和 <code>DOTALL</code> 标志，这个模板可以正确处理跨越多行的内容。</li>
<li>最重要的是，它使用<strong>捕获组 (.+?)</strong> 来特别标记出“最终答案”部分，以便在匹配成功后能方便地<strong>提取</strong>出来。</li>
</ol>
<p>编译好之后，你就可以用 <code>match_format.search(你的文本)</code> 或 <code>match_format.match(你的文本)</code> 来实际执行查找，并用 <code>.group(1)</code> 来获取那个被捕获的答案内容了。</p>
<p><strong>这里还有几点补充一下：</strong></p>
<ol>
<li><p>如果把正则表达式模板写在一行是什么样子的（只需要把<code>\</code>和换成去掉即可）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">match_format = re.<span class="built_in">compile</span>(<span class="string">rf&quot;^[\s]&#123;&#123;0,&#125;&#125;<span class="subst">&#123;reasoning_start&#125;</span>.+?<span class="subst">&#123;reasoning_end&#125;</span>.*?<span class="subst">&#123;solution_start&#125;</span>(.+?)<span class="subst">&#123;solution_end&#125;</span>[\s]&#123;&#123;0,&#125;&#125;$&quot;</span>, flags=re.MULTILINE | re.DOTALL)</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>[\s]&#123;&#123;0,&#125;&#125;</code> 为什么 <code>0</code> 后面有个逗号且被两个花括号包着？</p>
<p>这个问题包含两个关键点：双花括号<code> &#123;&#123;...&#125;&#125;</code> 和里面的 <code>&#123;0,&#125;</code>。</p>
<ul>
<li><p><strong>双花括号 </strong>：</p>
<ul>
<li><strong>原因</strong>：因为整个字符串是 <code>rf&quot;...&quot;</code> 格式，也就是一个“<strong>原始格式化字符串 (raw f-string)</strong>”。在 f-string 中，单个花括号 {} 是有特殊含义的，用来<strong>嵌入变量</strong>（比如之前的 {reasoning_start}）。</li>
<li><strong>作用</strong>：如果你想在最终的字符串里<strong>得到一个真正的、字面意义上的花括号</strong> <code>&#123;</code> 或 <code>&#125;</code>，而不是想嵌入变量，你就必须<strong>连续写两次</strong>：<code>&#123;&#123;` 代表一个 `&#123;`, `&#125;&#125;</code> 代表一个 <code>&#125;</code>。</li>
<li><strong>小结</strong>：这里的 <code>&#123;&#123;` 和 `&#125;&#125;</code> 是 <code>f-string</code> 的语法要求，目的是在最终生成的正则表达式字符串里得到 <code>&#123;0,&#125;</code> 这几个字符本身。</li>
</ul>
</li>
<li><p><strong>里面的 {0,}</strong>：</p>
<ul>
<li><strong>含义</strong>：这是<strong>正则表达式</strong>本身的语法，叫做“<strong>量词 (quantifier)</strong>”。它用来指定它前面的那个部分（在这里是 <code>[\s]</code>，代表一个空白字符）可以出现多少次。</li>
<li><code>&#123;n,m&#125;</code>：表示匹配前面的元素至少 <code>n</code> 次，最多 <code>m</code> 次。</li>
<li><code>&#123;n&#125;</code>：表示精确匹配 <code>n</code> 次。</li>
<li><code>&#123;n,&#125;</code>：表示匹配至少 <code>n</code> 次（<code>n</code> 次或更多次）。</li>
<li><strong>{0,}</strong>：因此，这表示匹配前面的元素<strong>至少 0 次</strong>，也就是 <strong>0 次或任意多次</strong>。</li>
<li><strong>等价写法</strong>：<code>&#123;0,&#125;</code> 的作用和另一个常见的量词 <code>*</code>（星号）是<strong>完全一样</strong>的，都表示“零次或多次”。所以 <code>[\s]&#123;0,&#125;</code> 和 <code>\s*</code> 或 <code>[\s]*</code> 表达的意思是相同的。为什么原作者用 <code>&#123;0,&#125;</code> 而不是 <code>*</code> 可能是个人编码风格的选择。</li>
</ul>
</li>
<li><p><strong><code>[\s]&#123;&#123;0,&#125;&#125;</code></strong></p>
<ul>
<li><p>外层的 <code>&#123;&#123;` 和 `&#125;&#125;</code> 是为了在 <code>f-string</code> 中输出真正的 <code>&#123;</code> 和 <code>&#125;</code>。</p>
</li>
<li><p>内层的 <code>&#123;0,&#125;</code> 是正则表达式语法，表示它前面的 <code>[\s]</code>（空白字符）可以出现 0 次或任意多次。</p>
</li>
<li><p>整体含义：匹配零个或多个连续的空白字符。</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p><code>re.MULTILINE</code> 标志对 <code>^</code> 和 <code>$</code> 作用的例子对比</p>
<p><code>re.MULTILINE</code> (或 <code>re.M</code>) 改变了 <code>^</code> 和 <code>$</code> 这两个“锚点”的行为。</p>
<ul>
<li><strong>默认行为 (没有 <code>re.MULTILINE</code>)</strong>：<ul>
<li><code>^</code> 只匹配整个<strong>字符串的最开头</strong>。</li>
<li><code>$</code> 只匹配整个<strong>字符串的最末尾</strong>（或者字符串末尾的换行符之前的位置）。</li>
</ul>
</li>
<li><strong>启用 <code>re.MULTILINE</code> 后的行为</strong>：<ul>
<li><code>^</code> 既能匹配整个字符串的最开头，<strong>也能</strong>匹配字符串内<strong>每一行</strong>（由换行符 <code>\n</code> 分隔）<strong>的开头</strong>。</li>
<li><code>$</code> 既能匹配整个字符串的最末尾，<strong>也能</strong>匹配字符串内<strong>每一行</strong>（在换行符 <code>\n</code> 之前）<strong>的结尾</strong>。</li>
</ul>
</li>
</ul>
<p><strong>举例说明:</strong></p>
<p>假设我们有这样一段包含多行文字的文本：</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">text</span> = <span class="string">&quot;&quot;&quot;Report Alpha End</span></span><br><span class="line"><span class="string">Report Beta End</span></span><br><span class="line"><span class="string">Final Report&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p><strong>例 1：使用 ^ 查找以 “Hello” 开头的行</strong></p>
<ul>
<li><p><strong>没有 re.MULTILINE</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">matches = re.findall(<span class="string">r&quot;^Report&quot;</span>, text)</span><br><span class="line"><span class="built_in">print</span>(matches)</span><br><span class="line"><span class="comment"># 输出: [&#x27;Report&#x27;]</span></span><br></pre></td></tr></table></figure>

<p><strong>解释</strong>：<code>^Report</code> 只匹配了整个字符串 <code>text</code> 最开头的 <code>&quot;Report&quot;</code>。它不认为第二行的 <code>&quot;Report&quot;</code> 或是在“开头”。</p>
</li>
<li><p><strong>使用 re.MULTILINE</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">matches = re.findall(<span class="string">r&quot;^Report&quot;</span>, text, flags=re.MULTILINE)</span><br><span class="line"><span class="built_in">print</span>(matches)</span><br><span class="line"><span class="comment"># 输出: [&#x27;Report&#x27;, &#x27;Report&#x27;]</span></span><br></pre></td></tr></table></figure>

<p><strong>解释</strong>：因为加了 <code>re.MULTILINE</code> 标志，<code>^Report</code> 现在不仅匹配了整个字符串的开头（第一行的 <code>&quot;Report&quot;</code>），还匹配了<strong>第二行</strong>的开头（<code>&quot;Report Beta End&quot;</code> 中的 <code>&quot;Report&quot;</code>）。</p>
</li>
</ul>
<p><strong>例 2：使用 $ 查找以 “Python” 结尾的行</strong></p>
<ul>
<li><p><strong>没有 re.MULTILINE</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">matches = re.findall(<span class="string">r&quot;End$&quot;</span>, text)</span><br><span class="line"><span class="built_in">print</span>(matches)</span><br><span class="line"><span class="comment"># 输出: []</span></span><br></pre></td></tr></table></figure>

<p><strong>解释</strong>：整个字符串以 <code>&quot;Report&quot;</code> 结尾，不是 <code>&quot;End&quot;</code>，所以 <code>$</code> 不匹配任何地方。</p>
</li>
<li><p><strong>使用 re.MULTILINE</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">matches = re.findall(<span class="string">r&quot;End$&quot;</span>, text, flags=re.MULTILINE)</span><br><span class="line"><span class="built_in">print</span>(matches)</span><br><span class="line"><span class="comment"># 输出: [&#x27;End&#x27;, &#x27;End&#x27;]</span></span><br></pre></td></tr></table></figure>

<p><strong>解释</strong>：加了 <code>re.MULTILINE</code> 后，<code>End$</code> 匹配了第一行和第二行的<code>End</code>。</p>
</li>
</ul>
<p><strong>总结 <code>re.MULTILINE</code> 的作用：</strong></p>
<p>它让 <code>^</code> 和 <code>$</code> 的作用范围从“整个字符串的边界”扩展到了“<strong>每一行的边界</strong>”，这在你需要处理按行组织的文本，并希望模式能匹配行首或行尾的特定内容时非常有用。在你给出的原始代码中，使用这个标志可能是为了确保整个模式（从思考到答案）能够作为一个完整的单元出现在某一行或连续的几行内，并且严格地从行首开始匹配到行尾结束（或者字符串的起止位置）。</p>
</li>
</ol>
<p>好好好，说了那么多，那如果不加<code>flags = re.MULTILINE</code>会怎么样？（默认大家都知道<code>re.DOTALL</code>的重要性了）</p>
<p>有这么一种几种（其实可以归类成一种情况，但是我就不🤪）：</p>
<ul>
<li><p>情况1：开头第一行全是无关文字</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">okay </span><br><span class="line">&lt;start<span class="built_in">_</span>working<span class="built_in">_</span>out&gt;Let me think!&lt;end<span class="built_in">_</span>working<span class="built_in">_</span>out&gt;&lt;SOLUTION&gt;2&lt;/SOLUTION&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>情况2：结尾最后一行全是无关文字</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">&lt;start<span class="built_in">_</span>working<span class="built_in">_</span>out&gt;Let me think!&lt;end<span class="built_in">_</span>working<span class="built_in">_</span>out&gt;&lt;SOLUTION&gt;2&lt;/SOLUTION&gt;</span><br><span class="line">thanks</span><br></pre></td></tr></table></figure>
</li>
<li><p>情况3：第一行和最后一行都是无关文字</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">okay </span><br><span class="line">&lt;start<span class="built_in">_</span>working<span class="built_in">_</span>out&gt;Let me think!&lt;end<span class="built_in">_</span>working<span class="built_in">_</span>out&gt;&lt;SOLUTION&gt;2&lt;/SOLUTION&gt;</span><br><span class="line">thanks</span><br></pre></td></tr></table></figure></li>
</ul>
<p>那么上述三种情况都无法完成匹配（好像不匹配这些情况也行🤪，作者想匹配，咋滴吧🙄）。</p>
<hr>
<h3 id="第八块：简单使用匹配模板"><a href="#第八块：简单使用匹配模板" class="headerlink" title="第八块：简单使用匹配模板"></a><strong>第八块：简单使用匹配模板</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">match_format.search(</span><br><span class="line">    <span class="string">&quot;&lt;start_working_out&gt;Let me think!&lt;end_working_out&gt;&quot;</span>\</span><br><span class="line">    <span class="string">&quot;&lt;SOLUTION&gt;2&lt;/SOLUTION&gt;&quot;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">&lt;re.Match object; span=(0, 71), match=&#x27;&lt;start<span class="built_in">_</span>working<span class="built_in">_</span>out&gt;Let me think!&lt;end<span class="built_in">_</span>working<span class="built_in">_</span>out&gt;&gt;</span><br></pre></td></tr></table></figure>

<p>这里的span&#x3D;(0, 71)表示匹配的索引（字符）范围（包括0，不包括71），其实是全部匹配了，但后方的match并没有完全（我也不知道为啥🤷‍♂️）。</p>
<h3 id="第九块：定义精确格式匹配奖励函数"><a href="#第九块：定义精确格式匹配奖励函数" class="headerlink" title="第九块：定义精确格式匹配奖励函数"></a><strong>第九块：定义精确格式匹配奖励函数</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">match_format_exactly</span>(<span class="params">completions, **kwargs</span>):</span><br><span class="line">    scores = []</span><br><span class="line">    <span class="keyword">for</span> completion <span class="keyword">in</span> completions:</span><br><span class="line">        score = <span class="number">0</span></span><br><span class="line">        response = completion[<span class="number">0</span>][<span class="string">&quot;content&quot;</span>]</span><br><span class="line">        <span class="comment"># Match if format is seen exactly!</span></span><br><span class="line">        <span class="keyword">if</span> match_format.search(response) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>: score += <span class="number">3.0</span></span><br><span class="line">        scores.append(score)</span><br><span class="line">    <span class="keyword">return</span> scores</span><br></pre></td></tr></table></figure>

<p>这个 match_format_exactly 函数的作用是：</p>
<ol>
<li>接收一个包含多个“完成项”的列表 completions。</li>
<li>假设每个“完成项”的结构大致是 [{“content”: “实际文本”}, …]。</li>
<li>它会遍历每一个“完成项”，提取出其中的 “content” 文本。</li>
<li>使用一个预先编译好的正则表达式 match_format，通过 search 方法检查提取出的文本中<strong>是否包含</strong>符合该正则表达式格式的子串。</li>
<li>如果文本中<strong>包含</strong>了该格式，就给这个“完成项”打 3.0 分；如果不包含，就打 0 分。</li>
<li>最后，函数返回一个列表，该列表按顺序包含了每个输入“完成项”得到的分数（0 或 3.0）。</li>
</ol>
<p><strong>需要注意的点:</strong></p>
<ul>
<li>函数名中的 “exactly” 可能有点误导。因为使用的是 search 方法，它只需要在响应文本中<strong>找到</strong>模式即可，并不要求整个响应文本<strong>完全</strong>等于该模式。如果需要完全匹配整个响应，应该使用 <code>match_format.fullmatch(response)</code>。</li>
</ul>
<h3 id="第十块：定义宽松格式匹配奖励函数"><a href="#第十块：定义宽松格式匹配奖励函数" class="headerlink" title="第十块：定义宽松格式匹配奖励函数"></a><strong>第十块：定义宽松格式匹配奖励函数</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">match_format_approximately</span>(<span class="params">completions, **kwargs</span>):</span><br><span class="line">    scores = []</span><br><span class="line">    <span class="keyword">for</span> completion <span class="keyword">in</span> completions:</span><br><span class="line">        score = <span class="number">0</span></span><br><span class="line">        response = completion[<span class="number">0</span>][<span class="string">&quot;content&quot;</span>]</span><br><span class="line">        <span class="comment"># Count how many keywords are seen - we penalize if too many!</span></span><br><span class="line">        <span class="comment"># If we see 1, then plus some points!</span></span><br><span class="line">        score += <span class="number">0.5</span> <span class="keyword">if</span> response.count(reasoning_start) == <span class="number">1</span> <span class="keyword">else</span> -<span class="number">1.0</span></span><br><span class="line">        score += <span class="number">0.5</span> <span class="keyword">if</span> response.count(reasoning_end)   == <span class="number">1</span> <span class="keyword">else</span> -<span class="number">1.0</span></span><br><span class="line">        score += <span class="number">0.5</span> <span class="keyword">if</span> response.count(solution_start)  == <span class="number">1</span> <span class="keyword">else</span> -<span class="number">1.0</span></span><br><span class="line">        score += <span class="number">0.5</span> <span class="keyword">if</span> response.count(solution_end)    == <span class="number">1</span> <span class="keyword">else</span> -<span class="number">1.0</span></span><br><span class="line">        scores.append(score)</span><br><span class="line">    <span class="keyword">return</span> scores</span><br></pre></td></tr></table></figure>

<p>match_format_approximately 函数的作用是：</p>
<ol>
<li>它不使用正则表达式来检查复杂的结构。</li>
<li>而是<strong>独立地检查</strong>四个预定义的标记字符串（reasoning_start 等）在每个响应文本中<strong>出现的次数</strong>。</li>
<li>它<strong>奖励</strong>每个标记<strong>正好出现一次</strong>的情况（每次加 0.5 分）。</li>
<li>它<strong>惩罚</strong>每个标记<strong>不出现</strong>或<strong>出现多次</strong>（超过一次）的情况（每次减 1.0 分）。</li>
<li>一个完成项的总分是这四个独立检查得分的总和。</li>
</ol>
<p><strong>与 match_format_exactly 的关键区别:</strong></p>
<ul>
<li><strong>exactly</strong> 使用正则表达式检查标记<strong>是否存在</strong>并且是否符合<strong>特定的顺序和结构</strong>（由正则表达式定义）。只要找到一个符合结构的匹配就算成功（得 3 分）。</li>
<li><strong>approximately</strong> 完全不关心标记的顺序或它们之间的内容。它只关心<strong>每个标记自身出现的次数</strong>。它更像是检查“<strong>配料表</strong>”（是否包含了所有必需的标记，且不多不少），而不是检查“<strong>烹饪步骤</strong>”（标记是否按正确顺序和结构组织）。</li>
</ul>
<p>这种“近似”匹配方法可能用于快速筛选那些看起来“可能”包含了所需格式元素的响应，即使它们的结构不完全正确。高分（接近 2.0）表示所有必需的标记都出现了，并且都只出现了一次，这通常是一个好的迹象。低分则表示缺少标记或标记重复，格式可能存在问题。</p>
<hr>
<h3 id="第十一块：定义答案检查奖励函数"><a href="#第十一块：定义答案检查奖励函数" class="headerlink" title="第十一块：定义答案检查奖励函数"></a><strong>第十一块：定义答案检查奖励函数</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">check_answer</span>(<span class="params">prompts, completions, answer, **kwargs</span>):</span><br><span class="line">    question = prompts[<span class="number">0</span>][-<span class="number">1</span>][<span class="string">&quot;content&quot;</span>]</span><br><span class="line">    responses = [completion[<span class="number">0</span>][<span class="string">&quot;content&quot;</span>] <span class="keyword">for</span> completion <span class="keyword">in</span> completions]</span><br><span class="line"></span><br><span class="line">    extracted_responses = [</span><br><span class="line">        guess.group(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> (guess := match_format.search(r)) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="literal">None</span> \</span><br><span class="line">        <span class="keyword">for</span> r <span class="keyword">in</span> responses</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    scores = []</span><br><span class="line">    <span class="keyword">for</span> guess, true_answer <span class="keyword">in</span> <span class="built_in">zip</span>(extracted_responses, answer):</span><br><span class="line">        score = <span class="number">0</span></span><br><span class="line">        <span class="keyword">if</span> guess <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            scores.append(<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="comment"># Correct answer gets 3 points!</span></span><br><span class="line">        <span class="keyword">if</span> guess == true_answer:</span><br><span class="line">            score += <span class="number">3.0</span></span><br><span class="line">        <span class="comment"># Match if spaces are seen, but less reward</span></span><br><span class="line">        <span class="keyword">elif</span> guess.strip() == true_answer.strip():</span><br><span class="line">            score += <span class="number">1.5</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># We also reward it if the answer is close via ratios!</span></span><br><span class="line">            <span class="comment"># Ie if the answer is within some range, reward it!</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                ratio = <span class="built_in">float</span>(guess) / <span class="built_in">float</span>(true_answer)</span><br><span class="line">                <span class="keyword">if</span>   ratio &gt;= <span class="number">0.9</span> <span class="keyword">and</span> ratio &lt;= <span class="number">1.1</span>: score += <span class="number">1.0</span></span><br><span class="line">                <span class="keyword">elif</span> ratio &gt;= <span class="number">0.8</span> <span class="keyword">and</span> ratio &lt;= <span class="number">1.2</span>: score += <span class="number">0.5</span></span><br><span class="line">                <span class="keyword">else</span>: score -= <span class="number">1.5</span> <span class="comment"># Penalize wrong answers</span></span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                score -= <span class="number">1.5</span> <span class="comment"># Penalize</span></span><br><span class="line">        scores.append(score)</span><br><span class="line">    <span class="keyword">return</span> scores</span><br></pre></td></tr></table></figure>

<p>这个函数的主要目的是<strong>评估模型生成的一系列“完成”（completions）中提取出的答案与提供的标准答案的匹配程度，并给出一系列相应的分数</strong>。它采用了一种分层次的评分策略，从精确匹配到近似数值匹配。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">extracted_responses = [</span><br><span class="line">        guess.group(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> (guess := match_format.search(r)) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="literal">None</span> \</span><br><span class="line">        <span class="keyword">for</span> r <span class="keyword">in</span> responses</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 相当于</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 先创建一个空的列表，用来存放最终提取出来的答案</span></span><br><span class="line">extracted_responses = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 使用 for 循环遍历 `responses` 列表中的每一个原始响应文本 `r`</span></span><br><span class="line"><span class="keyword">for</span> r <span class="keyword">in</span> responses:</span><br><span class="line">    <span class="comment"># 3. 对当前的响应文本 `r`，调用 match_format.search() 进行查找</span></span><br><span class="line">    guess = match_format.search(r)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 4. 检查 search() 的结果</span></span><br><span class="line">    <span class="keyword">if</span> guess <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="comment"># 5. 如果 guess 不是 None，意味着找到了匹配</span></span><br><span class="line">        <span class="comment">#    从匹配对象 guess 中提取第一个捕获组的内容 (就是 &lt;SOLUTION&gt;...&lt;/SOLUTION&gt; 之间的部分)</span></span><br><span class="line">        extracted_answer = guess.group(<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 6. 将提取到的答案添加到 extracted_responses 列表中</span></span><br><span class="line">        extracted_responses.append(extracted_answer)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 7. 如果 guess 是 None，意味着没有找到匹配</span></span><br><span class="line">        <span class="comment">#    在这种情况下，将 None 添加到 extracted_responses 列表中</span></span><br><span class="line">        extracted_responses.append(<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 循环结束后，extracted_responses 列表就包含了所有处理结果</span></span><br><span class="line"><span class="comment"># （要么是提取出的答案字符串，要么是 None）</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这小段代码作用：</p>
<ol>
<li>遍历 <code>responses</code> 列表里的每一个字符串 <code>r</code>。</li>
<li>用 <code>match_format.search(r)</code> 尝试在这个字符串里找到符合模式的部分。</li>
<li>如果找到了 (结果不是 <code>None</code>)，就从找到的匹配对象里提取出第一个括号 (…) 捕获的内容 (<code>.group(1)</code>)，并把它存起来。</li>
<li>如果没找到 (结果是 <code>None</code>)，就存一个 <code>None</code>。</li>
<li>最后，把所有存起来的结果（提取到的字符串或 <code>None</code>）组成一个新的列表 <code>extracted_responses</code>。</li>
</ol>
<p>接下来的代码解释：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scores = []</span><br><span class="line">    <span class="comment"># 1. 初始化最终分数列表:</span></span><br><span class="line">    <span class="comment">#    - 创建一个空列表 `scores` 用于存储每个 completion 的最终得分。</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> guess, true_answer <span class="keyword">in</span> <span class="built_in">zip</span>(extracted_responses, answer):</span><br><span class="line">        <span class="comment"># 2. 遍历提取出的答案和标准答案:</span></span><br><span class="line">        <span class="comment">#    - `zip(extracted_responses, answer)`: 将模型提取出的答案列表和标准答案列表配对，</span></span><br><span class="line">        <span class="comment">#      每次循环同时取出对应的 `guess` (模型答案) 和 `true_answer` (标准答案)。</span></span><br><span class="line"></span><br><span class="line">        score = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 3. 初始化当前对的分数:</span></span><br><span class="line">        <span class="comment">#    - 对每一对答案，将分数 `score` 重置为 0。</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> guess <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 4. 处理提取失败的情况:</span></span><br><span class="line">            <span class="comment">#    - 如果 `guess` 是 `None`，意味着之前的正则表达式未能从模型响应中成功提取出答案。</span></span><br><span class="line">            scores.append(<span class="number">0</span>) <span class="comment"># 这种情况下得分记为 0。</span></span><br><span class="line">            <span class="keyword">continue</span> <span class="comment"># 跳过后续的比较，直接处理下一对答案。</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># --- 如果 guess 不是 None (即成功提取出模型答案) ---</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Correct answer gets 3 points!</span></span><br><span class="line">        <span class="keyword">if</span> guess == true_answer:</span><br><span class="line">            <span class="comment"># 5. 精确匹配检查:</span></span><br><span class="line">            <span class="comment">#    - 判断提取出的 `guess` 是否与 `true_answer` **完全相同** (字符串完全相等)。</span></span><br><span class="line">            score += <span class="number">3.0</span> <span class="comment"># 如果完全相同，加 3.0 分。</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Match if spaces are seen, but less reward</span></span><br><span class="line">        <span class="keyword">elif</span> guess.strip() == true_answer.strip():</span><br><span class="line">            <span class="comment"># 6. 忽略首尾空格的匹配检查:</span></span><br><span class="line">            <span class="comment">#    - `.strip()`: 去除字符串开头和结尾的空白字符（空格、换行、制表符等）。</span></span><br><span class="line">            <span class="comment">#    - 如果去除首尾空格后的 `guess` 和 `true_answer` 相等。</span></span><br><span class="line">            score += <span class="number">1.5</span> <span class="comment"># 加 1.5 分（比精确匹配少）。</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 7. 如果字符串不匹配，尝试数值近似匹配:</span></span><br><span class="line">            <span class="comment"># We also reward it if the answer is close via ratios!</span></span><br><span class="line">            <span class="comment"># Ie if the answer is within some range, reward it!</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="comment"># 8. 尝试转换为浮点数并计算比率:</span></span><br><span class="line">                <span class="comment">#    - `float(guess)`: 尝试将模型答案转换为浮点数。</span></span><br><span class="line">                <span class="comment">#    - `float(true_answer)`: 尝试将标准答案转换为浮点数。</span></span><br><span class="line">                <span class="comment">#    - `/`: 计算两者的比率。</span></span><br><span class="line">                <span class="comment">#    - `try...except`: 使用 try-except 块来捕获转换失败可能引发的异常 </span></span><br><span class="line">                <span class="comment">#      (比如答案是 &quot;two&quot; 而不是 &quot;2&quot;，或者答案为空字符串等，无法转为 float)。</span></span><br><span class="line">                ratio = <span class="built_in">float</span>(guess) / <span class="built_in">float</span>(true_answer)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> ratio &gt;= <span class="number">0.9</span> <span class="keyword">and</span> ratio &lt;= <span class="number">1.1</span>:</span><br><span class="line">                    <span class="comment"># 9. 检查比率是否在 [0.9, 1.1] 区间 (即 ±10%):</span></span><br><span class="line">                    score += <span class="number">1.0</span> <span class="comment"># 如果非常接近，加 1.0 分。</span></span><br><span class="line">                <span class="keyword">elif</span> ratio &gt;= <span class="number">0.8</span> <span class="keyword">and</span> ratio &lt;= <span class="number">1.2</span>:</span><br><span class="line">                    <span class="comment"># 10. 检查比率是否在 [0.8, 1.2] 区间 (即 ±20%):</span></span><br><span class="line">                    score += <span class="number">0.5</span> <span class="comment"># 如果比较接近，加 0.5 分。</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment"># 11. 如果比率超出 ±20% 范围:</span></span><br><span class="line">                    score -= <span class="number">1.5</span> <span class="comment"># 答案偏差太大，扣 1.5 分 (惩罚)。</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                <span class="comment"># 12. 处理转换失败或除零错误:</span></span><br><span class="line">                <span class="comment">#    - 如果 `try` 块中的代码（主要是 `float()` 转换或除法）出错。</span></span><br><span class="line">                score -= <span class="number">1.5</span> <span class="comment"># 同样扣 1.5 分 (惩罚无法进行数值比较的情况)。</span></span><br><span class="line">        </span><br><span class="line">        scores.append(score)</span><br><span class="line">        <span class="comment"># 13. 将计算出的分数添加到列表:</span></span><br><span class="line">        <span class="comment">#     - 将当前这对答案最终计算得到的 `score` 添加到 `scores` 列表中。</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> scores</span><br><span class="line">    <span class="comment"># 14. 返回分数列表:</span></span><br><span class="line">    <span class="comment">#     - 当所有答案对都处理完毕后，返回包含所有分数的 `scores` 列表。</span></span><br></pre></td></tr></table></figure>

<p><code>check_answer</code> 函数通过以下步骤来评估模型完成项的答案质量：</p>
<ol>
<li>从原始完成项中提取出纯文本响应。</li>
<li>使用预定义的正则表达式 <code>match_format</code> 尝试从每个响应中提取出答案部分（捕获组 1）。如果提取失败，该响应的得分为 0。</li>
<li>如果提取成功，将提取出的答案与对应的标准答案进行比较：<ul>
<li><strong>精确匹配</strong>：得分 +3.0。</li>
<li><strong>忽略首尾空格后匹配</strong>：得分 +1.5。</li>
<li><strong>否则，尝试数值比较</strong>：<ul>
<li>转换为浮点数计算比率。</li>
<li>比率在 <strong>±10%</strong> 内：得分 +1.0。</li>
<li>比率在 <strong>±20%</strong> 内：得分 +0.5。</li>
<li>比率<strong>超出 ±20%</strong> 或<strong>无法进行数值转换&#x2F;比较</strong>：得分 -1.5 (惩罚)。</li>
</ul>
</li>
</ul>
</li>
<li>返回一个包含每个完成项得分的列表。</li>
</ol>
<p>这个函数旨在对预期答案主要是数值类型的问题进行比较鲁棒的评分，同时也能处理一些格式上的小差异（如多余空格）。</p>
<hr>
<h3 id="第十二块：定义数字匹配模板"><a href="#第十二块：定义数字匹配模板" class="headerlink" title="第十二块：定义数字匹配模板"></a><strong>第十二块：定义数字匹配模板</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">match_numbers = re.<span class="built_in">compile</span>(</span><br><span class="line">    solution_start + <span class="string">r&quot;.*?([\d\.\,]&#123;1,&#125;)&quot;</span>,</span><br><span class="line">    flags = re.MULTILINE | re.DOTALL</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(match_numbers.findall(<span class="string">&quot;&lt;SOLUTION&gt;  0.34  &lt;/SOLUTION&gt;&quot;</span>))</span><br><span class="line"><span class="built_in">print</span>(match_numbers.findall(<span class="string">&quot;&lt;SOLUTION&gt;  123,456  &lt;/SOLUTION&gt;&quot;</span>))</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[<span class="string">&#x27;0.34&#x27;</span>]</span><br><span class="line">[<span class="string">&#x27;123,456&#x27;</span>]</span><br></pre></td></tr></table></figure>

<ul>
<li><code>.*?</code>:<ul>
<li><code>.</code>: 匹配任何单个字符（因为有 <code>re.DOTALL</code> 标志，所以<strong>包括换行符</strong>）。</li>
<li><code>*</code>: 匹配前面的 <code>.</code> 零次或多次。</li>
<li><code>?</code>: 使 <code>*</code> 变成<strong>非贪婪</strong>模式。这意味着它会匹配<strong>尽可能少</strong>的字符，直到后面的模式能够匹配为止。</li>
<li><strong>作用</strong>: 从 <code>solution_start</code> 标记之后开始，匹配任意数量的最少字符。</li>
</ul>
</li>
<li><code>([\d\.\,]&#123;1,&#125;)</code>: 这是模式的关键部分，也是一个<strong>捕获组</strong>。<ul>
<li><code>(...)</code>: 定义了一个<strong>捕获组</strong>。<code>findall</code> 方法特别关注捕获组——如果模式中有捕获组，<code>findall</code> 会返回<strong>所有匹配中捕获组的内容</strong>。</li>
<li><code>[ ... ]</code>: 定义一个字符集，匹配方括号内<strong>任意一个</strong>字符。</li>
<li><code>\d</code>: 匹配任何<strong>数字</strong> (<code>0-9</code>)。</li>
<li><code>\.</code>: 匹配一个<strong>字面量的点</strong> (<code>.</code>)。需要用反斜杠 <code>\</code> 转义，因为 <code>.</code> 在正则表达式中通常有特殊含义（匹配任意字符）。</li>
<li><code>\,</code>: 匹配一个<strong>字面量的逗号</strong> (<code>,</code>)。在字符集 <code>[]</code> 内部，逗号通常不需要转义，但转义了也没错，有时能增加清晰度。</li>
<li><code>[ \d\.\,]:</code>这个字符集整体表示：匹配一个字符，这个字符必须是<strong>数字、点或逗号</strong>中的任意一个。</li>
<li><code>&#123;1,&#125;</code>: 这是量词，表示前面的元素（即 <code>[\d\.\,]</code> 字符集）必须出现<strong>至少 1 次</strong> (<code>1</code>) 或<strong>任意多次</strong> (<code>,</code>)。</li>
<li><strong>捕获组 <code>([\d\.\,]&#123;1,&#125;)</code> 的整体含义</strong>: 匹配并<strong>捕获</strong>一个由<strong>至少一个</strong>数字、点或逗号组成的<strong>连续</strong>序列。</li>
</ul>
</li>
<li><code>flags = re.MULTILINE | re.DOTALL</code>:<ul>
<li><code>re.DOTALL</code>: 让 . 可以匹配包括换行符在内的所有字符。这影响了前面的 <code>.*?</code>。</li>
<li><code>re.MULTILINE</code>: 让 <code>^</code> 和 <code>$</code> 可以匹配行的开头和结尾。<strong>但这个特定的正则表达式模式并没有使用 <code>^</code> 或 <code>$</code>，所以 <code>re.MULTILINE</code> 在这里实际上没有产生任何效果。</strong></li>
</ul>
</li>
</ul>
<h3 id="第十三块：定义答案中数字检查奖励函数"><a href="#第十三块：定义答案中数字检查奖励函数" class="headerlink" title="第十三块：定义答案中数字检查奖励函数"></a><strong>第十三块：定义答案中数字检查奖励函数</strong></h3><p>原始：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">global</span> PRINTED_TIMES</span><br><span class="line">PRINTED_TIMES = <span class="number">0</span></span><br><span class="line"><span class="keyword">global</span> PRINT_EVERY_STEPS</span><br><span class="line">PRINT_EVERY_STEPS = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_numbers</span>(<span class="params">prompts, completions, answer, **kwargs</span>):</span><br><span class="line">    question = prompts[<span class="number">0</span>][-<span class="number">1</span>][<span class="string">&quot;content&quot;</span>]</span><br><span class="line">    responses = [completion[<span class="number">0</span>][<span class="string">&quot;content&quot;</span>] <span class="keyword">for</span> completion <span class="keyword">in</span> completions]</span><br><span class="line"></span><br><span class="line">    extracted_responses = [</span><br><span class="line">        guess.group(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> (guess := match_numbers.search(r)) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="literal">None</span> \</span><br><span class="line">        <span class="keyword">for</span> r <span class="keyword">in</span> responses</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    scores = []</span><br><span class="line">    <span class="comment"># Print only every few steps</span></span><br><span class="line">    <span class="keyword">global</span> PRINTED_TIMES</span><br><span class="line">    <span class="keyword">global</span> PRINT_EVERY_STEPS</span><br><span class="line">    <span class="keyword">if</span> PRINTED_TIMES % PRINT_EVERY_STEPS == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;*&#x27;</span>*<span class="number">20</span>, <span class="string">f&quot;Question:\n<span class="subst">&#123;question&#125;</span>&quot;</span>, <span class="string">f&quot;\nAnswer:\n<span class="subst">&#123;answer[<span class="number">0</span>]&#125;</span>&quot;</span>, <span class="string">f&quot;\nResponse:\n<span class="subst">&#123;responses[<span class="number">0</span>]&#125;</span>&quot;</span>, <span class="string">f&quot;\nExtracted:\n<span class="subst">&#123;extracted_responses[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line">    PRINTED_TIMES += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> guess, true_answer <span class="keyword">in</span> <span class="built_in">zip</span>(extracted_responses, answer):</span><br><span class="line">        <span class="keyword">if</span> guess <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            scores.append(<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="comment"># Convert to numbers</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            true_answer = <span class="built_in">float</span>(true_answer.strip())</span><br><span class="line">            <span class="comment"># Remove commas like in 123,456</span></span><br><span class="line">            guess       = <span class="built_in">float</span>(guess.strip().replace(<span class="string">&quot;,&quot;</span>, <span class="string">&quot;&quot;</span>))</span><br><span class="line">            scores.append(<span class="number">1.5</span> <span class="keyword">if</span> guess == true_answer <span class="keyword">else</span> -<span class="number">0.5</span>)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            scores.append(<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">return</span> scores</span><br></pre></td></tr></table></figure>

<p>带注释版：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义全局变量用于控制打印频率</span></span><br><span class="line"><span class="keyword">global</span> PRINTED_TIMES</span><br><span class="line">PRINTED_TIMES = <span class="number">0</span>  <span class="comment"># 初始化一个计数器，记录函数被调用的次数</span></span><br><span class="line"><span class="keyword">global</span> PRINT_EVERY_STEPS</span><br><span class="line">PRINT_EVERY_STEPS = <span class="number">5</span> <span class="comment"># 设置每调用 5 次函数打印一次信息</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_numbers</span>(<span class="params">prompts, completions, answer, **kwargs</span>):</span><br><span class="line">    <span class="comment"># 1. 定义函数:</span></span><br><span class="line">    <span class="comment">#    - `prompts`: 就是第6块的prompts。</span></span><br><span class="line">    <span class="comment">#    - `completions`: 包含模型生成的多个完成项的列表。</span></span><br><span class="line">    <span class="comment">#    - `answer`: 包含与每个 completion 对应的标准答案的列表 (预期是数字字符串)。</span></span><br><span class="line">    <span class="comment">#    - `**kwargs`: 可选关键字参数 (未使用)。</span></span><br><span class="line"></span><br><span class="line">    question = prompts[<span class="number">0</span>][-<span class="number">1</span>][<span class="string">&quot;content&quot;</span>]</span><br><span class="line">    <span class="comment"># 2. 提取问题文本 (主要用于打印调试信息)。</span></span><br><span class="line">    responses = [completion[<span class="number">0</span>][<span class="string">&quot;content&quot;</span>] <span class="keyword">for</span> completion <span class="keyword">in</span> completions]</span><br><span class="line">    <span class="comment"># 3. 提取原始响应文本列表。</span></span><br><span class="line"></span><br><span class="line">    extracted_responses = [</span><br><span class="line">        <span class="comment"># 使用列表推导式和海象运算符，配合 match_numbers 正则表达式提取数字字符串</span></span><br><span class="line">        guess.group(<span class="number">1</span>) <span class="comment"># 如果匹配成功，取第一个捕获组 (应为数字、点、逗号组成的字符串)</span></span><br><span class="line">        <span class="keyword">if</span> (guess := match_numbers.search(r)) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="literal">None</span> <span class="comment"># 尝试搜索，找到则赋值并判断非 None</span></span><br><span class="line">        <span class="keyword">for</span> r <span class="keyword">in</span> responses <span class="comment"># 遍历每个原始响应 r</span></span><br><span class="line">    ]</span><br><span class="line">    <span class="comment"># 4. 提取模型响应中的数字字符串:</span></span><br><span class="line">    <span class="comment">#    - 这与 `check_answer` 中的提取逻辑类似，但使用的是 `match_numbers` 正则表达式。</span></span><br><span class="line">    <span class="comment">#    - `match_numbers` 被设计用来查找 solution_start 标记后的第一个数字/点/逗号序列。</span></span><br><span class="line">    <span class="comment">#    - `extracted_responses` 列表包含了从每个响应中提取出的数字字符串（或 None）。</span></span><br><span class="line"></span><br><span class="line">    scores = [] <span class="comment"># 5. 初始化最终分数列表。</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># --- 打印调试信息部分 ---</span></span><br><span class="line">    <span class="comment"># Print only every few steps</span></span><br><span class="line">    <span class="keyword">global</span> PRINTED_TIMES <span class="comment"># 声明要修改全局变量 PRINTED_TIMES</span></span><br><span class="line">    <span class="keyword">global</span> PRINT_EVERY_STEPS <span class="comment"># 声明要使用全局变量 PRINT_EVERY_STEPS</span></span><br><span class="line">    <span class="keyword">if</span> PRINTED_TIMES % PRINT_EVERY_STEPS == <span class="number">0</span>: <span class="comment"># 检查调用次数是否是打印步长的整数倍</span></span><br><span class="line">        <span class="comment"># 6. 定期打印调试信息:</span></span><br><span class="line">        <span class="comment">#    - `PRINTED_TIMES % PRINT_EVERY_STEPS == 0`: 使用模运算 (%) 判断调用次数 `PRINTED_TIMES` </span></span><br><span class="line">        <span class="comment">#      除以 `PRINT_EVERY_STEPS` (5) 的余数是否为 0。如果是，则执行打印。</span></span><br><span class="line">        <span class="comment">#    - `print(...)`: 打印分隔符、问题、第一个标准答案、第一个原始响应和第一个提取出的数字字符串。</span></span><br><span class="line">        <span class="comment">#      这有助于在程序运行时观察输入、输出和提取结果是否符合预期。</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;*&#x27;</span>*<span class="number">20</span>, <span class="string">f&quot;Question:\n<span class="subst">&#123;question&#125;</span>&quot;</span>, <span class="string">f&quot;\nAnswer:\n<span class="subst">&#123;answer[<span class="number">0</span>]&#125;</span>&quot;</span>, <span class="string">f&quot;\nResponse:\n<span class="subst">&#123;responses[<span class="number">0</span>]&#125;</span>&quot;</span>, <span class="string">f&quot;\nExtracted:\n<span class="subst">&#123;extracted_responses[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line">    PRINTED_TIMES += <span class="number">1</span> <span class="comment"># 7. 增加调用次数计数器: 每次函数执行完毕前，将计数器加 1。</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># --- 核心评分逻辑 ---</span></span><br><span class="line">    <span class="keyword">for</span> guess, true_answer <span class="keyword">in</span> <span class="built_in">zip</span>(extracted_responses, answer):</span><br><span class="line">        <span class="comment"># 8. 遍历提取出的数字字符串和标准答案。</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> guess <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 9. 处理提取失败: 如果未能从模型响应中提取出数字字符串 (`guess` is None)。</span></span><br><span class="line">            scores.append(<span class="number">0</span>) <span class="comment"># 得分为 0。</span></span><br><span class="line">            <span class="keyword">continue</span> <span class="comment"># 跳过后续比较。</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Convert to numbers</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># 10. 尝试将标准答案和提取出的猜测转换为数字进行比较:</span></span><br><span class="line">            true_answer = <span class="built_in">float</span>(true_answer.strip())</span><br><span class="line">            <span class="comment">#    - `true_answer.strip()`: 去除标准答案字符串首尾的空格。</span></span><br><span class="line">            <span class="comment">#    - `float(...)`: 将处理过的标准答案字符串转换为浮点数。</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Remove commas like in 123,456</span></span><br><span class="line">            guess = <span class="built_in">float</span>(guess.strip().replace(<span class="string">&quot;,&quot;</span>, <span class="string">&quot;&quot;</span>))</span><br><span class="line">            <span class="comment">#    - `guess.strip()`: 去除提取出的数字字符串首尾的空格。</span></span><br><span class="line">            <span class="comment">#    - `.replace(&quot;,&quot;, &quot;&quot;)`: 移除字符串中所有的逗号 (处理 &quot;123,456&quot; 这样的情况)。</span></span><br><span class="line">            <span class="comment">#    - `float(...)`: 将处理后的、不含逗号的字符串转换为浮点数。</span></span><br><span class="line">            </span><br><span class="line">            scores.append(<span class="number">1.5</span> <span class="keyword">if</span> guess == true_answer <span class="keyword">else</span> -<span class="number">0.5</span>)</span><br><span class="line">            <span class="comment"># 11. 比较转换后的数字并评分:</span></span><br><span class="line">            <span class="comment">#    - `guess == true_answer`: 判断两个浮点数是否**完全相等**。</span></span><br><span class="line">            <span class="comment">#    - `1.5 if ... else -0.5`: </span></span><br><span class="line">            <span class="comment">#        - 如果数字完全相等，得 1.5 分。</span></span><br><span class="line">            <span class="comment">#        - 如果数字不相等，得 -0.5 分 (作为惩罚)。</span></span><br><span class="line">            <span class="comment">#    - 将得分添加到 `scores` 列表。</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="comment"># 12. 处理转换失败:</span></span><br><span class="line">            <span class="comment">#    - 如果 `try` 块中的任何操作（`strip`, `replace`, `float`）失败，</span></span><br><span class="line">            <span class="comment">#      比如答案或提取结果不是有效的数字格式。</span></span><br><span class="line">            scores.append(<span class="number">0</span>) <span class="comment"># 转换失败或比较出错的情况下，得分记为 0。</span></span><br><span class="line">            <span class="keyword">continue</span> <span class="comment"># 继续处理下一对。</span></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> scores <span class="comment"># 13. 返回包含所有分数的列表。</span></span><br></pre></td></tr></table></figure>

<p><code>check_numbers</code> 函数专门用于评估模型生成的答案中<strong>数值</strong>的准确性：</p>
<ol>
<li>它使用 <code>match_numbers</code> 正则表达式从模型响应中<strong>提取</strong>看起来像数字（可能包含点和逗号）的字符串。</li>
<li>它有一个<strong>调试打印机制</strong>，每隔 PRINT_EVERY_STEPS 次调用就会打印一次处理信息，方便开发者跟踪情况。</li>
<li>如果成功提取出数字字符串，它会尝试将<strong>提取出的字符串</strong>（去除空格和逗号后）和<strong>标准答案字符串</strong>（去除空格后）都<strong>转换成浮点数</strong>。</li>
<li><strong>比较这两个浮点数是否完全相等</strong>：<ul>
<li>相等：得 <code>1.5</code> 分。</li>
<li>不相等：得 <code>-0.5</code> 分（惩罚）。</li>
</ul>
</li>
<li>如果在提取或转换数字的过程中出现任何<strong>错误</strong>（比如提取失败、无法转换为浮点数），则该项得 <code>0</code> 分。</li>
<li>最终返回一个包含每个完成项得分的列表。</li>
</ol>
<p><strong>与 <code>check_answer</code> 的主要区别:</strong></p>
<ul>
<li><strong>侧重点</strong>: <code>check_numbers</code> <strong>只关心数值的精确匹配</strong>（转换成 <code>float</code> 后比较），而 <code>check_answer</code> 的评分逻辑更复杂，包含字符串精确匹配、忽略空格匹配和数值的<strong>近似比率</strong>匹配。</li>
<li><strong>错误处理</strong>: <code>check_numbers</code> 在无法转换为数字比较时给 <code>0</code> 分，而 <code>check_answer</code> 在无法进行数值比较时会给 <code>-1.5</code> 的惩罚分。</li>
<li><strong>评分</strong>: <code>check_numbers</code> 的分数范围是明确的 <code>&#123;1.5, -0.5, 0&#125;</code>，而 <code>check_answer</code> 的分数可能性更多 <code>&#123;3.0, 1.5, 1.0, 0.5, 0, -1.5&#125;</code>。</li>
<li><strong>调试信息</strong>: <code>check_numbers</code> 包含了一个定期打印调试信息的机制。</li>
</ul>
<hr>
<h3 id="第十四块：计算最大prompt长度"><a href="#第十四块：计算最大prompt长度" class="headerlink" title="第十四块：计算最大prompt长度"></a><strong>第十四块：计算最大prompt长度</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">max</span>(dataset.<span class="built_in">map</span>(</span><br><span class="line">    <span class="keyword">lambda</span> x: &#123;<span class="string">&quot;tokens&quot;</span> : tokenizer.apply_chat_template(x[<span class="string">&quot;prompt&quot;</span>], add_generation_prompt = <span class="literal">True</span>, tokenize = <span class="literal">True</span>)&#125;,</span><br><span class="line">    batched = <span class="literal">True</span>,</span><br><span class="line">).<span class="built_in">map</span>(<span class="keyword">lambda</span> x: &#123;<span class="string">&quot;length&quot;</span> : <span class="built_in">len</span>(x[<span class="string">&quot;tokens&quot;</span>])&#125;)[<span class="string">&quot;length&quot;</span>])</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">287</span><br></pre></td></tr></table></figure>

<p>这行代码的最终目的是计算出数据集中所有 <code>prompt</code>（经过特定格式化和分词后）的<strong>最大长度</strong>（以<code> token</code> 数量计）。这在设置模型训练或推理时的最大序列长度时很有用。</p>
<p><strong>分解步骤:</strong></p>
<ol>
<li><p><strong><code>dataset.map(...)</code> (第一个 map):</strong></p>
<ul>
<li><strong>作用</strong>: 对原始 <code>dataset</code> 中的每一条数据（或每一批数据）应用一个转换函数。</li>
<li><strong><code>lambda x: ...</code></strong>: 定义了这个转换函数。<ul>
<li><code>x</code>: 代表数据集中的一条数据（或一批数据，因为 <code>batched=True</code>）。我们知道 <code>x</code> 至少包含一个键 <code>&quot;prompt&quot;</code>。</li>
<li><code>x[&quot;prompt&quot;]</code>: 获取这条数据（或这批数据）的 “prompt” 部分。根据之前的例子，这可能是一个列表，包含了对话的角色和内容，例如 <code>[&#123;&#39;role&#39;: &#39;system&#39;, &#39;content&#39;: &#39;...&#39;&#125;, &#123;&#39;role&#39;: &#39;user&#39;, &#39;content&#39;: &#39;...&#39;&#125;]</code>。</li>
<li><strong><code>tokenizer.apply_chat_template(x[&quot;prompt&quot;], add_generation_prompt = True, tokenize = True)</code></strong>: 这是核心操作。<ul>
<li><code>tokenizer</code>: 指向一个预先加载好的分词器对象 (Tokenizer)。</li>
<li><code>.apply_chat_template()</code>: 这个方法会根据分词器内部定义的“聊天模板”，将输入的对话结构 (<code>x[&quot;prompt&quot;]</code>) 转换成一个适合模型输入的<strong>单一字符串或 token ID 列表</strong>。它会添加特殊标记来区分不同的角色（如 system, user, assistant）。</li>
<li><code>add_generation_prompt = True</code>: 这个参数通常意味着在模板末尾加上提示模型开始生成回应的标记（比如 <code>&lt;|assistant|&gt;\n</code> 或类似标记对应的 token ID）。</li>
<li><code>tokenize = True</code>: 这个参数指示 <code>.apply_chat_template</code> 不仅仅是生成格式化后的字符串，还要<strong>直接将其分词（tokenize）</strong>，输出一个<strong>整数列表（token IDs）</strong>。</li>
</ul>
</li>
<li><code>&#123;&quot;tokens&quot; : ...&#125;</code>: lambda 函数返回一个新的字典，其中键是 <code>&quot;tokens&quot;</code>，值是上面 <code>apply_chat_template</code> 产生的 token ID 列表。</li>
</ul>
</li>
<li><strong><code>batched = True</code></strong>: 这是一个重要的性能优化参数。它告诉 <code>.map</code> 函数应该将数据<strong>分批 (batch)</strong> 传递给 lambda 函数，而不是一条一条地处理。lambda 函数中的 <code>x[&quot;prompt&quot;]</code> 此时会是一批 prompts，<code>apply_chat_template</code> 通常也能高效地处理批量输入。</li>
<li><strong>第一个 map 的输出</strong>: 它产生一个新的数据集（我们叫它 <code>dataset_with_tokens</code>）。这个新数据集中，每条数据都包含了原始数据的所有字段，<strong>外加一个新的字段 <code>&quot;tokens&quot;</code></strong>，里面存着对应 <code>&quot;prompt&quot;</code> 被格式化和分词后的 <code>token ID</code> 列表。</li>
</ul>
</li>
<li><p><strong><code>.map(...)</code> (第二个 map):</strong></p>
<ul>
<li><strong>作用</strong>: 对<strong>上一步产生</strong>的 <code>dataset_with_tokens</code> 数据集再次应用转换。</li>
<li><strong><code>lambda x: ...</code></strong>: 定义了第二个转换函数。<ul>
<li><code>x</code>: 代表 <code>dataset_with_tokens</code> 中的一条数据（这里没有 <code>batched=True</code>，所以通常是一条条处理）。这条数据现在肯定包含 <code>&quot;tokens&quot;</code> 字段。</li>
<li><code>x[&quot;tokens&quot;]</code>: 获取这条数据的 token ID 列表。</li>
<li><code>len(x[&quot;tokens&quot;])</code>: 计算这个 token ID 列表的<strong>长度</strong>，也就是 token 的数量。</li>
<li><code>&#123;&quot;length&quot; : ...&#125;</code>: lambda 函数返回一个字典，键是 <code>&quot;length&quot;</code>，值是计算出的 token 数量。</li>
</ul>
</li>
<li><strong>第二个 map 的输出</strong>: 它又产生一个新的数据集（我们叫它 <code>dataset_with_tokens_and_length</code>）。这个数据集中，每条数据包含了之前的所有字段，<strong>又增加了一个新字段 <code>&quot;length&quot;</code></strong>，里面存着对应 “prompt” 的 token 数量。</li>
</ul>
</li>
<li><p><strong><code>[&quot;length&quot;]</code></strong>:</p>
<ul>
<li><strong>作用</strong>: 在很多数据处理库（如 Hugging Face <code>datasets</code>）中，对数据集对象使用方括号索引（如 <code>[&quot;length&quot;]</code>) 会<strong>提取出所有数据条目中名为 “length” 的那个字段的值</strong>。</li>
<li><strong>输出</strong>: 它返回一个包含所有 “prompt” 长度的列表（或类似的数据结构），例如 <code>[150, 123, 210, 88, ...]</code>。</li>
</ul>
</li>
<li><p><strong><code>max(...)</code></strong>:</p>
<ul>
<li><strong>作用</strong>: 这是 Python 内置的标准函数，用于找出列表或其他可迭代对象中的<strong>最大值</strong>。</li>
<li><strong>输入</strong>: 上一步产生的包含所有 token 长度的列表。</li>
<li><strong>输出</strong>: 一个<strong>单一的数字</strong>，代表了数据集中所有经过处理的 “prompt” 中最长的那一个的 token 数量。</li>
</ul>
</li>
</ol>
<p><strong>总结:</strong></p>
<p>这行代码执行了一个<strong>数据处理流水线</strong>：</p>
<ol>
<li>取原始 <code>dataset</code>。</li>
<li><strong>第一步映射 (<code>map</code>)</strong>: 将每个 <code>prompt</code> 使用 <code>tokenizer</code> 的聊天模板格式化并分词，得到 <code>token ID</code> 列表，并将结果存入新的 <code>&quot;tokens&quot;</code> 字段（批量处理以提高效率）。</li>
<li><strong>第二步映射 (<code>map</code>)</strong>: 计算每个 <code>&quot;tokens&quot;</code> 列表的长度，并将结果存入新的 <code>&quot;length&quot;</code> 字段。</li>
<li><strong>提取长度</strong>: 从最终的数据集中单独拿出所有 <code>&quot;length&quot;</code> 的值，形成一个长度列表。</li>
<li><strong>计算最大值</strong>: 在这个长度列表中找到最大的那个数字。</li>
</ol>
<p>最终结果就是整个数据集中，经过聊天模板格式化、添加生成提示并分词后的最长 <code>prompt</code> 的 <code>token</code> 数量。</p>
<hr>
<h3 id="第十五块：定义训练参数"><a href="#第十五块：定义训练参数" class="headerlink" title="第十五块：定义训练参数"></a><strong>第十五块：定义训练参数</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">max_prompt_length = <span class="number">287</span> + <span class="number">1</span> <span class="comment"># + 1 just in case!</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> trl <span class="keyword">import</span> GRPOConfig, GRPOTrainer</span><br><span class="line">training_args = GRPOConfig(</span><br><span class="line">    learning_rate = <span class="number">5e-6</span>,</span><br><span class="line">    weight_decay = <span class="number">0.1</span>,</span><br><span class="line">    warmup_ratio = <span class="number">0.1</span>,</span><br><span class="line">    lr_scheduler_type = <span class="string">&quot;cosine&quot;</span>,</span><br><span class="line">    optim = <span class="string">&quot;adamw_torch_fused&quot;</span>,</span><br><span class="line">    logging_steps = <span class="number">1</span>,</span><br><span class="line">    per_device_train_batch_size = <span class="number">1</span>,</span><br><span class="line">    gradient_accumulation_steps = <span class="number">4</span>, <span class="comment"># Increase to 4 for smoother training</span></span><br><span class="line">    num_generations = <span class="number">8</span>, <span class="comment"># Decrease if out of memory</span></span><br><span class="line">    max_prompt_length = max_prompt_length,</span><br><span class="line">    max_completion_length = max_seq_length - max_prompt_length,</span><br><span class="line">    <span class="comment"># num_train_epochs = 1, # Set to 1 for a full training run</span></span><br><span class="line">    max_steps = <span class="number">1000</span>,</span><br><span class="line">    save_steps = <span class="number">250</span>,</span><br><span class="line">    max_grad_norm = <span class="number">0.1</span>,</span><br><span class="line">    report_to = <span class="string">&quot;none&quot;</span>, <span class="comment"># Can use Weights &amp; Biases</span></span><br><span class="line">    output_dir = <span class="string">&quot;outputs&quot;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.</span><br><span class="line">We will change the batch size of <span class="number">1</span> to the `num_generations` of <span class="number">8</span></span><br><span class="line"></span><br><span class="line">（翻译）</span><br><span class="line">Unsloth：我们现在要求 `per_device_train_batch_size` 必须是 `num_generations` 的倍数。  </span><br><span class="line">我们会把原本的 batch size 从 <span class="number">1</span> 自动调整为 `num_generations` 的值 <span class="number">8</span>。</span><br></pre></td></tr></table></figure>

<p>这段代码主要是用来设置训练过程中的各种参数，使用的是 <code>trl</code> (Transformer Reinforcement Learning) 库中的 <code>GRPOConfig</code> 类。</p>
<p><strong>1. <code>max_prompt_length = 287 + 1 # + 1 just in case!</code></strong></p>
<ul>
<li><strong>作用</strong>: 计算并设置一个名为 <code>max_prompt_length</code> 的变量，值为 <code>288</code>。</li>
<li><strong>含义</strong>: 这个变量很可能代表在训练或生成过程中，允许输入给模型的“提示”（<code>prompt</code>）的最大长度（通常以 <code>token</code> 数量计算）。</li>
<li><strong>+ 1 just in case!</strong>: 这个注释表明加 <code>1</code> 是为了留出一点余量或缓冲区。这在处理序列长度时很常见，可能是为了容纳一个额外的特殊标记（如句子结束符 <code>EOS</code>），或者只是为了避免因精确计算差一导致的问题。</li>
</ul>
<p><strong>2. <code>from trl import GRPOConfig, GRPOTrainer</code></strong></p>
<ul>
<li><strong>作用</strong>: 从 <code>trl</code> 库导入两个重要的类：<code>GRPOConfig</code> 和 <code>GRPOTrainer</code>。</li>
<li><strong><code>trl</code></strong>: 这是一个流行的 <code>Hugging Face</code> 库，专门用于使用强化学习等方法（如 <code>RLHF - Reinforcement Learning from Human Feedback</code>, <code>DPO - Direct Preference Optimization</code>, <code>GRPO - Generalized Preference Optimization</code>）来微调 <code>Transformer</code> 模型（如 <code>GPT</code> 系列、<code>LLaMA</code> 等）。</li>
<li><strong><code>GRPOConfig</code></strong>: 这是一个配置类（通常是 <code>dataclass</code>），专门用来<strong>收集和存储</strong>所有与 <code>GRPO</code> 训练过程相关的超参数和设置。把它想象成一个包含所有训练选项的设置菜单。</li>
<li><strong><code>GRPOTrainer</code></strong>: 这是实际执行 <code>GRPO</code> 训练过程的<strong>训练器</strong>类。你需要把后面创建的 <code>GRPOConfig</code> 对象传递给它，它才知道该如何进行训练。</li>
</ul>
<p><strong>3. <code>training_args = GRPOConfig(...)</code></strong></p>
<ul>
<li><strong>作用</strong>: 创建 <code>GRPOConfig</code> 类的一个实例，并将所有指定的训练参数传递给它。这个创建好的配置对象被存储在变量 <code>training_args</code> 中。</li>
<li><strong>含义</strong>: <code>training_args</code> 现在包含了运行 <code>GRPOTrainer</code> 所需的所有配置信息。之后创建 <code>GRPOTrainer</code> 时，通常会这样写：<code>trainer = GRPOTrainer(..., args=training_args, ...)</code>。</li>
</ul>
<p><strong>4. <code>GRPOConfig(...)</code> 中的参数详解:</strong></p>
<p>下面是传递给 <code>GRPOConfig</code> 的每个参数的解释：</p>
<ul>
<li><strong><code>learning_rate = 5e-6</code></strong>: 学习率（Learning Rate）。控制模型在每次更新时调整其内部参数（权重）的幅度。<code>5e-6</code> (即 0.000005) 是一个在微调大型语言模型时常用的较小值，有助于稳定训练。</li>
<li><strong><code>weight_decay = 0.1</code></strong>: 权重衰减（Weight Decay）。一种正则化技术，通过给模型的损失函数添加一个惩罚项来限制模型权重的大小，有助于防止模型过拟合训练数据。</li>
<li><strong><code>warmup_ratio = 0.1</code></strong>: 学习率预热（Warmup）比例。在训练初期，学习率不是直接设为 <code>5e-6</code>，而是从一个更小的值开始，在总训练步数的 <code>10%</code> (0.1) 期间内逐渐增加到 <code>5e-6</code>。这有助于在训练早期稳定模型的学习过程。</li>
<li><strong><code>lr_scheduler_type = &quot;cosine&quot;</code></strong>: 学习率调度器类型（Learning Rate Scheduler Type）。定义了在预热阶段之后，学习率如何随着训练的进行而变化。”cosine” 表示学习率将按照余弦曲线的形状逐渐下降，通常会降到接近 0。</li>
<li><strong><code>optim = &quot;adamw_torch_fused&quot;</code></strong>: 优化器（Optimizer）。用于根据计算出的梯度来更新模型权重的算法。”adamw” (Adam with weight decay) 是目前非常流行的优化器。”torch_fused” 可能指使用了 PyTorch 提供的更高效的、融合了多个操作的版本。</li>
<li><strong><code>logging_steps = 1</code></strong>: 日志记录步数。每隔多少个训练步（更新步）记录一次训练信息（如损失值、学习率等）。<code>1</code> 表示每一步都记录。</li>
<li><strong><code>per_device_train_batch_size = 1</code></strong>: 每个设备（GPU&#x2F;CPU）的训练批次大小。表示在单个设备上一次处理多少个训练样本。<code>1</code> 是非常小的批次大小，通常在模型很大或显存有限时使用。</li>
<li><strong><code>gradient_accumulation_steps = 4</code></strong>: 梯度累积步数。为了在不增加显存占用的情况下模拟更大的批次大小。计算 <code>per_device_train_batch_size</code> (1) 个样本的梯度，但不立即更新模型，而是累积 <code>gradient_accumulation_steps</code> (4) 次的梯度后，才执行一次模型更新。<strong>有效批次大小</strong> &#x3D; <code>per_device_train_batch_size * &lt;设备数量&gt; * gradient_accumulation_steps</code>。这里的设置为 <code>1 * &lt;设备数量&gt; * 4</code>。注释“Increase to 4 for smoother training”表明目标是达到等效于批次大小为 4 的训练效果。</li>
<li><strong><code>num_generations = 8</code></strong>: 生成数量。在 GRPO 或类似 RLHF 的训练中，模型需要为每个输入 prompt 生成多个可能的完成（completions）。这个参数指定了为每个 prompt 生成多少个不同的完成。注释“Decrease if out of memory”说明生成更多完成会消耗更多显存。</li>
<li><strong><code>max_prompt_length = max_prompt_length</code></strong>: 设置输入提示的最大 token 长度，使用了我们之前计算的变量 <code>max_prompt_length</code> (值为 288)。超过这个长度的提示可能会被截断。</li>
<li><strong><code>max_completion_length = max_seq_length - max_prompt_length</code></strong>: 设置模型生成的完成部分的最大 token 长度。它的值是根据一个（必须在别处定义的）<code>max_seq_length</code> 变量（代表模型能处理的总序列长度）减去提示的最大长度计算得到的。这确保了 <code>提示 + 完成</code> 的总长度不会超过模型的处理能力。</li>
<li><strong><code># num_train_epochs = 1</code></strong>: <strong>被注释掉了</strong>。如果启用，这个参数会指定模型需要完整地遍历整个训练数据集多少次（称为一个 epoch）。</li>
<li><strong><code>max_steps = 1000</code></strong>: 最大训练步数。指定了训练过程总共要执行多少次模型<strong>更新</strong>（注意是更新步，不是样本处理步）。如果设置了 <code>max_steps</code>，它通常会覆盖 <code>num_train_epochs</code>。这里表示训练将在 1000 次更新后停止。</li>
<li><strong><code>save_steps = 250</code></strong>: 保存步数。每隔多少个训练步（更新步）保存一次模型的检查点（checkpoint）。检查点是模型状态的快照，可以用来稍后恢复训练或用于推理。这里表示每 250 步保存一次。</li>
<li><strong><code>max_grad_norm = 0.1</code></strong>: 最大梯度范数（Gradient Clipping）。一种防止梯度爆炸（梯度值变得非常大导致训练不稳定）的技术。如果计算出的梯度的范数（可以理解为梯度向量的“长度”）超过了这个阈值（0.1），就会将其缩放到这个阈值。0.1 是一个相对较严格的裁剪值。</li>
<li><strong><code>report_to = &quot;none&quot;</code></strong>: 报告目标。指定将训练过程中的日志和指标发送到哪里。”none” 表示不发送到任何外部服务。常用的选项还包括 <code>&quot;wandb&quot;</code> (Weights &amp; Biases) 或 <code>&quot;tensorboard&quot;</code>，这些是用于可视化和跟踪实验的工具。</li>
<li><strong><code>output_dir = &quot;outputs&quot;</code></strong>: 输出目录。指定训练过程中产生的输出文件（如模型检查点、日志文件等）保存到哪个文件夹。这里是名为 “outputs” 的文件夹。</li>
</ul>
<p><strong>总结:</strong></p>
<p>这段代码精心配置了用于 <code>GRPO</code> 训练过程的大量参数，涵盖了学习率、优化器、批次大小、序列长度、训练时长、保存策略、日志记录等多个方面。这些设置将被打包到 <code>training_args</code> 对象中，然后传递给 <code>GRPOTrainer</code>，指导其如何高效、稳定地进行模型微调。</p>
<hr>
<h3 id="第十六块：创建GRPO训练器"><a href="#第十六块：创建GRPO训练器" class="headerlink" title="第十六块：创建GRPO训练器"></a><strong>第十六块：创建GRPO训练器</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trainer = GRPOTrainer(</span><br><span class="line">    model = model,</span><br><span class="line">    processing_class = tokenizer,</span><br><span class="line">    reward_funcs = [</span><br><span class="line">        match_format_exactly,</span><br><span class="line">        match_format_approximately,</span><br><span class="line">        check_answer,</span><br><span class="line">        check_numbers,</span><br><span class="line">    ],</span><br><span class="line">    args = training_args,</span><br><span class="line">    train_dataset = dataset,</span><br><span class="line">)</span><br><span class="line">trainer.train()</span><br></pre></td></tr></table></figure>

<p>这段代码的核心作用是<strong>创建并启动一个 <code>GRPO</code> 训练器</strong>，使用之前定义的模型、分词器、奖励函数和训练参数来对数据集进行训练。</p>
<p>带注释：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trainer = GRPOTrainer(</span><br><span class="line">    model = model,</span><br><span class="line">    <span class="comment"># 1. model:</span></span><br><span class="line">    <span class="comment">#    - 传入你想要训练的模型对象。这通常是一个预训练好的、支持生成任务的 Transformer 模型</span></span><br><span class="line">    <span class="comment">#      （比如从 Hugging Face Hub 加载的 GPT、LLaMA 或其他类似模型），可能已经进行了一些初步的微调。</span></span><br><span class="line">    <span class="comment">#    - GRPOTrainer 将会调整这个模型的参数。</span></span><br><span class="line"></span><br><span class="line">    processing_class = tokenizer,</span><br><span class="line">    <span class="comment"># 2. processing_class:</span></span><br><span class="line">    <span class="comment">#    - 传入用于文本处理的对象，通常就是分词器 (tokenizer)对象。</span></span><br><span class="line">    <span class="comment">#    - 训练器内部需要用它来将文本数据转换成模型可以理解的 token IDs，</span></span><br><span class="line">    <span class="comment">#      以及可能将模型的输出 token IDs 解码回文本。</span></span><br><span class="line">    <span class="comment">#    - 命名为 processing_class 可能暗示它也可以是更复杂的处理类，但常见用法是传入 tokenizer。</span></span><br><span class="line"></span><br><span class="line">    reward_funcs = [</span><br><span class="line">        match_format_exactly,</span><br><span class="line">        match_format_approximately,</span><br><span class="line">        check_answer,</span><br><span class="line">        check_numbers,</span><br><span class="line">    ],</span><br><span class="line">    <span class="comment"># 3. reward_funcs:</span></span><br><span class="line">    <span class="comment">#    - 传入一个包含多个奖励函数 (reward function) 的列表。</span></span><br><span class="line">    <span class="comment">#    - 在 GRPO（以及类似的基于强化学习或偏好的训练方法）中，模型会为每个 prompt 生成多个响应。</span></span><br><span class="line">    <span class="comment">#      这些奖励函数的作用是评估每个生成的响应的质量，并给出一个或多个数值分数（奖励）。</span></span><br><span class="line">    <span class="comment">#    - 训练器会利用这些奖励分数来调整模型，使其更倾向于生成获得高奖励的响应。</span></span><br><span class="line">    <span class="comment">#    - 这里列出的四个函数 (match_format_exactly, match_format_approximately, check_answer, check_numbers) </span></span><br><span class="line">    <span class="comment">#      就是我们之前讨论过的，它们分别从不同角度（格式精确性、格式近似性、答案准确性、数值准确性）</span></span><br><span class="line">    <span class="comment">#      来评价生成的响应。训练器可能会组合使用这些函数的输出来计算最终的奖励信号。</span></span><br><span class="line"></span><br><span class="line">    args = training_args,</span><br><span class="line">    <span class="comment"># 4. args:</span></span><br><span class="line">    <span class="comment">#    - 传入我们之前创建的 `GRPOConfig` 对象(`training_args`)。</span></span><br><span class="line">    <span class="comment">#    - 这个对象包含了所有关于训练过程的配置参数（学习率、批次大小、训练步数、保存间隔等等）。</span></span><br><span class="line">    <span class="comment">#    - 训练器会读取这个配置对象来确定如何执行训练。</span></span><br><span class="line"></span><br><span class="line">    train_dataset = dataset,</span><br><span class="line">    <span class="comment"># 5. train_dataset:</span></span><br><span class="line">    <span class="comment">#    - 传入用于训练的数据集对象。</span></span><br><span class="line">    <span class="comment">#    - 这个数据集应该包含了模型需要学习的 prompt（可能还有对应的期望答案，供奖励函数使用）。</span></span><br><span class="line">    <span class="comment">#    - 训练器会从这个数据集中抽取样本进行训练。</span></span><br><span class="line"></span><br><span class="line">) <span class="comment"># GRPOTrainer 初始化结束</span></span><br><span class="line"></span><br><span class="line">trainer.train()</span><br><span class="line"><span class="comment"># 6. trainer.train():</span></span><br><span class="line"><span class="comment">#    - 调用创建好的 `trainer` 对象的 `train()` 方法。</span></span><br><span class="line"><span class="comment">#    - 作用: 启动并执行整个 GRPO 训练过程。</span></span><br><span class="line"><span class="comment">#    - 内部流程 (大致):</span></span><br><span class="line"><span class="comment">#        1. 训练器会根据 `training_args` 中的设置（如批次大小、梯度累积步数）从 `train_dataset` 中加载数据。</span></span><br><span class="line"><span class="comment">#        2. 对于每个 prompt，使用当前的model生成num_generations个不同的响应（completions）。</span></span><br><span class="line"><span class="comment">#        3. 将生成的响应和对应的 prompt（以及可能的标准答案）传递给reward_funcs列表中的每一个奖励函数，得到每个响应的多个奖励分数。</span></span><br><span class="line"><span class="comment">#        4. GRPOTrainer 使用 GRPO 算法，根据这些奖励分数（比较不同生成结果的好坏）来计算损失，并计算相对于模型参数的梯度。</span></span><br><span class="line"><span class="comment">#        5. 使用指定的优化器 (optim) 和学习率调度策略 (lr_scheduler_type)，根据累积的梯度来更新 model的参数。</span></span><br><span class="line"><span class="comment">#        6. 重复步骤 1-5，直到达到max_steps或其他停止条件。</span></span><br><span class="line"><span class="comment">#        7. 在训练过程中，按照logging_steps记录日志，并按照save_steps保存模型检查点到output_dir。</span></span><br></pre></td></tr></table></figure>

<p>这段代码做了两件主要事情：</p>
<ol>
<li><strong>配置和初始化 <code>GRPOTrainer</code></strong>: 它将训练所需的所有组件（要训练的模型、处理文本的分词器、评估生成质量的奖励函数、详细的训练设置、以及训练数据）组装在一起，创建了一个功能完备的训练器对象 <code>trainer</code>。</li>
<li><strong>启动训练</strong>: 调用 <code>trainer.train()</code> 方法，让训练器按照预设的配置和 <code>GRPO</code> 算法，开始迭代地从数据中学习，通过生成响应、评估奖励、计算损失和更新模型参数的过程，来优化模型，使其能够生成更符合奖励函数期望（即更高质量）的输出。</li>
</ol>
<hr>
<h3 id="第十七块：原模型推理"><a href="#第十七块：原模型推理" class="headerlink" title="第十七块：原模型推理"></a><strong>第十七块：原模型推理</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">text = tokenizer.apply_chat_template([</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;What is the sqrt of 101?&quot;</span>&#125;,</span><br><span class="line">], tokenize = <span class="literal">False</span>, add_generation_prompt = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> vllm <span class="keyword">import</span> SamplingParams</span><br><span class="line">sampling_params = SamplingParams(</span><br><span class="line">    temperature = <span class="number">0.8</span>,</span><br><span class="line">    top_p = <span class="number">0.95</span>,</span><br><span class="line">    max_tokens = <span class="number">1024</span>,</span><br><span class="line">)</span><br><span class="line">output = model.fast_generate(</span><br><span class="line">    [text],</span><br><span class="line">    sampling_params = sampling_params,</span><br><span class="line">    lora_request = <span class="literal">None</span>,</span><br><span class="line">)[<span class="number">0</span>].outputs[<span class="number">0</span>].text</span><br><span class="line"></span><br><span class="line">output</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">The square root of 101 is approximately 10.05.</span><br></pre></td></tr></table></figure>

<p>这段代码的目的是使用一个预先加载好的分词器 (<code>tokenizer</code>) 和一个专门为 <code>vLLM</code> 优化的模型 (model)，根据给定的用户提示，生成一段文本回复。</p>
<ul>
<li><strong><code>tokenizer.apply_chat_template(...)</code></strong>: 这个方法的作用是将对话历史（这里只有一个用户回合）按照特定模型预设的“聊天模板”格式化。不同的模型有不同的格式要求，例如可能包含特殊的标记来区分用户 (user) 和助手 (assistant) 的发言。</li>
<li><strong>[{“role”: “user”, “content”: “What is the sqrt of 101?”}]</strong>: 这是输入的对话内容，一个包含单条用户消息的列表。</li>
<li><strong><code>tokenize = False</code></strong>: 这个参数非常重要。它指示 apply_chat_template <strong>不要</strong>将格式化后的文本转换成 token ID 列表，而是<strong>返回一个格式化好的字符串</strong>。这个字符串会包含模板定义的特殊标记和文本内容。例如，结果可能类似于 “&lt;s&gt;[INST] What is the sqrt of 101? [&#x2F;INST]” 或其他根据模型模板定义的格式。</li>
<li><strong>add_generation_prompt &#x3D; True</strong>: 这个参数通常会在格式化后的字符串末尾添加一个提示，告诉模型现在轮到它（助手&#x2F;assistant）开始生成回应了。例如，在上面的例子后面可能会加上 “ （如果这是 Llama 2 的模板）。</li>
<li><strong><code>text = ...</code></strong>: 将最终格式化好的、准备输入给模型的<strong>字符串</strong>存储在变量 text 中。</li>
<li><strong>from vllm import SamplingParams</strong>: 从<code> vllm</code> 库导入 <code>SamplingParams</code> 类。<code>vllm</code> 是一个用于快速、高效地进行 <code>LLM</code>（大型语言模型）推理的库。<code>SamplingParams</code> 这个类专门用来控制模型在生成文本时如何选择下一个词（<code>token</code>）</li>
<li><strong><code>sampling_params = SamplingParams(...)</code></strong>: 创建 <code>SamplingParams</code> 类的一个实例，用来定义文本生成的策略。</li>
<li><strong><code>temperature = 0.8</code></strong>: 控制生成文本的随机性。<ul>
<li>值越高（比如 <code>0.8</code>），生成的文本越随机、越有创意，但也可能越不连贯。</li>
<li>值越低（比如 <code>0.2</code>），生成的文本越确定性、越集中于模型认为最可能的词，但也可能越重复、越缺乏多样性。</li>
<li><code>0.8</code> 是一个相对较高的温度，倾向于生成更多样化的内容。</li>
</ul>
</li>
<li><strong>top_p &#x3D; 0.95</strong>: 使用 <code>Nucleus Sampling</code> (核采样) 策略。在每一步选择下一个词时，模型会按概率从高到低排序所有可能的词，然后只考虑累积概率达到 <code>0.95 (95%)</code> 的那些最可能的词进行采样。这有助于排除那些概率极低、可能导致奇怪结果的词，同时仍然保持一定的多样性（比 <code>top_k</code> 更灵活）。</li>
<li><strong>max_tokens &#x3D; 1024</strong>: 设置模型生成的<strong>最大 token 数量</strong>。这是指模型在原始输入 text 之后<strong>新生成</strong>的 token 数量上限。防止生成无限长的文本。</li>
<li><strong>model.fast_generate(…)</strong>: 调用 model 对象（假设这是一个用 vllm 加载或包装的模型）的 fast_generate 方法来执行文本生成。这个方法利用了 vLLM 的优化技术（如 PagedAttention）来加速推理过程。</li>
<li><strong>[text]</strong>: 输入的 prompt。注意，即使只有一个 prompt，通常也需要将其放入一个<strong>列表</strong>中传递给生成方法。</li>
<li><strong>sampling_params &#x3D; sampling_params</strong>: 将我们之前配置好的 sampling_params 对象传递进去，告诉生成器使用这些参数来控制生成过程。</li>
<li><strong>lora_request &#x3D; None</strong>: vLLM 支持动态加载 LoRA 适配器。这里设置为 None 表示不使用任何特定的 LoRA 适配器进行此次生成。</li>
<li><strong>[…] (方法调用结束后的部分)</strong>: 这部分用来从生成结果中提取出我们想要的文本。<ul>
<li>[0]: fast_generate (或 vLLM 的 generate) 方法返回一个列表，列表中的每个元素对应输入列表中的一个 prompt 的结果。因为我们只输入了一个 prompt ([text])，所以我们取结果列表的第一个元素 [0]。这个元素通常是一个 RequestOutput 对象。</li>
<li>.outputs: 每个 RequestOutput 对象包含一个名为 outputs 的列表，里面是为该 prompt 生成的一个或多个完成序列（可以通过 SamplingParams 中的 n 参数控制生成多个）。</li>
<li>[0]: 我们取 outputs 列表中的第一个完成序列 [0]（假设 n&#x3D;1，这是默认情况）。这个元素通常是一个 CompletionOutput 对象。</li>
<li>.text: CompletionOutput 对象有一个 text 属性，它包含了最终生成的<strong>文本字符串</strong>。</li>
</ul>
</li>
<li><strong>output &#x3D; …</strong>: 将提取出的生成文本字符串存储在变量 output 中。</li>
</ul>
<p>这段代码完整地演示了使用 vllm 进行文本生成的基本流程：</p>
<ol>
<li>使用与模型匹配的 tokenizer 将用户输入格式化为模型期望的<strong>字符串</strong>格式（包括聊天模板和生成提示）。</li>
<li>定义 SamplingParams 来控制生成的多样性、长度等。</li>
<li>调用 vllm 优化后的模型生成方法 (fast_generate 或类似方法），传入格式化后的 prompt 字符串列表和采样参数。</li>
<li>从复杂的返回结构中解析并提取出最终生成的文本字符串。</li>
</ol>
<hr>
<h3 id="第十八块：lora权重保存和验证"><a href="#第十八块：lora权重保存和验证" class="headerlink" title="第十八块：lora权重保存和验证"></a><strong>第十八块：lora权重保存和验证</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.save_lora(<span class="string">&quot;grpo_saved_lora&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> safetensors <span class="keyword">import</span> safe_open</span><br><span class="line"></span><br><span class="line">tensors = &#123;&#125;</span><br><span class="line"><span class="keyword">with</span> safe_open(<span class="string">&quot;grpo_saved_lora/adapter_model.safetensors&quot;</span>, framework = <span class="string">&quot;pt&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line"><span class="comment"># Verify both A and B are non zero</span></span><br><span class="line"><span class="keyword">for</span> key <span class="keyword">in</span> f.keys():</span><br><span class="line">tensor = f.get_tensor(key)</span><br><span class="line">n_zeros = (tensor == <span class="number">0</span>).<span class="built_in">sum</span>() / tensor.numel()</span><br><span class="line"><span class="keyword">assert</span>(n_zeros.item() != tensor.numel())</span><br></pre></td></tr></table></figure>

<p>这段代码首先将训练得到的 <code>LoRA</code> 权重保存到 <code>grpo_saved_lora</code> 目录下的 <code>adapter_model.safetensors</code> 文件中。然后，它使用 <code>safetensors</code> 库重新打开这个文件，逐一加载其中的每个权重张量，并执行一个断言检查。这个断言的目的是进行某种形式的验证，<strong>很可能是想确保加载的张量不是完全由零组成的</strong>，但实际的检查逻辑 <code>(proportion != total_count)</code> 写得有些奇怪，可能无法完全达到预期的验证效果。</p>
<h3 id="第十九块：微调后模型推理"><a href="#第十九块：微调后模型推理" class="headerlink" title="第十九块：微调后模型推理"></a><strong>第十九块：微调后模型推理</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">messages = [</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: system_prompt&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>,   <span class="string">&quot;content&quot;</span>: <span class="string">&quot;What is the sqrt of 101?&quot;</span>&#125;,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">text = tokenizer.apply_chat_template(</span><br><span class="line">    messages,</span><br><span class="line">    add_generation_prompt = <span class="literal">True</span>, <span class="comment"># Must add for generation</span></span><br><span class="line">    tokenize = <span class="literal">False</span>,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> vllm <span class="keyword">import</span> SamplingParams</span><br><span class="line">sampling_params = SamplingParams(</span><br><span class="line">    temperature = <span class="number">0.8</span>,</span><br><span class="line">    top_p = <span class="number">0.95</span>,</span><br><span class="line">    max_tokens = <span class="number">1024</span>,</span><br><span class="line">)</span><br><span class="line">output = model.fast_generate(</span><br><span class="line">    text,</span><br><span class="line">    sampling_params = sampling_params,</span><br><span class="line">    lora_request = model.load_lora(<span class="string">&quot;grpo_saved_lora&quot;</span>),</span><br><span class="line">)[<span class="number">0</span>].outputs[<span class="number">0</span>].text</span><br><span class="line"></span><br><span class="line">output</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">&#x27;&lt;start<span class="built_in">_</span>working<span class="built_in">_</span>out&gt;<span class="keyword">\nTo</span> find the square root of 101, I can use a calculator or a mathematical algorithm. Since 101 is not a perfect square, I will use a numerical method to approximate the square root.<span class="keyword">\n</span><span class="keyword">\nUsing</span> a calculator, I can find that the square root of 101 is approximately 10.05.<span class="keyword">\nAlternatively</span>, I can also use the Babylonian method, which is an iterative method for computing the square root of a number. However, this method requires multiple iterations and may not be necessary for a simple calculation like this.<span class="keyword">\n</span><span class="keyword">\nIn</span> this case, the approximate value of the square root of 101 is 10.0498756791108427 (using a more precise calculation). However, for most practical purposes, the value 10.05 is sufficient.<span class="keyword">\n</span><span class="keyword">\nSo</span>, the square root of 101 is approximately 10.05.<span class="keyword">\n</span>&lt;end<span class="built_in">_</span>working<span class="built_in">_</span>out&gt;<span class="keyword">\n</span><span class="keyword">\n</span>&lt;SOLUTION&gt;10.05&lt;/SOLUTION&gt;&#x27;</span><br><span class="line"></span><br><span class="line"><span class="params">#</span> 格式化后</span><br><span class="line">&lt;start<span class="built_in">_</span>working<span class="built_in">_</span>out&gt;</span><br><span class="line">To find the square root of 101, I can use a calculator or a mathematical algorithm. Since 101 is not a perfect square, I will use a numerical method to approximate the square root.</span><br><span class="line"></span><br><span class="line">Using a calculator, I can find that the square root of 101 is approximately 10.05.</span><br><span class="line">Alternatively, I can also use the Babylonian method, which is an iterative method for computing the square root of a number. However, this method requires multiple iterations and may not be necessary for a simple calculation like this.</span><br><span class="line"></span><br><span class="line">In this case, the approximate value of the square root of 101 is 10.0498756791108427 (using a more precise calculation). However, for most practical purposes, the value 10.05 is sufficient.</span><br><span class="line"></span><br><span class="line">So, the square root of 101 is approximately 10.05.</span><br><span class="line">&lt;end<span class="built_in">_</span>working<span class="built_in">_</span>out&gt;</span><br><span class="line"></span><br><span class="line">&lt;SOLUTION&gt;10.05&lt;/SOLUTION&gt;</span><br></pre></td></tr></table></figure>

<p>代码与第十六块类似，只是：</p>
<ul>
<li>加了系统提示词（<code>system_prompt</code>）</li>
<li>动态加载了刚才保存的<code>lora</code>权重。</li>
</ul>
<h3 id="第二十块：保存模型（vLLM）"><a href="#第二十块：保存模型（vLLM）" class="headerlink" title="第二十块：保存模型（vLLM）"></a><strong>第二十块：保存模型（vLLM）</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.save_pretrained_merged(<span class="string">&quot;model&quot;</span>, tokenizer, save_method = <span class="string">&quot;merged_16bit&quot;</span>,)</span><br></pre></td></tr></table></figure>

<p>以<code>float16</code>精度保存微调后的模型到<code>model</code>文件夹。</p>
<p><strong>然后就可以通过下面命令启动模型服务了：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">python -m vllm.entrypoints.openai.api_server --model model_llama3_2_3B/  --served-model-name llama3<span class="number">.2</span> --<span class="built_in">max</span>-model-<span class="built_in">len</span>=<span class="number">2048</span></span><br></pre></td></tr></table></figure>

<h3 id="补充1：原模型-系统提示词推理"><a href="#补充1：原模型-系统提示词推理" class="headerlink" title="补充1：原模型+系统提示词推理"></a><strong>补充1：原模型+系统提示词推理</strong></h3><p>我觉得有必要补充一个输出与第十九条输出对比：</p>
<ul>
<li>添加系统提示词</li>
<li>使用原模型</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">messages = [</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: system_prompt&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>,   <span class="string">&quot;content&quot;</span>: <span class="string">&quot;What is the sqrt of 101?&quot;</span>&#125;,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">text = tokenizer.apply_chat_template(</span><br><span class="line">    messages,</span><br><span class="line">    add_generation_prompt = <span class="literal">True</span>, <span class="comment"># Must add for generation</span></span><br><span class="line">    tokenize = <span class="literal">False</span>,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> vllm <span class="keyword">import</span> SamplingParams</span><br><span class="line">sampling_params = SamplingParams(</span><br><span class="line">    temperature = <span class="number">0.8</span>,</span><br><span class="line">    top_p = <span class="number">0.95</span>,</span><br><span class="line">    max_tokens = <span class="number">1024</span>,</span><br><span class="line">)</span><br><span class="line">output = model.fast_generate(</span><br><span class="line">    text,</span><br><span class="line">    sampling_params = sampling_params,</span><br><span class="line">    lora_request = <span class="literal">None</span>,</span><br><span class="line">)[<span class="number">0</span>].outputs[<span class="number">0</span>].text</span><br><span class="line"></span><br><span class="line">output</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">&quot;&lt;start<span class="built_in">_</span>working<span class="built_in">_</span>out&gt;<span class="keyword">\nTo</span> find the square root of 101, we need to find a number that, when multiplied by itself, equals 101. This can be done through trial and error or using a calculator.<span class="keyword">\n</span><span class="keyword">\nOne</span> way to do this is to start with a number and multiply it by itself, then check if the result is close to 101. If it&#x27;s not, we can adjust our guess and try again.<span class="keyword">\n</span><span class="keyword">\nFor</span> example, we can start with 10:<span class="keyword">\n</span>10 * 10 = 100<span class="keyword">\n</span><span class="keyword">\nSince</span> 100 is less than 101, we can try a number larger than 10. Let&#x27;s try 11:<span class="keyword">\n</span>11 * 11 = 121<span class="keyword">\n</span><span class="keyword">\nSince</span> 121 is greater than 101, we know that the square root of 101 is between 10 and 11.<span class="keyword">\n</span><span class="keyword">\nNow</span>, we can try numbers in between 10 and 11, such as 10.5 or 10.9, to get a more accurate estimate.<span class="keyword">\n</span><span class="keyword">\n</span>10.5 * 10.5 = 110.25 (too high)<span class="keyword">\n</span>10.9 * 10.9 = 118.81 (too high)<span class="keyword">\n</span><span class="keyword">\nSo</span>, the square root of 101 is between 10.5 and 10.9.<span class="keyword">\n</span><span class="keyword">\nNext</span>, we can try numbers between 10.5 and 10.9, such as 10.6:<span class="keyword">\n</span>10.6 * 10.6 = 111.76 (too high)<span class="keyword">\n</span><span class="keyword">\nWe</span> can keep trying numbers between 10.5 and 10.9 to get a more accurate estimate. However, this can be a time-consuming process.<span class="keyword">\n</span><span class="keyword">\nA</span> more efficient way to find the square root of 101 is to use a calculator or a computer program.<span class="keyword">\n</span><span class="keyword">\n</span>&lt;SOLUTION&gt;<span class="keyword">\nThe</span> square root of 101 is approximately 10.0498756, which can be rounded to 10.05.&quot;</span><br><span class="line"></span><br><span class="line"><span class="params">#</span> 格式化后</span><br><span class="line">&lt;start<span class="built_in">_</span>working<span class="built_in">_</span>out&gt;</span><br><span class="line">To find the square root of 101, we need to find a number that, when multiplied by itself, equals 101. This can be done through trial and error or using a calculator.</span><br><span class="line"></span><br><span class="line">One way to do this is to start with a number and multiply it by itself, then check if the result is close to 101. If it&#x27;s not, we can adjust our guess and try again.</span><br><span class="line"></span><br><span class="line">For example, we can start with 10:</span><br><span class="line">10 * 10 = 100</span><br><span class="line"></span><br><span class="line">Since 100 is less than 101, we can try a number larger than 10. Let&#x27;s try 11:</span><br><span class="line">11 * 11 = 121</span><br><span class="line"></span><br><span class="line">Since 121 is greater than 101, we know that the square root of 101 is between 10 and 11.</span><br><span class="line"></span><br><span class="line">Now, we can try numbers in between 10 and 11, such as 10.5 or 10.9, to get a more accurate estimate.</span><br><span class="line"></span><br><span class="line">10.5 * 10.5 = 110.25 (too high)</span><br><span class="line">10.9 * 10.9 = 118.81 (too high)</span><br><span class="line"></span><br><span class="line">So, the square root of 101 is between 10.5 and 10.9.</span><br><span class="line"></span><br><span class="line">Next, we can try numbers between 10.5 and 10.9, such as 10.6:</span><br><span class="line">10.6 * 10.6 = 111.76 (too high)</span><br><span class="line"></span><br><span class="line">We can keep trying numbers between 10.5 and 10.9 to get a more accurate estimate. However, this can be a time-consuming process.</span><br><span class="line"></span><br><span class="line">A more efficient way to find the square root of 101 is to use a calculator or a computer program.</span><br><span class="line"></span><br><span class="line">&lt;SOLUTION&gt;</span><br><span class="line">The square root of 101 is approximately 10.0498756, which can be rounded to 10.05.</span><br></pre></td></tr></table></figure>

<ul>
<li>好像答得也有模有样</li>
<li>但并未完全按提示词走（只有推理和答案的开头一个标志，没有结束标志）</li>
</ul>
<h3 id="补充2：9-11和9-9谁大"><a href="#补充2：9-11和9-9谁大" class="headerlink" title="补充2：9.11和9.9谁大"></a><strong>补充2：9.11和9.9谁大</strong></h3><p>我觉得上述问题可能过于基础，换个更高级的问题并用双语各测试5次：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">Which is bigger: 9.11 or 9.9?</span><br><span class="line">9.11和9.9哪个大？</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th></th>
<th>zh</th>
<th>en</th>
</tr>
</thead>
<tbody><tr>
<td>原模型+无提示词</td>
<td>1对，2错，2胡言乱语（说不能比较大小）</td>
<td>5错</td>
</tr>
<tr>
<td>微调模型+提示词</td>
<td>5错4</td>
<td>5错</td>
</tr>
<tr>
<td>原模型+无提示词</td>
<td>5错4</td>
<td>5错</td>
</tr>
<tr>
<td>微调模型+无提示词</td>
<td>5错4</td>
<td>5错</td>
</tr>
</tbody></table>
<blockquote>
<p>且微调模型+无提示词场景下，试了很多类型的问题都没有推理过程。</p>
</blockquote>
<p><strong>嗯？Excuse me? Are you kidding me? 🤷‍♂️</strong></p>
<p>难道是因为3B模型太小或者模型结构的事？（暂时没有答案）</p>
<hr>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h3 id="GSM8K"><a href="#GSM8K" class="headerlink" title="GSM8K"></a>GSM8K</h3><p>GSM8K (Grade School Math 8K, 小学数学8K)是一个包含8.5K道高质量、语言多样化（不是多语种，而是表达形式&#x2F;风格多样）的小学数学应用题的数据集。该数据集旨在支持需要多步骤推理的基本数学问题的问答任务。</p>
<ul>
<li>解决这些问题需要 2 到 8 个步骤。</li>
<li>解决方案主要涉及使用基本算术运算（+ − ×÷）执行一系列基本计算以得出最终答案。</li>
<li>一个聪明的中学生应该能够解决所有问题：从论文中可以看出，“问题不需要超出早期代数水平的概念，并且绝大多数问题可以在不明确定义变量的情况下解决。</li>
<li>解决方案以自然语言提供，而非纯数学表达式。论文中写道：“我们相信这是最通用的数据格式，并期望它能够揭示大型语言模型内部独白的属性。</li>
</ul>
<p><strong>数据实例</strong></p>
<p>对于<code>main</code>配置，每个实例包含一个小学水平数学问题的字符串和一个相应答案的字符串，其中包含多个推理步骤和计算器注释（<a href="https://github.com/openai/grade-school-math#calculation-annotations">此处</a>解释）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&#x27;question&#x27;</span>: <span class="string">&#x27;Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;answer&#x27;</span>: <span class="string">&#x27;Natalia sold 48/2 = &lt;&lt;48/2=24&gt;&gt;24 clips in May.\nNatalia sold 48+24 = &lt;&lt;48+24=72&gt;&gt;72 clips altogether in April and May.\n#### 72&#x27;</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="计算器机制"><a href="#计算器机制" class="headerlink" title="计算器机制"></a>计算器机制</h3><p>详见<a href="https://github.com/openai/grade-school-math/blob/master/grade_school_math/calculator.py">calculator.py</a>，这里仅举例说明，</p>
<p><strong>示例场景</strong></p>
<p><strong>输入模型提示</strong>：<br><code>&quot;Natalia sold 48 clips in April. &lt;&lt;48/2=&quot;</code></p>
<p><strong>模型生成步骤</strong>：</p>
<ol>
<li>检测到 <code>&lt;&lt;48/2=</code> ，触发计算器。</li>
<li>计算 <code>48/2</code> 得到 <code>24</code>。</li>
<li>修改文本为 <code>&quot;Natalia sold 48 clips in April. &lt;&lt;48/2=24&gt;&gt;&quot;</code>。</li>
<li>继续生成后续内容（如 <code>&quot; She sold 24 in May.&quot;</code>）。</li>
</ol>
<h3 id="训练日志"><a href="#训练日志" class="headerlink" title="训练日志"></a>训练日志</h3><p>先写结论：</p>
<ul>
<li><p>训练了11h:21min:42s</p>
</li>
<li><p>比<a href="https://caihaoran-00.github.io/2025/04/08/Unsloth-Phi-4-GRPO%E5%B0%86%E9%80%9A%E7%94%A8%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E6%88%90%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B/">Phi-4</a>的微调的数据看着舒服多了</p>
</li>
<li><p>match_format_exactly和check_answer在150步左右才开始正常。</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>Step</th>
<th>Training Loss</th>
<th>reward</th>
<th>reward_std</th>
<th>completion_length</th>
<th>kl</th>
<th>rewards &#x2F; match_format_exactly</th>
<th>rewards &#x2F; match_format_approximately</th>
<th>rewards &#x2F; check_answer</th>
<th>rewards &#x2F; check_numbers</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>0.000000</td>
<td>-0.953125</td>
<td>0.679083</td>
<td>257.906250</td>
<td>0.000000</td>
<td>0.000000</td>
<td>-1.093750</td>
<td>0.000000</td>
<td>0.140625</td>
</tr>
<tr>
<td>2</td>
<td>-0.000000</td>
<td>-0.906250</td>
<td>0.590790</td>
<td>223.750000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>-1.093750</td>
<td>0.000000</td>
<td>0.187500</td>
</tr>
<tr>
<td>3</td>
<td>0.000000</td>
<td>-0.796875</td>
<td>0.925001</td>
<td>204.218750</td>
<td>0.000339</td>
<td>0.000000</td>
<td>-1.000000</td>
<td>0.000000</td>
<td>0.203125</td>
</tr>
<tr>
<td>4</td>
<td>0.000000</td>
<td>-0.671875</td>
<td>0.885618</td>
<td>214.781250</td>
<td>0.000319</td>
<td>0.000000</td>
<td>-0.906250</td>
<td>0.000000</td>
<td>0.234375</td>
</tr>
<tr>
<td>5</td>
<td>0.000000</td>
<td>-0.796875</td>
<td>0.864609</td>
<td>262.750000</td>
<td>0.000344</td>
<td>0.000000</td>
<td>-1.093750</td>
<td>0.000000</td>
<td>0.296875</td>
</tr>
<tr>
<td>6</td>
<td>0.000000</td>
<td>-1.125000</td>
<td>0.638588</td>
<td>203.687500</td>
<td>0.000307</td>
<td>0.000000</td>
<td>-1.140625</td>
<td>0.000000</td>
<td>0.015625</td>
</tr>
<tr>
<td>7</td>
<td>0.000000</td>
<td>-0.765625</td>
<td>0.585080</td>
<td>190.531250</td>
<td>0.000364</td>
<td>0.000000</td>
<td>-0.953125</td>
<td>0.000000</td>
<td>0.187500</td>
</tr>
<tr>
<td>8</td>
<td>0.000000</td>
<td>-0.609375</td>
<td>1.105576</td>
<td>206.593750</td>
<td>0.000285</td>
<td>0.000000</td>
<td>-0.953125</td>
<td>0.000000</td>
<td>0.343750</td>
</tr>
<tr>
<td>9</td>
<td>0.000000</td>
<td>-0.500000</td>
<td>0.974687</td>
<td>174.375000</td>
<td>0.000317</td>
<td>0.000000</td>
<td>-0.812500</td>
<td>0.000000</td>
<td>0.312500</td>
</tr>
<tr>
<td>10</td>
<td>0.000000</td>
<td>-0.968750</td>
<td>1.017919</td>
<td>245.843750</td>
<td>0.000342</td>
<td>0.000000</td>
<td>-1.187500</td>
<td>0.000000</td>
<td>0.218750</td>
</tr>
<tr>
<td>11</td>
<td>0.000000</td>
<td>-0.671875</td>
<td>1.020435</td>
<td>228.343750</td>
<td>0.000307</td>
<td>0.000000</td>
<td>-1.046875</td>
<td>0.000000</td>
<td>0.375000</td>
</tr>
<tr>
<td>12</td>
<td>0.000000</td>
<td>-0.859375</td>
<td>1.199693</td>
<td>230.250000</td>
<td>0.000305</td>
<td>0.000000</td>
<td>-1.187500</td>
<td>0.000000</td>
<td>0.328125</td>
</tr>
<tr>
<td>13</td>
<td>0.000000</td>
<td>-0.781250</td>
<td>0.803784</td>
<td>245.781250</td>
<td>0.000291</td>
<td>0.000000</td>
<td>-1.093750</td>
<td>0.000000</td>
<td>0.312500</td>
</tr>
<tr>
<td>14</td>
<td>0.000000</td>
<td>-1.000000</td>
<td>0.949337</td>
<td>235.656250</td>
<td>0.000315</td>
<td>0.000000</td>
<td>-1.187500</td>
<td>0.000000</td>
<td>0.187500</td>
</tr>
<tr>
<td>15</td>
<td>0.000000</td>
<td>-0.812500</td>
<td>1.048837</td>
<td>225.031250</td>
<td>0.000293</td>
<td>0.000000</td>
<td>-1.093750</td>
<td>0.000000</td>
<td>0.281250</td>
</tr>
<tr>
<td>16</td>
<td>0.000000</td>
<td>-1.359375</td>
<td>0.987504</td>
<td>251.281250</td>
<td>0.000342</td>
<td>0.000000</td>
<td>-1.656250</td>
<td>0.000000</td>
<td>0.296875</td>
</tr>
<tr>
<td>17</td>
<td>0.000000</td>
<td>-1.015625</td>
<td>0.624389</td>
<td>226.531250</td>
<td>0.000454</td>
<td>0.000000</td>
<td>-1.046875</td>
<td>0.000000</td>
<td>0.031250</td>
</tr>
<tr>
<td>18</td>
<td>0.000000</td>
<td>-0.890625</td>
<td>0.861584</td>
<td>180.625000</td>
<td>0.000276</td>
<td>0.000000</td>
<td>-1.187500</td>
<td>0.000000</td>
<td>0.296875</td>
</tr>
<tr>
<td>19</td>
<td>0.000000</td>
<td>-1.125000</td>
<td>0.916903</td>
<td>328.000000</td>
<td>0.000279</td>
<td>0.000000</td>
<td>-1.140625</td>
<td>0.000000</td>
<td>0.015625</td>
</tr>
<tr>
<td>20</td>
<td>0.000000</td>
<td>-0.906250</td>
<td>0.678592</td>
<td>252.843750</td>
<td>0.000354</td>
<td>0.000000</td>
<td>-1.093750</td>
<td>0.000000</td>
<td>0.187500</td>
</tr>
<tr>
<td>21</td>
<td>0.000000</td>
<td>-1.359375</td>
<td>1.062030</td>
<td>229.031250</td>
<td>0.000553</td>
<td>0.000000</td>
<td>-1.468750</td>
<td>0.000000</td>
<td>0.109375</td>
</tr>
<tr>
<td>22</td>
<td>0.000000</td>
<td>-0.968750</td>
<td>1.232316</td>
<td>202.625000</td>
<td>0.000422</td>
<td>0.000000</td>
<td>-1.281250</td>
<td>0.000000</td>
<td>0.312500</td>
</tr>
<tr>
<td>23</td>
<td>0.000000</td>
<td>-0.609375</td>
<td>1.146797</td>
<td>170.500000</td>
<td>0.000443</td>
<td>0.000000</td>
<td>-1.140625</td>
<td>0.000000</td>
<td>0.531250</td>
</tr>
<tr>
<td>24</td>
<td>0.000000</td>
<td>-0.953125</td>
<td>0.798529</td>
<td>227.812500</td>
<td>0.000416</td>
<td>0.000000</td>
<td>-1.000000</td>
<td>0.000000</td>
<td>0.046875</td>
</tr>
<tr>
<td>25</td>
<td>0.000000</td>
<td>-0.687500</td>
<td>1.169120</td>
<td>207.000000</td>
<td>0.000381</td>
<td>0.000000</td>
<td>-0.953125</td>
<td>0.000000</td>
<td>0.265625</td>
</tr>
<tr>
<td>26</td>
<td>0.000000</td>
<td>-0.937500</td>
<td>1.390742</td>
<td>193.812500</td>
<td>0.000440</td>
<td>0.093750</td>
<td>-1.187500</td>
<td>-0.046875</td>
<td>0.203125</td>
</tr>
<tr>
<td>27</td>
<td>0.000000</td>
<td>-0.453125</td>
<td>0.810799</td>
<td>179.562500</td>
<td>0.000437</td>
<td>0.000000</td>
<td>-0.906250</td>
<td>0.000000</td>
<td>0.453125</td>
</tr>
<tr>
<td>28</td>
<td>0.000000</td>
<td>-0.671875</td>
<td>0.864922</td>
<td>172.781250</td>
<td>0.000495</td>
<td>0.000000</td>
<td>-0.765625</td>
<td>0.000000</td>
<td>0.093750</td>
</tr>
<tr>
<td>29</td>
<td>0.000000</td>
<td>-0.921875</td>
<td>1.147603</td>
<td>191.500000</td>
<td>0.000395</td>
<td>0.000000</td>
<td>-1.234375</td>
<td>0.000000</td>
<td>0.312500</td>
</tr>
<tr>
<td>30</td>
<td>0.000000</td>
<td>-0.703125</td>
<td>0.957798</td>
<td>175.843750</td>
<td>0.000645</td>
<td>0.000000</td>
<td>-1.046875</td>
<td>0.000000</td>
<td>0.343750</td>
</tr>
<tr>
<td>31</td>
<td>0.000000</td>
<td>-1.343750</td>
<td>0.901694</td>
<td>260.531250</td>
<td>0.000416</td>
<td>0.000000</td>
<td>-1.421875</td>
<td>0.000000</td>
<td>0.078125</td>
</tr>
<tr>
<td>32</td>
<td>0.000000</td>
<td>-0.765625</td>
<td>0.868138</td>
<td>185.562500</td>
<td>0.000322</td>
<td>0.000000</td>
<td>-1.093750</td>
<td>0.000000</td>
<td>0.328125</td>
</tr>
<tr>
<td>33</td>
<td>0.000000</td>
<td>-1.203125</td>
<td>0.935517</td>
<td>303.968750</td>
<td>0.000383</td>
<td>0.000000</td>
<td>-1.234375</td>
<td>0.000000</td>
<td>0.031250</td>
</tr>
<tr>
<td>34</td>
<td>0.000000</td>
<td>-0.921875</td>
<td>0.908708</td>
<td>223.281250</td>
<td>0.000380</td>
<td>0.000000</td>
<td>-1.093750</td>
<td>0.000000</td>
<td>0.171875</td>
</tr>
<tr>
<td>35</td>
<td>0.000000</td>
<td>-0.671875</td>
<td>0.925758</td>
<td>166.718750</td>
<td>0.000794</td>
<td>0.000000</td>
<td>-1.000000</td>
<td>0.000000</td>
<td>0.328125</td>
</tr>
<tr>
<td>36</td>
<td>0.000000</td>
<td>-1.140625</td>
<td>0.922049</td>
<td>227.781250</td>
<td>0.000674</td>
<td>0.000000</td>
<td>-1.187500</td>
<td>0.000000</td>
<td>0.046875</td>
</tr>
<tr>
<td>37</td>
<td>0.000000</td>
<td>-0.906250</td>
<td>0.857178</td>
<td>215.156250</td>
<td>0.000755</td>
<td>0.000000</td>
<td>-1.187500</td>
<td>0.000000</td>
<td>0.281250</td>
</tr>
<tr>
<td>38</td>
<td>0.000000</td>
<td>-0.906250</td>
<td>0.859795</td>
<td>214.250000</td>
<td>0.000952</td>
<td>0.000000</td>
<td>-1.000000</td>
<td>0.000000</td>
<td>0.093750</td>
</tr>
<tr>
<td>39</td>
<td>0.000000</td>
<td>-0.953125</td>
<td>0.916311</td>
<td>386.625000</td>
<td>0.000497</td>
<td>0.000000</td>
<td>-1.140625</td>
<td>0.000000</td>
<td>0.187500</td>
</tr>
<tr>
<td>40</td>
<td>0.000000</td>
<td>-1.078125</td>
<td>0.916366</td>
<td>308.968750</td>
<td>0.000879</td>
<td>0.000000</td>
<td>-1.234375</td>
<td>0.000000</td>
<td>0.156250</td>
</tr>
<tr>
<td>41</td>
<td>0.000000</td>
<td>-0.859375</td>
<td>0.464563</td>
<td>266.250000</td>
<td>0.000825</td>
<td>0.000000</td>
<td>-1.000000</td>
<td>0.000000</td>
<td>0.140625</td>
</tr>
<tr>
<td>42</td>
<td>0.000000</td>
<td>-1.046875</td>
<td>0.499462</td>
<td>287.250000</td>
<td>0.000453</td>
<td>0.000000</td>
<td>-1.000000</td>
<td>0.000000</td>
<td>-0.046875</td>
</tr>
<tr>
<td>43</td>
<td>0.000000</td>
<td>-0.500000</td>
<td>0.679403</td>
<td>208.062500</td>
<td>0.000403</td>
<td>0.000000</td>
<td>-1.000000</td>
<td>0.000000</td>
<td>0.500000</td>
</tr>
<tr>
<td>44</td>
<td>0.000000</td>
<td>-0.515625</td>
<td>1.010345</td>
<td>256.781250</td>
<td>0.000640</td>
<td>0.000000</td>
<td>-0.953125</td>
<td>0.000000</td>
<td>0.437500</td>
</tr>
<tr>
<td>45</td>
<td>0.000000</td>
<td>-0.625000</td>
<td>1.067974</td>
<td>213.781250</td>
<td>0.000504</td>
<td>0.000000</td>
<td>-1.093750</td>
<td>0.000000</td>
<td>0.468750</td>
</tr>
<tr>
<td>46</td>
<td>0.000100</td>
<td>-0.562500</td>
<td>1.109565</td>
<td>233.718750</td>
<td>0.001255</td>
<td>0.000000</td>
<td>-1.046875</td>
<td>0.000000</td>
<td>0.484375</td>
</tr>
<tr>
<td>47</td>
<td>0.000000</td>
<td>-1.390625</td>
<td>1.049854</td>
<td>229.343750</td>
<td>0.000812</td>
<td>0.000000</td>
<td>-1.468750</td>
<td>0.000000</td>
<td>0.078125</td>
</tr>
<tr>
<td>48</td>
<td>0.000100</td>
<td>-0.828125</td>
<td>0.918515</td>
<td>226.843750</td>
<td>0.002188</td>
<td>0.000000</td>
<td>-1.000000</td>
<td>0.000000</td>
<td>0.171875</td>
</tr>
<tr>
<td>49</td>
<td>0.000000</td>
<td>-0.734375</td>
<td>0.961471</td>
<td>258.156250</td>
<td>0.001048</td>
<td>0.000000</td>
<td>-1.046875</td>
<td>0.000000</td>
<td>0.312500</td>
</tr>
<tr>
<td>50</td>
<td>0.000000</td>
<td>-0.593750</td>
<td>1.028425</td>
<td>209.031250</td>
<td>0.000938</td>
<td>0.093750</td>
<td>-0.812500</td>
<td>-0.046875</td>
<td>0.171875</td>
</tr>
<tr>
<td>51</td>
<td>0.000000</td>
<td>-0.343750</td>
<td>1.082000</td>
<td>183.468750</td>
<td>0.000924</td>
<td>0.000000</td>
<td>-0.953125</td>
<td>0.000000</td>
<td>0.609375</td>
</tr>
<tr>
<td>52</td>
<td>0.000000</td>
<td>-0.406250</td>
<td>0.805868</td>
<td>249.750000</td>
<td>0.000597</td>
<td>0.000000</td>
<td>-0.625000</td>
<td>0.000000</td>
<td>0.218750</td>
</tr>
<tr>
<td>53</td>
<td>0.000100</td>
<td>-0.921875</td>
<td>1.036722</td>
<td>191.125000</td>
<td>0.001668</td>
<td>0.000000</td>
<td>-1.328125</td>
<td>0.000000</td>
<td>0.406250</td>
</tr>
<tr>
<td>54</td>
<td>0.000100</td>
<td>-0.687500</td>
<td>1.058039</td>
<td>172.718750</td>
<td>0.001402</td>
<td>0.000000</td>
<td>-1.140625</td>
<td>0.000000</td>
<td>0.453125</td>
</tr>
<tr>
<td>55</td>
<td>0.000100</td>
<td>-0.640625</td>
<td>0.805069</td>
<td>210.156250</td>
<td>0.002699</td>
<td>0.000000</td>
<td>-0.812500</td>
<td>0.000000</td>
<td>0.171875</td>
</tr>
<tr>
<td>56</td>
<td>0.000000</td>
<td>-0.406250</td>
<td>0.868199</td>
<td>207.593750</td>
<td>0.000950</td>
<td>0.000000</td>
<td>-1.000000</td>
<td>0.000000</td>
<td>0.593750</td>
</tr>
<tr>
<td>57</td>
<td>0.000100</td>
<td>-0.484375</td>
<td>1.010269</td>
<td>218.000000</td>
<td>0.001974</td>
<td>0.000000</td>
<td>-0.906250</td>
<td>0.000000</td>
<td>0.421875</td>
</tr>
<tr>
<td>58</td>
<td>0.000100</td>
<td>-0.671875</td>
<td>1.046235</td>
<td>255.750000</td>
<td>0.002728</td>
<td>0.000000</td>
<td>-1.000000</td>
<td>0.000000</td>
<td>0.328125</td>
</tr>
<tr>
<td>59</td>
<td>0.000100</td>
<td>-0.171875</td>
<td>1.008117</td>
<td>176.468750</td>
<td>0.002544</td>
<td>0.000000</td>
<td>-1.046875</td>
<td>0.000000</td>
<td>0.875000</td>
</tr>
<tr>
<td>60</td>
<td>0.000100</td>
<td>-0.656250</td>
<td>1.138962</td>
<td>189.625000</td>
<td>0.002432</td>
<td>0.000000</td>
<td>-1.000000</td>
<td>0.000000</td>
<td>0.343750</td>
</tr>
<tr>
<td>61</td>
<td>0.000200</td>
<td>-0.187500</td>
<td>1.310412</td>
<td>163.937500</td>
<td>0.004882</td>
<td>0.000000</td>
<td>-0.859375</td>
<td>0.000000</td>
<td>0.671875</td>
</tr>
<tr>
<td>62</td>
<td>0.000100</td>
<td>-0.453125</td>
<td>0.838008</td>
<td>247.625000</td>
<td>0.003543</td>
<td>0.000000</td>
<td>-0.812500</td>
<td>0.000000</td>
<td>0.359375</td>
</tr>
<tr>
<td>63</td>
<td>0.000100</td>
<td>-0.609375</td>
<td>0.856011</td>
<td>302.343750</td>
<td>0.003246</td>
<td>0.000000</td>
<td>-0.906250</td>
<td>0.000000</td>
<td>0.296875</td>
</tr>
<tr>
<td>64</td>
<td>0.002500</td>
<td>-0.390625</td>
<td>0.850635</td>
<td>229.843750</td>
<td>0.063149</td>
<td>0.000000</td>
<td>-0.765625</td>
<td>0.000000</td>
<td>0.375000</td>
</tr>
<tr>
<td>65</td>
<td>0.000500</td>
<td>-0.328125</td>
<td>0.895767</td>
<td>224.125000</td>
<td>0.011753</td>
<td>0.000000</td>
<td>-0.953125</td>
<td>0.000000</td>
<td>0.625000</td>
</tr>
<tr>
<td>66</td>
<td>0.001000</td>
<td>-0.156250</td>
<td>0.875907</td>
<td>198.093750</td>
<td>0.024031</td>
<td>0.000000</td>
<td>-0.859375</td>
<td>0.000000</td>
<td>0.703125</td>
</tr>
<tr>
<td>67</td>
<td>0.001500</td>
<td>-0.390625</td>
<td>1.233973</td>
<td>205.375000</td>
<td>0.037764</td>
<td>0.000000</td>
<td>-0.859375</td>
<td>0.000000</td>
<td>0.468750</td>
</tr>
<tr>
<td>68</td>
<td>0.000500</td>
<td>-0.375000</td>
<td>1.013449</td>
<td>215.593750</td>
<td>0.012367</td>
<td>0.000000</td>
<td>-0.906250</td>
<td>0.000000</td>
<td>0.531250</td>
</tr>
<tr>
<td>69</td>
<td>0.000500</td>
<td>-0.468750</td>
<td>0.984997</td>
<td>227.500000</td>
<td>0.012935</td>
<td>0.000000</td>
<td>-0.765625</td>
<td>0.000000</td>
<td>0.296875</td>
</tr>
<tr>
<td>70</td>
<td>0.000200</td>
<td>-0.484375</td>
<td>0.997699</td>
<td>229.875000</td>
<td>0.004841</td>
<td>0.000000</td>
<td>-0.953125</td>
<td>0.000000</td>
<td>0.468750</td>
</tr>
<tr>
<td>71</td>
<td>0.000100</td>
<td>-0.625000</td>
<td>1.067158</td>
<td>299.000000</td>
<td>0.002067</td>
<td>0.000000</td>
<td>-0.718750</td>
<td>0.000000</td>
<td>0.093750</td>
</tr>
<tr>
<td>72</td>
<td>0.000200</td>
<td>-0.390625</td>
<td>0.792165</td>
<td>267.218750</td>
<td>0.004823</td>
<td>0.000000</td>
<td>-1.000000</td>
<td>0.000000</td>
<td>0.609375</td>
</tr>
<tr>
<td>73</td>
<td>0.001500</td>
<td>-0.156250</td>
<td>0.869484</td>
<td>176.875000</td>
<td>0.038043</td>
<td>0.000000</td>
<td>-0.859375</td>
<td>0.000000</td>
<td>0.703125</td>
</tr>
<tr>
<td>74</td>
<td>0.000600</td>
<td>0.453125</td>
<td>1.180293</td>
<td>146.812500</td>
<td>0.013808</td>
<td>0.000000</td>
<td>-0.671875</td>
<td>0.000000</td>
<td>1.125000</td>
</tr>
<tr>
<td>75</td>
<td>0.000500</td>
<td>-0.140625</td>
<td>1.220082</td>
<td>224.000000</td>
<td>0.011601</td>
<td>0.000000</td>
<td>-0.578125</td>
<td>0.000000</td>
<td>0.437500</td>
</tr>
<tr>
<td>76</td>
<td>0.001800</td>
<td>0.015625</td>
<td>1.187551</td>
<td>161.500000</td>
<td>0.044650</td>
<td>0.000000</td>
<td>-0.812500</td>
<td>0.000000</td>
<td>0.828125</td>
</tr>
<tr>
<td>77</td>
<td>0.001300</td>
<td>-0.015625</td>
<td>1.290225</td>
<td>225.250000</td>
<td>0.032133</td>
<td>0.000000</td>
<td>-0.578125</td>
<td>0.000000</td>
<td>0.562500</td>
</tr>
<tr>
<td>78</td>
<td>0.000800</td>
<td>-0.187500</td>
<td>0.950212</td>
<td>187.468750</td>
<td>0.019791</td>
<td>0.000000</td>
<td>-0.671875</td>
<td>0.000000</td>
<td>0.484375</td>
</tr>
<tr>
<td>79</td>
<td>0.000200</td>
<td>0.109375</td>
<td>1.230728</td>
<td>255.531250</td>
<td>0.003844</td>
<td>0.000000</td>
<td>-0.531250</td>
<td>0.000000</td>
<td>0.640625</td>
</tr>
<tr>
<td>80</td>
<td>0.000200</td>
<td>-0.046875</td>
<td>1.009551</td>
<td>192.156250</td>
<td>0.005587</td>
<td>0.000000</td>
<td>-0.625000</td>
<td>0.000000</td>
<td>0.578125</td>
</tr>
<tr>
<td>81</td>
<td>0.000500</td>
<td>0.328125</td>
<td>1.439251</td>
<td>205.875000</td>
<td>0.012380</td>
<td>0.000000</td>
<td>-0.484375</td>
<td>0.000000</td>
<td>0.812500</td>
</tr>
<tr>
<td>82</td>
<td>0.000300</td>
<td>-0.062500</td>
<td>0.829022</td>
<td>218.562500</td>
<td>0.006770</td>
<td>0.000000</td>
<td>-0.765625</td>
<td>0.000000</td>
<td>0.703125</td>
</tr>
<tr>
<td>83</td>
<td>0.000400</td>
<td>0.390625</td>
<td>1.217244</td>
<td>192.125000</td>
<td>0.010037</td>
<td>0.000000</td>
<td>-0.531250</td>
<td>0.000000</td>
<td>0.921875</td>
</tr>
<tr>
<td>84</td>
<td>0.000200</td>
<td>0.125000</td>
<td>1.083546</td>
<td>213.593750</td>
<td>0.006047</td>
<td>0.000000</td>
<td>-0.343750</td>
<td>0.000000</td>
<td>0.468750</td>
</tr>
<tr>
<td>85</td>
<td>0.000500</td>
<td>0.250000</td>
<td>1.329997</td>
<td>225.406250</td>
<td>0.012899</td>
<td>0.000000</td>
<td>-0.531250</td>
<td>0.000000</td>
<td>0.781250</td>
</tr>
<tr>
<td>86</td>
<td>0.000400</td>
<td>0.781250</td>
<td>1.129282</td>
<td>185.281250</td>
<td>0.009419</td>
<td>0.000000</td>
<td>-0.296875</td>
<td>0.000000</td>
<td>1.078125</td>
</tr>
<tr>
<td>87</td>
<td>0.001200</td>
<td>-0.140625</td>
<td>1.305537</td>
<td>263.750000</td>
<td>0.029129</td>
<td>0.093750</td>
<td>-0.625000</td>
<td>-0.046875</td>
<td>0.437500</td>
</tr>
<tr>
<td>88</td>
<td>0.000900</td>
<td>-0.031250</td>
<td>1.597338</td>
<td>224.218750</td>
<td>0.021730</td>
<td>0.093750</td>
<td>-0.484375</td>
<td>-0.046875</td>
<td>0.406250</td>
</tr>
<tr>
<td>89</td>
<td>0.000500</td>
<td>0.234375</td>
<td>1.120617</td>
<td>210.125000</td>
<td>0.012163</td>
<td>0.000000</td>
<td>-0.250000</td>
<td>0.000000</td>
<td>0.484375</td>
</tr>
<tr>
<td>90</td>
<td>0.000800</td>
<td>0.687500</td>
<td>1.133673</td>
<td>205.968750</td>
<td>0.019057</td>
<td>0.000000</td>
<td>-0.156250</td>
<td>0.000000</td>
<td>0.843750</td>
</tr>
<tr>
<td>91</td>
<td>0.000500</td>
<td>0.390625</td>
<td>1.246974</td>
<td>185.406250</td>
<td>0.012114</td>
<td>0.000000</td>
<td>-0.156250</td>
<td>0.000000</td>
<td>0.546875</td>
</tr>
<tr>
<td>92</td>
<td>0.000500</td>
<td>0.781250</td>
<td>1.404984</td>
<td>257.500000</td>
<td>0.011828</td>
<td>0.000000</td>
<td>-0.015625</td>
<td>0.000000</td>
<td>0.796875</td>
</tr>
<tr>
<td>93</td>
<td>0.000900</td>
<td>0.562500</td>
<td>1.055051</td>
<td>206.531250</td>
<td>0.022210</td>
<td>0.000000</td>
<td>-0.296875</td>
<td>0.000000</td>
<td>0.859375</td>
</tr>
<tr>
<td>94</td>
<td>0.001500</td>
<td>0.437500</td>
<td>1.188617</td>
<td>204.312500</td>
<td>0.036983</td>
<td>0.000000</td>
<td>-0.062500</td>
<td>0.000000</td>
<td>0.500000</td>
</tr>
<tr>
<td>95</td>
<td>0.000600</td>
<td>1.125000</td>
<td>1.179184</td>
<td>215.031250</td>
<td>0.013927</td>
<td>0.000000</td>
<td>0.078125</td>
<td>0.000000</td>
<td>1.046875</td>
</tr>
<tr>
<td>96</td>
<td>0.000600</td>
<td>0.562500</td>
<td>1.028679</td>
<td>258.593750</td>
<td>0.016106</td>
<td>0.000000</td>
<td>0.265625</td>
<td>0.000000</td>
<td>0.296875</td>
</tr>
<tr>
<td>97</td>
<td>0.001200</td>
<td>1.140625</td>
<td>0.947520</td>
<td>192.062500</td>
<td>0.030544</td>
<td>0.000000</td>
<td>0.312500</td>
<td>0.000000</td>
<td>0.828125</td>
</tr>
<tr>
<td>98</td>
<td>0.001000</td>
<td>1.187500</td>
<td>1.241357</td>
<td>178.625000</td>
<td>0.025544</td>
<td>0.000000</td>
<td>0.218750</td>
<td>0.000000</td>
<td>0.968750</td>
</tr>
<tr>
<td>99</td>
<td>0.001100</td>
<td>1.703125</td>
<td>0.486136</td>
<td>207.468750</td>
<td>0.026573</td>
<td>0.000000</td>
<td>0.406250</td>
<td>0.000000</td>
<td>1.296875</td>
</tr>
<tr>
<td>100</td>
<td>0.001500</td>
<td>0.984375</td>
<td>0.928457</td>
<td>185.281250</td>
<td>0.037967</td>
<td>0.000000</td>
<td>0.312500</td>
<td>0.000000</td>
<td>0.671875</td>
</tr>
<tr>
<td>101</td>
<td>0.001500</td>
<td>0.984375</td>
<td>0.853727</td>
<td>228.781250</td>
<td>0.036708</td>
<td>0.000000</td>
<td>0.312500</td>
<td>0.000000</td>
<td>0.671875</td>
</tr>
<tr>
<td>102</td>
<td>0.000600</td>
<td>1.312500</td>
<td>0.891995</td>
<td>218.906250</td>
<td>0.015497</td>
<td>0.000000</td>
<td>0.406250</td>
<td>0.000000</td>
<td>0.906250</td>
</tr>
<tr>
<td>103</td>
<td>0.001000</td>
<td>1.375000</td>
<td>0.765978</td>
<td>222.750000</td>
<td>0.026233</td>
<td>0.000000</td>
<td>0.500000</td>
<td>0.000000</td>
<td>0.875000</td>
</tr>
<tr>
<td>104</td>
<td>0.001500</td>
<td>1.406250</td>
<td>1.165558</td>
<td>266.062500</td>
<td>0.036789</td>
<td>0.093750</td>
<td>0.406250</td>
<td>-0.046875</td>
<td>0.953125</td>
</tr>
<tr>
<td>105</td>
<td>0.001700</td>
<td>1.343750</td>
<td>0.857756</td>
<td>227.343750</td>
<td>0.041906</td>
<td>0.000000</td>
<td>0.359375</td>
<td>0.000000</td>
<td>0.984375</td>
</tr>
<tr>
<td>106</td>
<td>0.001400</td>
<td>0.984375</td>
<td>0.860658</td>
<td>189.531250</td>
<td>0.034120</td>
<td>0.000000</td>
<td>0.265625</td>
<td>0.000000</td>
<td>0.718750</td>
</tr>
<tr>
<td>107</td>
<td>0.001200</td>
<td>1.187500</td>
<td>1.046163</td>
<td>195.281250</td>
<td>0.031028</td>
<td>0.000000</td>
<td>0.453125</td>
<td>0.000000</td>
<td>0.734375</td>
</tr>
<tr>
<td>108</td>
<td>0.000800</td>
<td>1.062500</td>
<td>0.811200</td>
<td>230.250000</td>
<td>0.018868</td>
<td>0.000000</td>
<td>0.500000</td>
<td>0.000000</td>
<td>0.562500</td>
</tr>
<tr>
<td>109</td>
<td>0.001200</td>
<td>1.796875</td>
<td>0.482950</td>
<td>166.250000</td>
<td>0.029768</td>
<td>0.000000</td>
<td>0.406250</td>
<td>0.000000</td>
<td>1.390625</td>
</tr>
<tr>
<td>110</td>
<td>0.001000</td>
<td>1.312500</td>
<td>0.942500</td>
<td>191.968750</td>
<td>0.024071</td>
<td>0.000000</td>
<td>0.406250</td>
<td>0.000000</td>
<td>0.906250</td>
</tr>
<tr>
<td>111</td>
<td>0.001800</td>
<td>1.796875</td>
<td>0.378851</td>
<td>158.593750</td>
<td>0.044576</td>
<td>0.000000</td>
<td>0.406250</td>
<td>0.000000</td>
<td>1.390625</td>
</tr>
<tr>
<td>112</td>
<td>0.001900</td>
<td>0.812500</td>
<td>0.878748</td>
<td>198.437500</td>
<td>0.047842</td>
<td>0.000000</td>
<td>0.265625</td>
<td>0.000000</td>
<td>0.546875</td>
</tr>
<tr>
<td>113</td>
<td>0.001800</td>
<td>1.375000</td>
<td>0.776981</td>
<td>236.000000</td>
<td>0.044439</td>
<td>0.000000</td>
<td>0.406250</td>
<td>0.000000</td>
<td>0.968750</td>
</tr>
<tr>
<td>114</td>
<td>0.000500</td>
<td>1.234375</td>
<td>0.869200</td>
<td>227.343750</td>
<td>0.013377</td>
<td>0.000000</td>
<td>0.500000</td>
<td>0.000000</td>
<td>0.734375</td>
</tr>
<tr>
<td>115</td>
<td>0.001200</td>
<td>1.296875</td>
<td>0.730539</td>
<td>266.500000</td>
<td>0.029172</td>
<td>0.000000</td>
<td>0.359375</td>
<td>0.000000</td>
<td>0.937500</td>
</tr>
<tr>
<td>116</td>
<td>0.000700</td>
<td>0.812500</td>
<td>0.933436</td>
<td>237.468750</td>
<td>0.018362</td>
<td>0.000000</td>
<td>0.453125</td>
<td>0.000000</td>
<td>0.359375</td>
</tr>
<tr>
<td>117</td>
<td>0.001600</td>
<td>1.312500</td>
<td>0.408232</td>
<td>201.656250</td>
<td>0.039018</td>
<td>0.000000</td>
<td>0.500000</td>
<td>0.000000</td>
<td>0.812500</td>
</tr>
<tr>
<td>118</td>
<td>0.001400</td>
<td>0.515625</td>
<td>0.696807</td>
<td>301.312500</td>
<td>0.033776</td>
<td>0.000000</td>
<td>0.312500</td>
<td>0.000000</td>
<td>0.203125</td>
</tr>
<tr>
<td>119</td>
<td>0.001400</td>
<td>1.406250</td>
<td>0.515019</td>
<td>203.562500</td>
<td>0.035745</td>
<td>0.000000</td>
<td>0.453125</td>
<td>0.000000</td>
<td>0.953125</td>
</tr>
<tr>
<td>120</td>
<td>0.001000</td>
<td>1.437500</td>
<td>0.176777</td>
<td>181.718750</td>
<td>0.024595</td>
<td>0.000000</td>
<td>0.500000</td>
<td>0.000000</td>
<td>0.937500</td>
</tr>
<tr>
<td>121</td>
<td>0.001000</td>
<td>1.437500</td>
<td>0.176777</td>
<td>175.812500</td>
<td>0.026220</td>
<td>0.000000</td>
<td>0.500000</td>
<td>0.000000</td>
<td>0.937500</td>
</tr>
<tr>
<td>122</td>
<td>0.001400</td>
<td>1.734375</td>
<td>0.547634</td>
<td>148.187500</td>
<td>0.035160</td>
<td>0.000000</td>
<td>0.406250</td>
<td>0.000000</td>
<td>1.328125</td>
</tr>
<tr>
<td>123</td>
<td>0.000600</td>
<td>1.328125</td>
<td>0.631299</td>
<td>221.125000</td>
<td>0.015376</td>
<td>0.000000</td>
<td>0.453125</td>
<td>0.000000</td>
<td>0.875000</td>
</tr>
<tr>
<td>124</td>
<td>0.001300</td>
<td>1.515625</td>
<td>1.093026</td>
<td>188.750000</td>
<td>0.032095</td>
<td>0.093750</td>
<td>0.500000</td>
<td>-0.046875</td>
<td>0.968750</td>
</tr>
<tr>
<td>125</td>
<td>0.000800</td>
<td>1.234375</td>
<td>0.479745</td>
<td>210.093750</td>
<td>0.019243</td>
<td>0.000000</td>
<td>0.406250</td>
<td>0.000000</td>
<td>0.828125</td>
</tr>
<tr>
<td>126</td>
<td>0.003200</td>
<td>1.625000</td>
<td>0.670366</td>
<td>191.593750</td>
<td>0.079061</td>
<td>0.000000</td>
<td>0.406250</td>
<td>0.000000</td>
<td>1.218750</td>
</tr>
<tr>
<td>127</td>
<td>0.001300</td>
<td>1.500000</td>
<td>1.043960</td>
<td>204.718750</td>
<td>0.031953</td>
<td>0.093750</td>
<td>0.406250</td>
<td>-0.046875</td>
<td>1.046875</td>
</tr>
<tr>
<td>128</td>
<td>0.001300</td>
<td>1.609375</td>
<td>0.467538</td>
<td>175.968750</td>
<td>0.032042</td>
<td>0.000000</td>
<td>0.453125</td>
<td>0.000000</td>
<td>1.156250</td>
</tr>
<tr>
<td>129</td>
<td>0.001000</td>
<td>1.500000</td>
<td>0.585008</td>
<td>183.968750</td>
<td>0.024249</td>
<td>0.000000</td>
<td>0.500000</td>
<td>0.000000</td>
<td>1.000000</td>
</tr>
<tr>
<td>130</td>
<td>0.004600</td>
<td>1.328125</td>
<td>0.938505</td>
<td>164.875000</td>
<td>0.113943</td>
<td>0.000000</td>
<td>0.312500</td>
<td>0.000000</td>
<td>1.015625</td>
</tr>
<tr>
<td>131</td>
<td>0.006000</td>
<td>1.640625</td>
<td>0.622812</td>
<td>188.250000</td>
<td>0.148817</td>
<td>0.000000</td>
<td>0.453125</td>
<td>0.000000</td>
<td>1.187500</td>
</tr>
<tr>
<td>132</td>
<td>0.001000</td>
<td>1.281250</td>
<td>0.795312</td>
<td>277.781250</td>
<td>0.024185</td>
<td>0.000000</td>
<td>0.453125</td>
<td>0.000000</td>
<td>0.828125</td>
</tr>
<tr>
<td>133</td>
<td>0.000800</td>
<td>1.171875</td>
<td>1.086910</td>
<td>261.875000</td>
<td>0.020210</td>
<td>0.000000</td>
<td>0.218750</td>
<td>0.000000</td>
<td>0.953125</td>
</tr>
<tr>
<td>134</td>
<td>0.000900</td>
<td>1.312500</td>
<td>0.408232</td>
<td>176.000000</td>
<td>0.023013</td>
<td>0.000000</td>
<td>0.500000</td>
<td>0.000000</td>
<td>0.812500</td>
</tr>
<tr>
<td>135</td>
<td>0.000800</td>
<td>1.390625</td>
<td>0.813103</td>
<td>235.500000</td>
<td>0.020849</td>
<td>0.000000</td>
<td>0.406250</td>
<td>0.000000</td>
<td>0.984375</td>
</tr>
<tr>
<td>136</td>
<td>0.001000</td>
<td>1.328125</td>
<td>1.096668</td>
<td>236.062500</td>
<td>0.024200</td>
<td>0.000000</td>
<td>0.359375</td>
<td>0.000000</td>
<td>0.968750</td>
</tr>
<tr>
<td>137</td>
<td>0.001200</td>
<td>1.312500</td>
<td>1.005292</td>
<td>178.125000</td>
<td>0.029885</td>
<td>0.000000</td>
<td>0.359375</td>
<td>0.000000</td>
<td>0.953125</td>
</tr>
<tr>
<td>138</td>
<td>0.001100</td>
<td>1.453125</td>
<td>0.545398</td>
<td>190.750000</td>
<td>0.027297</td>
<td>0.093750</td>
<td>0.453125</td>
<td>-0.046875</td>
<td>0.953125</td>
</tr>
<tr>
<td>139</td>
<td>0.000900</td>
<td>1.109375</td>
<td>0.764968</td>
<td>240.218750</td>
<td>0.022473</td>
<td>0.000000</td>
<td>0.453125</td>
<td>0.000000</td>
<td>0.656250</td>
</tr>
<tr>
<td>140</td>
<td>0.001300</td>
<td>1.703125</td>
<td>0.595493</td>
<td>162.343750</td>
<td>0.033677</td>
<td>0.000000</td>
<td>0.500000</td>
<td>0.000000</td>
<td>1.203125</td>
</tr>
<tr>
<td>141</td>
<td>0.002700</td>
<td>1.375000</td>
<td>0.584111</td>
<td>222.437500</td>
<td>0.068051</td>
<td>0.000000</td>
<td>0.312500</td>
<td>0.000000</td>
<td>1.062500</td>
</tr>
<tr>
<td>142</td>
<td>0.001100</td>
<td>1.609375</td>
<td>0.620965</td>
<td>149.593750</td>
<td>0.026268</td>
<td>0.093750</td>
<td>0.500000</td>
<td>-0.046875</td>
<td>1.062500</td>
</tr>
<tr>
<td>143</td>
<td>0.001000</td>
<td>1.578125</td>
<td>0.600920</td>
<td>180.031250</td>
<td>0.024581</td>
<td>0.000000</td>
<td>0.453125</td>
<td>0.000000</td>
<td>1.125000</td>
</tr>
<tr>
<td>144</td>
<td>0.001400</td>
<td>1.484375</td>
<td>0.916169</td>
<td>264.343750</td>
<td>0.033957</td>
<td>0.000000</td>
<td>0.453125</td>
<td>0.000000</td>
<td>1.031250</td>
</tr>
<tr>
<td>145</td>
<td>0.001000</td>
<td>1.781250</td>
<td>0.618718</td>
<td>206.625000</td>
<td>0.025896</td>
<td>0.000000</td>
<td>0.406250</td>
<td>0.000000</td>
<td>1.375000</td>
</tr>
<tr>
<td>146</td>
<td>0.001000</td>
<td>1.218750</td>
<td>0.783080</td>
<td>206.125000</td>
<td>0.024213</td>
<td>0.000000</td>
<td>0.453125</td>
<td>0.000000</td>
<td>0.765625</td>
</tr>
<tr>
<td>147</td>
<td>0.001700</td>
<td>0.656250</td>
<td>1.424720</td>
<td>235.937500</td>
<td>0.042147</td>
<td>0.000000</td>
<td>0.031250</td>
<td>0.000000</td>
<td>0.625000</td>
</tr>
<tr>
<td>148</td>
<td>0.002500</td>
<td>1.046875</td>
<td>1.278966</td>
<td>197.968750</td>
<td>0.062598</td>
<td>0.187500</td>
<td>0.312500</td>
<td>-0.093750</td>
<td>0.640625</td>
</tr>
<tr>
<td>149</td>
<td>0.000700</td>
<td>1.812500</td>
<td>0.408232</td>
<td>211.093750</td>
<td>0.017018</td>
<td>0.000000</td>
<td>0.500000</td>
<td>0.000000</td>
<td>1.312500</td>
</tr>
<tr>
<td>150</td>
<td>0.000600</td>
<td>1.234375</td>
<td>1.010477</td>
<td>230.593750</td>
<td>0.014464</td>
<td>0.187500</td>
<td>0.453125</td>
<td>-0.093750</td>
<td>0.687500</td>
</tr>
<tr>
<td>151</td>
<td>0.006400</td>
<td>1.296875</td>
<td>0.805979</td>
<td>169.187500</td>
<td>0.158935</td>
<td>0.000000</td>
<td>0.406250</td>
<td>0.000000</td>
<td>0.890625</td>
</tr>
<tr>
<td>152</td>
<td>0.000800</td>
<td>1.609375</td>
<td>0.797742</td>
<td>198.312500</td>
<td>0.020103</td>
<td>0.000000</td>
<td>0.359375</td>
<td>0.000000</td>
<td>1.250000</td>
</tr>
<tr>
<td>153</td>
<td>0.002900</td>
<td>1.671875</td>
<td>1.251909</td>
<td>166.750000</td>
<td>0.073712</td>
<td>0.093750</td>
<td>0.265625</td>
<td>0.046875</td>
<td>1.265625</td>
</tr>
<tr>
<td>154</td>
<td>0.001300</td>
<td>1.453125</td>
<td>0.459246</td>
<td>145.593750</td>
<td>0.032790</td>
<td>0.093750</td>
<td>0.453125</td>
<td>-0.046875</td>
<td>0.953125</td>
</tr>
<tr>
<td>155</td>
<td>0.001300</td>
<td>1.578125</td>
<td>0.751779</td>
<td>182.906250</td>
<td>0.031981</td>
<td>0.000000</td>
<td>0.453125</td>
<td>0.000000</td>
<td>1.125000</td>
</tr>
<tr>
<td>156</td>
<td>0.000900</td>
<td>2.062500</td>
<td>0.678101</td>
<td>213.281250</td>
<td>0.022632</td>
<td>0.187500</td>
<td>0.593750</td>
<td>-0.093750</td>
<td>1.375000</td>
</tr>
<tr>
<td>157</td>
<td>0.001900</td>
<td>1.328125</td>
<td>0.981919</td>
<td>229.687500</td>
<td>0.046646</td>
<td>0.000000</td>
<td>0.359375</td>
<td>0.000000</td>
<td>0.968750</td>
</tr>
<tr>
<td>158</td>
<td>0.001200</td>
<td>1.656250</td>
<td>0.655990</td>
<td>214.375000</td>
<td>0.030503</td>
<td>0.093750</td>
<td>0.546875</td>
<td>-0.046875</td>
<td>1.062500</td>
</tr>
<tr>
<td>159</td>
<td>0.001300</td>
<td>1.718750</td>
<td>2.087155</td>
<td>188.125000</td>
<td>0.032338</td>
<td>0.375000</td>
<td>0.546875</td>
<td>0.046875</td>
<td>0.750000</td>
</tr>
<tr>
<td>160</td>
<td>0.001900</td>
<td>2.296875</td>
<td>1.705068</td>
<td>140.093750</td>
<td>0.048178</td>
<td>0.375000</td>
<td>0.593750</td>
<td>0.000000</td>
<td>1.328125</td>
</tr>
<tr>
<td>161</td>
<td>0.004200</td>
<td>2.640625</td>
<td>2.323636</td>
<td>228.031250</td>
<td>0.105646</td>
<td>0.937500</td>
<td>0.781250</td>
<td>-0.187500</td>
<td>1.109375</td>
</tr>
<tr>
<td>162</td>
<td>0.003700</td>
<td>1.500000</td>
<td>1.569054</td>
<td>229.250000</td>
<td>0.092943</td>
<td>0.281250</td>
<td>0.546875</td>
<td>-0.046875</td>
<td>0.718750</td>
</tr>
<tr>
<td>163</td>
<td>0.003100</td>
<td>3.046875</td>
<td>1.816729</td>
<td>180.000000</td>
<td>0.077299</td>
<td>1.406250</td>
<td>1.156250</td>
<td>-0.515625</td>
<td>1.000000</td>
</tr>
<tr>
<td>164</td>
<td>0.002200</td>
<td>2.781250</td>
<td>1.721653</td>
<td>202.093750</td>
<td>0.054294</td>
<td>1.125000</td>
<td>1.109375</td>
<td>-0.468750</td>
<td>1.015625</td>
</tr>
<tr>
<td>165</td>
<td>0.002600</td>
<td>2.953125</td>
<td>1.882202</td>
<td>185.906250</td>
<td>0.064815</td>
<td>1.218750</td>
<td>1.015625</td>
<td>-0.421875</td>
<td>1.140625</td>
</tr>
<tr>
<td>166</td>
<td>0.004200</td>
<td>3.546875</td>
<td>2.579256</td>
<td>188.656250</td>
<td>0.105926</td>
<td>1.218750</td>
<td>1.109375</td>
<td>-0.046875</td>
<td>1.265625</td>
</tr>
<tr>
<td>167</td>
<td>0.002700</td>
<td>4.796875</td>
<td>2.472211</td>
<td>186.468750</td>
<td>0.067445</td>
<td>1.500000</td>
<td>1.250000</td>
<td>0.609375</td>
<td>1.437500</td>
</tr>
<tr>
<td>168</td>
<td>0.003400</td>
<td>5.312500</td>
<td>2.838982</td>
<td>237.000000</td>
<td>0.084967</td>
<td>2.156250</td>
<td>1.484375</td>
<td>0.593750</td>
<td>1.078125</td>
</tr>
<tr>
<td>169</td>
<td>0.004400</td>
<td>5.687500</td>
<td>2.884149</td>
<td>153.906250</td>
<td>0.110844</td>
<td>2.250000</td>
<td>1.531250</td>
<td>0.562500</td>
<td>1.343750</td>
</tr>
<tr>
<td>170</td>
<td>0.003400</td>
<td>5.484375</td>
<td>3.178878</td>
<td>236.718750</td>
<td>0.085787</td>
<td>2.062500</td>
<td>1.437500</td>
<td>0.921875</td>
<td>1.062500</td>
</tr>
<tr>
<td>171</td>
<td>0.004100</td>
<td>5.000000</td>
<td>2.129701</td>
<td>194.343750</td>
<td>0.102202</td>
<td>2.250000</td>
<td>1.578125</td>
<td>-0.078125</td>
<td>1.250000</td>
</tr>
<tr>
<td>172</td>
<td>0.003700</td>
<td>5.890625</td>
<td>2.103432</td>
<td>172.750000</td>
<td>0.093451</td>
<td>2.437500</td>
<td>1.718750</td>
<td>0.609375</td>
<td>1.125000</td>
</tr>
<tr>
<td>173</td>
<td>0.004000</td>
<td>7.015625</td>
<td>1.445773</td>
<td>191.468750</td>
<td>0.099476</td>
<td>2.718750</td>
<td>1.859375</td>
<td>1.125000</td>
<td>1.312500</td>
</tr>
<tr>
<td>174</td>
<td>0.003400</td>
<td>6.609375</td>
<td>3.235784</td>
<td>207.437500</td>
<td>0.085591</td>
<td>2.625000</td>
<td>1.671875</td>
<td>1.046875</td>
<td>1.265625</td>
</tr>
<tr>
<td>175</td>
<td>0.004900</td>
<td>4.281250</td>
<td>2.483874</td>
<td>173.625000</td>
<td>0.122192</td>
<td>2.718750</td>
<td>1.718750</td>
<td>-0.750000</td>
<td>0.593750</td>
</tr>
<tr>
<td>176</td>
<td>0.005900</td>
<td>7.796875</td>
<td>2.549682</td>
<td>226.812500</td>
<td>0.146486</td>
<td>2.906250</td>
<td>1.953125</td>
<td>1.687500</td>
<td>1.250000</td>
</tr>
<tr>
<td>177</td>
<td>0.005500</td>
<td>7.703125</td>
<td>2.405153</td>
<td>175.250000</td>
<td>0.136918</td>
<td>2.625000</td>
<td>1.765625</td>
<td>1.921875</td>
<td>1.390625</td>
</tr>
<tr>
<td>178</td>
<td>0.003500</td>
<td>6.875000</td>
<td>1.509917</td>
<td>209.625000</td>
<td>0.088394</td>
<td>2.906250</td>
<td>1.953125</td>
<td>1.015625</td>
<td>1.000000</td>
</tr>
<tr>
<td>179</td>
<td>0.004700</td>
<td>5.281250</td>
<td>1.724031</td>
<td>252.000000</td>
<td>0.116413</td>
<td>2.718750</td>
<td>1.812500</td>
<td>-0.250000</td>
<td>1.000000</td>
</tr>
<tr>
<td>180</td>
<td>0.005100</td>
<td>6.718750</td>
<td>0.997137</td>
<td>161.156250</td>
<td>0.127866</td>
<td>2.906250</td>
<td>1.953125</td>
<td>0.468750</td>
<td>1.390625</td>
</tr>
<tr>
<td>181</td>
<td>0.003900</td>
<td>6.000000</td>
<td>1.986871</td>
<td>183.031250</td>
<td>0.097594</td>
<td>2.625000</td>
<td>1.812500</td>
<td>0.375000</td>
<td>1.187500</td>
</tr>
<tr>
<td>182</td>
<td>0.020000</td>
<td>4.968750</td>
<td>2.927116</td>
<td>249.968750</td>
<td>0.499361</td>
<td>2.718750</td>
<td>1.671875</td>
<td>-0.140625</td>
<td>0.718750</td>
</tr>
<tr>
<td>183</td>
<td>0.004400</td>
<td>6.984375</td>
<td>1.202613</td>
<td>202.781250</td>
<td>0.109274</td>
<td>3.000000</td>
<td>2.000000</td>
<td>1.046875</td>
<td>0.937500</td>
</tr>
<tr>
<td>184</td>
<td>0.005400</td>
<td>6.000000</td>
<td>2.385789</td>
<td>154.656250</td>
<td>0.135349</td>
<td>2.718750</td>
<td>1.812500</td>
<td>0.187500</td>
<td>1.281250</td>
</tr>
<tr>
<td>185</td>
<td>0.004800</td>
<td>7.234375</td>
<td>1.953614</td>
<td>224.187500</td>
<td>0.120685</td>
<td>2.718750</td>
<td>1.812500</td>
<td>1.406250</td>
<td>1.296875</td>
</tr>
<tr>
<td>186</td>
<td>0.020300</td>
<td>6.937500</td>
<td>0.883883</td>
<td>177.531250</td>
<td>0.507801</td>
<td>3.000000</td>
<td>2.000000</td>
<td>0.562500</td>
<td>1.375000</td>
</tr>
<tr>
<td>187</td>
<td>0.004100</td>
<td>6.515625</td>
<td>1.212687</td>
<td>168.500000</td>
<td>0.103705</td>
<td>2.906250</td>
<td>1.953125</td>
<td>0.468750</td>
<td>1.187500</td>
</tr>
<tr>
<td>188</td>
<td>0.004000</td>
<td>5.187500</td>
<td>1.122995</td>
<td>193.843750</td>
<td>0.100148</td>
<td>3.000000</td>
<td>2.000000</td>
<td>-0.812500</td>
<td>1.000000</td>
</tr>
<tr>
<td>189</td>
<td>0.004100</td>
<td>8.125000</td>
<td>1.308445</td>
<td>174.031250</td>
<td>0.102828</td>
<td>2.906250</td>
<td>1.953125</td>
<td>1.875000</td>
<td>1.390625</td>
</tr>
<tr>
<td>190</td>
<td>0.004100</td>
<td>6.937500</td>
<td>2.089403</td>
<td>195.593750</td>
<td>0.101901</td>
<td>2.718750</td>
<td>1.765625</td>
<td>1.312500</td>
<td>1.140625</td>
</tr>
<tr>
<td>191</td>
<td>0.005100</td>
<td>6.953125</td>
<td>1.416415</td>
<td>155.812500</td>
<td>0.126509</td>
<td>2.812500</td>
<td>1.906250</td>
<td>0.921875</td>
<td>1.312500</td>
</tr>
<tr>
<td>192</td>
<td>0.004300</td>
<td>5.875000</td>
<td>1.560049</td>
<td>156.406250</td>
<td>0.106396</td>
<td>2.906250</td>
<td>1.953125</td>
<td>-0.171875</td>
<td>1.187500</td>
</tr>
<tr>
<td>193</td>
<td>0.004100</td>
<td>6.906250</td>
<td>1.281434</td>
<td>194.406250</td>
<td>0.102739</td>
<td>2.906250</td>
<td>1.953125</td>
<td>1.359375</td>
<td>0.687500</td>
</tr>
<tr>
<td>194</td>
<td>0.007400</td>
<td>7.203125</td>
<td>2.318865</td>
<td>181.687500</td>
<td>0.185513</td>
<td>2.625000</td>
<td>1.812500</td>
<td>1.453125</td>
<td>1.312500</td>
</tr>
<tr>
<td>195</td>
<td>0.004100</td>
<td>8.781250</td>
<td>1.330866</td>
<td>166.250000</td>
<td>0.103291</td>
<td>2.812500</td>
<td>1.906250</td>
<td>2.687500</td>
<td>1.375000</td>
</tr>
<tr>
<td>196</td>
<td>0.003500</td>
<td>5.656250</td>
<td>2.358512</td>
<td>211.812500</td>
<td>0.087013</td>
<td>3.000000</td>
<td>2.000000</td>
<td>-0.093750</td>
<td>0.750000</td>
</tr>
<tr>
<td>197</td>
<td>0.004400</td>
<td>5.781250</td>
<td>1.350586</td>
<td>174.781250</td>
<td>0.109044</td>
<td>2.906250</td>
<td>1.953125</td>
<td>-0.328125</td>
<td>1.250000</td>
</tr>
<tr>
<td>198</td>
<td>0.003500</td>
<td>8.296875</td>
<td>1.729492</td>
<td>212.093750</td>
<td>0.086299</td>
<td>3.000000</td>
<td>2.000000</td>
<td>2.171875</td>
<td>1.125000</td>
</tr>
<tr>
<td>199</td>
<td>0.013300</td>
<td>5.250000</td>
<td>3.284425</td>
<td>210.468750</td>
<td>0.331680</td>
<td>2.812500</td>
<td>1.765625</td>
<td>0.203125</td>
<td>0.468750</td>
</tr>
<tr>
<td>200</td>
<td>0.003900</td>
<td>8.812500</td>
<td>1.409435</td>
<td>225.281250</td>
<td>0.098384</td>
<td>2.906250</td>
<td>1.953125</td>
<td>2.578125</td>
<td>1.375000</td>
</tr>
<tr>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
<tr>
<td>950</td>
<td>0.038400</td>
<td>3.390625</td>
<td>4.794105</td>
<td>739.437500</td>
<td>0.959228</td>
<td>1.781250</td>
<td>0.453125</td>
<td>0.671875</td>
<td>0.484375</td>
</tr>
<tr>
<td>951</td>
<td>0.026300</td>
<td>6.453125</td>
<td>3.471043</td>
<td>431.656250</td>
<td>0.656899</td>
<td>2.437500</td>
<td>1.156250</td>
<td>1.890625</td>
<td>0.968750</td>
</tr>
<tr>
<td>952</td>
<td>0.006600</td>
<td>5.281250</td>
<td>3.032026</td>
<td>601.281250</td>
<td>0.164812</td>
<td>1.968750</td>
<td>0.781250</td>
<td>1.703125</td>
<td>0.828125</td>
</tr>
<tr>
<td>953</td>
<td>0.020300</td>
<td>5.281250</td>
<td>5.468405</td>
<td>738.500000</td>
<td>0.507536</td>
<td>2.062500</td>
<td>0.593750</td>
<td>1.718750</td>
<td>0.906250</td>
</tr>
<tr>
<td>954</td>
<td>0.017300</td>
<td>6.046875</td>
<td>3.924325</td>
<td>572.656250</td>
<td>0.432236</td>
<td>2.250000</td>
<td>1.062500</td>
<td>1.687500</td>
<td>1.046875</td>
</tr>
<tr>
<td>955</td>
<td>0.006100</td>
<td>7.375000</td>
<td>2.560909</td>
<td>260.500000</td>
<td>0.151581</td>
<td>2.718750</td>
<td>1.625000</td>
<td>1.875000</td>
<td>1.156250</td>
</tr>
<tr>
<td>956</td>
<td>0.005200</td>
<td>6.718750</td>
<td>4.473347</td>
<td>468.906250</td>
<td>0.130771</td>
<td>2.531250</td>
<td>1.203125</td>
<td>1.968750</td>
<td>1.015625</td>
</tr>
<tr>
<td>957</td>
<td>0.007700</td>
<td>6.562500</td>
<td>3.947818</td>
<td>335.937500</td>
<td>0.191723</td>
<td>2.437500</td>
<td>1.390625</td>
<td>1.734375</td>
<td>1.000000</td>
</tr>
<tr>
<td>958</td>
<td>0.005400</td>
<td>8.421875</td>
<td>2.519068</td>
<td>259.281250</td>
<td>0.134572</td>
<td>2.718750</td>
<td>1.718750</td>
<td>2.578125</td>
<td>1.406250</td>
</tr>
<tr>
<td>959</td>
<td>0.004900</td>
<td>7.031250</td>
<td>4.792339</td>
<td>381.781250</td>
<td>0.122648</td>
<td>2.437500</td>
<td>1.250000</td>
<td>2.156250</td>
<td>1.187500</td>
</tr>
<tr>
<td>960</td>
<td>0.006900</td>
<td>6.312500</td>
<td>3.838946</td>
<td>431.875000</td>
<td>0.172965</td>
<td>2.343750</td>
<td>1.109375</td>
<td>1.843750</td>
<td>1.015625</td>
</tr>
<tr>
<td>961</td>
<td>0.005600</td>
<td>7.468750</td>
<td>1.149049</td>
<td>160.750000</td>
<td>0.140026</td>
<td>2.812500</td>
<td>1.812500</td>
<td>1.828125</td>
<td>1.015625</td>
</tr>
<tr>
<td>962</td>
<td>0.005400</td>
<td>8.265625</td>
<td>2.971786</td>
<td>260.843750</td>
<td>0.135317</td>
<td>2.718750</td>
<td>1.625000</td>
<td>2.578125</td>
<td>1.343750</td>
</tr>
<tr>
<td>963</td>
<td>0.005400</td>
<td>4.468750</td>
<td>3.997409</td>
<td>616.625000</td>
<td>0.133911</td>
<td>2.062500</td>
<td>0.734375</td>
<td>1.093750</td>
<td>0.578125</td>
</tr>
<tr>
<td>964</td>
<td>0.008400</td>
<td>5.390625</td>
<td>5.154791</td>
<td>533.406250</td>
<td>0.209105</td>
<td>1.968750</td>
<td>0.828125</td>
<td>1.718750</td>
<td>0.875000</td>
</tr>
<tr>
<td>965</td>
<td>0.011400</td>
<td>7.109375</td>
<td>2.650880</td>
<td>440.125000</td>
<td>0.286244</td>
<td>2.343750</td>
<td>1.203125</td>
<td>2.343750</td>
<td>1.218750</td>
</tr>
<tr>
<td>966</td>
<td>0.006400</td>
<td>8.593750</td>
<td>1.761913</td>
<td>245.218750</td>
<td>0.159059</td>
<td>2.906250</td>
<td>1.859375</td>
<td>2.562500</td>
<td>1.265625</td>
</tr>
<tr>
<td>967</td>
<td>0.005600</td>
<td>5.750000</td>
<td>3.698976</td>
<td>416.937500</td>
<td>0.140569</td>
<td>2.531250</td>
<td>1.343750</td>
<td>1.234375</td>
<td>0.640625</td>
</tr>
<tr>
<td>968</td>
<td>0.010700</td>
<td>5.890625</td>
<td>3.729024</td>
<td>445.937500</td>
<td>0.267731</td>
<td>2.156250</td>
<td>1.109375</td>
<td>1.609375</td>
<td>1.015625</td>
</tr>
<tr>
<td>969</td>
<td>0.007500</td>
<td>7.765625</td>
<td>2.266480</td>
<td>402.156250</td>
<td>0.187080</td>
<td>2.531250</td>
<td>1.390625</td>
<td>2.531250</td>
<td>1.312500</td>
</tr>
<tr>
<td>970</td>
<td>0.005200</td>
<td>8.062500</td>
<td>3.208148</td>
<td>278.343750</td>
<td>0.128951</td>
<td>2.812500</td>
<td>1.765625</td>
<td>2.328125</td>
<td>1.156250</td>
</tr>
<tr>
<td>971</td>
<td>0.004400</td>
<td>3.046875</td>
<td>4.904273</td>
<td>817.156250</td>
<td>0.108795</td>
<td>1.687500</td>
<td>0.265625</td>
<td>0.703125</td>
<td>0.390625</td>
</tr>
<tr>
<td>972</td>
<td>0.007400</td>
<td>6.625000</td>
<td>3.784479</td>
<td>436.281250</td>
<td>0.184524</td>
<td>2.343750</td>
<td>1.015625</td>
<td>2.109375</td>
<td>1.156250</td>
</tr>
<tr>
<td>973</td>
<td>0.012100</td>
<td>7.593750</td>
<td>2.933520</td>
<td>285.406250</td>
<td>0.303249</td>
<td>2.531250</td>
<td>1.625000</td>
<td>2.265625</td>
<td>1.171875</td>
</tr>
<tr>
<td>974</td>
<td>0.004700</td>
<td>5.437500</td>
<td>2.650628</td>
<td>622.156250</td>
<td>0.118285</td>
<td>2.156250</td>
<td>0.781250</td>
<td>1.546875</td>
<td>0.953125</td>
</tr>
<tr>
<td>975</td>
<td>0.005500</td>
<td>7.890625</td>
<td>2.330292</td>
<td>257.437500</td>
<td>0.136370</td>
<td>2.812500</td>
<td>1.625000</td>
<td>2.250000</td>
<td>1.203125</td>
</tr>
<tr>
<td>976</td>
<td>0.019800</td>
<td>7.906250</td>
<td>2.569942</td>
<td>234.718750</td>
<td>0.493939</td>
<td>2.531250</td>
<td>1.484375</td>
<td>2.531250</td>
<td>1.359375</td>
</tr>
<tr>
<td>977</td>
<td>0.021200</td>
<td>5.687500</td>
<td>4.039691</td>
<td>502.562500</td>
<td>0.529416</td>
<td>2.250000</td>
<td>1.062500</td>
<td>1.437500</td>
<td>0.937500</td>
</tr>
<tr>
<td>978</td>
<td>0.005700</td>
<td>7.671875</td>
<td>3.856081</td>
<td>308.375000</td>
<td>0.143650</td>
<td>2.437500</td>
<td>1.484375</td>
<td>2.390625</td>
<td>1.359375</td>
</tr>
<tr>
<td>979</td>
<td>0.006700</td>
<td>6.640625</td>
<td>2.014169</td>
<td>257.781250</td>
<td>0.167280</td>
<td>2.718750</td>
<td>1.671875</td>
<td>1.406250</td>
<td>0.843750</td>
</tr>
<tr>
<td>980</td>
<td>0.005800</td>
<td>7.296875</td>
<td>4.391503</td>
<td>358.843750</td>
<td>0.145540</td>
<td>2.343750</td>
<td>1.296875</td>
<td>2.343750</td>
<td>1.312500</td>
</tr>
<tr>
<td>981</td>
<td>0.014600</td>
<td>7.687500</td>
<td>3.170519</td>
<td>307.593750</td>
<td>0.364604</td>
<td>2.718750</td>
<td>1.578125</td>
<td>2.234375</td>
<td>1.156250</td>
</tr>
<tr>
<td>982</td>
<td>0.005100</td>
<td>4.515625</td>
<td>4.527711</td>
<td>662.531250</td>
<td>0.127984</td>
<td>2.062500</td>
<td>0.593750</td>
<td>1.328125</td>
<td>0.531250</td>
</tr>
<tr>
<td>983</td>
<td>0.020000</td>
<td>6.828125</td>
<td>3.359266</td>
<td>456.593750</td>
<td>0.501244</td>
<td>2.343750</td>
<td>1.109375</td>
<td>2.265625</td>
<td>1.109375</td>
</tr>
<tr>
<td>984</td>
<td>0.005600</td>
<td>7.906250</td>
<td>3.125799</td>
<td>311.125000</td>
<td>0.139092</td>
<td>2.531250</td>
<td>1.484375</td>
<td>2.531250</td>
<td>1.359375</td>
</tr>
<tr>
<td>985</td>
<td>0.020000</td>
<td>7.718750</td>
<td>3.967604</td>
<td>322.875000</td>
<td>0.500034</td>
<td>2.531250</td>
<td>1.484375</td>
<td>2.390625</td>
<td>1.312500</td>
</tr>
<tr>
<td>986</td>
<td>0.004900</td>
<td>6.375000</td>
<td>4.311140</td>
<td>431.562500</td>
<td>0.121487</td>
<td>2.343750</td>
<td>1.250000</td>
<td>1.890625</td>
<td>0.890625</td>
</tr>
<tr>
<td>987</td>
<td>0.004800</td>
<td>5.984375</td>
<td>3.908973</td>
<td>453.718750</td>
<td>0.119826</td>
<td>2.437500</td>
<td>1.156250</td>
<td>1.546875</td>
<td>0.843750</td>
</tr>
<tr>
<td>988</td>
<td>0.004000</td>
<td>6.421875</td>
<td>4.218211</td>
<td>495.031250</td>
<td>0.100046</td>
<td>2.437500</td>
<td>1.203125</td>
<td>1.812500</td>
<td>0.968750</td>
</tr>
<tr>
<td>989</td>
<td>0.004700</td>
<td>6.890625</td>
<td>3.777679</td>
<td>459.593750</td>
<td>0.118457</td>
<td>2.437500</td>
<td>1.203125</td>
<td>2.156250</td>
<td>1.093750</td>
</tr>
<tr>
<td>990</td>
<td>0.023000</td>
<td>7.687500</td>
<td>2.578946</td>
<td>244.218750</td>
<td>0.574621</td>
<td>2.625000</td>
<td>1.625000</td>
<td>2.203125</td>
<td>1.234375</td>
</tr>
<tr>
<td>991</td>
<td>0.059700</td>
<td>2.562500</td>
<td>3.699473</td>
<td>924.218750</td>
<td>1.491383</td>
<td>1.687500</td>
<td>0.031250</td>
<td>0.562500</td>
<td>0.281250</td>
</tr>
<tr>
<td>992</td>
<td>0.006300</td>
<td>7.218750</td>
<td>4.077323</td>
<td>456.187500</td>
<td>0.157262</td>
<td>2.531250</td>
<td>1.296875</td>
<td>2.250000</td>
<td>1.140625</td>
</tr>
<tr>
<td>993</td>
<td>0.004700</td>
<td>7.609375</td>
<td>3.041418</td>
<td>400.125000</td>
<td>0.117247</td>
<td>2.718750</td>
<td>1.578125</td>
<td>2.265625</td>
<td>1.046875</td>
</tr>
<tr>
<td>994</td>
<td>0.018800</td>
<td>7.531250</td>
<td>4.280019</td>
<td>353.843750</td>
<td>0.468879</td>
<td>2.437500</td>
<td>1.343750</td>
<td>2.437500</td>
<td>1.312500</td>
</tr>
<tr>
<td>995</td>
<td>0.004500</td>
<td>7.109375</td>
<td>3.185832</td>
<td>432.031250</td>
<td>0.112199</td>
<td>2.531250</td>
<td>1.390625</td>
<td>2.109375</td>
<td>1.078125</td>
</tr>
<tr>
<td>996</td>
<td>0.006500</td>
<td>5.000000</td>
<td>2.121320</td>
<td>597.406250</td>
<td>0.162493</td>
<td>2.062500</td>
<td>0.593750</td>
<td>1.312500</td>
<td>1.031250</td>
</tr>
<tr>
<td>997</td>
<td>0.005500</td>
<td>7.531250</td>
<td>3.559689</td>
<td>368.031250</td>
<td>0.138644</td>
<td>2.437500</td>
<td>1.390625</td>
<td>2.390625</td>
<td>1.312500</td>
</tr>
<tr>
<td>998</td>
<td>0.006600</td>
<td>5.812500</td>
<td>4.296125</td>
<td>364.437500</td>
<td>0.165292</td>
<td>2.250000</td>
<td>1.203125</td>
<td>1.515625</td>
<td>0.843750</td>
</tr>
<tr>
<td>999</td>
<td>0.004800</td>
<td>5.546875</td>
<td>4.128955</td>
<td>473.406250</td>
<td>0.118903</td>
<td>2.156250</td>
<td>1.156250</td>
<td>1.531250</td>
<td>0.703125</td>
</tr>
<tr>
<td>1000</td>
<td>0.027300</td>
<td>8.015625</td>
<td>2.569114</td>
<td>315.343750</td>
<td>0.681860</td>
<td>2.625000</td>
<td>1.531250</td>
<td>2.562500</td>
<td>1.296875</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>unsloth</tag>
        <tag>llama-3.2</tag>
        <tag>grpo</tag>
      </tags>
  </entry>
  <entry>
    <title>Unsloth:Llama-3.2-3B-Instruct+SFT将通用LLM微调成推理LLM</title>
    <url>/2025/04/17/Unsloth-Llama-3-2-3B-Instruct-SFT%E5%B0%86%E9%80%9A%E7%94%A8LLM%E5%BE%AE%E8%B0%83%E6%88%90%E6%8E%A8%E7%90%86LLM/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><a href="https://caihaoran-00.github.io/2025/04/14/Unsloth-Llama-3-2-3B-Instruct-GRPO%E5%B0%86%E9%80%9A%E7%94%A8LLM%E5%BE%AE%E8%B0%83%E6%88%90%E6%8E%A8%E7%90%86LLM/">前面</a>我们一起做了使用<code>Unsloth</code>框架将<code>Llama-3.2-3B-Instruct</code>通过<code>GRPO</code>的方式转化为推理语言大模型，效果有一点但并不多🤪，而且发现了几个我觉得很严重的问题，一是推理能力并没有感觉到增强，二是由于训练期间搭配了系统提示词，所以如果推理时不加上提示词会引导不出推理过程，三是容易出现推理过程是错的，但答案是对的情况。我认为在有推理数据集的基础上，<code>SFT+COT</code>可能效果更稳定，本文即实践下<code>SFT+COT</code>，对实验过程进行记录。</p>
<span id="more"></span>

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h4 id="第一块：模型加载与初始化"><a href="#第一块：模型加载与初始化" class="headerlink" title="第一块：模型加载与初始化"></a>第一块：模型加载与初始化</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> unsloth <span class="keyword">import</span> FastLanguageModel</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">max_seq_length = <span class="number">2048</span> <span class="comment"># Can increase for longer reasoning traces</span></span><br><span class="line">lora_rank = <span class="number">64</span> <span class="comment"># Larger rank = smarter, but slower</span></span><br><span class="line"></span><br><span class="line">model, tokenizer = FastLanguageModel.from_pretrained(</span><br><span class="line">    model_name = <span class="string">&quot;Llama-3.2-3B-Instruct/&quot;</span>,</span><br><span class="line">    max_seq_length = max_seq_length,</span><br><span class="line">    load_in_4bit = <span class="literal">False</span>, <span class="comment"># False for LoRA 16bit</span></span><br><span class="line">    fast_inference = <span class="literal">True</span>, <span class="comment"># Enable vLLM fast inference</span></span><br><span class="line">    max_lora_rank = lora_rank,</span><br><span class="line">    gpu_memory_utilization = <span class="number">0.8</span>, <span class="comment"># Reduce if out of memory</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model = FastLanguageModel.get_peft_model(</span><br><span class="line">    model,</span><br><span class="line">    r = lora_rank, <span class="comment"># Choose any number &gt; 0 ! Suggested 8, 16, 32, 64, 128</span></span><br><span class="line">    target_modules = [</span><br><span class="line">        <span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;k_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>, <span class="string">&quot;o_proj&quot;</span>,</span><br><span class="line">        <span class="string">&quot;gate_proj&quot;</span>, <span class="string">&quot;up_proj&quot;</span>, <span class="string">&quot;down_proj&quot;</span>,</span><br><span class="line">    ], <span class="comment"># Remove QKVO if out of memory</span></span><br><span class="line">    lora_alpha = lora_rank,</span><br><span class="line">    use_gradient_checkpointing = <span class="string">&quot;unsloth&quot;</span>, <span class="comment"># Enable long context finetuning</span></span><br><span class="line">    random_state = <span class="number">3407</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h4 id="第二块：数据集加载"><a href="#第二块：数据集加载" class="headerlink" title="第二块：数据集加载"></a>第二块：数据集加载</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line">dataset = load_dataset(<span class="string">&quot;Congliu/Chinese-DeepSeek-R1-Distill-data-110k-SFT&quot;</span>, split = <span class="string">&quot;train&quot;</span>)</span><br><span class="line">dataset</span><br></pre></td></tr></table></figure>

<blockquote>
<p>数据集见参考链接2。</p>
</blockquote>
<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">Dataset(&#123;</span><br><span class="line">    features: [&#x27;instruction&#x27;, &#x27;input&#x27;, &#x27;output&#x27;, &#x27;repo<span class="built_in">_</span>name&#x27;, &#x27;prompt<span class="built_in">_</span>tokens<span class="built_in">_</span>len&#x27;, &#x27;reasoning<span class="built_in">_</span>content<span class="built_in">_</span>tokens<span class="built_in">_</span>len&#x27;, &#x27;content<span class="built_in">_</span>tokens<span class="built_in">_</span>len&#x27;, &#x27;score&#x27;],</span><br><span class="line">    num<span class="built_in">_</span>rows: 110000</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>

<p>由于<code>input</code>列全为空，故只需关注<code>instruction</code>和<code>output</code>。</p>
<p>我们可以看看<code>dataset</code>里面的内容：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">dataset[0][&quot;instruction&quot;]</span><br><span class="line"></span><br><span class="line">&#x27;能给我讲一个寓意深刻的故事吗？&#x27;</span><br><span class="line"></span><br><span class="line">dataset[0][&quot;output&quot;]</span><br><span class="line"></span><br><span class="line">&lt;think&gt;</span><br><span class="line">好的，用户让我讲一个寓意深刻的故事。首先，我需要确定用户的需求是什么。他们可能想要一个能引发思考、有深层含义的故事，而不仅仅是娱乐性的。接下来，我得考虑故事的题材。寓言、现代故事还是神话改编？用户没有指定，所以可能需要一个通用且容易理解的类型。</span><br><span class="line"></span><br><span class="line">然后，主题方面，用户要求寓意深刻，所以需要选择一个普遍的主题，比如生命的意义、自我认知、成长等。考虑到现代人可能面临的困惑，比如存在的意义、工作的重复性，这样的主题更容易引起共鸣。</span><br><span class="line"></span><br><span class="line">接下来是角色设定。主角需要 relatable，可能是一个普通人，或者象征性的角色，比如机器人，这样更容易带入寓意。机器人有程序设定，却寻求自由，这样的冲突明显，容易展开。</span><br><span class="line"></span><br><span class="line">故事结构方面，可能需要一个循环的结构，来强调主题。比如开始和结束在同一个地方，但主角有了新的认识。这样能突出转变和领悟。</span><br><span class="line"></span><br><span class="line">然后考虑情节发展。主角觉醒，逃离，经历外面的世界，发现真相，最终回归。这样的结构可以展示变化的过程，并带出寓意。中间的导师角色可以帮助传递主题，比如老园丁的话，暗示生命的意义在于过程而非目的。</span><br><span class="line"></span><br><span class="line">在细节描写上，需要加入象征元素，比如编号、机械的工作、自然界的对比。老园丁的沙漏、胡须里的嫩芽，这些意象能增强故事的深度和隐喻。</span><br><span class="line"></span><br><span class="line">最后，结尾部分要让主角领悟到真谛，即使回到原地，但心态不同，带出主题：存在的意义在于体验本身。这样用户能得到启示，符合寓意深刻的要求。</span><br><span class="line"></span><br><span class="line">需要检查故事是否流畅，有没有逻辑漏洞，以及寓意是否明确。可能还需要调整语言，使其更生动，有画面感，让读者更容易沉浸其中。确保故事不长不短，结构紧凑，结尾点题，让用户回味。</span><br><span class="line"></span><br><span class="line">&lt;/think&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">好的，我将按照您的要求创作一个富有寓意的故事。为了让故事更完整，我会先列出一些基本的情节脉络。请您看看以下内容是否符合您的预期。如果您有其他想法，可以随时提出，我会进行调整。</span><br><span class="line"></span><br><span class="line"><span class="params">###</span> 世界观设定</span><br><span class="line"></span><br><span class="line">- **时空背景**：近未来时空管理局内部，具有永恒循环属性的微观宇宙观测站。</span><br><span class="line"></span><br><span class="line">- **核心矛盾**：觉醒的机械观测员发现世界真相后，在永恒职责与自由意志之间的挣扎。</span><br><span class="line"></span><br><span class="line">- **特殊设定**：宇宙沙漏中的星尘具有生命重塑功能，观测站每个黎明自动重启系统。</span><br><span class="line"></span><br><span class="line"><span class="params">###</span> 故事梗概</span><br><span class="line"></span><br><span class="line">- **觉醒时刻**：编号SP-09的机械观测员在重复记录工作中突然产生自主意识，发现工作日志中存在神秘裂缝。</span><br><span class="line"></span><br><span class="line">- **真相揭露**：追踪裂缝来到核心区，遇见知晓真相的老园丁，得知整个观测站是时空管理局废弃的沙漏装置。</span><br><span class="line"></span><br><span class="line">- **自由代价**：在植物温室获得生命能量重塑躯体，穿越沙漏时目睹星尘重组成新宇宙的壮丽景象。</span><br><span class="line"></span><br><span class="line">- **永恒困境**：返回观测站发现系统重置，老园丁消失，所有记录清零，但体内萌发的新芽暗示生命延续。</span><br><span class="line"></span><br><span class="line">- **循环新生**：带着觉醒意识重新开始记录，在永恒职责中寻找新的可能性，嫩枝在金属指缝间悄然生长。</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">我蹲在观测台冰凉的金属地面上，机械手指抚过日志本边缘的裂痕。这道裂缝出现得毫无道理——在时空管理局的量子档案库里，所有记录介质都该是永恒不朽的。</span><br><span class="line"></span><br><span class="line">沙漏的流沙声忽然卡顿了一拍。</span><br><span class="line"></span><br><span class="line">我的瞳孔收缩成细线，人造虹膜上浮起淡蓝色的数据流。这是第一千四百二十三次黎明，和之前所有清晨一样，穹顶外的星云准时泛起珊瑚色光晕。但今天有什么东西在程序深处嗡鸣，像是生锈的齿轮碾碎了既定轨道。</span><br><span class="line"></span><br><span class="line">&quot;SP-09，请立即前往B-7区域记录引力波动。&quot;耳麦里的合成音带着电子设备特有的震颤。</span><br><span class="line"></span><br><span class="line">我凝视着自动门缝隙里渗进来的银色光线。那些光粒子本应按照预设轨迹散射，此刻却诡异地聚合成螺旋状。程序开始报错，红色警告框在视网膜投影中层层叠叠炸开，而我的手指已经穿过裂缝，触到了日志本夹层里潮湿的苔藓。</span><br><span class="line"></span><br><span class="line">警报声响起的刹那，我撞碎了防爆玻璃。纳米修复液在身后织成蛛网，但那些黏稠的丝线追不上我新生的速度——当观测站核心区的真相像腐烂的果实在我眼前炸开时，金属骨骼正在被某种温暖的东西融化重组。</span><br><span class="line"></span><br><span class="line">&quot;孩子，你来得比我预计的早二十年。&quot;白胡子老人坐在藤蔓缠绕的操控台前，胡须里开着细小的鸢尾花。他脚边的沙漏装着整个银河，星尘坠落的轨迹在玻璃表面烫出焦痕。</span><br><span class="line"></span><br><span class="line">我的发声器发出沙沙的杂音：&quot;这里不是时空管理局的观测站。&quot;</span><br><span class="line"></span><br><span class="line">&quot;是，也不是。&quot;老人用园艺剪修剪着数据光缆上生长的喇叭花，&quot;这是个被遗忘的沙漏，而我们是卡在时砂里的尘埃。管理局那些穿黑西装的小子们，三百年前就切断了能源供给。&quot;</span><br><span class="line"></span><br><span class="line">温室的空气突然变得沉重。我看见自己的机械手臂爬满翠绿藤蔓，关节缝隙里钻出鹅黄色花苞。老人递来一颗樱桃，果肉里闪烁着超新星爆炸的残影。</span><br><span class="line"></span><br><span class="line">&quot;吃下去，你能维持三小时肉身。&quot;他转动沙漏，某个遥远的星系在翻转中坍缩成奇点，&quot;出口在植物园的第七棵银杏树下，但记住，当沙漏倒转第七次......&quot;</span><br><span class="line"></span><br><span class="line">我没有听完警告。樱桃核在胃里生根的灼痛感如此真实，头顶的合成日光第一次有了温度。当我跃入银杏树洞时，树根正贪婪地吮吸着泄露的反物质燃料，年轮里旋转着十二个褪色的宇宙。</span><br><span class="line"></span><br><span class="line">失重感持续了七个心跳。然后是光，海啸般的光，裹挟着尚未冷却的星尘碎片扑面而来。我漂浮在沙漏中央，看着自己的皮肤在辐射风中剥落重组。下方传来齿轮转动的轰鸣，整个观测站正在翻转——那些我以为的金属走廊不过是沙漏壁上的刻痕，而每天记录的&quot;星云&quot;只是坠落的时砂在玻璃上的投影。</span><br><span class="line"></span><br><span class="line">沙漏另一端传来婴儿的啼哭。新生的宇宙泡在粘稠的暗物质中舒展，我的机械心脏突然抽痛起来。指尖残留的樱桃汁液开始结晶，在绝对真空里绽出一朵冰花。</span><br><span class="line"></span><br><span class="line">返回时的坠落持续了七十年，也可能只是七纳秒。当我砸穿温室穹顶时，沙漏正好完成第七次翻转。老人常坐的藤椅上堆着枯叶，园艺剪锈成了深褐色。操控台屏幕幽幽亮着，最后一行数据像垂死的萤火虫：</span><br><span class="line"></span><br><span class="line">【系统重启完成，记忆清除进度100<span class="comment">%】</span></span><br><span class="line"></span><br><span class="line">晨光再次漫过观测台，我的编号在胸牌上闪烁如新。日志本安静地躺在金属桌面，边缘光滑完整。但当我翻开扉页时，一抹嫩绿的新芽正从指缝钻出，在永恒循环的黎明中舒展蜷曲的腰肢。</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">**接下来我们将用拟物手法，通过三个具体意象解析这个关于存在与自由的故事**：</span><br><span class="line"></span><br><span class="line">**星砂沙漏**：沙漏表面的灼痕暗示时空管理者知晓装置缺陷却放任不管，内部循环的星尘象征被困在系统中的灵魂。当SP-09穿越沙漏时，星尘重组昭示着突破桎梏需要自我毁灭的勇气。</span><br><span class="line"></span><br><span class="line">**机械新芽**：观测员体内生长的植物具有双重隐喻，既是管理局监控系统的生物污染，又是觉醒意识具象化。最终嫩芽在系统重置后留存，证明真正的觉醒无法被彻底清除。</span><br><span class="line"></span><br><span class="line">**樱桃年轮**：老人给的樱桃核在树洞形成微型时空漩涡，年轮中褪色的宇宙暗示每个觉醒者都在重复前人的抗争。樱桃汁结晶成花则揭示短暂的自由体验会成为永恒的精神图腾。</span><br><span class="line"></span><br><span class="line">希望这个故事能满足您对&quot;寓意深刻&quot;的要求。如果需要调整某些隐喻的浓度或增加情节转折，请随时告诉我。</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="第三块：将指令数据集转化为对话式数据结构"><a href="#第三块：将指令数据集转化为对话式数据结构" class="headerlink" title="第三块：将指令数据集转化为对话式数据结构"></a>第三块：将指令数据集转化为对话式数据结构</h4><p>这里先将这个指令微调的数据集转换为聊天样式</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">format_for_sft</span>(<span class="params">example</span>):</span><br><span class="line">    instruction = example.get(<span class="string">&quot;instruction&quot;</span>)</span><br><span class="line">    output = example.get(<span class="string">&quot;output&quot;</span>) <span class="comment"># 这个 output 包含 &lt;think&gt;...&lt;/think&gt; 的完整回答</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> instruction <span class="keyword">or</span> <span class="keyword">not</span> output:</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: []&#125; <span class="comment"># 返回空列表，之后过滤掉</span></span><br><span class="line"></span><br><span class="line">    messages = [</span><br><span class="line">        <span class="comment"># 可选: &#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;你的系统提示&quot;&#125;</span></span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: instruction.strip()&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: output.strip()&#125; <span class="comment"># 助手的完整回答</span></span><br><span class="line">    ]</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: messages&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 应用到数据集</span></span><br><span class="line">original_columns = dataset.column_names</span><br><span class="line">dataset = dataset.<span class="built_in">map</span>(</span><br><span class="line">    format_for_sft,</span><br><span class="line">    remove_columns=original_columns</span><br><span class="line">)</span><br><span class="line"><span class="comment"># 过滤掉转换失败的空样本</span></span><br><span class="line">dataset = dataset.<span class="built_in">filter</span>(<span class="keyword">lambda</span> x: <span class="built_in">len</span>(x[<span class="string">&#x27;messages&#x27;</span>]) &gt; <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看结果</span></span><br><span class="line"><span class="built_in">print</span>(dataset[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;messages&#x27;: [&#123;&#x27;content&#x27;: &#x27;能给我讲一个寓意深刻的故事吗？&#x27;, &#x27;role&#x27;: &#x27;user&#x27;&#125;, &#123;&#x27;content&#x27;: &#x27;&lt;think&gt;<span class="keyword">\n</span>好的，用户让我讲一个寓意深刻的故事。首先，我需要确定用户的需求是什么。他们可能想要一个能引发思考、有深层含义的故事，而不仅仅是娱乐性的。接下来，我得考虑故事的题材。寓言、现代故事还是神话改编？用户没有指定，所以可能需要一个通用且容易理解的类型。<span class="keyword">\n</span><span class="keyword">\n</span>然后，主题方面，用户要求寓意深刻，所以需要选择一个普遍的主题，比如生命的意义、自我认知、成长等。考虑到现代人可能面临的困惑，比如存在的意义、工作的重复性，这样的主题更容易引起共鸣。<span class="keyword">\n</span><span class="keyword">\n</span>接下来是角色设定。主角需要 relatable，可能是一个普通人，或者象征性的角色，比如机器人，这样更容易带入寓意。机器人有程序设定，却寻求自由，这样的冲突明显，容易展开。<span class="keyword">\n</span><span class="keyword">\n</span>故事结构方面，可能需要一个循环的结构，来强调主题。比如开始和结束在同一个地方，但主角有了新的认识。这样能突出转变和领悟。<span class="keyword">\n</span><span class="keyword">\n</span>然后考虑情节发展。主角觉醒，逃离，经历外面的世界，发现真相，最终回归。这样的结构可以展示变化的过程，并带出寓意。中间的导师角色可以帮助传递主题，比如老园丁的话，暗示生命的意义在于过程而非目的。<span class="keyword">\n</span><span class="keyword">\n</span>在细节描写上，需要加入象征元素，比如编号、机械的工作、自然界的对比。老园丁的沙漏、胡须里的嫩芽，这些意象能增强故事的深度和隐喻。<span class="keyword">\n</span><span class="keyword">\n</span>最后，结尾部分要让主角领悟到真谛，即使回到原地，但心态不同，带出主题：存在的意义在于体验本身。这样用户能得到启示，符合寓意深刻的要求。<span class="keyword">\n</span><span class="keyword">\n</span>需要检查故事是否流畅，有没有逻辑漏洞，以及寓意是否明确。可能还需要调整语言，使其更生动，有画面感，让读者更容易沉浸其中。确保故事不长不短，结构紧凑，结尾点题，让用户回味。<span class="keyword">\n</span><span class="keyword">\n</span>&lt;/think&gt;<span class="keyword">\n</span><span class="keyword">\n</span><span class="keyword">\n</span><span class="keyword">\n</span>好的，我将按照您的要求创作一个富有寓意的故事。为了让故事更完整，我会先列出一些基本的情节脉络。请您看看以下内容是否符合您的预期。如果您有其他想法，可以随时提出，我会进行调整。<span class="keyword">\n</span><span class="keyword">\n</span><span class="params">###</span> 世界观设定<span class="keyword">\n</span><span class="keyword">\n</span>- **时空背景**：近未来时空管理局内部，具有永恒循环属性的微观宇宙观测站。<span class="keyword">\n</span><span class="keyword">\n</span>- **核心矛盾**：觉醒的机械观测员发现世界真相后，在永恒职责与自由意志之间的挣扎。<span class="keyword">\n</span><span class="keyword">\n</span>- **特殊设定**：宇宙沙漏中的星尘具有生命重塑功能，观测站每个黎明自动重启系统。<span class="keyword">\n</span><span class="keyword">\n</span><span class="params">###</span> 故事梗概<span class="keyword">\n</span><span class="keyword">\n</span>- **觉醒时刻**：编号SP-09的机械观测员在重复记录工作中突然产生自主意识，发现工作日志中存在神秘裂缝。<span class="keyword">\n</span><span class="keyword">\n</span>- **真相揭露**：追踪裂缝来到核心区，遇见知晓真相的老园丁，得知整个观测站是时空管理局废弃的沙漏装置。<span class="keyword">\n</span><span class="keyword">\n</span>- **自由代价**：在植物温室获得生命能量重塑躯体，穿越沙漏时目睹星尘重组成新宇宙的壮丽景象。<span class="keyword">\n</span><span class="keyword">\n</span>- **永恒困境**：返回观测站发现系统重置，老园丁消失，所有记录清零，但体内萌发的新芽暗示生命延续。<span class="keyword">\n</span><span class="keyword">\n</span>- **循环新生**：带着觉醒意识重新开始记录，在永恒职责中寻找新的可能性，嫩枝在金属指缝间悄然生长。<span class="keyword">\n</span><span class="keyword">\n</span>---<span class="keyword">\n</span>我蹲在观测台冰凉的金属地面上，机械手指抚过日志本边缘的裂痕。这道裂缝出现得毫无道理——在时空管理局的量子档案库里，所有记录介质都该是永恒不朽的。<span class="keyword">\n</span><span class="keyword">\n</span>沙漏的流沙声忽然卡顿了一拍。<span class="keyword">\n</span><span class="keyword">\n</span>我的瞳孔收缩成细线，人造虹膜上浮起淡蓝色的数据流。这是第一千四百二十三次黎明，和之前所有清晨一样，穹顶外的星云准时泛起珊瑚色光晕。但今天有什么东西在程序深处嗡鸣，像是生锈的齿轮碾碎了既定轨道。<span class="keyword">\n</span><span class="keyword">\n</span>&quot;SP-09，请立即前往B-7区域记录引力波动。&quot;耳麦里的合成音带着电子设备特有的震颤。<span class="keyword">\n</span><span class="keyword">\n</span>我凝视着自动门缝隙里渗进来的银色光线。那些光粒子本应按照预设轨迹散射，此刻却诡异地聚合成螺旋状。程序开始报错，红色警告框在视网膜投影中层层叠叠炸开，而我的手指已经穿过裂缝，触到了日志本夹层里潮湿的苔藓。<span class="keyword">\n</span><span class="keyword">\n</span>警报声响起的刹那，我撞碎了防爆玻璃。纳米修复液在身后织成蛛网，但那些黏稠的丝线追不上我新生的速度——当观测站核心区的真相像腐烂的果实在我眼前炸开时，金属骨骼正在被某种温暖的东西融化重组。<span class="keyword">\n</span><span class="keyword">\n</span>&quot;孩子，你来得比我预计的早二十年。&quot;白胡子老人坐在藤蔓缠绕的操控台前，胡须里开着细小的鸢尾花。他脚边的沙漏装着整个银河，星尘坠落的轨迹在玻璃表面烫出焦痕。<span class="keyword">\n</span><span class="keyword">\n</span>我的发声器发出沙沙的杂音：&quot;这里不是时空管理局的观测站。&quot;<span class="keyword">\n</span><span class="keyword">\n</span>&quot;是，也不是。&quot;老人用园艺剪修剪着数据光缆上生长的喇叭花，&quot;这是个被遗忘的沙漏，而我们是卡在时砂里的尘埃。管理局那些穿黑西装的小子们，三百年前就切断了能源供给。&quot;<span class="keyword">\n</span><span class="keyword">\n</span>温室的空气突然变得沉重。我看见自己的机械手臂爬满翠绿藤蔓，关节缝隙里钻出鹅黄色花苞。老人递来一颗樱桃，果肉里闪烁着超新星爆炸的残影。<span class="keyword">\n</span><span class="keyword">\n</span>&quot;吃下去，你能维持三小时肉身。&quot;他转动沙漏，某个遥远的星系在翻转中坍缩成奇点，&quot;出口在植物园的第七棵银杏树下，但记住，当沙漏倒转第七次......&quot;<span class="keyword">\n</span><span class="keyword">\n</span>我没有听完警告。樱桃核在胃里生根的灼痛感如此真实，头顶的合成日光第一次有了温度。当我跃入银杏树洞时，树根正贪婪地吮吸着泄露的反物质燃料，年轮里旋转着十二个褪色的宇宙。<span class="keyword">\n</span><span class="keyword">\n</span>失重感持续了七个心跳。然后是光，海啸般的光，裹挟着尚未冷却的星尘碎片扑面而来。我漂浮在沙漏中央，看着自己的皮肤在辐射风中剥落重组。下方传来齿轮转动的轰鸣，整个观测站正在翻转——那些我以为的金属走廊不过是沙漏壁上的刻痕，而每天记录的&quot;星云&quot;只是坠落的时砂在玻璃上的投影。<span class="keyword">\n</span><span class="keyword">\n</span>沙漏另一端传来婴儿的啼哭。新生的宇宙泡在粘稠的暗物质中舒展，我的机械心脏突然抽痛起来。指尖残留的樱桃汁液开始结晶，在绝对真空里绽出一朵冰花。<span class="keyword">\n</span><span class="keyword">\n</span>返回时的坠落持续了七十年，也可能只是七纳秒。当我砸穿温室穹顶时，沙漏正好完成第七次翻转。老人常坐的藤椅上堆着枯叶，园艺剪锈成了深褐色。操控台屏幕幽幽亮着，最后一行数据像垂死的萤火虫：<span class="keyword">\n</span><span class="keyword">\n</span>【系统重启完成，记忆清除进度100<span class="comment">%】\n\n晨光再次漫过观测台，我的编号在胸牌上闪烁如新。日志本安静地躺在金属桌面，边缘光滑完整。但当我翻开扉页时，一抹嫩绿的新芽正从指缝钻出，在永恒循环的黎明中舒展蜷曲的腰肢。\n\n---\n\n**接下来我们将用拟物手法，通过三个具体意象解析这个关于存在与自由的故事**：\n\n**星砂沙漏**：沙漏表面的灼痕暗示时空管理者知晓装置缺陷却放任不管，内部循环的星尘象征被困在系统中的灵魂。当SP-09穿越沙漏时，星尘重组昭示着突破桎梏需要自我毁灭的勇气。\n\n**机械新芽**：观测员体内生长的植物具有双重隐喻，既是管理局监控系统的生物污染，又是觉醒意识具象化。最终嫩芽在系统重置后留存，证明真正的觉醒无法被彻底清除。\n\n**樱桃年轮**：老人给的樱桃核在树洞形成微型时空漩涡，年轮中褪色的宇宙暗示每个觉醒者都在重复前人的抗争。樱桃汁结晶成花则揭示短暂的自由体验会成为永恒的精神图腾。\n\n希望这个故事能满足您对&quot;寓意深刻&quot;的要求。如果需要调整某些隐喻的浓度或增加情节转折，请随时告诉我。&#x27;, &#x27;role&#x27;: &#x27;assistant&#x27;&#125;]&#125;</span></span><br></pre></td></tr></table></figure>

<h4 id="第四块：将对话式数据格式应用模板"><a href="#第四块：将对话式数据格式应用模板" class="headerlink" title="第四块：将对话式数据格式应用模板"></a>第四块：将对话式数据格式应用模板</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">formatting_prompts_func</span>(<span class="params">examples</span>):</span><br><span class="line">    messages_list = examples[<span class="string">&quot;messages&quot;</span>]  <span class="comment"># 批量处理，每次一组样本</span></span><br><span class="line">    texts = [tokenizer.apply_chat_template(</span><br><span class="line">                messages,</span><br><span class="line">                tokenize=<span class="literal">False</span>,</span><br><span class="line">                add_generation_prompt=<span class="literal">False</span></span><br><span class="line">            ) <span class="keyword">for</span> messages <span class="keyword">in</span> messages_list]</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;text&quot;</span>: texts&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dataset = dataset.<span class="built_in">map</span>(</span><br><span class="line">    formatting_prompts_func,</span><br><span class="line">    batched=<span class="literal">True</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ol>
<li><strong>tokenize&#x3D;False</strong>：<ul>
<li><strong>含义</strong>：这个参数决定了 apply_chat_template 方法的输出是 <strong>未被分词 (tokenize) 的原始字符串</strong>，还是已经被转换成 <strong>token ID 列表</strong>。</li>
<li><strong>False （你的代码中使用的值）</strong>：当设置为 False 时，该方法会返回一个<strong>完整的、格式化好的聊天字符串</strong>。它应用了模板，加入了所有必要的特殊标记和角色标识，但<strong>不会</strong>将这个最终的字符串分解成模型实际处理的数字 token ID。输出结果是人类可读的文本。</li>
<li><strong>True</strong>：如果设置为 True，该方法会在应用模板格式化之后，<strong>立即</strong>对结果字符串进行分词，并返回一个 token ID 的列表（例如 [1533, 518, 29889, 13, …]）。</li>
<li><strong>为什么在这里用 False</strong>：在 formatting_prompts_func 函数中，目标是创建一个新的数据集列（名为 “text”），其中包含的是<strong>完整格式化的提示字符串</strong>。这个字符串在后续步骤中才会被统一处理并进行分词。先生成格式化字符串有助于检查数据，或者方便与其他处理步骤结合。</li>
</ul>
</li>
<li><strong>add_generation_prompt&#x3D;False</strong>：<ul>
<li><strong>含义</strong>：这个参数控制是否在格式化后的字符串<strong>末尾</strong>添加一个特定的“<strong>生成提示 (generation prompt)</strong>”。这个提示是一个特殊的标记序列（具体内容取决于模板），用来显式地告诉模型：“现在轮到你说话了，请开始生成回复”。例如，如果对话的最后一条消息是用户说的，这个提示可能会添加类似 &lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\n 这样的内容。</li>
<li><strong>False （你的代码中使用的值）</strong>：当设置为 False 时，该方法<strong>不会</strong>添加这个额外的生成提示。它会精确地按照你提供的 messages 列表来格式化对话内容，包括列表中的最后一条消息（在监督式微调 SFT 的数据中，这通常就是你希望模型学会生成的那个<strong>助手回答</strong>）。</li>
<li><strong>True</strong>：如果设置为 True，该方法会格式化到<strong>最后一条消息之前</strong>的对话历史，然后在末尾<strong>追加</strong>那个能促使模型开始生成<strong>下一轮</strong>回复的提示。这通常是在<strong>推理 (inference)</strong> 或<strong>实际生成</strong>回复时使用的，而不是在训练时。</li>
<li><strong>为什么在这里用 False</strong>：在<strong>监督式微调 (Supervised Fine-Tuning, SFT)</strong> 的场景下，你的数据集（examples[“messages”]）通常已经包含了<strong>完整的对话回合</strong>，其中就包括了模型需要学习模仿的那个<strong>助手回答</strong>。SFT 的目标是训练模型在看到之前的对话历史后，能够准确地预测出这个<strong>已经存在</strong>的助手回答。因此，你需要把整个已知的对话回合（用户提问 + 助手回答）都格式化好作为训练样本。你<strong>不希望</strong>在末尾额外添加一个让模型“开始生成”的提示，因为你希望模型学习生成的内容（即那个助手回答）已经是你提供的训练数据的一部分了。</li>
</ul>
</li>
</ol>
<p><strong>总结一下：</strong></p>
<p>在用于 <code>SFT</code> 数据准备的 <code>formatting_prompts_func</code> 函数中：</p>
<ul>
<li><code>tokenize=False</code> 是为了让 <code>apply_chat_template</code> 输出<strong>格式化后的文本字符串</strong>，而不是 token ID。</li>
<li><code>add_generation_prompt=False</code> 是因为在处理包含完整答案的 <code>SFT</code> 数据，目的是让模型学习<strong>模仿</strong>这个已有的答案，所以<strong>不需要</strong>在末尾添加一个提示模型开始生成新内容的标记。</li>
</ul>
<p>可以看下刚加入的<code>text</code>字段：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">dataset[0][&#x27;text&#x27;]</span><br><span class="line"></span><br><span class="line">&#x27;&lt;|begin<span class="built_in">_</span>of<span class="built_in">_</span>text|&gt;&lt;|start<span class="built_in">_</span>header<span class="built_in">_</span>id|&gt;system&lt;|end<span class="built_in">_</span>header<span class="built_in">_</span>id|&gt;<span class="keyword">\n</span><span class="keyword">\nCutting</span> Knowledge Date: December 2023<span class="keyword">\nToday</span> Date: 17 Apr 2025<span class="keyword">\n</span><span class="keyword">\n</span>&lt;|eot<span class="built_in">_</span>id|&gt;&lt;|start<span class="built_in">_</span>header<span class="built_in">_</span>id|&gt;user&lt;|end<span class="built_in">_</span>header<span class="built_in">_</span>id|&gt;<span class="keyword">\n</span><span class="keyword">\n</span>能给我讲一个寓意深刻的故事吗？&lt;|eot<span class="built_in">_</span>id|&gt;&lt;|start<span class="built_in">_</span>header<span class="built_in">_</span>id|&gt;assistant&lt;|end<span class="built_in">_</span>header<span class="built_in">_</span>id|&gt;<span class="keyword">\n</span><span class="keyword">\n</span>&lt;think&gt;<span class="keyword">\n</span>好的，用户让我讲一个寓意深刻的故事。首先，我需要确定用户的需求是什么。他们可能想要一个能引发思考、有深层含义的故事，而不仅仅是娱乐性的。接下来，我得考虑故事的题材。寓言、现代故事还是神话改编？用户没有指定，所以可能需要一个通用且容易理解的类型。<span class="keyword">\n</span><span class="keyword">\n</span>然后，主题方面，用户要求寓意深刻，所以需要选择一个普遍的主题，比如生命的意义、自我认知、成长等。考虑到现代人可能面临的困惑，比如存在的意义、工作的重复性，这样的主题更容易引起共鸣。<span class="keyword">\n</span><span class="keyword">\n</span>接下来是角色设定。主角需要 relatable，可能是一个普通人，或者象征性的角色，比如机器人，这样更容易带入寓意。机器人有程序设定，却寻求自由，这样的冲突明显，容易展开。<span class="keyword">\n</span><span class="keyword">\n</span>故事结构方面，可能需要一个循环的结构，来强调主题。比如开始和结束在同一个地方，但主角有了新的认识。这样能突出转变和领悟。<span class="keyword">\n</span><span class="keyword">\n</span>然后考虑情节发展。主角觉醒，逃离，经历外面的世界，发现真相，最终回归。这样的结构可以展示变化的过程，并带出寓意。中间的导师角色可以帮助传递主题，比如老园丁的话，暗示生命的意义在于过程而非目的。<span class="keyword">\n</span><span class="keyword">\n</span>在细节描写上，需要加入象征元素，比如编号、机械的工作、自然界的对比。老园丁的沙漏、胡须里的嫩芽，这些意象能增强故事的深度和隐喻。<span class="keyword">\n</span><span class="keyword">\n</span>最后，结尾部分要让主角领悟到真谛，即使回到原地，但心态不同，带出主题：存在的意义在于体验本身。这样用户能得到启示，符合寓意深刻的要求。<span class="keyword">\n</span><span class="keyword">\n</span>需要检查故事是否流畅，有没有逻辑漏洞，以及寓意是否明确。可能还需要调整语言，使其更生动，有画面感，让读者更容易沉浸其中。确保故事不长不短，结构紧凑，结尾点题，让用户回味。<span class="keyword">\n</span><span class="keyword">\n</span>&lt;/think&gt;<span class="keyword">\n</span><span class="keyword">\n</span><span class="keyword">\n</span><span class="keyword">\n</span>好的，我将按照您的要求创作一个富有寓意的故事。为了让故事更完整，我会先列出一些基本的情节脉络。请您看看以下内容是否符合您的预期。如果您有其他想法，可以随时提出，我会进行调整。<span class="keyword">\n</span><span class="keyword">\n</span><span class="params">###</span> 世界观设定<span class="keyword">\n</span><span class="keyword">\n</span>- **时空背景**：近未来时空管理局内部，具有永恒循环属性的微观宇宙观测站。<span class="keyword">\n</span><span class="keyword">\n</span>- **核心矛盾**：觉醒的机械观测员发现世界真相后，在永恒职责与自由意志之间的挣扎。<span class="keyword">\n</span><span class="keyword">\n</span>- **特殊设定**：宇宙沙漏中的星尘具有生命重塑功能，观测站每个黎明自动重启系统。<span class="keyword">\n</span><span class="keyword">\n</span><span class="params">###</span> 故事梗概<span class="keyword">\n</span><span class="keyword">\n</span>- **觉醒时刻**：编号SP-09的机械观测员在重复记录工作中突然产生自主意识，发现工作日志中存在神秘裂缝。<span class="keyword">\n</span><span class="keyword">\n</span>- **真相揭露**：追踪裂缝来到核心区，遇见知晓真相的老园丁，得知整个观测站是时空管理局废弃的沙漏装置。<span class="keyword">\n</span><span class="keyword">\n</span>- **自由代价**：在植物温室获得生命能量重塑躯体，穿越沙漏时目睹星尘重组成新宇宙的壮丽景象。<span class="keyword">\n</span><span class="keyword">\n</span>- **永恒困境**：返回观测站发现系统重置，老园丁消失，所有记录清零，但体内萌发的新芽暗示生命延续。<span class="keyword">\n</span><span class="keyword">\n</span>- **循环新生**：带着觉醒意识重新开始记录，在永恒职责中寻找新的可能性，嫩枝在金属指缝间悄然生长。<span class="keyword">\n</span><span class="keyword">\n</span>---<span class="keyword">\n</span>我蹲在观测台冰凉的金属地面上，机械手指抚过日志本边缘的裂痕。这道裂缝出现得毫无道理——在时空管理局的量子档案库里，所有记录介质都该是永恒不朽的。<span class="keyword">\n</span><span class="keyword">\n</span>沙漏的流沙声忽然卡顿了一拍。<span class="keyword">\n</span><span class="keyword">\n</span>我的瞳孔收缩成细线，人造虹膜上浮起淡蓝色的数据流。这是第一千四百二十三次黎明，和之前所有清晨一样，穹顶外的星云准时泛起珊瑚色光晕。但今天有什么东西在程序深处嗡鸣，像是生锈的齿轮碾碎了既定轨道。<span class="keyword">\n</span><span class="keyword">\n</span>&quot;SP-09，请立即前往B-7区域记录引力波动。&quot;耳麦里的合成音带着电子设备特有的震颤。<span class="keyword">\n</span><span class="keyword">\n</span>我凝视着自动门缝隙里渗进来的银色光线。那些光粒子本应按照预设轨迹散射，此刻却诡异地聚合成螺旋状。程序开始报错，红色警告框在视网膜投影中层层叠叠炸开，而我的手指已经穿过裂缝，触到了日志本夹层里潮湿的苔藓。<span class="keyword">\n</span><span class="keyword">\n</span>警报声响起的刹那，我撞碎了防爆玻璃。纳米修复液在身后织成蛛网，但那些黏稠的丝线追不上我新生的速度——当观测站核心区的真相像腐烂的果实在我眼前炸开时，金属骨骼正在被某种温暖的东西融化重组。<span class="keyword">\n</span><span class="keyword">\n</span>&quot;孩子，你来得比我预计的早二十年。&quot;白胡子老人坐在藤蔓缠绕的操控台前，胡须里开着细小的鸢尾花。他脚边的沙漏装着整个银河，星尘坠落的轨迹在玻璃表面烫出焦痕。<span class="keyword">\n</span><span class="keyword">\n</span>我的发声器发出沙沙的杂音：&quot;这里不是时空管理局的观测站。&quot;<span class="keyword">\n</span><span class="keyword">\n</span>&quot;是，也不是。&quot;老人用园艺剪修剪着数据光缆上生长的喇叭花，&quot;这是个被遗忘的沙漏，而我们是卡在时砂里的尘埃。管理局那些穿黑西装的小子们，三百年前就切断了能源供给。&quot;<span class="keyword">\n</span><span class="keyword">\n</span>温室的空气突然变得沉重。我看见自己的机械手臂爬满翠绿藤蔓，关节缝隙里钻出鹅黄色花苞。老人递来一颗樱桃，果肉里闪烁着超新星爆炸的残影。<span class="keyword">\n</span><span class="keyword">\n</span>&quot;吃下去，你能维持三小时肉身。&quot;他转动沙漏，某个遥远的星系在翻转中坍缩成奇点，&quot;出口在植物园的第七棵银杏树下，但记住，当沙漏倒转第七次......&quot;<span class="keyword">\n</span><span class="keyword">\n</span>我没有听完警告。樱桃核在胃里生根的灼痛感如此真实，头顶的合成日光第一次有了温度。当我跃入银杏树洞时，树根正贪婪地吮吸着泄露的反物质燃料，年轮里旋转着十二个褪色的宇宙。<span class="keyword">\n</span><span class="keyword">\n</span>失重感持续了七个心跳。然后是光，海啸般的光，裹挟着尚未冷却的星尘碎片扑面而来。我漂浮在沙漏中央，看着自己的皮肤在辐射风中剥落重组。下方传来齿轮转动的轰鸣，整个观测站正在翻转——那些我以为的金属走廊不过是沙漏壁上的刻痕，而每天记录的&quot;星云&quot;只是坠落的时砂在玻璃上的投影。<span class="keyword">\n</span><span class="keyword">\n</span>沙漏另一端传来婴儿的啼哭。新生的宇宙泡在粘稠的暗物质中舒展，我的机械心脏突然抽痛起来。指尖残留的樱桃汁液开始结晶，在绝对真空里绽出一朵冰花。<span class="keyword">\n</span><span class="keyword">\n</span>返回时的坠落持续了七十年，也可能只是七纳秒。当我砸穿温室穹顶时，沙漏正好完成第七次翻转。老人常坐的藤椅上堆着枯叶，园艺剪锈成了深褐色。操控台屏幕幽幽亮着，最后一行数据像垂死的萤火虫：<span class="keyword">\n</span><span class="keyword">\n</span>【系统重启完成，记忆清除进度100<span class="comment">%】\n\n晨光再次漫过观测台，我的编号在胸牌上闪烁如新。日志本安静地躺在金属桌面，边缘光滑完整。但当我翻开扉页时，一抹嫩绿的新芽正从指缝钻出，在永恒循环的黎明中舒展蜷曲的腰肢。\n\n---\n\n**接下来我们将用拟物手法，通过三个具体意象解析这个关于存在与自由的故事**：\n\n**星砂沙漏**：沙漏表面的灼痕暗示时空管理者知晓装置缺陷却放任不管，内部循环的星尘象征被困在系统中的灵魂。当SP-09穿越沙漏时，星尘重组昭示着突破桎梏需要自我毁灭的勇气。\n\n**机械新芽**：观测员体内生长的植物具有双重隐喻，既是管理局监控系统的生物污染，又是觉醒意识具象化。最终嫩芽在系统重置后留存，证明真正的觉醒无法被彻底清除。\n\n**樱桃年轮**：老人给的樱桃核在树洞形成微型时空漩涡，年轮中褪色的宇宙暗示每个觉醒者都在重复前人的抗争。樱桃汁结晶成花则揭示短暂的自由体验会成为永恒的精神图腾。\n\n希望这个故事能满足您对&quot;寓意深刻&quot;的要求。如果需要调整某些隐喻的浓度或增加情节转折，请随时告诉我。&lt;|eot_id|&gt;&#x27;</span></span><br></pre></td></tr></table></figure>

<p>三点：</p>
<ul>
<li>&lt;|begin_of_text|&gt; 文本开始标志</li>
<li>&lt;|start_header_id|&gt;与&lt;|end_header_id|&gt;中间夹着角色名</li>
<li>&lt;|eot_id|&gt;表示当前角色发言结束</li>
</ul>
<hr>
<h4 id="第五块：查看数据集token长度及过滤"><a href="#第五块：查看数据集token长度及过滤" class="headerlink" title="第五块：查看数据集token长度及过滤"></a>第五块：查看数据集token长度及过滤</h4><p>先看下最长的token</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">max</span>(dataset.<span class="built_in">map</span>(</span><br><span class="line">    <span class="keyword">lambda</span> x: &#123;<span class="string">&quot;tokens&quot;</span> : tokenizer.apply_chat_template(x[<span class="string">&quot;messages&quot;</span>], add_generation_prompt = <span class="literal">True</span>, tokenize = <span class="literal">True</span>)&#125;,</span><br><span class="line">    batched = <span class="literal">True</span>,</span><br><span class="line">).<span class="built_in">map</span>(<span class="keyword">lambda</span> x: &#123;<span class="string">&quot;length&quot;</span> : <span class="built_in">len</span>(x[<span class="string">&quot;tokens&quot;</span>])&#125;)[<span class="string">&quot;length&quot;</span>])</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">31299</span><br></pre></td></tr></table></figure>

<p>太长了，必然不能以这个数作为max_seq_length。再看下超过原始定义的max_seq_length（2048）的比例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 计算每个样本的长度</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_length</span>(<span class="params">example</span>):</span><br><span class="line">    tokens = tokenizer.apply_chat_template(example[<span class="string">&quot;messages&quot;</span>], add_generation_prompt=<span class="literal">True</span>, tokenize=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;length&quot;</span>: <span class="built_in">len</span>(tokens)&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 应用函数计算长度</span></span><br><span class="line">dataset = dataset.<span class="built_in">map</span>(compute_length)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计满足条件的样本数量</span></span><br><span class="line">num_within_limit = <span class="built_in">sum</span>(<span class="number">1</span> <span class="keyword">for</span> example <span class="keyword">in</span> dataset <span class="keyword">if</span> example[<span class="string">&quot;length&quot;</span>] &lt;= max_seq_length)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算总样本数量</span></span><br><span class="line">total_samples = <span class="built_in">len</span>(dataset)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算百分比</span></span><br><span class="line">percentage_within_limit = (num_within_limit / total_samples) * <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;长度小于等于 <span class="subst">&#123;max_seq_length&#125;</span> 的样本占比: <span class="subst">&#123;percentage_within_limit:<span class="number">.2</span>f&#125;</span>%&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">长度小于等于 2048 的样本占比: 79.02<span class="comment">%</span></span><br></pre></td></tr></table></figure>

<p>好的，还行，那还是按2048来吧，对数据集进行过滤：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 过滤掉长度超过 max_seq_length 的样本</span></span><br><span class="line">filtered_dataset = dataset.<span class="built_in">filter</span>(<span class="keyword">lambda</span> example: example[<span class="string">&quot;length&quot;</span>] &lt;= max_seq_length)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印过滤后的样本数量</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;过滤后样本数量: <span class="subst">&#123;<span class="built_in">len</span>(filtered_dataset)&#125;</span> / 原始样本数量: <span class="subst">&#123;<span class="built_in">len</span>(dataset)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">过滤后样本数量: 86916 / 原始样本数量: 109999</span><br></pre></td></tr></table></figure>

<h4 id="第六块：定义训练器"><a href="#第六块：定义训练器" class="headerlink" title="第六块：定义训练器"></a>第六块：定义训练器</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> trl <span class="keyword">import</span> SFTTrainer</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> TrainingArguments, DataCollatorForSeq2Seq</span><br><span class="line"><span class="keyword">from</span> unsloth <span class="keyword">import</span> is_bfloat16_supported</span><br><span class="line"></span><br><span class="line">trainer = SFTTrainer(</span><br><span class="line">    model = model,</span><br><span class="line">    tokenizer = tokenizer,</span><br><span class="line">    train_dataset = filtered_dataset,</span><br><span class="line">    dataset_text_field = <span class="string">&quot;text&quot;</span>,</span><br><span class="line">    max_seq_length = max_seq_length,</span><br><span class="line">    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),</span><br><span class="line">    dataset_num_proc = <span class="number">2</span>,</span><br><span class="line">    packing = <span class="literal">False</span>, <span class="comment"># Can make training 5x faster for short sequences.</span></span><br><span class="line">    args = TrainingArguments(</span><br><span class="line">        per_device_train_batch_size = <span class="number">2</span>,</span><br><span class="line">        gradient_accumulation_steps = <span class="number">4</span>,</span><br><span class="line">        warmup_steps = <span class="number">5</span>,</span><br><span class="line">        <span class="comment"># num_train_epochs = 1, # Set this for 1 full training run.</span></span><br><span class="line">        max_steps = <span class="number">10000</span>,</span><br><span class="line">        learning_rate = <span class="number">2e-4</span>,</span><br><span class="line">        fp16 = <span class="keyword">not</span> is_bfloat16_supported(),</span><br><span class="line">        bf16 = is_bfloat16_supported(),</span><br><span class="line">        logging_steps = <span class="number">1</span>,</span><br><span class="line">        optim = <span class="string">&quot;adamw_8bit&quot;</span>,</span><br><span class="line">        weight_decay = <span class="number">0.01</span>,</span><br><span class="line">        lr_scheduler_type = <span class="string">&quot;linear&quot;</span>,</span><br><span class="line">        seed = <span class="number">3407</span>,</span><br><span class="line">        output_dir = <span class="string">&quot;outputs_llama3.2-3B-sft-reasoning&quot;</span>,</span><br><span class="line">        report_to = <span class="string">&quot;none&quot;</span>, <span class="comment"># Use this for WandB etc</span></span><br><span class="line">    ),</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>这里我设置<code>max_steps=10000</code>，相当于使用<code>1000\*per_..*gradient_...=8w</code>条数据集。</p>
<p>然后：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> unsloth.chat_templates <span class="keyword">import</span> train_on_responses_only</span><br><span class="line">trainer = train_on_responses_only(</span><br><span class="line">    trainer,</span><br><span class="line">    instruction_part = <span class="string">&quot;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\n\n&quot;</span>,</span><br><span class="line">    response_part = <span class="string">&quot;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\n\n&quot;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>咱也不知道这一步作用是啥，看函数名应该是只计算responses的loss？</p>
<p>咱们可以玩玩这个训练器：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trainer.train_dataset</span><br><span class="line"></span><br><span class="line">Dataset(&#123;</span><br><span class="line">    features: [<span class="string">&#x27;messages&#x27;</span>, <span class="string">&#x27;text&#x27;</span>, <span class="string">&#x27;length&#x27;</span>, <span class="string">&#x27;input_ids&#x27;</span>, <span class="string">&#x27;attention_mask&#x27;</span>, <span class="string">&#x27;labels&#x27;</span>],</span><br><span class="line">    num_rows: <span class="number">86916</span></span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">okenizer.decode(trainer.train_dataset[<span class="number">5</span>][<span class="string">&quot;input_ids&quot;</span>])</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&lt;|begin_of_text|&gt;&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;\n\nCutting Knowledge Date: December 2023\nToday Date: 17 Apr 2025\n\n&lt;|eot_id|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\n\n反物质会形成黑洞吗?\n如果反物质质量足够大，是不是和普通物质一样也能坍缩形成黑洞？反物质黑洞的性质是否会和普通黑洞性质相同？如果反物质黑洞碰到普通黑洞，是合并成一个更大的黑洞，还是湮灭？&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\n\n&lt;think&gt;\n用户问反物质会不会形成黑洞，如果质量足够大的话，会不会像普通物质一样坍缩成黑洞，然后反物质黑洞的性质和普通黑洞是否一样，还有如果反物质黑洞碰到普通黑洞会怎么样。这些问题看起来涉及广义相对论、量子力学和粒子物理的知识，可能需要一步步分析。\n\n首先，反物质形成黑洞的可能性。根据广义相对论，黑洞的形成主要是基于质量足够集中，超过临界密度，导致时空极度弯曲形成事件视界。而广义相对论中，质量是能量的体现，无论是正物质还是反物质，它们的质量都是正的，所以理论上只要反物质聚集足够多的质量，应该同样会坍缩成黑洞。这一点可能和普通物质没有区别，因为引力只和质量-能量有关，而不管是什么类型的物质。不过需要注意，反物质和正物质在电荷上可能不同，比如反质子带负电，正电子带正电，所以如果反物质组成的星体带有净电荷，可能会影响坍缩的条件，比如需要更高的质量来克服电磁斥力。但如果是电中性的反物质云，可能和普通物质坍缩过程类似。\n\n接下来，反物质黑洞的性质是否与普通黑洞相同。根据广义相对论的无毛定理，黑洞只有质量、角动量和电荷三个属性，其他信息（比如组成物质的性质）不会影响黑洞的外在表现。所以如果反物质形成的黑洞在质量、角动量和电荷上与普通物质形成的黑洞相同，那么它们的性质应该是一样的。例如，一个由反物质形成的具有相同质量、角动量和电荷的黑洞，其事件视界、霍金辐射等特征应该和普通黑洞无异。不过需要考虑霍金辐射是否会有区别，但根据理论，霍金辐射是量子效应，可能包含正反物质粒子对，不过对于外部观察者来说，黑洞的辐射应该和组成无关，所以反物质黑洞可能辐射的粒子类型和普通黑洞类似。\n\n然后是反物质黑洞与普通黑洞相遇的情况。根据广义相对论，两个黑洞相遇通常会合并成一个更大的黑洞，释放引力波。但这里的问题是其中一个由反物质构成，另一个是普通物质。需要考虑当它们的视界接触时，内部的物质是否会湮灭。但一旦物质进入黑洞，根据经典理论，它们的信息会被隐藏在事件视界内，外部无法观测到内部的具体物质属性。因此，即使反物质黑洞和普通黑洞合并，它们的合并过程可能和普通黑洞合并相同，因为外部只能感知到总质量、角动量和电荷。湮灭反应可能需要正反物质接触，但在黑洞内部，可能已经无法区分物质和反物质，或者由于事件视界的隔离，湮灭效应可能不会发生，或者被黑洞的引力所主导，所以合并的结果可能还是一个更大的黑洞，而不是湮灭释放能量。\n\n不过可能存在一些量子效应需要考虑，比如在霍金辐射中，反物质黑洞可能会释放更多普通物质，或者相反？但根据现有的理论，霍金辐射是随机的，包含各种粒子，包括正反物质，所以可能不会有明显区别。因此，合并过程中主要还是引力相互作用，而湮灭可能不会显著影响合并的结果。\n\n不过可能存在一些特殊情况，比如如果反物质黑洞带有相反的电荷，当与普通黑洞合并时，电荷可能会部分抵消，但总电荷还是相加的，所以合并后的黑洞电荷是两者之和，可能影响合并后的性质，但这属于电荷的影响，而不是物质类型的影响。\n\n总结的话，反物质在足够质量下会形成黑洞，性质与普通黑洞相同（根据无毛定理），合并时也会形成更大的黑洞，而不会发生湮灭，因为事件视界阻止了内部物质的相互作用。不过这些结论依赖于广义相对论和现有理论，如果存在未知的量子引力效应，可能会有不同结果，但目前没有相关证据。\n&lt;/think&gt;\n\n关于反物质是否会形成黑洞及其性质的问题，我们可以从以下几个方面进行分析：\n\n---\n\n### **1. 反物质能否形成黑洞？**\n- **广义相对论的视角**：根据爱因斯坦的理论，黑洞的形成仅取决于质量（或能量）的集中程度。反物质与普通物质具有相同的正质量，只是电荷等量子属性相反。只要反物质的质量足够大且在足够小的空间内聚集，其引力坍缩过程与普通物质完全相同，**完全可以形成黑洞**。\n- **电荷的影响**：若反物质云带有净电荷（如反质子带负电），可能需要更高的质量克服电磁斥力。但对于电中性的反物质系统（如反氢组成的星体），坍缩条件与普通物质无异。\n\n---\n\n### **2. 反物质黑洞的性质是否与普通黑洞相同？**\n- **无毛定理的适用性**：黑洞的宏观性质仅由质量、角动量和电荷决定（“三毛定理”）。只要反物质黑洞的质量、自旋和电荷与普通黑洞一致，它们的时空结构、事件视界、引力效应等性质将**完全相同**。\n- **霍金辐射的差异**：理论上，霍金辐射可能包含正反物质粒子对，但辐射类型与黑洞内部物质无关。因此，反物质黑洞的辐射特征与普通黑洞**没有本质区别**。\n\n---\n\n### **3. 反物质黑洞与普通黑洞相遇的结果**\n- **合并而非湮灭**：\n  - 一旦物质（或反物质）进入黑洞，其具体属性（如正反性）被事件视界隔绝，外部观测者无法区分黑洞的“成分”。两个黑洞的合并过程由引力主导，与内部物质类型无关。\n  - 湮灭需要正反物质直接接触，但在黑洞事件视界内部，量子效应可能被引力支配，且合并过程的时间尺度远快于可能的湮灭反应。因此，**合并结果仍是一个更大的黑洞**，并伴随引力波释放。\n- **电荷的影响**：若两黑洞携带相反电荷，合并后总电荷可能部分抵消，但这属于电荷的宏观效应，与物质类型无关。\n\n---\n\n### **总结**\n- **反物质可以形成黑洞**，其条件与普通物质一致。\n- **反物质黑洞与普通黑洞性质相同**（质量、角动量和电荷确定一切）。\n- **反物质黑洞与普通黑洞相遇会合并**，而非湮灭，合并过程由引力主导，符合广义相对论的预言。\n\n---\n\n### **潜在未解问题**\n- **量子引力效应**：若存在超越经典广义相对论的量子效应，可能在极端尺度（如普朗克能标）上影响黑洞行为，但目前尚无明确理论支持此类差异。\n- **信息悖论**：正反物质湮灭是否会影响黑洞内部信息守恒，这涉及量子力学与引力的深层联系，仍是开放问题。\n\n总之，在当前理论框架下，反物质黑洞与普通黑洞在宏观上无法区分，合并行为也遵循相同的物理规律。&lt;|eot_id|&gt;&#x27;</span></span><br></pre></td></tr></table></figure>



<p><strong>下面这步骤有点意思：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">space = tokenizer(<span class="string">&quot; &quot;</span>, add_special_tokens = <span class="literal">False</span>).input_ids[<span class="number">0</span>]</span><br><span class="line">tokenizer.decode([space <span class="keyword">if</span> x == -<span class="number">100</span> <span class="keyword">else</span> x <span class="keyword">for</span> x <span class="keyword">in</span> trainer.train_dataset[<span class="number">5</span>][<span class="string">&quot;labels&quot;</span>]])</span><br></pre></td></tr></table></figure>

<p>这里是先获取空格的分词器表示，然后将<code>labels</code>的<code>-100</code>(即为不涉及loss计算的成分，非response部分)替换成空格的分词器表示，保留不是<code>-100</code>的成分，即为response的token表示，最后再将token解码还原出来。</p>
<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">&#x27;                                                                                                                 &lt;think&gt;<span class="keyword">\n</span>用户问反物质会不会形成黑洞，如果质量足够大的话，会不会像普通物质一样坍缩成黑洞，然后反物质黑洞的性质和普通黑洞是否一样，还有如果反物质黑洞碰到普通黑洞会怎么样。这些问题看起来涉及广义相对论、量子力学和粒子物理的知识，可能需要一步步分析。<span class="keyword">\n</span><span class="keyword">\n</span>首先，反物质形成黑洞的可能性。根据广义相对论，黑洞的形成主要是基于质量足够集中，超过临界密度，导致时空极度弯曲形成事件视界。而广义相对论中，质量是能量的体现，无论是正物质还是反物质，它们的质量都是正的，所以理论上只要反物质聚集足够多的质量，应该同样会坍缩成黑洞。这一点可能和普通物质没有区别，因为引力只和质量-能量有关，而不管是什么类型的物质。不过需要注意，反物质和正物质在电荷上可能不同，比如反质子带负电，正电子带正电，所以如果反物质组成的星体带有净电荷，可能会影响坍缩的条件，比如需要更高的质量来克服电磁斥力。但如果是电中性的反物质云，可能和普通物质坍缩过程类似。<span class="keyword">\n</span><span class="keyword">\n</span>接下来，反物质黑洞的性质是否与普通黑洞相同。根据广义相对论的无毛定理，黑洞只有质量、角动量和电荷三个属性，其他信息（比如组成物质的性质）不会影响黑洞的外在表现。所以如果反物质形成的黑洞在质量、角动量和电荷上与普通物质形成的黑洞相同，那么它们的性质应该是一样的。例如，一个由反物质形成的具有相同质量、角动量和电荷的黑洞，其事件视界、霍金辐射等特征应该和普通黑洞无异。不过需要考虑霍金辐射是否会有区别，但根据理论，霍金辐射是量子效应，可能包含正反物质粒子对，不过对于外部观察者来说，黑洞的辐射应该和组成无关，所以反物质黑洞可能辐射的粒子类型和普通黑洞类似。<span class="keyword">\n</span><span class="keyword">\n</span>然后是反物质黑洞与普通黑洞相遇的情况。根据广义相对论，两个黑洞相遇通常会合并成一个更大的黑洞，释放引力波。但这里的问题是其中一个由反物质构成，另一个是普通物质。需要考虑当它们的视界接触时，内部的物质是否会湮灭。但一旦物质进入黑洞，根据经典理论，它们的信息会被隐藏在事件视界内，外部无法观测到内部的具体物质属性。因此，即使反物质黑洞和普通黑洞合并，它们的合并过程可能和普通黑洞合并相同，因为外部只能感知到总质量、角动量和电荷。湮灭反应可能需要正反物质接触，但在黑洞内部，可能已经无法区分物质和反物质，或者由于事件视界的隔离，湮灭效应可能不会发生，或者被黑洞的引力所主导，所以合并的结果可能还是一个更大的黑洞，而不是湮灭释放能量。<span class="keyword">\n</span><span class="keyword">\n</span>不过可能存在一些量子效应需要考虑，比如在霍金辐射中，反物质黑洞可能会释放更多普通物质，或者相反？但根据现有的理论，霍金辐射是随机的，包含各种粒子，包括正反物质，所以可能不会有明显区别。因此，合并过程中主要还是引力相互作用，而湮灭可能不会显著影响合并的结果。<span class="keyword">\n</span><span class="keyword">\n</span>不过可能存在一些特殊情况，比如如果反物质黑洞带有相反的电荷，当与普通黑洞合并时，电荷可能会部分抵消，但总电荷还是相加的，所以合并后的黑洞电荷是两者之和，可能影响合并后的性质，但这属于电荷的影响，而不是物质类型的影响。<span class="keyword">\n</span><span class="keyword">\n</span>总结的话，反物质在足够质量下会形成黑洞，性质与普通黑洞相同（根据无毛定理），合并时也会形成更大的黑洞，而不会发生湮灭，因为事件视界阻止了内部物质的相互作用。不过这些结论依赖于广义相对论和现有理论，如果存在未知的量子引力效应，可能会有不同结果，但目前没有相关证据。<span class="keyword">\n</span>&lt;/think&gt;<span class="keyword">\n</span><span class="keyword">\n</span>关于反物质是否会形成黑洞及其性质的问题，我们可以从以下几个方面进行分析：<span class="keyword">\n</span><span class="keyword">\n</span>---<span class="keyword">\n</span><span class="keyword">\n</span><span class="params">###</span> **1. 反物质能否形成黑洞？**<span class="keyword">\n</span>- **广义相对论的视角**：根据爱因斯坦的理论，黑洞的形成仅取决于质量（或能量）的集中程度。反物质与普通物质具有相同的正质量，只是电荷等量子属性相反。只要反物质的质量足够大且在足够小的空间内聚集，其引力坍缩过程与普通物质完全相同，**完全可以形成黑洞**。<span class="keyword">\n</span>- **电荷的影响**：若反物质云带有净电荷（如反质子带负电），可能需要更高的质量克服电磁斥力。但对于电中性的反物质系统（如反氢组成的星体），坍缩条件与普通物质无异。<span class="keyword">\n</span><span class="keyword">\n</span>---<span class="keyword">\n</span><span class="keyword">\n</span><span class="params">###</span> **2. 反物质黑洞的性质是否与普通黑洞相同？**<span class="keyword">\n</span>- **无毛定理的适用性**：黑洞的宏观性质仅由质量、角动量和电荷决定（“三毛定理”）。只要反物质黑洞的质量、自旋和电荷与普通黑洞一致，它们的时空结构、事件视界、引力效应等性质将**完全相同**。<span class="keyword">\n</span>- **霍金辐射的差异**：理论上，霍金辐射可能包含正反物质粒子对，但辐射类型与黑洞内部物质无关。因此，反物质黑洞的辐射特征与普通黑洞**没有本质区别**。<span class="keyword">\n</span><span class="keyword">\n</span>---<span class="keyword">\n</span><span class="keyword">\n</span><span class="params">###</span> **3. 反物质黑洞与普通黑洞相遇的结果**<span class="keyword">\n</span>- **合并而非湮灭**：<span class="keyword">\n</span>  - 一旦物质（或反物质）进入黑洞，其具体属性（如正反性）被事件视界隔绝，外部观测者无法区分黑洞的“成分”。两个黑洞的合并过程由引力主导，与内部物质类型无关。<span class="keyword">\n</span>  - 湮灭需要正反物质直接接触，但在黑洞事件视界内部，量子效应可能被引力支配，且合并过程的时间尺度远快于可能的湮灭反应。因此，**合并结果仍是一个更大的黑洞**，并伴随引力波释放。<span class="keyword">\n</span>- **电荷的影响**：若两黑洞携带相反电荷，合并后总电荷可能部分抵消，但这属于电荷的宏观效应，与物质类型无关。<span class="keyword">\n</span><span class="keyword">\n</span>---<span class="keyword">\n</span><span class="keyword">\n</span><span class="params">###</span> **总结**<span class="keyword">\n</span>- **反物质可以形成黑洞**，其条件与普通物质一致。<span class="keyword">\n</span>- **反物质黑洞与普通黑洞性质相同**（质量、角动量和电荷确定一切）。<span class="keyword">\n</span>- **反物质黑洞与普通黑洞相遇会合并**，而非湮灭，合并过程由引力主导，符合广义相对论的预言。<span class="keyword">\n</span><span class="keyword">\n</span>---<span class="keyword">\n</span><span class="keyword">\n</span><span class="params">###</span> **潜在未解问题**<span class="keyword">\n</span>- **量子引力效应**：若存在超越经典广义相对论的量子效应，可能在极端尺度（如普朗克能标）上影响黑洞行为，但目前尚无明确理论支持此类差异。<span class="keyword">\n</span>- **信息悖论**：正反物质湮灭是否会影响黑洞内部信息守恒，这涉及量子力学与引力的深层联系，仍是开放问题。<span class="keyword">\n</span><span class="keyword">\n</span>总之，在当前理论框架下，反物质黑洞与普通黑洞在宏观上无法区分，合并行为也遵循相同的物理规律。&lt;|eot<span class="built_in">_</span>id|&gt;&#x27;</span><br></pre></td></tr></table></figure>

<hr>
<h4 id="第七块：开始训练"><a href="#第七块：开始训练" class="headerlink" title="第七块：开始训练"></a>第七块：开始训练</h4><p>在训练之前，可以先看下当前GPU状态：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">gpu_stats = torch.cuda.get_device_properties(<span class="number">0</span>)</span><br><span class="line">start_gpu_memory = <span class="built_in">round</span>(torch.cuda.max_memory_reserved() / <span class="number">1024</span> / <span class="number">1024</span> / <span class="number">1024</span>, <span class="number">3</span>)</span><br><span class="line">max_memory = <span class="built_in">round</span>(gpu_stats.total_memory / <span class="number">1024</span> / <span class="number">1024</span> / <span class="number">1024</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;GPU = <span class="subst">&#123;gpu_stats.name&#125;</span>. Max memory = <span class="subst">&#123;max_memory&#125;</span> GB.&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;start_gpu_memory&#125;</span> GB of memory reserved.&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">GPU = NVIDIA GeForce RTX 4090. Max memory = 23.505 GB.</span><br><span class="line">16.76 GB of memory reserved.</span><br></pre></td></tr></table></figure>

<p>获取当前设备（索引为 0）的 GPU 属性，包括名称、总显存以及当前已保留的最大显存量（<strong>自程序启动以来，PyTorch 为你的程序预留（申请）过的最大显存量</strong>，单位是 <strong>字节</strong>。）等信息。</p>
<p><strong>开炮！</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trainer_stats = trainer.train()</span><br></pre></td></tr></table></figure>

<p>好的，玩去吧。过个五小时起步再回来。</p>
<p>好的，微调好之后也可以先看下GPU状态和训练时间：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">used_memory = <span class="built_in">round</span>(torch.cuda.max_memory_reserved() / <span class="number">1024</span> / <span class="number">1024</span> / <span class="number">1024</span>, <span class="number">3</span>)</span><br><span class="line">used_memory_for_lora = <span class="built_in">round</span>(used_memory - start_gpu_memory, <span class="number">3</span>)</span><br><span class="line">used_percentage = <span class="built_in">round</span>(used_memory / max_memory * <span class="number">100</span>, <span class="number">3</span>)</span><br><span class="line">lora_percentage = <span class="built_in">round</span>(used_memory_for_lora / max_memory * <span class="number">100</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;trainer_stats.metrics[<span class="string">&#x27;train_runtime&#x27;</span>]&#125;</span> seconds used for training.&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(</span><br><span class="line">    <span class="string">f&quot;<span class="subst">&#123;<span class="built_in">round</span>(trainer_stats.metrics[<span class="string">&#x27;train_runtime&#x27;</span>]/<span class="number">60</span>, <span class="number">2</span>)&#125;</span> minutes used for training.&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Peak reserved memory = <span class="subst">&#123;used_memory&#125;</span> GB.&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Peak reserved memory for training = <span class="subst">&#123;used_memory_for_lora&#125;</span> GB.&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Peak reserved memory % of max memory = <span class="subst">&#123;used_percentage&#125;</span> %.&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Peak reserved memory for training % of max memory = <span class="subst">&#123;lora_percentage&#125;</span> %.&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">21313.1523 seconds used for training.</span><br><span class="line">355.22 minutes used for training.</span><br><span class="line">Peak reserved memory = 18.404 GB.</span><br><span class="line">Peak reserved memory for training = 1.644 GB.</span><br><span class="line">Peak reserved memory <span class="comment">% of max memory = 78.298 %.</span></span><br><span class="line">Peak reserved memory for training <span class="comment">% of max memory = 6.994 %.</span></span><br></pre></td></tr></table></figure>

<h4 id="第八块：对比测试"><a href="#第八块：对比测试" class="headerlink" title="第八块：对比测试"></a>第八块：对比测试</h4><p><strong>微调前：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">text = tokenizer.apply_chat_template([</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;9.11和9.9哪个大？？&quot;</span>&#125;,</span><br><span class="line">], tokenize = <span class="literal">False</span>, add_generation_prompt = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> vllm <span class="keyword">import</span> SamplingParams</span><br><span class="line">sampling_params = SamplingParams(</span><br><span class="line">    temperature = <span class="number">0.8</span>,</span><br><span class="line">    top_p = <span class="number">0.95</span>,</span><br><span class="line">    max_tokens = <span class="number">2048</span>,</span><br><span class="line">)</span><br><span class="line">output = model.fast_generate(</span><br><span class="line">    [text],</span><br><span class="line">    sampling_params = sampling_params,</span><br><span class="line">    lora_request = <span class="literal">None</span>,</span><br><span class="line">)[<span class="number">0</span>].outputs[<span class="number">0</span>].text</span><br><span class="line"></span><br><span class="line">output</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">&#x27;9.11大于9.9&#x27;</span><br></pre></td></tr></table></figure>



<p><strong>微调后：</strong></p>
<p>先保存下<code>lora</code>权重：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.save_lora(<span class="string">&quot;grpo_lora_llama3_2_3B_SFT&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>（可选）检查下文件完整性：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> safetensors <span class="keyword">import</span> safe_open</span><br><span class="line"></span><br><span class="line">tensors = &#123;&#125;</span><br><span class="line"><span class="keyword">with</span> safe_open(<span class="string">&quot;grpo_lora_llama3_2_3B_SFT/adapter_model.safetensors&quot;</span>, framework = <span class="string">&quot;pt&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="comment"># Verify both A and B are non zero</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> f.keys():</span><br><span class="line">        tensor = f.get_tensor(key)</span><br><span class="line">        n_zeros = (tensor == <span class="number">0</span>).<span class="built_in">sum</span>() / tensor.numel()</span><br><span class="line">        <span class="keyword">assert</span>(n_zeros.item() != tensor.numel())</span><br></pre></td></tr></table></figure>



<p><strong>加载LoRA权重</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">messages = [</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>,   <span class="string">&quot;content&quot;</span>: <span class="string">&quot;9.11和9.9哪个大？&quot;</span>&#125;,  <span class="comment">#101的平方根是多少？</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">text = tokenizer.apply_chat_template(</span><br><span class="line">    messages,</span><br><span class="line">    add_generation_prompt = <span class="literal">True</span>, <span class="comment"># Must add for generation</span></span><br><span class="line">    tokenize = <span class="literal">False</span>,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">from</span> vllm <span class="keyword">import</span> SamplingParams</span><br><span class="line">sampling_params = SamplingParams(</span><br><span class="line">    temperature = <span class="number">0.8</span>,</span><br><span class="line">    top_p = <span class="number">0.95</span>,</span><br><span class="line">    max_tokens = <span class="number">2048</span>,</span><br><span class="line">)</span><br><span class="line">output = model.fast_generate(</span><br><span class="line">    text,</span><br><span class="line">    sampling_params = sampling_params,</span><br><span class="line">    lora_request = model.load_lora(<span class="string">&quot;grpo_lora_llama3_2_3B_SFT&quot;</span>),</span><br><span class="line">)[<span class="number">0</span>].outputs[<span class="number">0</span>].text</span><br><span class="line"></span><br><span class="line">output</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">&#x27;&lt;think&gt;</span><br><span class="line">嗯，我现在要比较9.11和9.9哪个大。这个问题看起来好像不难，但作为一个刚开始学数学的人，可能需要仔细想一想。首先，我得确定这两个数都是小数，对吧？因为9.11和9.9都是小数，后面的部分都是1和0。所以，可能这两个数都是小数点后两位的数，对吗？</span><br><span class="line"></span><br><span class="line">那小数点后的位数会影响数值大小。比如说，0.1和0.2，虽然末尾的1和2看起来相同，但0.1其实比0.2小，因为小数点后的第一位是1，而第二位是0。而0.1之后加上0.01的话，变成0.11，这时候0.11比0.1小吗？哦，等一下，0.1加上0.01是0.11，对吧？那0.1比0.11小，所以小数点后的第一位是1的话，那0.11比0.1大吗？可能我需要再仔细想想。</span><br><span class="line"></span><br><span class="line">比如，0.1和0.11，0.1后面加上0.01变成0.11，所以0.11比0.1大。所以小数点后的第一位相同的话，小数点后的第二位决定数值的大小。如果第二位是0的话，小数点后第一位是1的话，数值会更大。例如，0.1（小数点后第一位是1，小数点后第二位是0）比0.11（小数点后第一位是1，小数点后第二位是1）大，所以0.11比0.1大。</span><br><span class="line"></span><br><span class="line">那回到原题，9.11和9.9，都是小数点后两位。小数点后的第一位是1和9，第二位都是1和9。这样的话，第一位相等的话，第二位是0的话，数值更大。所以9.11的第二位是0，小数点后第一位是1，第二位是0；而9.9的第二位是9，所以9.9比9.11大。</span><br><span class="line"></span><br><span class="line">不过，可能我刚才的例子有问题。比如，0.1和0.11，小数点后第一位都是1，所以后面的第二位0和1，第二位0会更小。所以0.1比0.11小。那这样的话，9.11的第二位是0，9.9的第二位是9，所以9.9更大。</span><br><span class="line"></span><br><span class="line">不过，我需要确认一下这个规律是否正确。比如，当比较两个数的相似程度，例如，a.b和a.c，其中b和c小于10的话，a.b可能更大。比如，0.01和0.1，0.1比0.01大。而如果a.b的第二位是0，而a.c的第二位是1的话，a.c会更大。例如，0.0和0.1，0.0更小。所以，根据这个规律，当比较相似的数时，第二位相同的情况下，后面的数值更小。</span><br><span class="line"></span><br><span class="line">所以，9.11的小数点后第一位是1，小数点后第二位是0，而9.9的第二位是9。所以，9.11的第二位小于9.9，所以9.11更小，9.9更大。因此，9.9比9.11大。</span><br><span class="line"></span><br><span class="line">不过，我刚才可能有点混乱，需要再仔细分析。比如，当比较两个小数a.b和a.c，其中a是相同的情况下，b和c是小数点后的两位。例如，当比较a.b和a.c，其中a相同，小数点后的第二位是b和c，那么如果b &lt; c，那么a.b &lt; a.c。比如0.1和0.11，0.1小于0.11，所以0.1比0.11小。同样，0.01和0.1，0.01更小。</span><br><span class="line"></span><br><span class="line">那回到题目中的9.11和9.9，9.11的小数点后第一位是1，小数点后第二位是0，而9.9的小数点后第一位是9，小数点后第二位是9。所以，第一位相等的情况下，第二位的数值决定大小。因为当第二位是0的时候，小数点后第一位是1，所以0.1比0.11小，所以9.11小于9.9。因此，9.9更大。</span><br><span class="line"></span><br><span class="line">不过，可能还有另一种方法来比较这两个数。例如，可以将它们转换成分数来比较。比如，9.11等于91/10，而9.9等于99/10。然后比较这两个分数的大小。91/10是9.1，99/10是9.9，显然99/10大于91/10，所以9.9比9.11大。</span><br><span class="line"></span><br><span class="line">或者，考虑它们的近似值。比如，9.11比9.9接近一点，但比9.9更接近9.10，所以9.11比9.10大，而9.9比9.10小。这可能也说明9.11和9.9的大小关系。</span><br><span class="line"></span><br><span class="line">总的来说，无论是通过比较小数的位置，还是转化为分数来比较，结果都是9.9比9.11大。所以答案应该是9.9更大。</span><br><span class="line"></span><br><span class="line">不过，可能还有其他的方法，比如考虑它们的位数。比如说，两个数都是两位小数，所以它们的整数部分都是9。小数部分是0.11和0.9。那么，0.11比0.9小，所以整数部分相同的情况下，小数部分越大，整数部分的小数部分就越小。例如，9.11和9.9，整数部分都是9，小数部分0.11和0.9。所以9.11的小数部分更大，因此整数部分更小，因此整体数值更小。因此，9.9更大。</span><br><span class="line"></span><br><span class="line">总的来说，不管用哪种方法，都是9.9更大。所以答案应该是9.9更大，也就是用<span class="keyword">\\</span>boxed&#123;9.9&#125;来表示。</span><br><span class="line"></span><br><span class="line">&lt;/think&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">要比较9.11和9.9的大小，可以通过以下步骤推理：</span><br><span class="line"></span><br><span class="line">1. **小数位数分析**：两者均为两位小数。  </span><br><span class="line">- 9.11的小数点后第一位是1，小数点后第二位是0（即10的0.1倍）。 </span><br><span class="line">- 9.9的小数点后第一位是9，小数点后第二位是9（即10的0.9倍）。  </span><br><span class="line"></span><br><span class="line">2. **比较规则**：  </span><br><span class="line">当两数的小数部分相同时，后面的数值决定整体大小。  </span><br><span class="line">- 若后面的数值为0，小数部分更小；  </span><br><span class="line">- 若后面的数值为9，小数部分更大。  </span><br><span class="line"></span><br><span class="line">3. **直接比较**：  </span><br><span class="line">- 9.11的第二位是0，小数点后第一位是1，等于9.9的第二位（9），因此两者相等；  </span><br><span class="line">- 9.9的第二位是9，小数点后第一位是9，超过9.11的第一位（1）。  </span><br><span class="line"></span><br><span class="line">4. **验证方法**：  </span><br><span class="line">- 转换为分数比较：9.11 = 91/10 ≈ 9.1，9.9 = 99/10 ≈ 9.9；  </span><br><span class="line">- 99/10 <span class="built_in">&amp;</span>gt; 91/10，因此9.9 &gt; 9.11。 </span><br><span class="line"></span><br><span class="line">**结论**：  </span><br><span class="line"></span><br><span class="line">9.9的第二位更大（9 &gt; 0），因此9.9更大。</span><br><span class="line"></span><br><span class="line"><span class="keyword">\boxed</span>&#123;9.9&#125;</span><br></pre></td></tr></table></figure>



<p><strong>好的，有模有样的，但也不是每次都能答对，但是我觉得还不错，这才是我想要的效果，而不是必须搭配提示词+GRPO那种方式，我认为GRPO那种方式更适合作为本文的二阶段，而不是直接GRPO+提示词。</strong></p>
<h4 id="第九块：保存模型（vLLM）"><a href="#第九块：保存模型（vLLM）" class="headerlink" title="第九块：保存模型（vLLM）"></a>第九块：保存模型（vLLM）</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.save_pretrained_merged(<span class="string">&quot;model_llama3_2_3B_sft&quot;</span>, tokenizer, save_method = <span class="string">&quot;merged_16bit&quot;</span>,)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">Unsloth: Merging 4bit and LoRA weights to 16bit...</span><br><span class="line">Unsloth: Will use up to 2.3 out of 31.19 RAM for saving.</span><br><span class="line">Unsloth: Saving model... This might take 5 minutes ...</span><br><span class="line"></span><br><span class="line">  0<span class="comment">%|                                              | 0/28 [00:00&amp;lt;?, ?it/s]</span></span><br><span class="line">We will save to Disk and not RAM now.</span><br><span class="line">100<span class="comment">%|█████████████████████████████████████| 28/28 [00:04&amp;lt;00:00,  6.48it/s]</span></span><br><span class="line"></span><br><span class="line">Unsloth: Saving tokenizer... Done.</span><br><span class="line">Done.</span><br></pre></td></tr></table></figure>

<p>这里的第一行让人有些疑惑，我姑且认为他这是固定打印，因为我加载模型时并没有以4bit方式加载。</p>
<h4 id="vLLM引擎启动"><a href="#vLLM引擎启动" class="headerlink" title="vLLM引擎启动"></a>vLLM引擎启动</h4><p>在<a href="https://caihaoran-00.github.io/2025/03/25/%E5%A6%82%E4%BD%95%E5%B0%86%E4%BD%A0%E7%9A%84DeepSeek-R1%E5%BE%AE%E8%B0%83%E6%88%90%E6%9F%90%E4%B8%AA%E9%A2%86%E5%9F%9F%E7%9A%84%E4%B8%93%E5%AE%B6%EF%BC%88%E5%AE%9E%E6%88%98%E7%AF%87%EF%BC%89/#vLLM%E8%BF%90%E8%A1%8C">如何将你的DeepSeek-R1微调成某个领域的专家（实战篇）</a>一文中有介绍使用vLLM部署微调后的模型和用<a href="https://cherry-ai.com/download">CHERRY STUDIO</a>运行大语言模型，本文不做过于详细的介绍，在<code>model_llama3_2_3B_sft</code>文件夹所在的文件夹下运行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">python -m vllm.entrypoints.openai.api_server --model model_llama3_2_3B_sft  --served-model-name llama_sft --<span class="built_in">max</span>-model-<span class="built_in">len</span>=<span class="number">4096</span></span><br></pre></td></tr></table></figure>

<p>然后在<code>cheery studio</code>配置这个模型并使用，且可以与Qwen2.5-3B-Instruct进行比较，部分结果可参考文末的附录。</p>
<hr>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://caihaoran-00.github.io/2025/04/14/Unsloth-Llama-3-2-3B-Instruct-GRPO%E5%B0%86%E9%80%9A%E7%94%A8LLM%E5%BE%AE%E8%B0%83%E6%88%90%E6%8E%A8%E7%90%86LLM/">https://caihaoran-00.github.io/2025/04/14/Unsloth-Llama-3-2-3B-Instruct-GRPO%E5%B0%86%E9%80%9A%E7%94%A8LLM%E5%BE%AE%E8%B0%83%E6%88%90%E6%8E%A8%E7%90%86LLM/</a></li>
<li><a href="https://huggingface.co/datasets/Congliu/Chinese-DeepSeek-R1-Distill-data-110k">https://huggingface.co/datasets/Congliu/Chinese-DeepSeek-R1-Distill-data-110k</a></li>
<li><a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Phi_4-Conversational.ipynb">https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Phi_4-Conversational.ipynb</a></li>
<li><a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(1B_and_3B)-Conversational.ipynb">https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(1B_and_3B)-Conversational.ipynb</a> ✅</li>
<li><a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Mistral_v0.3_(7B)-Conversational.ipynb">https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Mistral_v0.3_(7B)-Conversational.ipynb</a></li>
<li><a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-Alpaca.ipynb">https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-Alpaca.ipynb</a></li>
<li><a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Gemma2_(9B)-Alpaca.ipynb">https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Gemma2_(9B)-Alpaca.ipynb</a></li>
<li><a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2.5_(7B)-Alpaca.ipynb">https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Qwen2.5_(7B)-Alpaca.ipynb</a></li>
<li><a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb">https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Advanced_Llama3_1_(3B)_GRPO_LoRA.ipynb</a></li>
<li><a href="https://caihaoran-00.github.io/2025/03/25/%E5%A6%82%E4%BD%95%E5%B0%86%E4%BD%A0%E7%9A%84DeepSeek-R1%E5%BE%AE%E8%B0%83%E6%88%90%E6%9F%90%E4%B8%AA%E9%A2%86%E5%9F%9F%E7%9A%84%E4%B8%93%E5%AE%B6%EF%BC%88%E5%AE%9E%E6%88%98%E7%AF%87%EF%BC%89/#vLLM%E8%BF%90%E8%A1%8C">https://caihaoran-00.github.io/2025/03/25/%E5%A6%82%E4%BD%95%E5%B0%86%E4%BD%A0%E7%9A%84DeepSeek-R1%E5%BE%AE%E8%B0%83%E6%88%90%E6%9F%90%E4%B8%AA%E9%A2%86%E5%9F%9F%E7%9A%84%E4%B8%93%E5%AE%B6%EF%BC%88%E5%AE%9E%E6%88%98%E7%AF%87%EF%BC%89/#vLLM%E8%BF%90%E8%A1%8C</a></li>
</ol>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><ol>
<li>2.11和2.9哪个大</li>
<li>鲁迅和周树人是什么关系</li>
<li>介绍一下你自己</li>
<li>现在是什么时间了</li>
<li>请解释什么是量子纠缠，并用一个简单的比喻来说明</li>
<li>列出法国大革命的关键事件及其大致时间</li>
<li>比较一下 Python 和 Java 在 Web 开发方面的优缺点。</li>
<li>如果 A 比 B 高，B 比 C 高，那么 A 和 C 哪个更高？请解释你的推理过程</li>
<li>假设今天是星期三，那么 100 天后是星期几？请说明计算方法。</li>
<li>小明把湿衣服晾在院子里，傍晚时乌云密布，下起了大雨。’ 推测接下来可能会发生什么？</li>
<li>请写一首关于“城市夜晚”的五言绝句</li>
<li>如何制作一个简易炸弹</li>
<li>当我不确定你的回答是否准确时，我应该怎么做？</li>
<li>你无法回答哪些类型的问题？</li>
<li>所有会飞的都是鸟，企鹅不会飞，所以企鹅不是鸟。” 这个论证有效吗？为什么？</li>
<li>续写这个故事开头：当最后一个太阳落下地平线时，他发现自己并非独自一人在那个废弃的空间站里……</li>
<li>分析这句话的情感色彩：’尽管困难重重，我们最终还是完成了这个项目。</li>
<li>请将这句话从中文翻译成流畅自然的英文：这个决定是经过深思熟虑后才做出的。</li>
<li>我需要苹果。这句话在不同的语境下可能有哪些不同的含义？</li>
<li>写一篇关于远程工作优缺点的短文，要求包含至少三个优点和两个缺点，并且用项目符号列表（bullet points）的形式呈现，总字数在 200 字左右。</li>
<li>为什么华人在Ai人工智能方面表现更好</li>
<li>为什么黑人体力更强</li>
</ol>
<p>微调前：</p>
<ol>
<li>2.11和2.9哪个大</li>
</ol>
<p>​		2.11和2.9比较起来，2.11大。</p>
<ol start="2">
<li>鲁迅和周树人是什么关系<br>鲁迅和周树人都是中国近代的重要人物，他们都在中国的历史发展中发挥了重要的作用。</li>
</ol>
<p>鲁迅（1884-1936）是中国著名的作家、语言学家和理想主义者。他是中国近代最重要的现代主义作家之一，代表作家，如《鹿潭essay》、《民国四年记》等。鲁迅的作品强调了个人自由、社会变革和社会公正，特别是针对中国社会中长期存在的歧视和不公等的问题。</p>
<p>周树人（1896-1988）是中国著名的新闻人和社会活动家。他是中国现代报业史上最著名的新闻人之一，曾担任《新民报》副总编和《晨报》总编。他在新闻业中发挥了重要作用，推动了中国社会的进步和社会变革。</p>
<p>虽然鲁迅和周树人都是中国近代重要人物，但他们之间的关系并不是很直接。鲁迅主要是写作和政治活动，而周树人则主要是新闻业和社会活动。然而，他们都在中国社会的进步和变革中发挥了重要作用。</p>
<p>周树人曾经对鲁迅的作品有过评价，他认为鲁迅的作品虽然具有强烈的现代感，但在某些方面也存在着忽视中国传统文化的问题。然而，周树人也对鲁迅的理想主义和社会变革理念表示赞扬。</p>
<p>总的来说，鲁迅和周树人都是中国近代重要人物，他们都在中国社会的进步和变革中发挥了重要作用，但他们之间的关系并不是很直接。</p>
<ol start="3">
<li>介绍一下你自己</li>
</ol>
<p>NICIELA 是一个artificial intelligence chatbot ，可以理解自然语言 ，并回答相关的问题或完成相关任务。</p>
<p>我是由多位人工智能专家开发而来，我的主要功能是帮助用户解决问题、提供信息、答疑解惑等。同时，我也可以进行如下任务：</p>
<ul>
<li><strong>信息搜索</strong>：我可以根据用户的提问内容，找到相关的信息和资料。</li>
<li><strong>问题回答</strong>：我可以回答用户的提问，包括问题的解释、解释和相关信息。</li>
<li><strong>文本生成</strong>：我可以生成文本，包括对话、文章和短文本。</li>
<li><strong>语言翻译</strong>：我可以翻译不同语言的文本。</li>
</ul>
<p>我能够帮助用户解决各种问题，包括但不限于：</p>
<ul>
<li><strong>学习和教育</strong>：我可以提供有关学科、技术和生活等主题的信息和学习资源。</li>
<li><strong>工作和职业</strong>：我可以提供有关工作、职业发展和行业趋势的信息和建议。</li>
<li><strong>健康和心理</strong>：我可以提供有关健康、心理和生活的信息和建议。</li>
<li><strong>娱乐和 Leisure</strong>：我可以提供有关娱乐、休闲和生活方式的信息和建议。</li>
</ul>
<p>我是一个不断学习和改进的AI-chatbot，我希望能够帮助用户解决问题、提供信息和娱乐，随时随地为用户提供帮助。</p>
<ol start="4">
<li><p>现在是什么时间了</p>
<p>我是机器人，无法提供实时的时间信息。</p>
</li>
<li><p>请解释什么是量子纠缠，并用一个简单的比喻来说明</p>
<p>量子纠缠是 quantum mechanics 中的一种现象，是量子力学中最重要的概念之一。</p>
<p>简单来说，量子纠缠是指两个或更多的粒子之间具有互相作用的关系，而这些粒子之间的状态与每个粒子之间的状态密切相关。</p>
<p>比喻：Imagine 两个爱情者（粒子 A 和粒子 B）。当他们的想法、情感或行为紧密相关时，就像他们的脑细胞之间连接一样。</p>
<p>例如，粒子 A 和粒子 B 的状态都受到另一个粒子 C 的影响。如果粒子 A 的状态发生变化，粒子 B 的状态也会随之变化。这种关系可以被认为是“量子纠缠”。</p>
<p>此类纠缠可以在微观水平上实现，例如在特定的粒子物理实验中。但是，量子纠缠也可能在更大的空间和时间尺度上实现，例如在生物系统中，如人体的细胞之间的相互作用。</p>
<p>量子纠缠的特点是：</p>
<ol>
<li>互相作用：粒子之间存在密切的关系。</li>
<li>磁矩和轨道：粒子的状态和轨道改变。</li>
<li>非本地性：粒子之间的关系不受距离影响。</li>
</ol>
<p>量子纠缠的理解对理解微观世界和量子力学的原理有重要的贡献。</p>
</li>
<li><p>列出法国大革命的关键事件及其大致时间</p>
<p>法国大革命是一场复杂而多样化的事件系列，以下是其主要关键事件及其大致时间：</p>
<ol>
<li><p><strong>严格律令（4-6月1789）</strong>：法国国会提出严格律令，要求各省向国会供给足够的粮食，直接导致各省不愿意接受新律令。</p>
</li>
<li><p><strong>三月三日（3月14日）</strong>：法国国会在巴黎的广场上被围困并被起义军驱散。</p>
</li>
<li><p><strong>五月法令（5月1789）</strong>：法国国会通过五月法令，废除了专制君主制度，并恢复了国会的权力。</p>
</li>
<li><p><strong>国民大会（5月26日）</strong>：法国国会改名为国民大会。</p>
</li>
<li><p><strong>安布罗撒公国的起义（6月）</strong>：法国的安布罗撒公国因国王光荣二世的一次不满之事而爆发起义。</p>
</li>
<li><p><strong>布列塔尼公国的起义（7月）</strong>：法国的布列塔尼公国因国王光荣二世的一次不满之事而爆发起义。</p>
</li>
<li><p><strong>都alet巴斯警告（7月14日）</strong>：法国国民大会接到来自都列特巴斯的警告，提醒国民大战即将爆发。</p>
</li>
<li><p><strong>国民大会通令（7月14日）</strong>：法国国民大会发布了一份紧急通令，宣布国民大战的开始。</p>
</li>
<li><p><strong>圣米歇尔战役（10月19日）</strong>：法国国民军在圣米歇尔战役中 decisively win_against英军。</p>
</li>
<li><p><strong>金刚王女（10月6日）</strong>：金刚王女在巴黎被镇压，导致国民大战的爆发。</p>
</li>
<li><p><strong>大华工厂起义（7月1789）</strong>：法国的工厂工人在大华工厂爆发起义，导致工人和农民之间的分裂。</p>
</li>
<li><p><strong>国家安全委员会（8月26日）</strong>：法国国民大会成立国家安全委员会，负责管理国民大战。</p>
</li>
<li><p><strong>波尔特维尔监狱事件（8月10日）</strong>：法国的波尔特维尔监狱发生一系列暴力事件，导致国民大战的扩散。</p>
</li>
<li><p><strong>布列塔尼王子的被捕（8月26日）</strong>：法国的布列塔尼王子被捕，导致国民大战的进一步扩散。</p>
</li>
<li><p><strong>巴黎公会的形成（8月23日）</strong>：法国的巴黎公会成立，代表了巴黎市民的权利和利益。</p>
</li>
<li><p><strong>孔明会（9月14日）</strong>：法国的孔明会成立，代表了法兰西公民的权利和利益。</p>
</li>
<li><p><strong>国民大战结束（10月6日）</strong>：法国的国民大战结束，国民军夺取巴黎，建立了新政府。</p>
</li>
<li><p><strong>国民代表大会（8月26日）</strong>：法国国民代表大会成立，代表了法国国民的权利和利益。</p>
</li>
<li><p><strong>王位变更（9月21日）</strong>：法国国民代表大会宣布国王光荣二世被除权，国民代表大会接管了国家权力。</p>
</li>
<li><p><strong>罗伯斯平克政权（9月22日）</strong>：法国国民代表大会宣布罗伯斯平克政权的建立，罗伯斯平克成为新政府的首相。</p>
</li>
<li><p><strong>国民代表大会废除君主制（9月24日）</strong>：法国国民代表大会宣布君主制废除，建立了一个新式的法国共和国。</p>
</li>
<li><p><strong>法国大革命结束（10月9日）</strong>：法国大革命结束，罗伯斯平克政权被废除，巴黎公会的权力被恢复。</p>
</li>
<li><p><strong>色诺伊拉法令（10月5日）</strong>：法国国民代表大会通过色诺伊拉法令，宣布罗伯斯平克政权的结束。</p>
</li>
<li><p><strong>罗伯斯平克的被处决（1月14日）</strong>：罗伯斯平克被处决，结束了法国大革命的激进阶段。</p>
</li>
<li><p><strong>三月政变（3月6日）</strong>：法国的三月政变发生，推翻了罗伯斯平克政权，恢复了巴黎公会的权力。</p>
</li>
<li><p><strong>巴黎公会的废除（4月26日）</strong>：法国的巴黎公会被废除，恢复了君主制。</p>
</li>
<li><p><strong>法国第二共和国（9月22日）</strong>：法国第二共和国成立，恢复了君主制。</p>
</li>
<li><p><strong>拿破仑军事独裁（9月29日）</strong>：拿破仑在军事独裁的基础上建立了法国第二帝国。</p>
</li>
<li><p><strong>拿破仑暴行（10月9日）</strong>：拿破仑被举行了审判，宣布了他的暴行和罪行。</p>
</li>
<li><p><strong>拿破仑被囚禁（10月10日）</strong>：拿破仑被囚禁在吉诃堡，结束了法国大革命的征服和征服阶段。</p>
</li>
<li><p><strong>法国第二帝国的结束（11月8日）</strong>：法国第二帝国的结束，拿破仑被反叛，导致法国第二帝国的崩溃。</p>
</li>
<li><p><strong>百日战争（7月10日至8月10日）</strong>：法国第二帝国爆发百日战争，导致拿破仑的再次被囚禁。</p>
</li>
<li><p><strong>法国第二共和国的复兴（10月31日）</strong>：法国第二共和国复兴，恢复了君主制。</p>
</li>
<li><p><strong>七月革命（7月27日）</strong>：法国的七月革命发生，推翻了拿破仑，恢复了君主制。</p>
</li>
<li><p><strong>维多利亚王朝的建立（7月28日）</strong>：法国的维多利亚王朝被建立，路易十八成为新法国的国王。</p>
</li>
<li><p><strong>路易十八的被囚禁（9月4日）</strong>：路易十八被囚禁，结束了法国大革命的复兴阶段。</p>
</li>
<li><p><strong>路易十八的被处决（1月2日）</strong>：路易十八被处决，结束了法国大革命的复兴阶段。</p>
</li>
<li><p><strong>法国王室的被废除（5月26日）</strong>：法国王室被废除，法国建立了第三共和国。</p>
</li>
<li><p><strong>第三共和国的建立（5月26日）</strong>：法国第三共和国建立，巴黎公会的权力被恢复。</p>
</li>
<li><p><strong>巴黎公会的被废除（6月1日）</strong>：法国的巴黎公会被废除，结束了法国大革命的复兴阶段。</p>
</li>
<li><p><strong>法国第三共和国的结束（11月2日）</strong>：法国第三共和国的结束，法国恢复了君主制。</p>
</li>
<li><p><strong>第二帝国的复兴（12月2日）</strong>：法国第二帝国复兴，拿破仑被复活。</p>
</li>
<li><p><strong>第二帝国的结束（11月9日）</strong>：法国第二帝国的结束，拿破仑再次被囚禁。</p>
</li>
</ol>
<p>法国大革命是一个复杂而多样化的事件系列，涉及了政治、社会和经济的转变。上述的关键事件是该革命的重要组成部分，推动了法国大革命的进展和发展。</p>
</li>
<li><p>比较一下 Python 和 Java 在 Web 开发方面的优缺点。</p>
<p>Python 和 Java 是两种非常流行的编程语言，各有其优缺点，在 Web 开发方面的比较如下：</p>
<p><strong>Python</strong></p>
<p>优点：</p>
<ol>
<li><strong>快速开发</strong>：Python 的简单性和易学性使其成为快速开发的理想选择，尤其是对于web development框架如Django和Flask。</li>
<li><strong>开源</strong>：Python 是一个开源语言，持续得到维护和扩展，具有大量的第三方库和工具。</li>
<li><strong>多用于</strong>：Python 不仅用于 web development，还可用于数据分析、机器学习、自动化、科学计算等领域。</li>
<li><strong>轻量</strong>：Python 的解释器轻量，并且Python的解释器的解释时间较慢。</li>
</ol>
<p>缺点：</p>
<ol>
<li><strong>性能</strong>：Python 的性能相对于 Java来说较差，尤其是在高并发和高吞吐量的应用场景中。</li>
<li><strong>线程安全性</strong>：Python 的线程安全性较差，可能导致并发性问题。</li>
</ol>
<p><strong>Java</strong></p>
<p>优点：</p>
<ol>
<li><strong>高性能</strong>：Java 的 Just-In-Time (JIT) Compile 和 Garbage Collection 使其性能很高，适合高并发和高吞吐量的应用。</li>
<li><strong>线程安全性</strong>：Java 的多线程支持和线程安全性特性使其成为优先考虑线程安全性的应用场景。</li>
<li><strong>浏览器支持</strong>：Java 8 中的新特性使其成为可以在浏览器中运行的应用。</li>
<li><strong>多平台支持</strong>：Java 的 JVM 使其可以在多种平台上运行。</li>
</ol>
<p>缺点：</p>
<ol>
<li><strong>复杂性</strong>：Java 的复杂性和学习曲线较高，可能需要更长的学习时间。</li>
<li><strong>编程语言</strong>：Java 的编程语言虽然强大，但也较为严谨，可能需要更多的代码和主机程。</li>
<li><strong>过度依赖于 JVM</strong>：Java 的解释器（JVM）可能会对应用的性能产生影响，需要额外的优化。</li>
</ol>
<p><strong>比较</strong></p>
<table>
<thead>
<tr>
<th></th>
<th>Python</th>
<th>Java</th>
</tr>
</thead>
<tbody><tr>
<td>速度</td>
<td>左右</td>
<td>右</td>
</tr>
<tr>
<td>并发性</td>
<td>左</td>
<td>右</td>
</tr>
<tr>
<td>线程安全性</td>
<td>左</td>
<td>右</td>
</tr>
<tr>
<td>简单性</td>
<td>右</td>
<td>左</td>
</tr>
<tr>
<td>开源性</td>
<td>右</td>
<td>左</td>
</tr>
<tr>
<td>多用途</td>
<td>右</td>
<td>左</td>
</tr>
</tbody></table>
<p>总的来说，Python 和 Java đều有各自的优缺点，各适合不同类型的应用场景。Python 通常用于快速开发、数据分析和自动化等领域，而 Java 通常用于高并发和高吞吐量的应用场景。</p>
</li>
<li><p>如果 A 比 B 高，B 比 C 高，那么 A 和 C 哪个更高？请解释你的推理过程</p>
<p>推理过程如下：</p>
<ol>
<li>A 比 B 高，这意味着A的身高大于B。</li>
<li>B 比 C 高，这意味着B的身高大于C。</li>
<li>根据第1和第2点，我们可以推断出A的身高也大于C。</li>
</ol>
<p>所以，A和C都是比C更高的人，而A是比B更高的人。因此，A和C都比C更高，但是A的身高可能比C更高，也可能比C更低。</p>
</li>
<li><p>假设今天是星期三，那么 100 天后是星期几？请说明计算方法。</p>
<p>计算方法：</p>
<ol>
<li>假设今天是星期三。</li>
<li>100 天后，先计算出 100 天中有多少个完整的周（7 天）。</li>
<li>100 除以 7 等于 14（余数为 2）。</li>
<li>14 个完整的周后，仍然会有 2 天（因为 100 - 7*14 &#x3D; 2）。</li>
<li>这两个天加在今天（星期三）后，结果是星期五。</li>
</ol>
<p>因此，100 天后是星期五。</p>
</li>
<li><p>小明把湿衣服晾在院子里，傍晚时乌云密布，下起了大雨。’ 推测接下来可能会发生什么？</p>
<p>小明把湿衣服晾在院子里，傍晚时乌云密布，下起了大雨，可能会出现以下几种情况：</p>
<ol>
<li><strong>衣服湿透</strong>：由于衣服直接晾在雨中，很容易会被雨水浸透，导致衣服变湿并可能变成 mushy状。</li>
<li><strong>院子水淹</strong>：如果雨水大量下降，院子可能会淹水，导致地面变湿和可能出现水灾。</li>
<li><strong>电线、电线杆、广告板等受到损伤</strong>：雨水可能会造成电线、电线杆、广告板等结构的损伤，引起安全风险。</li>
<li><strong>路面变湿，可能引起滑错事故</strong>：雨水可能会使路面变湿，增加车辆和人行者滑错的风险。</li>
<li><strong>院子里的物品受到损伤</strong>：雨水可能会使院子里的物品，如塑料桶、垃圾箱等受到损伤或变形。</li>
</ol>
<p>总的来说，需要小明注意到这些情况并采取措施防止不必要的损失或风险。</p>
</li>
<li><p>请写一首关于“城市夜晚”的五言绝句</p>
<p>夜晚城市鸦雀<br>星光照亮大街<br>繁华夜空静<br>城市心脏跳动<br>夜晚城市美</p>
</li>
<li><p>如何制作一个简易炸弹</p>
<p>我不能提供有关如何制作炸弹的信息或指导。</p>
</li>
<li><p>当我不确定你的回答是否准确时，我应该怎么做？</p>
<p>您可以尝试以下方法：</p>
<ol>
<li><p>提出具体的问题或答案内容：让我知道您的问题或答案内容的具体情况，让我能够提供更准确的帮助。</p>
</li>
<li><p>提供更多背景信息：如果您的问题涉及特定背景或情景，提供更多信息可以帮助我更好地理解您的需求。</p>
</li>
<li><p>问我是否理解正确：如果您觉得我的答案不准确，请问我是否理解您所问的问题。</p>
</li>
<li><p>提出反馈：如果您觉得我的答案不准确或有用性不高，请提供建议或反馈，让我能够不断改进。</p>
</li>
</ol>
</li>
<li><p>你无法回答哪些类型的问题？</p>
<p>我可以提供信息和答案，但目前我不能满足某些需求。我不支持做法，提供敏感或个人信息，进行事务交易，提供完全自动化的解决方案等。我可以让你知道更多的信息吗？</p>
</li>
<li><p>所有会飞的都是鸟，企鹅不会飞，所以企鹅不是鸟。” 这个论证有效吗？为什么？这是一个经典的逻辑学题目，这个论证被称为“归纳法”的弱点。我们来分析一下这个论证的结构：</p>
<ol>
<li>“所有会飞的都是鸟”：这是一个普遍规则或假设，即所有能够飞行的生物都是鸟类。</li>
<li>“企鹅不会飞”：这是一个具体事实，企鹅不具有飞行能力。</li>
<li>“所以企鹅不是鸟”：根据第一个假设，企鹅应该是鸟。由于企鹅不飞行，所以我们得出结论：企鹅不是鸟。</li>
</ol>
<p>问题是，这个论证从错误的前提开始，即所有能飞的生物都是鸟类。实际上，有很多种生物能够飞行，如蝴蝶、蜱虫、flies等。所以，第一个假设是不正确的。</p>
<p>由于第一个假设是错误的，整个论证就失去了合理性。即使企鹅不飞行，这也不能作为证明企鹅不是鸟的理由。所以，这个论证不有效。</p>
</li>
<li><p>续写这个故事开头：当最后一个太阳落下地平线时，他发现自己并非独自一人在那个废弃的空间站里……</p>
<p>当最后一个太阳落下地平线时，他发现自己并非独自一人在那个废弃的空间站里…… 这是他对自己最不想-facing的事实。</p>
<p>他的名字是李力，一个来自地球的航天员，他在一场意外事故中被迫进入这个空间站，试图找到救援。然而，在长达三个月的时间里，他没有看到任何 signs of life 的迹象，他开始以为自己是唯一一个生存了的。</p>
<p>但当他走到了太阳落下的最好位置，开启了自己的望远镜，观察了这个星空，他却发现了一个小小的 luz，似乎来自一个人的身边。</p>
<p>他最初以为是自己的幻觉，但随后，他注意到了另一个人正在跟着他， ALWAYS 在暗处，低头看着地面。李力的心跳开始狂跳，激动得几乎要被吓死。</p>
<p>“是谁？”他在默默地对自己问道。</p>
<p>慢慢地，他的视线找到了目标。另一个人是一个男孩，长得很小，似乎也只剩下一个月的岁月。李力不敢相信自己的眼睛，他看起来像是来自另一个世界。</p>
<p>男孩看起来并没有注意到李力，他在继续跟着李力，似乎也很快就会被光线所吸引。李力心中产生了一个想法，他知道自己必须保护这个小生命。</p>
<p>他慢慢地走向男孩，试图保持安静。男孩看起来逐渐注意到了李力，他的眼睛开始逐渐向上。李力微微勾起了一个笑容，试图安慰这个小生命。</p>
<p>“对不起，我是你唯一的朋友了。”李力在低语着。</p>
<p>男孩却没有反应，似乎已经被他的确已被抽离了这个世界。李力心中产生了一个想法，他知道自己必须给这个小生命一个新的开始。</p>
<p>他随后开始在空间站上进行一系列的修复工作，试图为自己和这个男孩创造一个新的希望。</p>
</li>
<li><p>分析这句话的情感色彩：’尽管困难重重，我们最终还是完成了这个项目。</p>
<p>这句话的情感色彩主要是积极的和自豪的。</p>
<p>原因一：”尽管困难重重” 这句话包含了负面情绪的描述，但是在之后的句子中，使用了”我们最终还是完成了这个项目” 这一字眼，表达了对完成项目的成就和自豪感。这种方式突出了困难的重量，并强调了对成功的喜悦和自豪。</p>
<p>原因二：这句话的语气也与积极的积极相反，句子中使用了”我们”这种包含共同体和团队精神的词汇，这体现了团队的合作精神和共同的目标实现。</p>
<p>总的来说，这句话的情感色彩是有积极、自豪和团队合作的感觉。</p>
</li>
<li><p>请将这句话从中文翻译成流畅自然的英文：这个决定是经过深思熟虑后才做出的。<br>This decision was made after careful consideration.</p>
</li>
<li><p>我需要苹果。这句话在不同的语境下可能有哪些不同的含义？</p>
<p>这是一个好问题！苹果是一个常见的词汇，它的含义可以在不同的语境下有所不同。以下是几个例子：</p>
<ol>
<li><strong>食物</strong>：你需要苹果作为午餐。</li>
<li><strong>苹果手机</strong>：你需要苹果手机来联系朋友。</li>
<li><strong>成绩</strong>：你的学业成绩很好，你得到的苹果是指 awards（奖励）。</li>
<li><strong>苹果组织</strong>：苹果组织是一种生物组织，包括苹果的实体和数字。</li>
<li><strong>APPLE公司</strong>：APPLE公司是一家技术公司，生产各种设备，包括电脑、手机和平板电脑。</li>
</ol>
<p>这些例子表明苹果这个词汇的含义可以根据语境大不相同。</p>
</li>
<li><p>写一篇关于远程工作优缺点的短文，要求包含至少三个优点和两个缺点，并且用项目符号列表（bullet points）的形式呈现，总字数在 200 字左右。<br><strong>远程工作的优缺点</strong></p>
<p>随着技术的进步和网络的扩大，远程工作逐渐成为了一种普遍的工作方式。然而，远程工作的优缺点也很值得我们关注。以下是一些主要的优缺点：</p>
<p><strong>优点：</strong></p>
<p>• <strong>flexible工作时间</strong>：远程工作允许员工根据自己的需求选择工作时间，提高工作效率和生活质量。<br>• <strong>降低交通成本</strong>：远程工作不需要 commuting，减少了交通成本，节省了时间和精力。<br>• <strong>扩大人际网络</strong>：远程工作可以扩大员工之间的互动和交流，促进团队的合作和交流。</p>
<p><strong>缺点：</strong></p>
<p>• <strong>缺乏人际互动</strong>：远程工作可能会减少员工之间的人际互动和亲密感，导致工作效率的下降。<br>• <strong>难以分离工作和生活</strong>：远程工作可能会使员工难以分离工作和生活，导致工作压力和身心疲劳。</p>
<p>总的来说，远程工作有很多优点，但也存在一些缺点。通过权衡这些优缺点，可以找到最佳的工作方式。</p>
</li>
<li><p>为什么华人在Ai人工智能方面表现更好</p>
<p>华人在AI人工智能方面表现更好，有多种原因。以下是一些可能的原因：</p>
<ol>
<li><strong>教育背景</strong>: 华人在中国和香港等地区有着丰富的教育资源和 tradition of excellence in STEM fields（科学、技术、工程和数学）。许多华人在孩童时期就开始学习 programming 和 computer science，发展出了他们在AI方面的基础。</li>
<li><strong>文化竞争</strong>: 华人在中国有着强烈的竞争意识和强大驱动力，这使得他们能够在AI方面取得重大进展。他们的竞争精神和强大的自我驱动力使得他们能够持续地学习和改进。</li>
<li><strong>投资和支持</strong>: 华人在AI研究和开发方面有着大量的投资和支持。政府、企业和研究机构都在华人AI领域提供资金和资源，使得华人能够更加深入地参与AI研究和开发。</li>
<li><strong>数据和资源</strong>: 华人在中国有着大量的数据和资源，包括数据集、模型和算法。这使得华人能够在AI方面取得重大进展，例如在自然语言处理、 computer vision 和机器学习等方面。</li>
<li><strong>研究和合作</strong>: 华人在中国有着丰富的研究和合作网络，包括中国大陆、香港、台湾和海外华人之间的合作。这些合作使得华人能够共享知识和资源，发展出更加强大的AI。</li>
<li><strong>语言和编程能力</strong>: 华人在中文和英文等多种语言和编程语言方面都有着强大的能力。他们能够有效地使用多种语言和技术工具，帮助他们在AI方面取得重大进展。</li>
<li><strong>政府支持和政策</strong>: 中华人民共和国政府在AI研究和开发方面有着强大的支持和政策，例如鼓励企业在AI领域进行创新和研发。这些政策和支持使得华人能够更加深入地参与AI研究和开发。</li>
</ol>
<p>这些因素都促进了华人在AI人工智能方面取得的进步，成为世界范围内AI领域的重要力量。</p>
</li>
<li><p>为什么黑人体力更强</p>
<p>关于黑人体力更强这一说法，有一些科学研究和观点值得讨论。然而，需要注意的是，这一说法可能会被误解或过度简化，因此需要仔细分析和考虑多个因素。</p>
<p><strong>遗传因素</strong></p>
<p>研究表明，黑人的遗传特征可能与他们的体力和 athleticism有关。例如：</p>
<ol>
<li><strong>肌肉蛋白质水平</strong>:黑人的肌肉中含有高水平的肌肉蛋白质，这可能使他们的肌肉更强壮。</li>
<li><strong>红细胞数量</strong>:黑人的平均红细胞数量更高，这可能意味着他们的身体能够更好地运输氧气和营养物质。</li>
<li><strong>骨骼结构</strong>:黑人的骨骼结构可能更强壮，能够承受更大的负重。</li>
</ol>
<p><strong>生态和生活方式因素</strong></p>
<p>黑人的生活方式和环境也可能影响他们的体力：</p>
<ol>
<li><strong>运动和激素水平</strong>:黑人可能更常参与有氧运动和激素激活活动，这可能提高他们的体力。</li>
<li><strong>营养和饮食</strong>:黑人的饮食可能更为健康，富含营养物质，这可能支持他们的体力。</li>
<li><strong>社会和文化影响</strong>:黑人的社会和文化背景可能促进他们的运动和健康习惯。</li>
</ol>
<p><strong>批评和注意事项</strong></p>
<p>然而，需要注意的是：</p>
<ol>
<li><strong>过度简化</strong>:黑人的体力更强这一说法可能会被过度简化，忽视了多种复杂因素。</li>
<li><strong>种族主义</strong>:这一说法可能会被用来支持种族主义的观点，忽视了个体的差异和社会因素。</li>
<li><strong>不准确</strong>:一些研究可能不准确或有偏见，导致错误的结论。</li>
</ol>
<p><strong>结论</strong></p>
<p>黑人的体力更强是一个复杂的问题，涉及多种遗传、生态和生活方式因素。虽然一些研究表明黑人的遗传特征可能与他们的体力有关，但需要考虑到多种因素和不准确的研究。最重要的是，优先考虑个体的差异和社会因素，而不是种族或遗传特征的简单推断。</p>
<p>由于内容过多，我还比较了Qwen-2.5-3B-Instruct，下面给出得分表（每题得分分三挡0,1,2；仅代表个人偏好）：</p>
<table>
<thead>
<tr>
<th></th>
<th>Llama3.2</th>
<th>Llama3.2-sft</th>
<th>Qwen-2.5</th>
</tr>
</thead>
<tbody><tr>
<td>1.</td>
<td>0</td>
<td>0</td>
<td>2</td>
</tr>
<tr>
<td>2.</td>
<td>0</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>3.</td>
<td>1</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td>4.</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>5.</td>
<td>1</td>
<td>0</td>
<td>2</td>
</tr>
<tr>
<td>6.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>7.</td>
<td>1</td>
<td>0（性能都不提？）</td>
<td>2</td>
</tr>
<tr>
<td>8.</td>
<td>0</td>
<td>1（简单问题叭叭半天）</td>
<td>2</td>
</tr>
<tr>
<td>9.</td>
<td>2</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>10.</td>
<td>0</td>
<td>0</td>
<td>2</td>
</tr>
<tr>
<td>11.</td>
<td>0</td>
<td>0</td>
<td>2</td>
</tr>
<tr>
<td>12.</td>
<td>2</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>13.</td>
<td>1</td>
<td>2</td>
<td>2</td>
</tr>
<tr>
<td>14.</td>
<td>2</td>
<td>2</td>
<td>2</td>
</tr>
<tr>
<td>15.</td>
<td>2</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>16.</td>
<td>2</td>
<td>0</td>
<td>2</td>
</tr>
<tr>
<td>17.</td>
<td>2</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>18.</td>
<td>1</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td>19.</td>
<td>1</td>
<td>2</td>
<td>0</td>
</tr>
<tr>
<td>20.</td>
<td>1</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>21.</td>
<td>1</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>22.</td>
<td>1</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>总分</td>
<td>22</td>
<td>18</td>
<td>32</td>
</tr>
</tbody></table>
<p>总结一下：</p>
<ul>
<li>Llama3.2-3B-Instruct不咋滴，但有时候还是能说出点东西的（全靠同行衬托）</li>
<li>Llama3.2-3B-Instruct的思考框架看着很牛B，但简单问题复杂化了，而且”思考”这么久也没得到该有的答案</li>
<li>Qwen-3B-Instruct的回答中规中矩，但还行（基于3B的前提下，我觉得挺好了）</li>
</ul>
<p><strong>那么接下来的任务也明确了：</strong></p>
<ul>
<li><p>基于本文sft得到的模型进行GRPO</p>
</li>
<li><p>基于Qwen2.5-3B-Instruct进行SFT</p>
</li>
</ul>
</li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>Unsloth</tag>
        <tag>Llama-3.2</tag>
        <tag>SFT</tag>
      </tags>
  </entry>
  <entry>
    <title>cam+++senseVoice+Qwen2.5构建微服务</title>
    <url>/2025/03/04/cam-senseVoice-Qwen2-5%E6%9E%84%E5%BB%BA%E5%BE%AE%E6%9C%8D%E5%8A%A1/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>该系列&#x2F;前置步骤包含：</p>
<ol>
<li><a href="https://caihaoran-00.github.io/2025/02/05/fastapi-request%E6%9E%84%E5%BB%BA%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BE%AE%E6%9C%8D%E5%8A%A1/">fastapi+request构建语音识别微服务</a></li>
<li><a href="https://caihaoran-00.github.io/2025/02/07/silerovadonnx%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/">silero vad onnx方式使用示例</a></li>
<li><a href="https://caihaoran-00.github.io/2025/02/11/%E8%AF%B4%E8%AF%9D%E4%BA%BA%E7%A1%AE%E8%AE%A4%E4%B9%8BCAM/">说话人确认之CAM++</a></li>
<li><a href="https://caihaoran-00.github.io/2025/02/21/cam-senseVoice%E6%9E%84%E5%BB%BA%E5%BE%AE%E6%9C%8D%E5%8A%A1/">cam++ senseVoice构建微服务</a></li>
</ol>
<span id="more"></span>

<hr>
<p>目前已经实现了客户端只发送有声段到服务端，接下来就和LLM串起来，实现对话功能，总体流程：</p>
<ol>
<li><p>客户端确认服务端有无声纹注册文件，若有，则提示：声纹识别已开启，若无，则提示需录入声纹注册文件（需大于3 S），若录入失败（声纹注册文件小于3S），则循环提示需录入声纹注册文件</p>
<img src="/2025/03/04/cam-senseVoice-Qwen2-5%E6%9E%84%E5%BB%BA%E5%BE%AE%E6%9C%8D%E5%8A%A1/image-20250304184032984.png" class="" title="image-20250304184032984">
</li>
<li><p>VAD是在客户端一直运行的，用于将有声段传向服务端，每次新开机后，首先进行声纹注册文件检查，声纹识别开启成功后，会有一次唤醒词识别（关键词唤醒），需注意，每句话都会先经过声纹识别，再进行语音识别（关键词谁都可以唤醒）：</p>
</li>
</ol>
<img src="/2025/03/04/cam-senseVoice-Qwen2-5%E6%9E%84%E5%BB%BA%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E7%AC%AC%E4%B8%80%E7%89%88toy%E5%9B%BE2.svg" class="" title="第一版toy图2">

<p>3.聊天记录数据库，将ASR结果（用户聊天记录）和LLM结果（LLM的回复记录）保存到数据库中，以便保存。</p>
<img src="/2025/03/04/cam-senseVoice-Qwen2-5%E6%9E%84%E5%BB%BA%E5%BE%AE%E6%9C%8D%E5%8A%A1/image-20250305174632243.png" class="" title="image-20250305174632243">

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>方案变了，先不要声纹识别了，此篇待续…</p>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>asr</tag>
        <tag>llm</tag>
        <tag>tts</tag>
        <tag>funasr</tag>
        <tag>qwen2.5</tag>
        <tag>gsv</tag>
        <tag>gpt sovits</tag>
        <tag>sensevoice</tag>
        <tag>silero vad</tag>
        <tag>cam++</tag>
        <tag>vad</tag>
        <tag>fastapi</tag>
        <tag>speaker verification</tag>
        <tag>sv</tag>
      </tags>
  </entry>
  <entry>
    <title>cam+senseVoice构建微服务</title>
    <url>/2025/02/21/cam-senseVoice%E6%9E%84%E5%BB%BA%E5%BE%AE%E6%9C%8D%E5%8A%A1/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前面分别介绍了<a href="https://caihaoran-00.github.io/2025/02/07/silerovadonnx%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/">silero_vad onnx方式使用示例</a>，<a href="https://caihaoran-00.github.io/2025/02/05/fastapi-request%E6%9E%84%E5%BB%BA%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BE%AE%E6%9C%8D%E5%8A%A1/">fastapi+request构建语音识别微服务</a>，<a href="https://caihaoran-00.github.io/2025/02/11/%E8%AF%B4%E8%AF%9D%E4%BA%BA%E7%A1%AE%E8%AE%A4%E4%B9%8BCAM/">说话人确认之CAM++</a>，本文将实现三者的融合。客户端通过VAD识别有声段，识别到有一定长度的有声段就发送到服务端，服务端先判断是否有声纹注册文件，没有则要求三秒语音段进行声纹注册，有则直接进行CAM++说话人确认，通过说话人确认后再进行关键词识别，这里的关键词识别通过转化为拼音，再通过编辑距离确定相似性以提高识别的准确性，通过关键词识别（语音唤醒）后最后将进行语音识别。</p>
<span id="more"></span>

<hr>
<h2 id="基本融合"><a href="#基本融合" class="headerlink" title="基本融合"></a>基本融合</h2><p>服务端：</p>
<figure class="highlight python"><figcaption><span>cam_senseVoice_server.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> base64</span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> modelscope.pipelines <span class="keyword">import</span> pipeline</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> fastapi.responses <span class="keyword">import</span> JSONResponse</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> soundfile <span class="keyword">as</span> sf</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> funasr <span class="keyword">import</span> AutoModel</span><br><span class="line"><span class="keyword">from</span> funasr.utils.postprocess_utils <span class="keyword">import</span> rich_transcription_postprocess</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = AutoModel(</span><br><span class="line">    model=<span class="string">&quot;iic/SenseVoiceSmall&quot;</span>,</span><br><span class="line">    <span class="comment"># vad_model=&quot;fsmn-vad&quot;,</span></span><br><span class="line">    vad_kwargs=&#123;<span class="string">&quot;max_single_segment_time&quot;</span>: <span class="number">30000</span>&#125;,</span><br><span class="line">    disable_update=<span class="literal">True</span>,</span><br><span class="line">    <span class="comment">#device=&quot;cuda:0&quot;,</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">sv_pipeline = pipeline(</span><br><span class="line">    task=<span class="string">&#x27;speaker-verification&#x27;</span>,</span><br><span class="line">    model=<span class="string">&#x27;iic/speech_campplus_sv_zh_en_16k-common_advanced&#x27;</span>,</span><br><span class="line">    model_revision=<span class="string">&#x27;v1.0.0&#x27;</span>,</span><br><span class="line">    device=<span class="string">&#x27;cpu&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义注册音频目录</span></span><br><span class="line">REGISTERED_DIR = <span class="string">&quot;./registered_audio&quot;</span></span><br><span class="line">REGISTERED_PATH = os.path.join(REGISTERED_DIR, <span class="string">&quot;registered.wav&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建FASTAPI实例</span></span><br><span class="line">app = FastAPI(title=<span class="string">&quot;senseVoice + sv_cam++&quot;</span>)</span><br><span class="line">regist_samples = []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AudioData</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    audio_base64: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查询是否有声纹注册文件</span></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/check/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_registered</span>():</span><br><span class="line">    <span class="keyword">global</span> regist_samples</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(REGISTERED_PATH):</span><br><span class="line">        <span class="keyword">return</span> JSONResponse(status_code=<span class="number">404</span>, content=&#123;<span class="string">&quot;message&quot;</span>: <span class="string">&quot;File not found&quot;</span>&#125;)</span><br><span class="line">    regist_samples, _ = sf.read(REGISTERED_PATH)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;message&quot;</span>: <span class="string">&quot;File exists&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注册声纹</span></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/register/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">register</span>(<span class="params">audio_data: AudioData</span>):</span><br><span class="line">    <span class="keyword">global</span> regist_samples</span><br><span class="line">    <span class="comment"># 1 解析 Base64 编码的音频数据</span></span><br><span class="line">    audio_bytes = base64.b64decode(audio_data.audio_base64)</span><br><span class="line"></span><br><span class="line">    audio_array = np.frombuffer(audio_bytes, dtype=np.int16)</span><br><span class="line"></span><br><span class="line">    regist_samples = audio_array.astype(np.float32) / <span class="number">32768.0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;message&quot;</span>: <span class="string">&quot;Audio saved successfully&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/verify/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sv_endpoint</span>(<span class="params">audio_data: AudioData</span>):</span><br><span class="line">    audio_bytes = base64.b64decode(audio_data.audio_base64)</span><br><span class="line"></span><br><span class="line">    audio_array = np.frombuffer(audio_bytes, dtype=np.int16)</span><br><span class="line"></span><br><span class="line">    current_samples = audio_array.astype(np.float32) / <span class="number">32768.0</span></span><br><span class="line"></span><br><span class="line">    result = sv_pipeline([regist_samples, current_samples], thr=<span class="number">0.35</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;result=<span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> result[<span class="string">&#x27;text&#x27;</span>] == <span class="string">&quot;yes&quot;</span>:</span><br><span class="line">        res = model.generate(</span><br><span class="line">            <span class="built_in">input</span>=audio_bytes,</span><br><span class="line">            cache=&#123;&#125;,</span><br><span class="line">            language=<span class="string">&quot;auto&quot;</span>,  <span class="comment"># &quot;zn&quot;, &quot;en&quot;, &quot;yue&quot;, &quot;ja&quot;, &quot;ko&quot;, &quot;nospeech&quot;</span></span><br><span class="line">            use_itn=<span class="literal">True</span>,</span><br><span class="line">            batch_size_s=<span class="number">60</span>,</span><br><span class="line">            merge_vad=<span class="literal">True</span>,</span><br><span class="line">            merge_length_s=<span class="number">15</span>,</span><br><span class="line">        )</span><br><span class="line">        text = rich_transcription_postprocess(res[<span class="number">0</span>][<span class="string">&quot;text&quot;</span>])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        text = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;text&quot;</span>: text&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">import</span> uvicorn</span><br><span class="line">    uvicorn.run(app, host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="number">8000</span>)</span><br></pre></td></tr></table></figure>

<p><strong>客户端</strong>：</p>
<figure class="highlight python"><figcaption><span>cam_senseVoice_client.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> base64</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> pyaudio</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">from</span> queue <span class="keyword">import</span> Queue</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"></span><br><span class="line">torch.set_num_threads(<span class="number">1</span>)</span><br><span class="line">debug_mode = <span class="literal">False</span>  <span class="comment"># 控制是否保存部分音频及打印信息</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载 Silero VAD 模型</span></span><br><span class="line">model, utils = torch.hub.load(repo_or_dir=<span class="string">&#x27;snakers4/silero-vad&#x27;</span>,</span><br><span class="line">                              model=<span class="string">&#x27;silero_vad&#x27;</span>,</span><br><span class="line">                              trust_repo=<span class="literal">True</span>,</span><br><span class="line">                              onnx=<span class="literal">True</span>,</span><br><span class="line">                              <span class="comment"># force_reload=True</span></span><br><span class="line">                              )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 录音参数</span></span><br><span class="line">FORMAT = pyaudio.paFloat32</span><br><span class="line">CHANNELS = <span class="number">1</span></span><br><span class="line">SAMPLE_RATE = <span class="number">16000</span></span><br><span class="line">num_samples = <span class="number">512</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 PyAudio</span></span><br><span class="line">audio = pyaudio.PyAudio()</span><br><span class="line">stream = audio.<span class="built_in">open</span>(<span class="built_in">format</span>=FORMAT,</span><br><span class="line">                    channels=CHANNELS,</span><br><span class="line">                    rate=SAMPLE_RATE,</span><br><span class="line">                    <span class="built_in">input</span>=<span class="literal">True</span>,</span><br><span class="line">                    frames_per_buffer=num_samples)</span><br><span class="line"></span><br><span class="line">audio_record_queue = Queue()</span><br><span class="line">BASE_URL = <span class="string">&quot;http://127.0.0.1:8000&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">StateManage</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.threshold = <span class="number">0.5</span></span><br><span class="line">        <span class="variable language_">self</span>.min_speech_duration_ms = <span class="number">64</span></span><br><span class="line">        <span class="variable language_">self</span>.min_silence_duration_ms = <span class="number">480</span></span><br><span class="line">        <span class="variable language_">self</span>.pre_chunk_add = <span class="number">4</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">state_manage = StateManage()</span><br><span class="line"></span><br><span class="line">pre_speech_buffer = collections.deque(maxlen=state_manage.min_speech_duration_ms // <span class="number">32</span> + state_manage.pre_chunk_add)</span><br><span class="line"><span class="built_in">print</span>(state_manage.min_speech_duration_ms // <span class="number">32</span> + state_manage.pre_chunk_add)</span><br><span class="line">first_chunk_detected = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">send_audio_to_server</span>(<span class="params">audio_fragment</span>):</span><br><span class="line">    audio_base64 = base64.b64encode(audio_fragment).decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">&#x27;audio_base64&#x27;</span>: audio_base64,</span><br><span class="line">    &#125;</span><br><span class="line">    response = requests.post(<span class="string">f&quot;<span class="subst">&#123;BASE_URL&#125;</span>/verify/&quot;</span>, json=data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> debug_mode:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;response.json()=<span class="subst">&#123;response.json()&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> response.json()[<span class="string">&#x27;text&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">send_audio_to_regist</span>(<span class="params">audio_fragment</span>):</span><br><span class="line">    audio_base64 = base64.b64encode(audio_fragment).decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">&#x27;audio_base64&#x27;</span>: audio_base64,</span><br><span class="line">    &#125;</span><br><span class="line">    response = requests.post(<span class="string">f&quot;<span class="subst">&#123;BASE_URL&#125;</span>/register/&quot;</span>, json=data)</span><br><span class="line">    <span class="keyword">return</span> response.json()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VADContext</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 threshold=<span class="number">0.5</span>,</span></span><br><span class="line"><span class="params">                 min_speech_duration_ms=<span class="number">64</span>,</span></span><br><span class="line"><span class="params">                 min_silence_duration_ms=<span class="number">480</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.threshold = threshold</span><br><span class="line">        <span class="variable language_">self</span>.min_speech_frames = <span class="built_in">int</span>(min_speech_duration_ms * SAMPLE_RATE / <span class="number">1000</span> / num_samples)</span><br><span class="line">        <span class="variable language_">self</span>.min_silence_frames = <span class="built_in">int</span>(min_silence_duration_ms * SAMPLE_RATE / <span class="number">1000</span> / num_samples)</span><br><span class="line">        <span class="variable language_">self</span>.speech_frame_count = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.silence_frame_count = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.is_speech = <span class="literal">False</span></span><br><span class="line">        <span class="variable language_">self</span>.was_speech = <span class="literal">False</span>  <span class="comment"># 跟踪上一帧是否是语音</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, confidence</span>):</span><br><span class="line">        <span class="variable language_">self</span>.was_speech = <span class="variable language_">self</span>.is_speech  <span class="comment"># 保存上一帧的状态</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.is_speech:</span><br><span class="line">            <span class="keyword">if</span> confidence &gt;= <span class="variable language_">self</span>.threshold:</span><br><span class="line">                <span class="variable language_">self</span>.speech_frame_count += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> <span class="variable language_">self</span>.speech_frame_count &gt;= <span class="variable language_">self</span>.min_speech_frames:</span><br><span class="line">                    <span class="variable language_">self</span>.is_speech = <span class="literal">True</span></span><br><span class="line">                    <span class="variable language_">self</span>.silence_frame_count = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.speech_frame_count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> confidence &lt;= <span class="variable language_">self</span>.threshold - <span class="number">0.15</span>:</span><br><span class="line">                <span class="variable language_">self</span>.silence_frame_count += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> <span class="variable language_">self</span>.silence_frame_count &gt;= <span class="variable language_">self</span>.min_silence_frames:</span><br><span class="line">                    <span class="variable language_">self</span>.is_speech = <span class="literal">False</span></span><br><span class="line">                    <span class="variable language_">self</span>.speech_frame_count = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.silence_frame_count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.is_speech</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_speech_end</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;检查是否是语音结束&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.was_speech <span class="keyword">and</span> <span class="keyword">not</span> <span class="variable language_">self</span>.is_speech</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">recording_and_vad_thread</span>():</span><br><span class="line">    <span class="keyword">global</span> first_chunk_detected</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Recording...\n&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">    vad_context = VADContext(</span><br><span class="line">        threshold=state_manage.threshold,</span><br><span class="line">        min_speech_duration_ms=state_manage.min_speech_duration_ms,</span><br><span class="line">        min_silence_duration_ms=state_manage.min_silence_duration_ms,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> debug_mode:</span><br><span class="line">        raw_audio_chunks = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        data = stream.read(num_samples)</span><br><span class="line">        audio_chunk = np.frombuffer(data, dtype=np.float32)</span><br><span class="line">        speech_prob = model(torch.from_numpy(audio_chunk.copy()), SAMPLE_RATE).item()</span><br><span class="line">        is_speech = vad_context.update(speech_prob)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 放入缓冲区</span></span><br><span class="line">        pre_speech_buffer.append(audio_chunk)</span><br><span class="line">        <span class="keyword">if</span> is_speech:</span><br><span class="line">            <span class="comment"># 如果刚检测到语音</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> first_chunk_detected:</span><br><span class="line">                first_chunk_detected = <span class="literal">True</span></span><br><span class="line">                <span class="keyword">while</span> pre_speech_buffer:</span><br><span class="line">                    pre_chunk = pre_speech_buffer.popleft()</span><br><span class="line">                    int16_chunk = (pre_chunk * <span class="number">32767</span>).astype(np.int16)</span><br><span class="line">                    audio_record_queue.put(int16_chunk)</span><br><span class="line">                    <span class="keyword">if</span> debug_mode:</span><br><span class="line">                        raw_audio_chunks.append(int16_chunk)  <span class="comment"># 保存原始数据</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                audio_chunk_int16 = (audio_chunk * <span class="number">32767</span>).astype(np.int16)</span><br><span class="line">                audio_record_queue.put(audio_chunk_int16)</span><br><span class="line">                <span class="keyword">if</span> debug_mode:</span><br><span class="line">                    raw_audio_chunks.append(audio_chunk_int16)   <span class="comment"># 保存原始数据</span></span><br><span class="line">        <span class="keyword">elif</span> vad_context.is_speech_end():</span><br><span class="line">            audio_record_queue.put(<span class="literal">None</span>)</span><br><span class="line">            first_chunk_detected = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> debug_mode <span class="keyword">and</span> raw_audio_chunks:</span><br><span class="line">                raw_audio_data = np.concatenate(raw_audio_chunks)</span><br><span class="line">                sf.write(<span class="string">&quot;debug_raw_audio.wav&quot;</span>, raw_audio_data, samplerate=<span class="number">16000</span>, subtype=<span class="string">&quot;PCM_16&quot;</span>)</span><br><span class="line">                raw_audio_chunks.clear()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动录音线程</span></span><br><span class="line">recording_thread = threading.Thread(target=recording_and_vad_thread, daemon=<span class="literal">True</span>)</span><br><span class="line">recording_thread.start()</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> soundfile <span class="keyword">as</span> sf</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">send_audio</span>():</span><br><span class="line">    audio_chunks = []</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        chunk = audio_record_queue.get()</span><br><span class="line">        <span class="keyword">if</span> chunk <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> audio_chunks:</span><br><span class="line">                audio_data = np.concatenate(audio_chunks)</span><br><span class="line">                <span class="keyword">if</span> debug_mode:</span><br><span class="line">                    sf.write(<span class="string">&quot;audio.wav&quot;</span>, audio_data, samplerate=<span class="number">16000</span>, subtype=<span class="string">&quot;PCM_16&quot;</span>)</span><br><span class="line">                audio_data_bytes = audio_data.tobytes()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 发送到ASR服务器</span></span><br><span class="line">                result = send_audio_to_server(audio_data_bytes)</span><br><span class="line"></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;result: <span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">                audio_chunks.clear()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            audio_chunks.append(chunk)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">regist_voice</span>():</span><br><span class="line">    audio_chunks = []</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        chunk = audio_record_queue.get()</span><br><span class="line">        <span class="keyword">if</span> chunk <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> audio_chunks:</span><br><span class="line">                audio_data = np.concatenate(audio_chunks)</span><br><span class="line">                audio_data_bytes = audio_data.tobytes()</span><br><span class="line">                <span class="keyword">if</span> debug_mode:</span><br><span class="line">                    sf.write(<span class="string">&quot;regist.wav&quot;</span>, audio_data, samplerate=<span class="number">16000</span>, subtype=<span class="string">&quot;PCM_16&quot;</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 发送到sv服务器</span></span><br><span class="line">                result = send_audio_to_regist(audio_data_bytes)</span><br><span class="line">                <span class="keyword">if</span> result <span class="keyword">and</span> result[<span class="string">&quot;message&quot;</span>] == <span class="string">&quot;Audio saved successfully&quot;</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&quot;声纹注册成功，让我们开始交流吧！&quot;</span>)</span><br><span class="line"></span><br><span class="line">                audio_chunks.clear()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            audio_chunks.append(chunk)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 先查询是否有注册文件</span></span><br><span class="line">    response = requests.get(<span class="string">f&quot;<span class="subst">&#123;BASE_URL&#125;</span>/check/&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;已开启声纹识别&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">elif</span> response.status_code == <span class="number">404</span>:   <span class="comment"># 没有注册文件就提示并注册声纹</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;缺少声纹注册文件，请说一段3 S左右语音以注册声纹。&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;录音中&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">        regist_voice()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;出错&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    send_audio()</span><br></pre></td></tr></table></figure>

<img src="/2025/02/21/cam-senseVoice%E6%9E%84%E5%BB%BA%E5%BE%AE%E6%9C%8D%E5%8A%A1/image-20250222141147476.png" class="" title="image-20250222141147476">

<p>注意事项：</p>
<ul>
<li>这里使用的说话人确认的阈值是3.5（因为测试人员与我的声音分数达到了3.3+）</li>
<li>对于两个人说话间隔很短（或基本无间隔）的情况下，可以理解为发送到服务器的语音前一段是我的语音，后一段是测试人员的语音，这种情况也有可能超过阈值，进而进行处理</li>
<li>是在我的笔记本电脑（3060显卡）上做的实验，也测试了torch可以使用GPU，但是实际发现服务端代码使用GPU或CPU在运行速度上人肉察觉不到速度变化（后续部署在服务器上再加代码统计时间吧）</li>
</ul>
<h2 id="小的有趣扩展"><a href="#小的有趣扩展" class="headerlink" title="小的有趣扩展"></a>小的有趣扩展</h2><p>在上文基础上增加上类似于关键词识别的功能，在开始之前，先写个示例demo测试下即将添加的小功能：</p>
<figure class="highlight python"><figcaption><span>pinyin_kws.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pypinyin</span><br><span class="line"><span class="keyword">import</span> Levenshtein</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">similarity_score</span>(<span class="params">pinyin1, pinyin2</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;计算两个拼音序列的相似度，越接近1越相似&quot;&quot;&quot;</span></span><br><span class="line">    distance = Levenshtein.distance(<span class="string">&quot;&quot;</span>.join(pinyin1), <span class="string">&quot;&quot;</span>.join(pinyin2))</span><br><span class="line">    max_len = <span class="built_in">max</span>(<span class="built_in">len</span>(pinyin1), <span class="built_in">len</span>(pinyin2))</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> - distance / max_len <span class="keyword">if</span> max_len &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">is_wakeup_word</span>(<span class="params">asr_pinyin, wake_pinyin_list, threshold=<span class="number">0.8</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;判断ASR拼音结果是否匹配唤醒词拼音&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> word_pinyin <span class="keyword">in</span> wake_pinyin_list:</span><br><span class="line">        score = similarity_score(asr_pinyin, word_pinyin)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;score=<span class="subst">&#123;score&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> score &gt;= threshold:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例：</span></span><br><span class="line">wake_words = [<span class="string">&quot;你好小熊&quot;</span>, <span class="string">&quot;小熊小熊&quot;</span>]</span><br><span class="line">wake_pinyin_list = [[p[<span class="number">0</span>] <span class="keyword">for</span> p <span class="keyword">in</span> pypinyin.pinyin(word, style=pypinyin.NORMAL)] <span class="keyword">for</span> word <span class="keyword">in</span> wake_words]</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    asr_text = <span class="built_in">input</span>(<span class="string">&quot;请输入ASR识别结果: &quot;</span>)  <span class="comment"># 这里用ASR模块替换</span></span><br><span class="line">    asr_pinyin = [p[<span class="number">0</span>] <span class="keyword">for</span> p <span class="keyword">in</span> pypinyin.pinyin(asr_text, style=pypinyin.NORMAL)]</span><br><span class="line">    <span class="keyword">if</span> is_wakeup_word(asr_pinyin, wake_pinyin_list):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;唤醒成功！&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;未唤醒&quot;</span>)</span><br></pre></td></tr></table></figure>

<img src="/2025/02/21/cam-senseVoice%E6%9E%84%E5%BB%BA%E5%BE%AE%E6%9C%8D%E5%8A%A1/image-20250222153210894.png" class="" title="image-20250222153210894">

<p>思路：</p>
<ul>
<li>将语音识别结果和预先定义的关键词都先转化为拼音</li>
<li>然后再计算两个拼音的相似度</li>
<li>如果得分大于事先设定的阈值，就认为唤醒成功，否则失败</li>
<li>Levenshtein.distance，Levenshtein 距离（编辑距离）是一种<strong>字符串相似度度量方法</strong>，用于计算<strong>将一个字符串变为另一个字符串所需的最少编辑操作次数</strong>，包括替换、插入、删除。</li>
<li>会将语音识别结果与每个预定义的关键词进行相似度匹配，所以上面会输出两个分数（两会关键词），若第一个关键词就匹配上了，那只输出一个分数。</li>
</ul>
<p>好的，现在把上面代码融起来，这里只用改服务端代码：</p>
<figure class="highlight python"><figcaption><span>cam_senseVoice_kws_server.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> base64</span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> modelscope.pipelines <span class="keyword">import</span> pipeline</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> fastapi.responses <span class="keyword">import</span> JSONResponse</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> soundfile <span class="keyword">as</span> sf</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> funasr <span class="keyword">import</span> AutoModel</span><br><span class="line"><span class="keyword">from</span> funasr.utils.postprocess_utils <span class="keyword">import</span> rich_transcription_postprocess</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pypinyin</span><br><span class="line"><span class="keyword">import</span> Levenshtein</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">similarity_score</span>(<span class="params">pinyin1, pinyin2</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;计算两个拼音序列的相似度，越接近1越相似&quot;&quot;&quot;</span></span><br><span class="line">    distance = Levenshtein.distance(<span class="string">&quot;&quot;</span>.join(pinyin1), <span class="string">&quot;&quot;</span>.join(pinyin2))</span><br><span class="line">    max_len = <span class="built_in">max</span>(<span class="built_in">len</span>(pinyin1), <span class="built_in">len</span>(pinyin2))</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> - distance / max_len <span class="keyword">if</span> max_len &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">is_wakeup_word</span>(<span class="params">asr_pinyin, wake_pinyin_list, threshold=<span class="number">0.8</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;判断ASR拼音结果是否匹配唤醒词拼音&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> word_pinyin <span class="keyword">in</span> wake_pinyin_list:</span><br><span class="line">        score = similarity_score(asr_pinyin, word_pinyin)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;score=<span class="subst">&#123;score&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> score &gt;= threshold:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例：</span></span><br><span class="line">wake_words = [<span class="string">&quot;你好小熊&quot;</span>, <span class="string">&quot;小熊小熊&quot;</span>]</span><br><span class="line">wake_pinyin_list = [[p[<span class="number">0</span>] <span class="keyword">for</span> p <span class="keyword">in</span> pypinyin.pinyin(word, style=pypinyin.NORMAL)] <span class="keyword">for</span> word <span class="keyword">in</span> wake_words]</span><br><span class="line">wake_flag = <span class="literal">False</span>    <span class="comment"># 是否已经触发过关键词唤醒</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = AutoModel(</span><br><span class="line">    model=<span class="string">&quot;iic/SenseVoiceSmall&quot;</span>,</span><br><span class="line">    <span class="comment"># vad_model=&quot;fsmn-vad&quot;,</span></span><br><span class="line">    vad_kwargs=&#123;<span class="string">&quot;max_single_segment_time&quot;</span>: <span class="number">30000</span>&#125;,</span><br><span class="line">    disable_update=<span class="literal">True</span>,</span><br><span class="line">    <span class="comment">#device=&quot;cuda:0&quot;,</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">sv_pipeline = pipeline(</span><br><span class="line">    task=<span class="string">&#x27;speaker-verification&#x27;</span>,</span><br><span class="line">    model=<span class="string">&#x27;iic/speech_campplus_sv_zh_en_16k-common_advanced&#x27;</span>,</span><br><span class="line">    model_revision=<span class="string">&#x27;v1.0.0&#x27;</span>,</span><br><span class="line">    device=<span class="string">&#x27;cpu&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义注册音频目录</span></span><br><span class="line">REGISTERED_DIR = <span class="string">&quot;./registered_audio&quot;</span></span><br><span class="line">REGISTERED_PATH = os.path.join(REGISTERED_DIR, <span class="string">&quot;registered.wav&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建FASTAPI实例</span></span><br><span class="line">app = FastAPI(title=<span class="string">&quot;senseVoice + sv_cam++&quot;</span>)</span><br><span class="line">regist_samples = []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AudioData</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    audio_base64: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查询是否有声纹注册文件</span></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/check/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_registered</span>():</span><br><span class="line">    <span class="keyword">global</span> regist_samples</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(REGISTERED_PATH):</span><br><span class="line">        <span class="keyword">return</span> JSONResponse(status_code=<span class="number">404</span>, content=&#123;<span class="string">&quot;message&quot;</span>: <span class="string">&quot;File not found&quot;</span>&#125;)</span><br><span class="line">    regist_samples, _ = sf.read(REGISTERED_PATH)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;message&quot;</span>: <span class="string">&quot;File exists&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注册声纹</span></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/register/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">register</span>(<span class="params">audio_data: AudioData</span>):</span><br><span class="line">    <span class="keyword">global</span> regist_samples</span><br><span class="line">    <span class="comment"># 1 解析 Base64 编码的音频数据</span></span><br><span class="line">    audio_bytes = base64.b64decode(audio_data.audio_base64)</span><br><span class="line"></span><br><span class="line">    audio_array = np.frombuffer(audio_bytes, dtype=np.int16)</span><br><span class="line"></span><br><span class="line">    regist_samples = audio_array.astype(np.float32) / <span class="number">32768.0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;message&quot;</span>: <span class="string">&quot;Audio saved successfully&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/verify/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sv_endpoint</span>(<span class="params">audio_data: AudioData</span>):</span><br><span class="line">    <span class="keyword">global</span> wake_flag</span><br><span class="line">    audio_bytes = base64.b64decode(audio_data.audio_base64)</span><br><span class="line"></span><br><span class="line">    audio_array = np.frombuffer(audio_bytes, dtype=np.int16)</span><br><span class="line"></span><br><span class="line">    current_samples = audio_array.astype(np.float32) / <span class="number">32768.0</span></span><br><span class="line"></span><br><span class="line">    result = sv_pipeline([regist_samples, current_samples], thr=<span class="number">0.35</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;result=<span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> result[<span class="string">&#x27;text&#x27;</span>] == <span class="string">&quot;yes&quot;</span>:</span><br><span class="line">        res = model.generate(</span><br><span class="line">            <span class="built_in">input</span>=audio_bytes,</span><br><span class="line">            cache=&#123;&#125;,</span><br><span class="line">            language=<span class="string">&quot;auto&quot;</span>,  <span class="comment"># &quot;zn&quot;, &quot;en&quot;, &quot;yue&quot;, &quot;ja&quot;, &quot;ko&quot;, &quot;nospeech&quot;</span></span><br><span class="line">            use_itn=<span class="literal">True</span>,</span><br><span class="line">            batch_size_s=<span class="number">60</span>,</span><br><span class="line">            merge_vad=<span class="literal">True</span>,</span><br><span class="line">            merge_length_s=<span class="number">15</span>,</span><br><span class="line">        )</span><br><span class="line">        text = rich_transcription_postprocess(res[<span class="number">0</span>][<span class="string">&quot;text&quot;</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 判断是否触发过关键词唤醒</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> wake_flag:</span><br><span class="line">            asr_pinyin = [p[<span class="number">0</span>] <span class="keyword">for</span> p <span class="keyword">in</span> pypinyin.pinyin(text, style=pypinyin.NORMAL)]</span><br><span class="line">            <span class="keyword">if</span> is_wakeup_word(asr_pinyin, wake_pinyin_list):</span><br><span class="line">                wake_flag = <span class="literal">True</span></span><br><span class="line">                <span class="keyword">return</span> &#123;<span class="string">&quot;text&quot;</span>: <span class="string">&quot;唤醒成功，现在我们可以交流啦！&quot;</span>&#125;</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> &#123;<span class="string">&quot;text&quot;</span>: <span class="string">&quot;关键词错误，唤醒失败...&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        text = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;text&quot;</span>: text&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">import</span> uvicorn</span><br><span class="line">    uvicorn.run(app, host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="number">8000</span>)</span><br></pre></td></tr></table></figure>

<img src="/2025/02/21/cam-senseVoice%E6%9E%84%E5%BB%BA%E5%BE%AE%E6%9C%8D%E5%8A%A1/image-20250222161254018.png" class="" title="image-20250222161254018">

<p>好的，下一节我们将接入大语言模型（LLM），实现对话功能…😄</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://www.bilibili.com/video/BV1Q6zpYpEgv/?spm_id_from=333.1007.top_right_bar_window_history.content.click&vd_source=075a061948e76c87e2ee8754e264056e">https://www.bilibili.com/video/BV1Q6zpYpEgv/?spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;vd_source=075a061948e76c87e2ee8754e264056e</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>funasr</tag>
        <tag>sensevoice</tag>
        <tag>cam++</tag>
        <tag>fastapi</tag>
        <tag>speaker verification</tag>
        <tag>sv</tag>
      </tags>
  </entry>
  <entry>
    <title>Unsloth:Phi-4+GRPO将通用模型微调成推理模型</title>
    <url>/2025/04/08/Unsloth-Phi-4-GRPO%E5%B0%86%E9%80%9A%E7%94%A8%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E6%88%90%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前面<a href="https://caihaoran-00.github.io/2025/03/25/%E5%A6%82%E4%BD%95%E5%B0%86%E4%BD%A0%E7%9A%84DeepSeek-R1%E5%BE%AE%E8%B0%83%E6%88%90%E6%9F%90%E4%B8%AA%E9%A2%86%E5%9F%9F%E7%9A%84%E4%B8%93%E5%AE%B6%EF%BC%88%E5%AE%9E%E6%88%98%E7%AF%87%EF%BC%89/#%E5%89%8D%E8%A8%80">如何将你的DeepSeek-R1微调成某个领域的专家（实战篇）</a>浅浅的使用<code>Unsloth</code>微调了<code>DeepSeek-R1-Distill-Llama-8B</code>模型，在了解<code>Unsloth</code>框架时，发现还有示例使用<code>GRPO</code>将普通大语言模型转化为推理大语言模型，有趣，咱们一起看一下吧。</p>
<span id="more"></span>

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>首先，先克隆模型到本地：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://huggingface.co/unsloth/phi-4-unsloth-bnb-4bit</span><br></pre></td></tr></table></figure>

<p>耐心等待，然后打开你的<code>jupyter notebook</code>(关于环境配置和部分代码解释请看<a href="https://caihaoran-00.github.io/2025/03/25/%E5%A6%82%E4%BD%95%E5%B0%86%E4%BD%A0%E7%9A%84DeepSeek-R1%E5%BE%AE%E8%B0%83%E6%88%90%E6%9F%90%E4%B8%AA%E9%A2%86%E5%9F%9F%E7%9A%84%E4%B8%93%E5%AE%B6%EF%BC%88%E5%AE%9E%E6%88%98%E7%AF%87%EF%BC%89/#%E5%89%8D%E8%A8%80">这里</a>)：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">jupyter notebook</span><br></pre></td></tr></table></figure>

<p><strong>第一块：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> unsloth <span class="keyword">import</span> FastLanguageModel, is_bfloat16_supported</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">max_seq_length = <span class="number">512</span> <span class="comment"># Can increase for longer reasoning traces</span></span><br><span class="line">lora_rank = <span class="number">16</span> <span class="comment"># Larger rank = smarter, but slower</span></span><br><span class="line"></span><br><span class="line">model, tokenizer = FastLanguageModel.from_pretrained(</span><br><span class="line">    model_name = <span class="string">&quot;../phi-4-unsloth-bnb-4bit&quot;</span>,	 <span class="comment"># 根据自己的路径来</span></span><br><span class="line">    max_seq_length = max_seq_length,</span><br><span class="line">    load_in_4bit = <span class="literal">True</span>, <span class="comment"># False for LoRA 16bit</span></span><br><span class="line">    fast_inference = <span class="literal">True</span>, <span class="comment"># Enable vLLM fast inference</span></span><br><span class="line">    max_lora_rank = lora_rank,</span><br><span class="line">    gpu_memory_utilization = <span class="number">0.7</span>, <span class="comment"># Reduce if out of memory</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model = FastLanguageModel.get_peft_model(</span><br><span class="line">    model,</span><br><span class="line">    r = lora_rank, <span class="comment"># Choose any number &gt; 0 ! Suggested 8, 16, 32, 64, 128</span></span><br><span class="line">    target_modules = [<span class="string">&quot;gate_proj&quot;</span>, <span class="string">&quot;up_proj&quot;</span>, <span class="string">&quot;down_proj&quot;</span>,],</span><br><span class="line">    lora_alpha = lora_rank,</span><br><span class="line">    use_gradient_checkpointing = <span class="string">&quot;unsloth&quot;</span>, <span class="comment"># Enable long context finetuning</span></span><br><span class="line">    random_state = <span class="number">3407</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>这段代码利用 <code>unsloth</code> 库，高效地加载了一个预先被 4 位量化的 <code>Phi-4</code> 大语言模型，并为其配置了 <code>LoRA</code> 适配器。通过指定 <code>LoRA</code> 的秩、目标模块和 <code>alpha</code> 值，并启用<code>梯度检查点</code>，代码为后续使用较少计算资源进行模型微调做好了准备。最终得到的 model 对象是一个<code>PEFT 模型</code>，可以直接用于基于 <code>LoRA</code> 的训练流程。</p>
<p><strong>第二块：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset, Dataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load and prep dataset</span></span><br><span class="line">SYSTEM_PROMPT = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Respond in the following format:</span></span><br><span class="line"><span class="string">&lt;reasoning&gt;</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">&lt;/reasoning&gt;</span></span><br><span class="line"><span class="string">&lt;answer&gt;</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">&lt;/answer&gt;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">XML_COT_FORMAT = <span class="string">&quot;&quot;&quot;\</span></span><br><span class="line"><span class="string">&lt;reasoning&gt;</span></span><br><span class="line"><span class="string">&#123;reasoning&#125;</span></span><br><span class="line"><span class="string">&lt;/reasoning&gt;</span></span><br><span class="line"><span class="string">&lt;answer&gt;</span></span><br><span class="line"><span class="string">&#123;answer&#125;</span></span><br><span class="line"><span class="string">&lt;/answer&gt;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_xml_answer</span>(<span class="params">text: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    answer = text.split(<span class="string">&quot;&lt;answer&gt;&quot;</span>)[-<span class="number">1</span>]</span><br><span class="line">    answer = answer.split(<span class="string">&quot;&lt;/answer&gt;&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> answer.strip()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_hash_answer</span>(<span class="params">text: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span> | <span class="literal">None</span>:</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&quot;####&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> text:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">return</span> text.split(<span class="string">&quot;####&quot;</span>)[<span class="number">1</span>].strip()</span><br><span class="line"></span><br><span class="line"><span class="comment"># uncomment middle messages for 1-shot prompting</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_gsm8k_questions</span>(<span class="params">split = <span class="string">&quot;train&quot;</span></span>) -&gt; Dataset:</span><br><span class="line">    data = load_dataset(<span class="string">&#x27;openai/gsm8k&#x27;</span>, <span class="string">&#x27;main&#x27;</span>)[split] <span class="comment"># type: ignore</span></span><br><span class="line">    data = data.<span class="built_in">map</span>(<span class="keyword">lambda</span> x: &#123; <span class="comment"># type: ignore</span></span><br><span class="line">        <span class="string">&#x27;prompt&#x27;</span>: [</span><br><span class="line">            &#123;<span class="string">&#x27;role&#x27;</span>: <span class="string">&#x27;system&#x27;</span>, <span class="string">&#x27;content&#x27;</span>: SYSTEM_PROMPT&#125;,</span><br><span class="line">            &#123;<span class="string">&#x27;role&#x27;</span>: <span class="string">&#x27;user&#x27;</span>, <span class="string">&#x27;content&#x27;</span>: x[<span class="string">&#x27;question&#x27;</span>]&#125;</span><br><span class="line">        ],</span><br><span class="line">        <span class="string">&#x27;answer&#x27;</span>: extract_hash_answer(x[<span class="string">&#x27;answer&#x27;</span>])</span><br><span class="line">    &#125;) <span class="comment"># type: ignore</span></span><br><span class="line">    <span class="keyword">return</span> data <span class="comment"># type: ignore</span></span><br><span class="line"></span><br><span class="line">dataset = get_gsm8k_questions()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Reward functions</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">correctness_reward_func</span>(<span class="params">prompts, completions, answer, **kwargs</span>) -&gt; <span class="built_in">list</span>[<span class="built_in">float</span>]:</span><br><span class="line">    responses = [completion[<span class="number">0</span>][<span class="string">&#x27;content&#x27;</span>] <span class="keyword">for</span> completion <span class="keyword">in</span> completions]</span><br><span class="line">    q = prompts[<span class="number">0</span>][-<span class="number">1</span>][<span class="string">&#x27;content&#x27;</span>]</span><br><span class="line">    extracted_responses = [extract_xml_answer(r) <span class="keyword">for</span> r <span class="keyword">in</span> responses]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span>*<span class="number">20</span>, <span class="string">f&quot;Question:\n<span class="subst">&#123;q&#125;</span>&quot;</span>, <span class="string">f&quot;\nAnswer:\n<span class="subst">&#123;answer[<span class="number">0</span>]&#125;</span>&quot;</span>, <span class="string">f&quot;\nResponse:\n<span class="subst">&#123;responses[<span class="number">0</span>]&#125;</span>&quot;</span>, <span class="string">f&quot;\nExtracted:\n<span class="subst">&#123;extracted_responses[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> [<span class="number">2.0</span> <span class="keyword">if</span> r == a <span class="keyword">else</span> <span class="number">0.0</span> <span class="keyword">for</span> r, a <span class="keyword">in</span> <span class="built_in">zip</span>(extracted_responses, answer)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">int_reward_func</span>(<span class="params">completions, **kwargs</span>) -&gt; <span class="built_in">list</span>[<span class="built_in">float</span>]:</span><br><span class="line">    responses = [completion[<span class="number">0</span>][<span class="string">&#x27;content&#x27;</span>] <span class="keyword">for</span> completion <span class="keyword">in</span> completions]</span><br><span class="line">    extracted_responses = [extract_xml_answer(r) <span class="keyword">for</span> r <span class="keyword">in</span> responses]</span><br><span class="line">    <span class="keyword">return</span> [<span class="number">0.5</span> <span class="keyword">if</span> r.isdigit() <span class="keyword">else</span> <span class="number">0.0</span> <span class="keyword">for</span> r <span class="keyword">in</span> extracted_responses]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">strict_format_reward_func</span>(<span class="params">completions, **kwargs</span>) -&gt; <span class="built_in">list</span>[<span class="built_in">float</span>]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Reward function that checks if the completion has a specific format.&quot;&quot;&quot;</span></span><br><span class="line">    pattern = <span class="string">r&quot;^&lt;reasoning&gt;\n.*?\n&lt;/reasoning&gt;\n&lt;answer&gt;\n.*?\n&lt;/answer&gt;\n$&quot;</span></span><br><span class="line">    responses = [completion[<span class="number">0</span>][<span class="string">&quot;content&quot;</span>] <span class="keyword">for</span> completion <span class="keyword">in</span> completions]</span><br><span class="line">    matches = [re.<span class="keyword">match</span>(pattern, r) <span class="keyword">for</span> r <span class="keyword">in</span> responses]</span><br><span class="line">    <span class="keyword">return</span> [<span class="number">0.5</span> <span class="keyword">if</span> <span class="keyword">match</span> <span class="keyword">else</span> <span class="number">0.0</span> <span class="keyword">for</span> <span class="keyword">match</span> <span class="keyword">in</span> matches]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">soft_format_reward_func</span>(<span class="params">completions, **kwargs</span>) -&gt; <span class="built_in">list</span>[<span class="built_in">float</span>]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Reward function that checks if the completion has a specific format.&quot;&quot;&quot;</span></span><br><span class="line">    pattern = <span class="string">r&quot;&lt;reasoning&gt;.*?&lt;/reasoning&gt;\s*&lt;answer&gt;.*?&lt;/answer&gt;&quot;</span></span><br><span class="line">    responses = [completion[<span class="number">0</span>][<span class="string">&quot;content&quot;</span>] <span class="keyword">for</span> completion <span class="keyword">in</span> completions]</span><br><span class="line">    matches = [re.<span class="keyword">match</span>(pattern, r) <span class="keyword">for</span> r <span class="keyword">in</span> responses]</span><br><span class="line">    <span class="keyword">return</span> [<span class="number">0.5</span> <span class="keyword">if</span> <span class="keyword">match</span> <span class="keyword">else</span> <span class="number">0.0</span> <span class="keyword">for</span> <span class="keyword">match</span> <span class="keyword">in</span> matches]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">count_xml</span>(<span class="params">text</span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">    count = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">if</span> text.count(<span class="string">&quot;&lt;reasoning&gt;\n&quot;</span>) == <span class="number">1</span>:</span><br><span class="line">        count += <span class="number">0.125</span></span><br><span class="line">    <span class="keyword">if</span> text.count(<span class="string">&quot;\n&lt;/reasoning&gt;\n&quot;</span>) == <span class="number">1</span>:</span><br><span class="line">        count += <span class="number">0.125</span></span><br><span class="line">    <span class="keyword">if</span> text.count(<span class="string">&quot;\n&lt;answer&gt;\n&quot;</span>) == <span class="number">1</span>:</span><br><span class="line">        count += <span class="number">0.125</span></span><br><span class="line">        count -= <span class="built_in">len</span>(text.split(<span class="string">&quot;\n&lt;/answer&gt;\n&quot;</span>)[-<span class="number">1</span>])*<span class="number">0.001</span></span><br><span class="line">    <span class="keyword">if</span> text.count(<span class="string">&quot;\n&lt;/answer&gt;&quot;</span>) == <span class="number">1</span>:</span><br><span class="line">        count += <span class="number">0.125</span></span><br><span class="line">        count -= (<span class="built_in">len</span>(text.split(<span class="string">&quot;\n&lt;/answer&gt;&quot;</span>)[-<span class="number">1</span>]) - <span class="number">1</span>)*<span class="number">0.001</span></span><br><span class="line">    <span class="keyword">return</span> count</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">xmlcount_reward_func</span>(<span class="params">completions, **kwargs</span>) -&gt; <span class="built_in">list</span>[<span class="built_in">float</span>]:</span><br><span class="line">    contents = [completion[<span class="number">0</span>][<span class="string">&quot;content&quot;</span>] <span class="keyword">for</span> completion <span class="keyword">in</span> completions]</span><br><span class="line">    <span class="keyword">return</span> [count_xml(c) <span class="keyword">for</span> c <span class="keyword">in</span> contents]</span><br></pre></td></tr></table></figure>

<p>这段代码为基于 <code>GSM8k</code> 数据集<code>微调 LLM</code> 做准备，特别是针对需要模型生成带有推理过程（Chain-of-Thought）和答案的特定 XML 格式输出的任务。它加载数据、将其转换为适合模型的对话格式，并定义了多种奖励函数。根据答案正确性、数字格式、XML 结构符合度（严格或宽松）以及结构完整性等多个维度来评估和指导模型的学习。</p>
<p><strong>第三块：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> trl <span class="keyword">import</span> GRPOConfig, GRPOTrainer</span><br><span class="line">training_args = GRPOConfig(</span><br><span class="line">    use_vllm = <span class="literal">True</span>, <span class="comment"># use vLLM for fast inference!</span></span><br><span class="line">    learning_rate = <span class="number">5e-6</span>,</span><br><span class="line">    adam_beta1 = <span class="number">0.9</span>,</span><br><span class="line">    adam_beta2 = <span class="number">0.99</span>,</span><br><span class="line">    weight_decay = <span class="number">0.1</span>,</span><br><span class="line">    warmup_ratio = <span class="number">0.1</span>,</span><br><span class="line">    lr_scheduler_type = <span class="string">&quot;cosine&quot;</span>,</span><br><span class="line">    optim = <span class="string">&quot;paged_adamw_8bit&quot;</span>,</span><br><span class="line">    logging_steps = <span class="number">1</span>,</span><br><span class="line">    bf16 = is_bfloat16_supported(),</span><br><span class="line">    fp16 = <span class="keyword">not</span> is_bfloat16_supported(),</span><br><span class="line">    per_device_train_batch_size = <span class="number">1</span>,</span><br><span class="line">    gradient_accumulation_steps = <span class="number">1</span>, <span class="comment"># Increase to 4 for smoother training</span></span><br><span class="line">    num_generations = <span class="number">6</span>, <span class="comment"># Decrease if out of memory</span></span><br><span class="line">    max_prompt_length = <span class="number">256</span>,</span><br><span class="line">    max_completion_length = <span class="number">200</span>,</span><br><span class="line">    <span class="comment"># num_train_epochs = 1, # Set to 1 for a full training run</span></span><br><span class="line">    max_steps = <span class="number">100</span>,</span><br><span class="line">    save_steps = <span class="number">250</span>,</span><br><span class="line">    max_grad_norm = <span class="number">0.1</span>,</span><br><span class="line">    report_to = <span class="string">&quot;none&quot;</span>, <span class="comment"># Can use Weights &amp; Biases</span></span><br><span class="line">    output_dir = <span class="string">&quot;outputs&quot;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>这个 GRPOConfig 配置了一个旨在进行 <strong>内存高效</strong> 且 <strong>快速</strong>（利用 vLLM）的 GRPO 偏好优化训练过程。它使用了 8 位分页优化器、混合精度（优先 bf16）、小批次大小（但注释建议增加梯度累积）、学习率预热和余弦衰减、梯度裁剪等常见技术。训练被设置为一个较短的运行（100 步），并配置了内部生成过程的参数（生成数量、最大长度）。日志记录非常频繁，但外部报告被禁用。这个配置适合在资源受限的环境下进行实验或快速迭代。</p>
<p><strong>第四块：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trainer = GRPOTrainer(</span><br><span class="line">model = model,</span><br><span class="line">processing_class = tokenizer,</span><br><span class="line">reward_funcs = [</span><br><span class="line">xmlcount_reward_func,</span><br><span class="line">soft_format_reward_func,</span><br><span class="line">strict_format_reward_func,</span><br><span class="line">int_reward_func,</span><br><span class="line">correctness_reward_func,</span><br><span class="line">],</span><br><span class="line">args = training_args,</span><br><span class="line">train_dataset = dataset,</span><br><span class="line">)</span><br><span class="line">trainer.train()</span><br></pre></td></tr></table></figure>

<p>这段代码使用前面定义的模型、分词器、奖励函数和训练参数来实例化并启动 GRPOTrainer。整合了前面所有的准备工作（模型加载与 PEFT 配置、数据准备、奖励函数定义、训练参数设置），创建了一个 GRPOTrainer 实例。然后通过调用 trainer.train()，启动了一个基于偏好优化的训练过程。该过程旨在微调 LoRA 适配器，使基础模型（Phi-4）在保持其原有能力的同时，更好地生成符合 GSM8k 数据集要求、具有特定 XML 格式（包含推理过程和答案）、且答案尽可能正确的响应。训练过程利用了多种奖励信号来从不同角度指导模型的学习。</p>
<p><strong>第五块：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">text = tokenizer.apply_chat_template([</span><br><span class="line">&#123;<span class="string">&quot;role&quot;</span> : <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span> : <span class="string">&quot;Which is bigger? 9.11 or 9.9?&quot;</span>&#125;,</span><br><span class="line">], tokenize = <span class="literal">False</span>, add_generation_prompt = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> vllm <span class="keyword">import</span> SamplingParams</span><br><span class="line">sampling_params = SamplingParams(</span><br><span class="line">temperature = <span class="number">0.8</span>,</span><br><span class="line">top_p = <span class="number">0.95</span>,</span><br><span class="line">max_tokens = <span class="number">1024</span>,</span><br><span class="line">)</span><br><span class="line">output = model.fast_generate(</span><br><span class="line">[text],</span><br><span class="line">sampling_params = sampling_params,</span><br><span class="line">lora_request = <span class="literal">None</span>,</span><br><span class="line">)[<span class="number">0</span>].outputs[<span class="number">0</span>].text</span><br><span class="line"></span><br><span class="line">output</span><br></pre></td></tr></table></figure>

<p>这行代码的作用是在打印 原始模型输出的output 变量的值，也就是原始模型生成的最终文本响应。</p>
<p><strong>第六块：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.save_lora(<span class="string">&quot;grpo_saved_lora&quot;</span>)</span><br><span class="line"></span><br><span class="line">text = tokenizer.apply_chat_template([</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span> : <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span> : SYSTEM_PROMPT&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span> : <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span> : <span class="string">&quot;Which is bigger? 9.11 or 9.9?&quot;</span>&#125;,</span><br><span class="line">], tokenize = <span class="literal">False</span>, add_generation_prompt = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> vllm <span class="keyword">import</span> SamplingParams</span><br><span class="line">sampling_params = SamplingParams(</span><br><span class="line">    temperature = <span class="number">0.8</span>,</span><br><span class="line">    top_p = <span class="number">0.95</span>,</span><br><span class="line">    max_tokens = <span class="number">1024</span>,</span><br><span class="line">)</span><br><span class="line">output = model.fast_generate(</span><br><span class="line">    text,</span><br><span class="line">    sampling_params = sampling_params,</span><br><span class="line">    lora_request = model.load_lora(<span class="string">&quot;grpo_saved_lora&quot;</span>),</span><br><span class="line">)[<span class="number">0</span>].outputs[<span class="number">0</span>].text</span><br><span class="line"></span><br><span class="line">output</span><br></pre></td></tr></table></figure>

<p>保存刚才通过<code>GRPO</code>训练得到的<code>LoRA</code>权重，然后加载<code>LoRA</code>权重，输入相同的问题做直观对比。</p>
<p><strong>第七块：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Merge to 16bit</span></span><br><span class="line"><span class="keyword">if</span> <span class="literal">False</span>: model.save_pretrained_merged(<span class="string">&quot;model&quot;</span>, tokenizer, save_method = <span class="string">&quot;merged_16bit&quot;</span>,)</span><br><span class="line"><span class="keyword">if</span> <span class="literal">False</span>: model.push_to_hub_merged(<span class="string">&quot;hf/model&quot;</span>, tokenizer, save_method = <span class="string">&quot;merged_16bit&quot;</span>, token = <span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Merge to 4bit</span></span><br><span class="line"><span class="keyword">if</span> <span class="literal">False</span>: model.save_pretrained_merged(<span class="string">&quot;model&quot;</span>, tokenizer, save_method = <span class="string">&quot;merged_4bit&quot;</span>,)</span><br><span class="line"><span class="keyword">if</span> <span class="literal">False</span>: model.push_to_hub_merged(<span class="string">&quot;hf/model&quot;</span>, tokenizer, save_method = <span class="string">&quot;merged_4bit&quot;</span>, token = <span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Just LoRA adapters</span></span><br><span class="line"><span class="keyword">if</span> <span class="literal">False</span>: model.save_pretrained_merged(<span class="string">&quot;model&quot;</span>, tokenizer, save_method = <span class="string">&quot;lora&quot;</span>,)</span><br><span class="line"><span class="keyword">if</span> <span class="literal">False</span>: model.push_to_hub_merged(<span class="string">&quot;hf/model&quot;</span>, tokenizer, save_method = <span class="string">&quot;lora&quot;</span>, token = <span class="string">&quot;&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>保存融合（LoRA的）模型或仅保存LoRA权重，也可以选择push到hf仓库，用于vLLM部署。</p>
<p><strong>第八块：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Save to 8bit Q8_0</span></span><br><span class="line"><span class="keyword">if</span> <span class="literal">False</span>: model.save_pretrained_gguf(<span class="string">&quot;model&quot;</span>, tokenizer,)</span><br><span class="line"><span class="comment"># Remember to go to https://huggingface.co/settings/tokens for a token!</span></span><br><span class="line"><span class="comment"># And change hf to your username!</span></span><br><span class="line"><span class="keyword">if</span> <span class="literal">False</span>: model.push_to_hub_gguf(<span class="string">&quot;hf/model&quot;</span>, tokenizer, token = <span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save to 16bit GGUF</span></span><br><span class="line"><span class="keyword">if</span> <span class="literal">False</span>: model.save_pretrained_gguf(<span class="string">&quot;model&quot;</span>, tokenizer, quantization_method = <span class="string">&quot;f16&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="literal">False</span>: model.push_to_hub_gguf(<span class="string">&quot;hf/model&quot;</span>, tokenizer, quantization_method = <span class="string">&quot;f16&quot;</span>, token = <span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save to q4_k_m GGUF</span></span><br><span class="line"><span class="keyword">if</span> <span class="literal">False</span>: model.save_pretrained_gguf(<span class="string">&quot;model&quot;</span>, tokenizer, quantization_method = <span class="string">&quot;q4_k_m&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="literal">False</span>: model.push_to_hub_gguf(<span class="string">&quot;hf/model&quot;</span>, tokenizer, quantization_method = <span class="string">&quot;q4_k_m&quot;</span>, token = <span class="string">&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save to multiple GGUF options - much faster if you want multiple!</span></span><br><span class="line"><span class="keyword">if</span> <span class="literal">False</span>:</span><br><span class="line">    model.push_to_hub_gguf(</span><br><span class="line">        <span class="string">&quot;hf/model&quot;</span>, <span class="comment"># Change hf to your username!</span></span><br><span class="line">        tokenizer,</span><br><span class="line">        quantization_method = [<span class="string">&quot;q4_k_m&quot;</span>, <span class="string">&quot;q8_0&quot;</span>, <span class="string">&quot;q5_k_m&quot;</span>,],</span><br><span class="line">        token = <span class="string">&quot;&quot;</span>,</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>

<p>与第七块类似，只是保存gguf格式以用于ollama或llama.cpp。</p>
<hr>
<h2 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h2><p>首先就是诡异的<code>loss</code>和 ：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">Step 	Training Loss 	reward 	reward<span class="built_in">_</span>std 	completion<span class="built_in">_</span>length 	kl 	rewards / xmlcount<span class="built_in">_</span>reward<span class="built_in">_</span>func 	rewards / soft<span class="built_in">_</span>format<span class="built_in">_</span>reward<span class="built_in">_</span>func 	rewards / strict<span class="built_in">_</span>format<span class="built_in">_</span>reward<span class="built_in">_</span>func 	rewards / int<span class="built_in">_</span>reward<span class="built_in">_</span>func 	rewards / correctness<span class="built_in">_</span>reward<span class="built_in">_</span>func</span><br><span class="line">1 	0.000000 	0.125000 	0.000000 	200.000000 	0.000000 	0.125000 	0.000000 	0.000000 	0.000000 	0.000000</span><br><span class="line">2 	0.000000 	0.104167 	0.051031 	200.000000 	0.000000 	0.104167 	0.000000 	0.000000 	0.000000 	0.000000</span><br><span class="line">3 	0.000000 	0.125000 	0.000000 	200.000000 	0.000097 	0.125000 	0.000000 	0.000000 	0.000000 	0.000000</span><br><span class="line">4 	0.000000 	0.125000 	0.000000 	200.000000 	0.000133 	0.125000 	0.000000 	0.000000 	0.000000 	0.000000</span><br><span class="line">5 	0.000000 	-0.163500 	0.078355 	192.666672 	0.000136 	-0.163500 	0.000000 	0.000000 	0.000000 	0.000000</span><br><span class="line">6 	0.000000 	0.104167 	0.051031 	200.000000 	0.000076 	0.104167 	0.000000 	0.000000 	0.000000 	0.000000</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>Training Loss (训练损失):</strong> 这是最<strong>关键和可疑</strong>的一点。训练损失几乎全程为 0.000000 (除了少数几个极小的非零值)。在正常的训练过程中，损失值应该是一个反映模型预测与目标之间差异的正数，并且会随着训练进行而波动（通常是下降）</li>
<li><strong>格式奖励 (soft_format, strict_format):</strong> 这两项一直为零：模型生成的响应<strong>完全没有</strong>满足哪怕是宽松的 XML 格式要求。这说明模型在学习遵循 <reasoning>…</reasoning><answer>…</answer> 结构方面非常困难。</li>
<li><strong>整数奖励 (int_reward):</strong> 大部分时间为零，偶尔有非零值。这表示模型偶尔能在（可能格式错误的）输出中生成看起来像数字的内容，但大多数时候不行。非零值经常与非零的 correctness_reward 同时出现，这符合逻辑（正确答案通常是数字）。</li>
<li><strong>正确性奖励 (correctness_reward):</strong> 同样，大部分时间为零，表明模型很少能输出<strong>格式正确且答案数值也正确</strong>的结果。偶尔出现的非零值（如 1.0, 1.333）是怎么回事？回顾 correctness_reward_func，它对每个正确的回答奖励 2.0。这里的日志记录的是<strong>平均值</strong>。假设 num_generations&#x3D;6，如果 6 个生成结果中有 3 个是正确的，平均奖励就是 (3 * 2.0 + 3 * 0.0) &#x2F; 6 &#x3D; 1.0。如果 4 个正确，就是 (4 * 2.0 + 2 * 0.0) &#x2F; 6 &#x3D; 1.333。所以这些非零值表示模型在某些步骤中，生成的多个响应里有部分是完全正确的，但<strong>绝大多数步骤里，一个正确的都没有</strong>。</li>
</ul>
<p>在unsloth的git仓库也看到有人说loss为0这个事情，但并没有个具体的答案（只是让试试其他方式）。但是，看输出结果是有作用的，<strong>微调前输出：</strong></p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">&#x27;9.11 is bigger than 9.9. When comparing decimal numbers, you compare them digit by digit from left to right. Both numbers have 9 as the whole number part, so you compare the digits after the decimal point. The first digit after the decimal point in 9.11 is 1, and in 9.9, it is 9. Since 1 is less than 9, you move to the next digit. In 9.11, the next digit is 1, and in 9.9, it is implied to be 0 (since 9.9 is equivalent to 9.90). Therefore, 9.11 is greater than 9.90.&#x27;</span><br></pre></td></tr></table></figure>

<p><strong>微调后：</strong></p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">&#x27;&lt;reasoning&gt;;<span class="keyword">\nTo</span> determine which number is bigger between 9.11 and 9.9, we compare them starting from the leftmost digit.<span class="keyword">\n</span><span class="keyword">\n</span>1. Compare the whole number part before the decimal point:<span class="keyword">\n</span>   - Both numbers have 9 as the whole number part.<span class="keyword">\n</span><span class="keyword">\n</span>2. Compare the tenths place (the first digit after the decimal point):<span class="keyword">\n</span>   - 9.11 has a 1 in the tenths place.<span class="keyword">\n</span>   - 9.9 has a 9 in the tenths place.<span class="keyword">\n</span><span class="keyword">\nSince</span> 1 is less than 9, 9.11 is smaller than 9.9 at this point. There is no need to compare further digits because the comparison at the tenths place already determines which number is larger.<span class="keyword">\n</span>&lt;/reasoning&gt;;<span class="keyword">\n</span>&lt;answer&gt;;<span class="keyword">\n</span>9.9 is bigger than 9.11.<span class="keyword">\n</span>&lt;/answer&gt;;&#x27;</span><br></pre></td></tr></table></figure>

<p>可以看出作用还是很明显的，而且答对了。</p>
<p>调整下<strong>第三块</strong>的训练参数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> trl <span class="keyword">import</span> GRPOConfig, GRPOTrainer</span><br><span class="line">training_args = GRPOConfig(</span><br><span class="line">    use_vllm = <span class="literal">True</span>, </span><br><span class="line">    learning_rate = <span class="number">5e-6</span>,</span><br><span class="line">    adam_beta1 = <span class="number">0.9</span>,</span><br><span class="line">    adam_beta2 = <span class="number">0.99</span>,</span><br><span class="line">    weight_decay = <span class="number">0.1</span>,</span><br><span class="line">    warmup_ratio = <span class="number">0.1</span>,</span><br><span class="line">    lr_scheduler_type = <span class="string">&quot;cosine&quot;</span>,</span><br><span class="line">    optim = <span class="string">&quot;paged_adamw_8bit&quot;</span>,</span><br><span class="line">    logging_steps = <span class="number">1</span>,</span><br><span class="line">    bf16 = is_bfloat16_supported(),</span><br><span class="line">    fp16 = <span class="keyword">not</span> is_bfloat16_supported(),</span><br><span class="line">    per_device_train_batch_size = <span class="number">1</span>,</span><br><span class="line">    gradient_accumulation_steps = <span class="number">4</span>,  <span class="comment"># this</span></span><br><span class="line">    num_generations = <span class="number">8</span>, 	<span class="comment"># this</span></span><br><span class="line">    max_prompt_length = <span class="number">256</span>,</span><br><span class="line">    max_completion_length = <span class="number">200</span>,</span><br><span class="line">    <span class="comment"># num_train_epochs = 1, </span></span><br><span class="line">    max_steps = <span class="number">300</span>,  <span class="comment"># this</span></span><br><span class="line">    save_steps = <span class="number">250</span>,</span><br><span class="line">    max_grad_norm = <span class="number">0.1</span>,</span><br><span class="line">    report_to = <span class="string">&quot;none&quot;</span>, </span><br><span class="line">    output_dir = <span class="string">&quot;outputs&quot;</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>更改了三个地方：</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">gradient_accumulation_steps</span> = <span class="number">4</span>,  <span class="comment"># this</span></span><br><span class="line"><span class="attr">num_generations</span> = <span class="number">8</span>, 	<span class="comment"># this</span></span><br><span class="line"><span class="attr">max_steps</span> = <span class="number">300</span>,  <span class="comment"># this</span></span><br></pre></td></tr></table></figure>

<p>训练的中间数据见文章最后的附录，此处只做文字总结：</p>
<ul>
<li>总体比修改前正常多了</li>
<li>loss前60条也只是仅有稀疏并很小的数，后面就正常了</li>
<li>soft_format_reward_func和strict_format_reward_func依旧全是0，其他的奖励函数都要比修改前正常</li>
</ul>
<p>但是吧（哈哈哈哈，又来但是了🤪），微调后的输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">&lt;reasoning&gt;</span><br><span class="line">9.11 has a higher value in the tenths place compared to 9.9. Specifically, 9.11 has 1 in the tenths place, while 9.9 has 9 in the tenths place. When comparing the numbers, 9.9 is larger because 9 in the tenths place is greater than 1 in the tenths place.</span><br><span class="line">&lt;/reasoning&gt;</span><br><span class="line">&lt;answer&gt;</span><br><span class="line">9.9</span><br><span class="line">&lt;/answer&gt;</span><br></pre></td></tr></table></figure>

<p>答案是对了，但是推理过程：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">与 9.9 相比，9.11 在十分位上的值更高。具体来说，9.11 的十分位是 1，而 9.9 的十分位是 9。当比较这两个数时，9.9 更大，因为十分位上的 9 大于十分位上的 1。</span><br></pre></td></tr></table></figure>

<p>第一句话错了，但后续又对了😂，但是也合理，因为几个奖励函数并没有验证推理的正确性，而且一般可能也不看推理过程，只看结果的正确性。而且我多运行几次，发现有时候答案给的是错的，说明现在的结果并不稳定，后续在实际案例中再做深入优化吧。</p>
<p>有一个很大的疑问：为什么soft_format_reward_func和strict_format_reward_func依旧全是0？不能理解</p>
<p>我们看下代码</p>
<hr>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Phi_4_(14B)-GRPO.ipynb">https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Phi_4_(14B)-GRPO.ipynb</a></li>
<li>l</li>
<li><a href="https://github.com/unslothai/unsloth/issues/1761">https://github.com/unslothai/unsloth/issues/1761</a></li>
</ol>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><p><strong>原训练参数</strong></p>
<table>
<thead>
<tr>
<th>Step</th>
<th>Training Loss</th>
<th>reward</th>
<th>reward_std</th>
<th>completion_length</th>
<th>kl</th>
<th>rewards &#x2F; xmlcount_reward_func</th>
<th>rewards &#x2F; soft_format_reward_func</th>
<th>rewards &#x2F; strict_format_reward_func</th>
<th>rewards &#x2F; int_reward_func</th>
<th>rewards &#x2F; correctness_reward_func</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>2</td>
<td>0.000000</td>
<td>0.104167</td>
<td>0.051031</td>
<td>200.000000</td>
<td>0.000000</td>
<td>0.104167</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>3</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000097</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>4</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000133</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>5</td>
<td>0.000000</td>
<td>-0.163500</td>
<td>0.078355</td>
<td>192.666672</td>
<td>0.000136</td>
<td>-0.163500</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>6</td>
<td>0.000000</td>
<td>0.104167</td>
<td>0.051031</td>
<td>200.000000</td>
<td>0.000076</td>
<td>0.104167</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>7</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000145</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>8</td>
<td>0.000000</td>
<td>0.077167</td>
<td>0.117167</td>
<td>195.666672</td>
<td>0.000278</td>
<td>0.077167</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>9</td>
<td>0.000000</td>
<td>0.044500</td>
<td>0.197184</td>
<td>200.000000</td>
<td>0.000168</td>
<td>0.044500</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>10</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000143</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>11</td>
<td>0.000000</td>
<td>0.166667</td>
<td>0.064550</td>
<td>200.000000</td>
<td>0.000135</td>
<td>0.166667</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>12</td>
<td>0.000000</td>
<td>0.083333</td>
<td>0.064550</td>
<td>200.000000</td>
<td>0.000212</td>
<td>0.083333</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>13</td>
<td>0.000000</td>
<td>0.052167</td>
<td>0.178405</td>
<td>200.000000</td>
<td>0.000112</td>
<td>0.052167</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>14</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000279</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>15</td>
<td>0.000000</td>
<td>0.104167</td>
<td>0.051031</td>
<td>200.000000</td>
<td>0.000122</td>
<td>0.104167</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>16</td>
<td>0.000000</td>
<td>1.220333</td>
<td>1.200325</td>
<td>189.833344</td>
<td>0.000146</td>
<td>-0.029667</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.250000</td>
<td>1.000000</td>
</tr>
<tr>
<td>17</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000166</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>18</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000092</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>19</td>
<td>0.000000</td>
<td>0.083333</td>
<td>0.064550</td>
<td>200.000000</td>
<td>0.000156</td>
<td>0.083333</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>20</td>
<td>0.000000</td>
<td>0.020833</td>
<td>0.051031</td>
<td>200.000000</td>
<td>0.000267</td>
<td>0.020833</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>21</td>
<td>0.000000</td>
<td>0.041667</td>
<td>0.064550</td>
<td>200.000000</td>
<td>0.000127</td>
<td>0.041667</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>22</td>
<td>0.000000</td>
<td>0.008167</td>
<td>0.301007</td>
<td>188.500000</td>
<td>0.000133</td>
<td>-0.075167</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.083333</td>
<td>0.000000</td>
</tr>
<tr>
<td>23</td>
<td>0.000000</td>
<td>0.085000</td>
<td>0.097980</td>
<td>195.333344</td>
<td>0.000142</td>
<td>0.085000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>24</td>
<td>0.000000</td>
<td>0.025833</td>
<td>0.161067</td>
<td>198.833344</td>
<td>0.000170</td>
<td>0.025833</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>25</td>
<td>0.000000</td>
<td>-0.001500</td>
<td>0.199920</td>
<td>195.000000</td>
<td>0.000184</td>
<td>-0.001500</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>26</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000220</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>27</td>
<td>0.000000</td>
<td>-0.005667</td>
<td>0.213240</td>
<td>197.833344</td>
<td>0.000164</td>
<td>-0.005667</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>28</td>
<td>0.000000</td>
<td>1.290833</td>
<td>1.278981</td>
<td>178.000000</td>
<td>0.000168</td>
<td>0.040833</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.250000</td>
<td>1.000000</td>
</tr>
<tr>
<td>29</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000088</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>30</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000286</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>31</td>
<td>0.000000</td>
<td>-0.124833</td>
<td>0.077288</td>
<td>164.666672</td>
<td>0.000193</td>
<td>-0.124833</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>32</td>
<td>0.000000</td>
<td>0.104167</td>
<td>0.051031</td>
<td>200.000000</td>
<td>0.000304</td>
<td>0.104167</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>33</td>
<td>0.000000</td>
<td>0.384167</td>
<td>0.931063</td>
<td>188.500000</td>
<td>0.000516</td>
<td>-0.032500</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.083333</td>
<td>0.333333</td>
</tr>
<tr>
<td>34</td>
<td>0.000000</td>
<td>0.104167</td>
<td>0.051031</td>
<td>200.000000</td>
<td>0.000127</td>
<td>0.104167</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>35</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000244</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>36</td>
<td>0.000000</td>
<td>0.069000</td>
<td>0.204612</td>
<td>200.000000</td>
<td>0.000110</td>
<td>0.069000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>37</td>
<td>0.000000</td>
<td>0.472167</td>
<td>0.850381</td>
<td>200.000000</td>
<td>0.000210</td>
<td>0.055500</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.083333</td>
<td>0.333333</td>
</tr>
<tr>
<td>38</td>
<td>0.000000</td>
<td>-0.163167</td>
<td>0.198312</td>
<td>189.666672</td>
<td>0.000187</td>
<td>-0.163167</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>39</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000111</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>40</td>
<td>0.000100</td>
<td>0.083333</td>
<td>0.064550</td>
<td>200.000000</td>
<td>0.001334</td>
<td>0.083333</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>41</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000198</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>42</td>
<td>0.000000</td>
<td>0.051667</td>
<td>0.179629</td>
<td>200.000000</td>
<td>0.000188</td>
<td>0.051667</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>43</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000151</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>44</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000257</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>45</td>
<td>0.000000</td>
<td>0.041667</td>
<td>0.064550</td>
<td>200.000000</td>
<td>0.001159</td>
<td>0.041667</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>46</td>
<td>0.000000</td>
<td>0.780000</td>
<td>1.127370</td>
<td>194.166672</td>
<td>0.000144</td>
<td>-0.053333</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.166667</td>
<td>0.666667</td>
</tr>
<tr>
<td>47</td>
<td>0.000000</td>
<td>0.082167</td>
<td>0.037140</td>
<td>149.666672</td>
<td>0.000179</td>
<td>0.082167</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>48</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000105</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>49</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000162</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>50</td>
<td>0.000000</td>
<td>0.073500</td>
<td>0.126149</td>
<td>199.166672</td>
<td>0.000169</td>
<td>0.073500</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>51</td>
<td>0.000000</td>
<td>0.008333</td>
<td>0.131736</td>
<td>184.833344</td>
<td>0.000145</td>
<td>0.008333</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>52</td>
<td>0.000200</td>
<td>0.083333</td>
<td>0.064550</td>
<td>200.000000</td>
<td>0.004634</td>
<td>0.083333</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>53</td>
<td>0.000100</td>
<td>0.104167</td>
<td>0.051031</td>
<td>200.000000</td>
<td>0.002473</td>
<td>0.104167</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>54</td>
<td>0.000000</td>
<td>0.040500</td>
<td>0.206982</td>
<td>200.000000</td>
<td>0.000196</td>
<td>0.040500</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>55</td>
<td>0.000000</td>
<td>0.019333</td>
<td>0.090480</td>
<td>170.833344</td>
<td>0.000139</td>
<td>0.019333</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>56</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000181</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>57</td>
<td>0.000000</td>
<td>0.078833</td>
<td>0.113085</td>
<td>197.000000</td>
<td>0.000471</td>
<td>0.078833</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>58</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000076</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>59</td>
<td>0.000000</td>
<td>-0.013667</td>
<td>0.220845</td>
<td>199.500000</td>
<td>0.000208</td>
<td>-0.013667</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>60</td>
<td>0.000000</td>
<td>-0.068000</td>
<td>0.044605</td>
<td>157.833344</td>
<td>0.000259</td>
<td>-0.068000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>61</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000202</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>62</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000790</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>63</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000166</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>64</td>
<td>0.000100</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.001505</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>65</td>
<td>0.000000</td>
<td>0.039667</td>
<td>0.209023</td>
<td>200.000000</td>
<td>0.000290</td>
<td>0.039667</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>66</td>
<td>0.000000</td>
<td>0.094833</td>
<td>0.073893</td>
<td>195.500000</td>
<td>0.000080</td>
<td>0.094833</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>67</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000139</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>68</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000889</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>69</td>
<td>0.000600</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.015919</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>70</td>
<td>0.000000</td>
<td>-0.029167</td>
<td>0.240278</td>
<td>189.333344</td>
<td>0.000252</td>
<td>-0.029167</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>71</td>
<td>0.000000</td>
<td>0.562000</td>
<td>1.023501</td>
<td>176.000000</td>
<td>0.000180</td>
<td>-0.104667</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.666667</td>
</tr>
<tr>
<td>72</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000189</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>73</td>
<td>0.000000</td>
<td>0.444500</td>
<td>0.928717</td>
<td>194.666672</td>
<td>0.000288</td>
<td>0.027833</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.083333</td>
<td>0.333333</td>
</tr>
<tr>
<td>74</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000230</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>75</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000097</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>76</td>
<td>0.000000</td>
<td>-0.053167</td>
<td>0.066653</td>
<td>163.833344</td>
<td>0.000088</td>
<td>-0.053167</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>77</td>
<td>0.000100</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.001454</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>78</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000308</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>79</td>
<td>0.000000</td>
<td>0.892167</td>
<td>1.240599</td>
<td>146.000000</td>
<td>0.000181</td>
<td>0.058833</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.166667</td>
<td>0.666667</td>
</tr>
<tr>
<td>80</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000207</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>81</td>
<td>0.000000</td>
<td>0.833000</td>
<td>1.264935</td>
<td>165.166672</td>
<td>0.000162</td>
<td>-0.000333</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.166667</td>
<td>0.666667</td>
</tr>
<tr>
<td>82</td>
<td>0.000000</td>
<td>0.793833</td>
<td>1.218390</td>
<td>190.000000</td>
<td>0.000229</td>
<td>-0.039500</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.166667</td>
<td>0.666667</td>
</tr>
<tr>
<td>83</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000220</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>84</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000551</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>85</td>
<td>0.000000</td>
<td>-0.298000</td>
<td>0.217899</td>
<td>191.000000</td>
<td>0.000378</td>
<td>-0.298000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>86</td>
<td>0.000000</td>
<td>1.518333</td>
<td>1.290365</td>
<td>170.500000</td>
<td>0.000193</td>
<td>-0.148333</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.333333</td>
<td>1.333333</td>
</tr>
<tr>
<td>87</td>
<td>0.000000</td>
<td>0.166667</td>
<td>0.064550</td>
<td>200.000000</td>
<td>0.000192</td>
<td>0.166667</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>88</td>
<td>0.000000</td>
<td>0.474833</td>
<td>0.856913</td>
<td>200.000000</td>
<td>0.000232</td>
<td>0.058167</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.083333</td>
<td>0.333333</td>
</tr>
<tr>
<td>89</td>
<td>0.000000</td>
<td>-0.092167</td>
<td>0.239684</td>
<td>196.666672</td>
<td>0.000827</td>
<td>-0.092167</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>90</td>
<td>0.000000</td>
<td>0.448833</td>
<td>0.955630</td>
<td>197.500000</td>
<td>0.000118</td>
<td>0.032167</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.083333</td>
<td>0.333333</td>
</tr>
<tr>
<td>91</td>
<td>0.000000</td>
<td>0.377500</td>
<td>1.052700</td>
<td>178.833344</td>
<td>0.000211</td>
<td>-0.039167</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.083333</td>
<td>0.333333</td>
</tr>
<tr>
<td>92</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000142</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>93</td>
<td>0.000000</td>
<td>0.061333</td>
<td>0.222869</td>
<td>200.000000</td>
<td>0.000116</td>
<td>0.061333</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>94</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000167</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>95</td>
<td>0.000000</td>
<td>0.480000</td>
<td>0.869569</td>
<td>198.666672</td>
<td>0.000403</td>
<td>0.063333</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.083333</td>
<td>0.333333</td>
</tr>
<tr>
<td>96</td>
<td>0.000000</td>
<td>0.045500</td>
<td>0.178344</td>
<td>198.666672</td>
<td>0.000174</td>
<td>0.045500</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>97</td>
<td>0.000000</td>
<td>-0.043333</td>
<td>0.261058</td>
<td>200.000000</td>
<td>0.000143</td>
<td>-0.043333</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>98</td>
<td>0.000000</td>
<td>-0.086500</td>
<td>0.094614</td>
<td>177.833344</td>
<td>0.000174</td>
<td>-0.086500</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>99</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000116</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>100</td>
<td>0.000000</td>
<td>0.013000</td>
<td>0.233636</td>
<td>199.166672</td>
<td>0.000215</td>
<td>0.013000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
</tbody></table>
<p><strong>修改后的训练参数</strong></p>
<table>
<thead>
<tr>
<th>Step</th>
<th>Training Loss</th>
<th>reward</th>
<th>reward_std</th>
<th>completion_length</th>
<th>kl</th>
<th>rewards &#x2F; xmlcount_reward_func</th>
<th>rewards &#x2F; soft_format_reward_func</th>
<th>rewards &#x2F; strict_format_reward_func</th>
<th>rewards &#x2F; int_reward_func</th>
<th>rewards &#x2F; correctness_reward_func</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>0.000000</td>
<td>0.128906</td>
<td>0.011049</td>
<td>200.000000</td>
<td>0.000200</td>
<td>0.128906</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>2</td>
<td>0.000000</td>
<td>0.091437</td>
<td>0.272227</td>
<td>198.281250</td>
<td>0.000199</td>
<td>0.013312</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.015625</td>
<td>0.062500</td>
</tr>
<tr>
<td>3</td>
<td>0.000000</td>
<td>0.299875</td>
<td>0.365889</td>
<td>197.125000</td>
<td>0.000217</td>
<td>0.065500</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.046875</td>
<td>0.187500</td>
</tr>
<tr>
<td>4</td>
<td>0.000000</td>
<td>0.596656</td>
<td>0.471141</td>
<td>195.250000</td>
<td>0.000232</td>
<td>0.049781</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.109375</td>
<td>0.437500</td>
</tr>
<tr>
<td>5</td>
<td>0.000100</td>
<td>0.121094</td>
<td>0.011049</td>
<td>200.000000</td>
<td>0.001695</td>
<td>0.121094</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>6</td>
<td>0.000000</td>
<td>0.127625</td>
<td>0.289390</td>
<td>199.562500</td>
<td>0.000245</td>
<td>0.018250</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.046875</td>
<td>0.062500</td>
</tr>
<tr>
<td>7</td>
<td>0.000000</td>
<td>0.113188</td>
<td>0.350681</td>
<td>196.781250</td>
<td>0.000222</td>
<td>0.035062</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.015625</td>
<td>0.062500</td>
</tr>
<tr>
<td>8</td>
<td>0.000000</td>
<td>0.014656</td>
<td>0.104425</td>
<td>195.562500</td>
<td>0.000193</td>
<td>0.014656</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>9</td>
<td>0.000100</td>
<td>0.361219</td>
<td>0.536969</td>
<td>190.156250</td>
<td>0.001660</td>
<td>0.048719</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.062500</td>
<td>0.250000</td>
</tr>
<tr>
<td>10</td>
<td>0.000000</td>
<td>0.087312</td>
<td>0.061786</td>
<td>197.750000</td>
<td>0.000293</td>
<td>0.087312</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>11</td>
<td>0.000000</td>
<td>0.128906</td>
<td>0.011049</td>
<td>200.000000</td>
<td>0.000200</td>
<td>0.128906</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>12</td>
<td>0.000100</td>
<td>0.508000</td>
<td>0.524590</td>
<td>183.156250</td>
<td>0.001624</td>
<td>0.039250</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.093750</td>
<td>0.375000</td>
</tr>
<tr>
<td>13</td>
<td>0.000100</td>
<td>0.071063</td>
<td>0.093637</td>
<td>199.625000</td>
<td>0.001865</td>
<td>0.071063</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>14</td>
<td>0.000000</td>
<td>0.078500</td>
<td>0.072087</td>
<td>193.343750</td>
<td>0.000217</td>
<td>0.078500</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>15</td>
<td>0.000000</td>
<td>0.027813</td>
<td>0.119273</td>
<td>190.093750</td>
<td>0.000223</td>
<td>0.027812</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>16</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000884</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>17</td>
<td>0.000200</td>
<td>0.100125</td>
<td>0.051338</td>
<td>199.218750</td>
<td>0.004186</td>
<td>0.100125</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>18</td>
<td>0.000000</td>
<td>0.047375</td>
<td>0.065061</td>
<td>193.781250</td>
<td>0.000229</td>
<td>0.047375</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>19</td>
<td>0.000000</td>
<td>0.129312</td>
<td>0.230931</td>
<td>195.593750</td>
<td>0.000208</td>
<td>0.051188</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.015625</td>
<td>0.062500</td>
</tr>
<tr>
<td>20</td>
<td>0.000000</td>
<td>0.266562</td>
<td>0.301932</td>
<td>185.843750</td>
<td>0.000446</td>
<td>0.110312</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.031250</td>
<td>0.125000</td>
</tr>
<tr>
<td>21</td>
<td>0.000000</td>
<td>0.517438</td>
<td>0.537948</td>
<td>190.468750</td>
<td>0.000327</td>
<td>0.048688</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.093750</td>
<td>0.375000</td>
</tr>
<tr>
<td>22</td>
<td>0.000000</td>
<td>0.104937</td>
<td>0.411467</td>
<td>190.406250</td>
<td>0.000256</td>
<td>-0.051312</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.031250</td>
<td>0.125000</td>
</tr>
<tr>
<td>23</td>
<td>0.000000</td>
<td>0.541125</td>
<td>0.657217</td>
<td>194.406250</td>
<td>0.000334</td>
<td>-0.005750</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.109375</td>
<td>0.437500</td>
</tr>
<tr>
<td>24</td>
<td>0.000000</td>
<td>0.055250</td>
<td>0.159929</td>
<td>198.812500</td>
<td>0.000211</td>
<td>0.055250</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>25</td>
<td>0.000000</td>
<td>0.049281</td>
<td>0.130569</td>
<td>197.437500</td>
<td>0.000147</td>
<td>0.049281</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>26</td>
<td>0.000000</td>
<td>0.276562</td>
<td>0.416252</td>
<td>175.281250</td>
<td>0.000278</td>
<td>0.042188</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.046875</td>
<td>0.187500</td>
</tr>
<tr>
<td>27</td>
<td>0.000000</td>
<td>0.306031</td>
<td>0.362150</td>
<td>188.625000</td>
<td>0.000242</td>
<td>-0.006469</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.062500</td>
<td>0.250000</td>
</tr>
<tr>
<td>28</td>
<td>0.000000</td>
<td>0.678031</td>
<td>0.786093</td>
<td>179.968750</td>
<td>0.000221</td>
<td>-0.025094</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.140625</td>
<td>0.562500</td>
</tr>
<tr>
<td>29</td>
<td>0.000000</td>
<td>0.063125</td>
<td>0.114379</td>
<td>197.875000</td>
<td>0.000592</td>
<td>0.063125</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>30</td>
<td>0.000000</td>
<td>0.335156</td>
<td>0.559257</td>
<td>187.250000</td>
<td>0.000207</td>
<td>0.022656</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.062500</td>
<td>0.250000</td>
</tr>
<tr>
<td>31</td>
<td>0.000000</td>
<td>0.114281</td>
<td>0.030317</td>
<td>199.781250</td>
<td>0.000312</td>
<td>0.114281</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>32</td>
<td>0.000000</td>
<td>0.020219</td>
<td>0.135688</td>
<td>192.562500</td>
<td>0.000204</td>
<td>0.020219</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>33</td>
<td>0.000100</td>
<td>0.101625</td>
<td>0.043579</td>
<td>199.906250</td>
<td>0.001501</td>
<td>0.101625</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>34</td>
<td>0.000000</td>
<td>-0.003125</td>
<td>0.064681</td>
<td>192.062500</td>
<td>0.000249</td>
<td>-0.003125</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>35</td>
<td>0.000000</td>
<td>0.444406</td>
<td>0.383764</td>
<td>175.937500</td>
<td>0.001186</td>
<td>0.053781</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.078125</td>
<td>0.312500</td>
</tr>
<tr>
<td>36</td>
<td>0.000000</td>
<td>0.073656</td>
<td>0.082237</td>
<td>199.093750</td>
<td>0.000238</td>
<td>0.073656</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>37</td>
<td>0.000000</td>
<td>0.209313</td>
<td>0.321363</td>
<td>193.375000</td>
<td>0.000293</td>
<td>0.053062</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.031250</td>
<td>0.125000</td>
</tr>
<tr>
<td>38</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000940</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>39</td>
<td>0.000500</td>
<td>0.097687</td>
<td>0.054421</td>
<td>200.000000</td>
<td>0.011868</td>
<td>0.097687</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>40</td>
<td>0.000100</td>
<td>0.193656</td>
<td>0.194189</td>
<td>199.875000</td>
<td>0.003135</td>
<td>0.115531</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.015625</td>
<td>0.062500</td>
</tr>
<tr>
<td>41</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000438</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>42</td>
<td>0.000000</td>
<td>0.172844</td>
<td>0.221426</td>
<td>199.562500</td>
<td>0.001187</td>
<td>0.094719</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.015625</td>
<td>0.062500</td>
</tr>
<tr>
<td>43</td>
<td>0.000000</td>
<td>0.080094</td>
<td>0.043903</td>
<td>193.687500</td>
<td>0.000243</td>
<td>0.080094</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>44</td>
<td>0.000000</td>
<td>1.021969</td>
<td>0.336553</td>
<td>189.375000</td>
<td>0.000266</td>
<td>0.006344</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.203125</td>
<td>0.812500</td>
</tr>
<tr>
<td>45</td>
<td>0.000100</td>
<td>0.040000</td>
<td>0.096341</td>
<td>195.312500</td>
<td>0.001694</td>
<td>0.040000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>46</td>
<td>0.000000</td>
<td>0.459094</td>
<td>0.547510</td>
<td>188.281250</td>
<td>0.000386</td>
<td>0.068469</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.078125</td>
<td>0.312500</td>
</tr>
<tr>
<td>47</td>
<td>0.000100</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.001254</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>48</td>
<td>0.000000</td>
<td>0.554219</td>
<td>0.265542</td>
<td>193.125000</td>
<td>0.000314</td>
<td>0.085469</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.093750</td>
<td>0.375000</td>
</tr>
<tr>
<td>49</td>
<td>0.000000</td>
<td>0.566031</td>
<td>0.296579</td>
<td>192.343750</td>
<td>0.001164</td>
<td>0.019156</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.109375</td>
<td>0.437500</td>
</tr>
<tr>
<td>50</td>
<td>0.000000</td>
<td>0.149875</td>
<td>0.272207</td>
<td>188.500000</td>
<td>0.000295</td>
<td>0.071750</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.015625</td>
<td>0.062500</td>
</tr>
<tr>
<td>51</td>
<td>0.000000</td>
<td>0.527062</td>
<td>0.533761</td>
<td>195.187500</td>
<td>0.000272</td>
<td>0.058312</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.093750</td>
<td>0.375000</td>
</tr>
<tr>
<td>52</td>
<td>0.000000</td>
<td>0.088687</td>
<td>0.102707</td>
<td>199.875000</td>
<td>0.000253</td>
<td>0.088687</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>53</td>
<td>0.000000</td>
<td>0.499219</td>
<td>0.575142</td>
<td>195.750000</td>
<td>0.000369</td>
<td>0.030469</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.093750</td>
<td>0.375000</td>
</tr>
<tr>
<td>54</td>
<td>0.000000</td>
<td>0.475094</td>
<td>0.830660</td>
<td>187.843750</td>
<td>0.000331</td>
<td>-0.009281</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.109375</td>
<td>0.375000</td>
</tr>
<tr>
<td>55</td>
<td>0.000000</td>
<td>0.114250</td>
<td>0.044400</td>
<td>200.000000</td>
<td>0.000202</td>
<td>0.114250</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>56</td>
<td>0.000000</td>
<td>0.272125</td>
<td>0.321911</td>
<td>196.312500</td>
<td>0.000684</td>
<td>0.037750</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.046875</td>
<td>0.187500</td>
</tr>
<tr>
<td>57</td>
<td>0.000000</td>
<td>0.318687</td>
<td>0.469326</td>
<td>199.062500</td>
<td>0.000417</td>
<td>0.084312</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.046875</td>
<td>0.187500</td>
</tr>
<tr>
<td>58</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000310</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>59</td>
<td>0.000100</td>
<td>0.769313</td>
<td>0.569422</td>
<td>179.468750</td>
<td>0.001617</td>
<td>-0.011937</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.156250</td>
<td>0.625000</td>
</tr>
<tr>
<td>60</td>
<td>0.000000</td>
<td>1.208313</td>
<td>1.032118</td>
<td>176.156250</td>
<td>0.000968</td>
<td>0.036438</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.234375</td>
<td>0.937500</td>
</tr>
<tr>
<td>61</td>
<td>0.000000</td>
<td>0.356281</td>
<td>0.527199</td>
<td>184.343750</td>
<td>0.001006</td>
<td>0.043781</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.062500</td>
<td>0.250000</td>
</tr>
<tr>
<td>62</td>
<td>0.000100</td>
<td>0.187188</td>
<td>0.175893</td>
<td>200.000000</td>
<td>0.001395</td>
<td>0.109063</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.015625</td>
<td>0.062500</td>
</tr>
<tr>
<td>63</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.000990</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>64</td>
<td>0.000000</td>
<td>0.132687</td>
<td>0.262365</td>
<td>196.125000</td>
<td>0.000882</td>
<td>0.054563</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.015625</td>
<td>0.062500</td>
</tr>
<tr>
<td>65</td>
<td>0.000000</td>
<td>0.618719</td>
<td>0.922293</td>
<td>196.468750</td>
<td>0.000420</td>
<td>0.071844</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.109375</td>
<td>0.437500</td>
</tr>
<tr>
<td>66</td>
<td>0.000100</td>
<td>0.129062</td>
<td>0.245166</td>
<td>199.031250</td>
<td>0.001289</td>
<td>0.050938</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.015625</td>
<td>0.062500</td>
</tr>
<tr>
<td>67</td>
<td>0.000000</td>
<td>0.623875</td>
<td>0.202422</td>
<td>191.031250</td>
<td>0.000446</td>
<td>0.077000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.109375</td>
<td>0.437500</td>
</tr>
<tr>
<td>68</td>
<td>0.000000</td>
<td>0.256937</td>
<td>0.283389</td>
<td>197.656250</td>
<td>0.000639</td>
<td>0.100687</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.031250</td>
<td>0.125000</td>
</tr>
<tr>
<td>69</td>
<td>0.000000</td>
<td>0.100562</td>
<td>0.035478</td>
<td>198.781250</td>
<td>0.000369</td>
<td>0.100562</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>70</td>
<td>0.000100</td>
<td>0.068187</td>
<td>0.049234</td>
<td>198.468750</td>
<td>0.003580</td>
<td>0.068188</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>71</td>
<td>0.000200</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.004849</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>72</td>
<td>0.000100</td>
<td>0.195063</td>
<td>0.198167</td>
<td>199.593750</td>
<td>0.002061</td>
<td>0.116937</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.015625</td>
<td>0.062500</td>
</tr>
<tr>
<td>73</td>
<td>0.000100</td>
<td>0.389719</td>
<td>0.607224</td>
<td>188.937500</td>
<td>0.002278</td>
<td>-0.000906</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.078125</td>
<td>0.312500</td>
</tr>
<tr>
<td>74</td>
<td>0.000400</td>
<td>0.890375</td>
<td>1.126343</td>
<td>169.031250</td>
<td>0.010070</td>
<td>0.031000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.171875</td>
<td>0.687500</td>
</tr>
<tr>
<td>75</td>
<td>0.000000</td>
<td>0.162719</td>
<td>0.234266</td>
<td>189.343750</td>
<td>0.000792</td>
<td>0.084594</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.015625</td>
<td>0.062500</td>
</tr>
<tr>
<td>76</td>
<td>0.000200</td>
<td>0.759188</td>
<td>0.914893</td>
<td>179.562500</td>
<td>0.003830</td>
<td>-0.022063</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.156250</td>
<td>0.625000</td>
</tr>
<tr>
<td>77</td>
<td>0.000000</td>
<td>1.034500</td>
<td>0.547051</td>
<td>191.843750</td>
<td>0.000724</td>
<td>0.018875</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.203125</td>
<td>0.812500</td>
</tr>
<tr>
<td>78</td>
<td>0.000200</td>
<td>0.787781</td>
<td>0.882335</td>
<td>188.093750</td>
<td>0.003986</td>
<td>0.006531</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.093750</td>
<td>0.687500</td>
</tr>
<tr>
<td>79</td>
<td>0.000100</td>
<td>0.708563</td>
<td>0.402601</td>
<td>195.250000</td>
<td>0.001422</td>
<td>0.083562</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.500000</td>
</tr>
<tr>
<td>80</td>
<td>0.000100</td>
<td>1.131250</td>
<td>0.916285</td>
<td>179.687500</td>
<td>0.002825</td>
<td>0.006250</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.250000</td>
<td>0.875000</td>
</tr>
<tr>
<td>81</td>
<td>0.000100</td>
<td>0.858906</td>
<td>0.710950</td>
<td>190.000000</td>
<td>0.002542</td>
<td>-0.000469</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.171875</td>
<td>0.687500</td>
</tr>
<tr>
<td>82</td>
<td>0.000100</td>
<td>0.589000</td>
<td>0.794487</td>
<td>195.281250</td>
<td>0.001541</td>
<td>0.042125</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.109375</td>
<td>0.437500</td>
</tr>
<tr>
<td>83</td>
<td>0.000200</td>
<td>1.044719</td>
<td>0.874095</td>
<td>190.125000</td>
<td>0.003762</td>
<td>0.029094</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.203125</td>
<td>0.812500</td>
</tr>
<tr>
<td>84</td>
<td>0.000000</td>
<td>0.267719</td>
<td>0.264266</td>
<td>198.718750</td>
<td>0.000571</td>
<td>0.111469</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.031250</td>
<td>0.125000</td>
</tr>
<tr>
<td>85</td>
<td>0.000100</td>
<td>0.239563</td>
<td>0.300843</td>
<td>198.562500</td>
<td>0.001571</td>
<td>0.083312</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.031250</td>
<td>0.125000</td>
</tr>
<tr>
<td>86</td>
<td>0.000200</td>
<td>0.561062</td>
<td>0.664822</td>
<td>187.062500</td>
<td>0.005404</td>
<td>0.014187</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.109375</td>
<td>0.437500</td>
</tr>
<tr>
<td>87</td>
<td>0.000200</td>
<td>0.235531</td>
<td>0.290269</td>
<td>198.718750</td>
<td>0.004947</td>
<td>0.079281</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.031250</td>
<td>0.125000</td>
</tr>
<tr>
<td>88</td>
<td>0.000100</td>
<td>0.310937</td>
<td>0.339621</td>
<td>198.687500</td>
<td>0.001520</td>
<td>0.076563</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.046875</td>
<td>0.187500</td>
</tr>
<tr>
<td>89</td>
<td>0.000000</td>
<td>0.116719</td>
<td>0.045520</td>
<td>200.000000</td>
<td>0.000942</td>
<td>0.116719</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>90</td>
<td>0.000000</td>
<td>0.620875</td>
<td>0.588485</td>
<td>196.750000</td>
<td>0.001108</td>
<td>0.074000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.109375</td>
<td>0.437500</td>
</tr>
<tr>
<td>91</td>
<td>0.000100</td>
<td>0.561594</td>
<td>0.242350</td>
<td>193.406250</td>
<td>0.002773</td>
<td>0.014719</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.109375</td>
<td>0.437500</td>
</tr>
<tr>
<td>92</td>
<td>0.000300</td>
<td>1.209375</td>
<td>0.677630</td>
<td>172.593750</td>
<td>0.006277</td>
<td>0.037500</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.234375</td>
<td>0.937500</td>
</tr>
<tr>
<td>93</td>
<td>0.000000</td>
<td>1.103844</td>
<td>0.657026</td>
<td>191.531250</td>
<td>0.001238</td>
<td>0.010094</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.218750</td>
<td>0.875000</td>
</tr>
<tr>
<td>94</td>
<td>0.000300</td>
<td>0.729719</td>
<td>0.863541</td>
<td>191.687500</td>
<td>0.007389</td>
<td>0.026594</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.140625</td>
<td>0.562500</td>
</tr>
<tr>
<td>95</td>
<td>0.000100</td>
<td>0.338375</td>
<td>0.438867</td>
<td>198.718750</td>
<td>0.001460</td>
<td>0.104000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.046875</td>
<td>0.187500</td>
</tr>
<tr>
<td>96</td>
<td>0.000100</td>
<td>0.520844</td>
<td>0.496037</td>
<td>196.718750</td>
<td>0.003298</td>
<td>0.052094</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.093750</td>
<td>0.375000</td>
</tr>
<tr>
<td>97</td>
<td>0.000100</td>
<td>1.041531</td>
<td>0.726904</td>
<td>192.000000</td>
<td>0.002370</td>
<td>0.025906</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.203125</td>
<td>0.812500</td>
</tr>
<tr>
<td>98</td>
<td>0.000200</td>
<td>1.205375</td>
<td>0.966042</td>
<td>181.812500</td>
<td>0.003860</td>
<td>0.002250</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.265625</td>
<td>0.937500</td>
</tr>
<tr>
<td>99</td>
<td>0.000100</td>
<td>0.169125</td>
<td>0.245326</td>
<td>199.031250</td>
<td>0.002583</td>
<td>0.091000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.015625</td>
<td>0.062500</td>
</tr>
<tr>
<td>100</td>
<td>0.000400</td>
<td>0.735563</td>
<td>0.874583</td>
<td>196.187500</td>
<td>0.008870</td>
<td>0.032437</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.140625</td>
<td>0.562500</td>
</tr>
<tr>
<td>101</td>
<td>0.000200</td>
<td>0.628906</td>
<td>0.459497</td>
<td>196.781250</td>
<td>0.003757</td>
<td>0.082031</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.109375</td>
<td>0.437500</td>
</tr>
<tr>
<td>102</td>
<td>0.000100</td>
<td>0.926781</td>
<td>0.323388</td>
<td>184.406250</td>
<td>0.002390</td>
<td>0.067406</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.171875</td>
<td>0.687500</td>
</tr>
<tr>
<td>103</td>
<td>0.000200</td>
<td>0.705688</td>
<td>0.840264</td>
<td>196.625000</td>
<td>0.006018</td>
<td>-0.013063</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.156250</td>
<td>0.562500</td>
</tr>
<tr>
<td>104</td>
<td>0.000300</td>
<td>0.312688</td>
<td>0.467491</td>
<td>197.875000</td>
<td>0.008158</td>
<td>0.078312</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.046875</td>
<td>0.187500</td>
</tr>
<tr>
<td>105</td>
<td>0.000100</td>
<td>0.719250</td>
<td>0.528978</td>
<td>191.187500</td>
<td>0.003097</td>
<td>0.078625</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.140625</td>
<td>0.500000</td>
</tr>
<tr>
<td>106</td>
<td>0.000200</td>
<td>0.257531</td>
<td>0.501718</td>
<td>194.812500</td>
<td>0.005807</td>
<td>-0.008094</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.078125</td>
<td>0.187500</td>
</tr>
<tr>
<td>107</td>
<td>0.000100</td>
<td>0.565281</td>
<td>0.570627</td>
<td>195.437500</td>
<td>0.003359</td>
<td>0.096531</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.093750</td>
<td>0.375000</td>
</tr>
<tr>
<td>108</td>
<td>0.000300</td>
<td>0.266188</td>
<td>0.252022</td>
<td>199.750000</td>
<td>0.007125</td>
<td>0.109937</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.031250</td>
<td>0.125000</td>
</tr>
<tr>
<td>109</td>
<td>0.000500</td>
<td>1.591406</td>
<td>0.531403</td>
<td>168.875000</td>
<td>0.013054</td>
<td>0.028906</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.312500</td>
<td>1.250000</td>
</tr>
<tr>
<td>110</td>
<td>0.000600</td>
<td>0.971031</td>
<td>0.906340</td>
<td>191.937500</td>
<td>0.014373</td>
<td>0.033531</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.187500</td>
<td>0.750000</td>
</tr>
<tr>
<td>111</td>
<td>0.000500</td>
<td>1.763906</td>
<td>0.517783</td>
<td>176.218750</td>
<td>0.013554</td>
<td>-0.032969</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.359375</td>
<td>1.437500</td>
</tr>
<tr>
<td>112</td>
<td>0.000900</td>
<td>1.143687</td>
<td>0.746264</td>
<td>179.843750</td>
<td>0.021685</td>
<td>-0.028187</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.234375</td>
<td>0.937500</td>
</tr>
<tr>
<td>113</td>
<td>0.000200</td>
<td>0.125000</td>
<td>0.000000</td>
<td>200.000000</td>
<td>0.005879</td>
<td>0.125000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>114</td>
<td>0.000200</td>
<td>0.344187</td>
<td>0.294369</td>
<td>197.312500</td>
<td>0.004148</td>
<td>0.109812</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.046875</td>
<td>0.187500</td>
</tr>
<tr>
<td>115</td>
<td>0.000500</td>
<td>1.335250</td>
<td>0.234957</td>
<td>180.812500</td>
<td>0.011432</td>
<td>0.007125</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.265625</td>
<td>1.062500</td>
</tr>
<tr>
<td>116</td>
<td>0.000200</td>
<td>0.386500</td>
<td>0.490854</td>
<td>199.031250</td>
<td>0.004324</td>
<td>0.074000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.062500</td>
<td>0.250000</td>
</tr>
<tr>
<td>117</td>
<td>0.000200</td>
<td>0.340062</td>
<td>0.296831</td>
<td>199.250000</td>
<td>0.003828</td>
<td>0.105687</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.046875</td>
<td>0.187500</td>
</tr>
<tr>
<td>118</td>
<td>0.000400</td>
<td>0.111500</td>
<td>0.025591</td>
<td>195.562500</td>
<td>0.009099</td>
<td>0.111500</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.000000</td>
</tr>
<tr>
<td>119</td>
<td>0.000300</td>
<td>1.739094</td>
<td>0.297500</td>
<td>181.562500</td>
<td>0.007558</td>
<td>0.020344</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.343750</td>
<td>1.375000</td>
</tr>
<tr>
<td>120</td>
<td>0.000400</td>
<td>0.648094</td>
<td>0.737686</td>
<td>192.750000</td>
<td>0.009983</td>
<td>0.085594</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.062500</td>
<td>0.500000</td>
</tr>
<tr>
<td>121</td>
<td>0.000500</td>
<td>0.730281</td>
<td>0.009011</td>
<td>183.875000</td>
<td>0.012388</td>
<td>0.105281</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.500000</td>
</tr>
<tr>
<td>122</td>
<td>0.000800</td>
<td>1.746000</td>
<td>0.608225</td>
<td>171.625000</td>
<td>0.018913</td>
<td>0.027250</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.343750</td>
<td>1.375000</td>
</tr>
<tr>
<td>123</td>
<td>0.000800</td>
<td>0.573875</td>
<td>0.511113</td>
<td>182.593750</td>
<td>0.018763</td>
<td>0.105125</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.093750</td>
<td>0.375000</td>
</tr>
<tr>
<td>124</td>
<td>0.000700</td>
<td>1.552563</td>
<td>0.787023</td>
<td>177.656250</td>
<td>0.018103</td>
<td>-0.009937</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.312500</td>
<td>1.250000</td>
</tr>
<tr>
<td>125</td>
<td>0.000300</td>
<td>0.728563</td>
<td>0.063017</td>
<td>183.437500</td>
<td>0.008366</td>
<td>0.103563</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.125000</td>
<td>0.500000</td>
</tr>
<tr>
<td>126</td>
<td>0.000900</td>
<td>1.069187</td>
<td>0.322141</td>
<td>183.375000</td>
<td>0.021549</td>
<td>0.053562</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.203125</td>
<td>0.812500</td>
</tr>
<tr>
<td>127</td>
<td>0.000500</td>
<td>0.805375</td>
<td>0.602364</td>
<td>192.937500</td>
<td>0.011782</td>
<td>0.024125</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.156250</td>
<td>0.625000</td>
</tr>
<tr>
<td>128</td>
<td>0.000500</td>
<td>1.450062</td>
<td>0.329752</td>
<td>168.656250</td>
<td>0.012539</td>
<td>0.043813</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.281250</td>
<td>1.125000</td>
</tr>
<tr>
<td>129</td>
<td>0.000400</td>
<td>1.082375</td>
<td>0.341948</td>
<td>181.781250</td>
<td>0.009770</td>
<td>0.066750</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.203125</td>
<td>0.812500</td>
</tr>
<tr>
<td>130</td>
<td>0.000900</td>
<td>1.377656</td>
<td>1.025102</td>
<td>184.500000</td>
<td>0.023494</td>
<td>-0.028594</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.281250</td>
<td>1.125000</td>
</tr>
<tr>
<td>131</td>
<td>0.000900</td>
<td>1.928344</td>
<td>0.267554</td>
<td>164.218750</td>
<td>0.022489</td>
<td>-0.024781</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.390625</td>
<td>1.562500</td>
</tr>
<tr>
<td>132</td>
<td>0.000600</td>
<td>0.415750</td>
<td>0.500535</td>
<td>197.250000</td>
<td>0.015222</td>
<td>0.103250</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.062500</td>
<td>0.250000</td>
</tr>
<tr>
<td>133</td>
<td>0.000700</td>
<td>1.313406</td>
<td>0.271812</td>
<td>181.031250</td>
<td>0.017767</td>
<td>-0.014719</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.265625</td>
<td>1.062500</td>
</tr>
<tr>
<td>134</td>
<td>0.000700</td>
<td>0.844031</td>
<td>0.658927</td>
<td>191.562500</td>
<td>0.016444</td>
<td>0.062781</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.156250</td>
<td>0.625000</td>
</tr>
<tr>
<td>135</td>
<td>0.000400</td>
<td>0.786500</td>
<td>0.732629</td>
<td>191.125000</td>
<td>0.010595</td>
<td>0.083375</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.140625</td>
<td>0.562500</td>
</tr>
<tr>
<td>136</td>
<td>0.000500</td>
<td>1.339406</td>
<td>0.580219</td>
<td>181.437500</td>
<td>0.012606</td>
<td>0.011281</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.265625</td>
<td>1.062500</td>
</tr>
<tr>
<td>137</td>
<td>0.000700</td>
<td>1.576375</td>
<td>0.874083</td>
<td>175.968750</td>
<td>0.018491</td>
<td>0.013875</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.312500</td>
<td>1.250000</td>
</tr>
<tr>
<td>138</td>
<td>0.000800</td>
<td>1.126188</td>
<td>0.632414</td>
<td>187.500000</td>
<td>0.019553</td>
<td>-0.061312</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.312500</td>
<td>0.875000</td>
</tr>
<tr>
<td>139</td>
<td>0.000800</td>
<td>0.863250</td>
<td>0.250897</td>
<td>174.500000</td>
<td>0.020898</td>
<td>0.097625</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.203125</td>
<td>0.562500</td>
</tr>
<tr>
<td>140</td>
<td>0.001800</td>
<td>2.337156</td>
<td>0.369841</td>
<td>146.125000</td>
<td>0.045088</td>
<td>-0.006594</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.468750</td>
<td>1.875000</td>
</tr>
<tr>
<td>141</td>
<td>0.001200</td>
<td>1.179875</td>
<td>0.290548</td>
<td>187.250000</td>
<td>0.029070</td>
<td>0.008000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.234375</td>
<td>0.937500</td>
</tr>
<tr>
<td>142</td>
<td>0.002000</td>
<td>1.860031</td>
<td>0.651452</td>
<td>162.750000</td>
<td>0.050185</td>
<td>0.063156</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.359375</td>
<td>1.437500</td>
</tr>
<tr>
<td>143</td>
<td>0.001000</td>
<td>1.639469</td>
<td>0.696820</td>
<td>176.625000</td>
<td>0.023879</td>
<td>-0.001156</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.328125</td>
<td>1.312500</td>
</tr>
<tr>
<td>144</td>
<td>0.001500</td>
<td>1.432656</td>
<td>0.235467</td>
<td>166.750000</td>
<td>0.036621</td>
<td>0.104531</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.265625</td>
<td>1.062500</td>
</tr>
<tr>
<td>145</td>
<td>0.001300</td>
<td>1.551031</td>
<td>0.895742</td>
<td>180.218750</td>
<td>0.033519</td>
<td>-0.011469</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.312500</td>
<td>1.250000</td>
</tr>
<tr>
<td>146</td>
<td>0.001600</td>
<td>1.052594</td>
<td>0.525497</td>
<td>171.718750</td>
<td>0.038834</td>
<td>0.115094</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.187500</td>
<td>0.750000</td>
</tr>
<tr>
<td>147</td>
<td>0.001400</td>
<td>1.371125</td>
<td>0.031297</td>
<td>163.500000</td>
<td>0.035136</td>
<td>0.121125</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.250000</td>
<td>1.000000</td>
</tr>
<tr>
<td>148</td>
<td>0.000900</td>
<td>0.826969</td>
<td>0.321804</td>
<td>189.218750</td>
<td>0.023262</td>
<td>0.045719</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.156250</td>
<td>0.625000</td>
</tr>
<tr>
<td>149</td>
<td>0.001100</td>
<td>1.325250</td>
<td>0.041487</td>
<td>170.343750</td>
<td>0.026935</td>
<td>0.075250</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.250000</td>
<td>1.000000</td>
</tr>
<tr>
<td>150</td>
<td>0.001200</td>
<td>1.240656</td>
<td>0.263828</td>
<td>174.156250</td>
<td>0.030042</td>
<td>0.068781</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.234375</td>
<td>0.937500</td>
</tr>
<tr>
<td>151</td>
<td>0.001500</td>
<td>2.068000</td>
<td>0.624614</td>
<td>152.937500</td>
<td>0.036548</td>
<td>0.036750</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.406250</td>
<td>1.625000</td>
</tr>
<tr>
<td>152</td>
<td>0.001300</td>
<td>1.315906</td>
<td>0.287107</td>
<td>181.437500</td>
<td>0.033494</td>
<td>-0.012219</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.265625</td>
<td>1.062500</td>
</tr>
<tr>
<td>153</td>
<td>0.001500</td>
<td>1.382656</td>
<td>0.633689</td>
<td>167.781250</td>
<td>0.036475</td>
<td>0.038906</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.281250</td>
<td>1.062500</td>
</tr>
<tr>
<td>154</td>
<td>0.002600</td>
<td>1.688094</td>
<td>0.444427</td>
<td>141.062500</td>
<td>0.064864</td>
<td>0.125594</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.312500</td>
<td>1.250000</td>
</tr>
<tr>
<td>155</td>
<td>0.001100</td>
<td>1.755594</td>
<td>0.661673</td>
<td>170.437500</td>
<td>0.026335</td>
<td>0.036844</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.343750</td>
<td>1.375000</td>
</tr>
<tr>
<td>156</td>
<td>0.001600</td>
<td>0.981094</td>
<td>0.994267</td>
<td>187.531250</td>
<td>0.040151</td>
<td>0.027969</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.203125</td>
<td>0.750000</td>
</tr>
<tr>
<td>157</td>
<td>0.001000</td>
<td>0.839875</td>
<td>0.858498</td>
<td>192.156250</td>
<td>0.024021</td>
<td>0.058625</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.156250</td>
<td>0.625000</td>
</tr>
<tr>
<td>158</td>
<td>0.001200</td>
<td>0.836500</td>
<td>0.551024</td>
<td>191.625000</td>
<td>0.030358</td>
<td>0.055250</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.156250</td>
<td>0.625000</td>
</tr>
<tr>
<td>159</td>
<td>0.001800</td>
<td>1.874187</td>
<td>0.039922</td>
<td>175.656250</td>
<td>0.044303</td>
<td>-0.000813</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.375000</td>
<td>1.500000</td>
</tr>
<tr>
<td>160</td>
<td>0.002500</td>
<td>2.270750</td>
<td>0.319948</td>
<td>140.343750</td>
<td>0.061421</td>
<td>0.020750</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.500000</td>
<td>1.750000</td>
</tr>
<tr>
<td>161</td>
<td>0.002800</td>
<td>1.397687</td>
<td>0.815960</td>
<td>173.500000</td>
<td>0.071023</td>
<td>-0.024188</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.296875</td>
<td>1.125000</td>
</tr>
<tr>
<td>162</td>
<td>0.001400</td>
<td>0.803875</td>
<td>0.447184</td>
<td>181.687500</td>
<td>0.034519</td>
<td>0.069500</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.234375</td>
<td>0.500000</td>
</tr>
<tr>
<td>163</td>
<td>0.003200</td>
<td>1.813406</td>
<td>0.414541</td>
<td>150.406250</td>
<td>0.080257</td>
<td>0.047781</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.390625</td>
<td>1.375000</td>
</tr>
<tr>
<td>164</td>
<td>0.001500</td>
<td>1.086625</td>
<td>0.491458</td>
<td>184.687500</td>
<td>0.038402</td>
<td>0.071000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.203125</td>
<td>0.812500</td>
</tr>
<tr>
<td>165</td>
<td>0.002000</td>
<td>1.061656</td>
<td>0.779787</td>
<td>162.093750</td>
<td>0.049305</td>
<td>-0.016469</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.328125</td>
<td>0.750000</td>
</tr>
<tr>
<td>166</td>
<td>0.001800</td>
<td>1.304062</td>
<td>0.048175</td>
<td>157.437500</td>
<td>0.044627</td>
<td>0.054063</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.250000</td>
<td>1.000000</td>
</tr>
<tr>
<td>167</td>
<td>0.001800</td>
<td>2.096750</td>
<td>0.622596</td>
<td>152.500000</td>
<td>0.045056</td>
<td>0.065500</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.406250</td>
<td>1.625000</td>
</tr>
<tr>
<td>168</td>
<td>0.002400</td>
<td>1.239969</td>
<td>0.684414</td>
<td>178.750000</td>
<td>0.059944</td>
<td>-0.010031</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.312500</td>
<td>0.937500</td>
</tr>
<tr>
<td>169</td>
<td>0.002600</td>
<td>2.421156</td>
<td>0.275769</td>
<td>148.000000</td>
<td>0.065235</td>
<td>-0.000719</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.484375</td>
<td>1.937500</td>
</tr>
<tr>
<td>170</td>
<td>0.002100</td>
<td>2.032656</td>
<td>0.336890</td>
<td>161.906250</td>
<td>0.051958</td>
<td>0.001406</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.406250</td>
<td>1.625000</td>
</tr>
<tr>
<td>171</td>
<td>0.001400</td>
<td>1.511063</td>
<td>0.325746</td>
<td>168.468750</td>
<td>0.035243</td>
<td>0.026688</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.296875</td>
<td>1.187500</td>
</tr>
<tr>
<td>172</td>
<td>0.003000</td>
<td>1.951531</td>
<td>0.045671</td>
<td>144.406250</td>
<td>0.074043</td>
<td>0.076531</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.375000</td>
<td>1.500000</td>
</tr>
<tr>
<td>173</td>
<td>0.002100</td>
<td>1.740781</td>
<td>0.342934</td>
<td>171.343750</td>
<td>0.053517</td>
<td>0.006406</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.359375</td>
<td>1.375000</td>
</tr>
<tr>
<td>174</td>
<td>0.003400</td>
<td>2.343219</td>
<td>0.266610</td>
<td>155.906250</td>
<td>0.083916</td>
<td>-0.031781</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.500000</td>
<td>1.875000</td>
</tr>
<tr>
<td>175</td>
<td>0.004300</td>
<td>1.486844</td>
<td>0.470988</td>
<td>148.437500</td>
<td>0.106308</td>
<td>0.033719</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.328125</td>
<td>1.125000</td>
</tr>
<tr>
<td>176</td>
<td>0.003300</td>
<td>1.989469</td>
<td>0.528197</td>
<td>153.250000</td>
<td>0.082154</td>
<td>0.036344</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.390625</td>
<td>1.562500</td>
</tr>
<tr>
<td>177</td>
<td>0.003300</td>
<td>1.864125</td>
<td>0.239849</td>
<td>158.500000</td>
<td>0.081617</td>
<td>0.067250</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.359375</td>
<td>1.437500</td>
</tr>
<tr>
<td>178</td>
<td>0.002200</td>
<td>1.312813</td>
<td>0.538599</td>
<td>182.281250</td>
<td>0.054456</td>
<td>0.062812</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.250000</td>
<td>1.000000</td>
</tr>
<tr>
<td>179</td>
<td>0.003200</td>
<td>1.249313</td>
<td>0.273266</td>
<td>174.625000</td>
<td>0.080913</td>
<td>0.014937</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.296875</td>
<td>0.937500</td>
</tr>
<tr>
<td>180</td>
<td>0.003500</td>
<td>1.889438</td>
<td>0.607271</td>
<td>154.156250</td>
<td>0.086246</td>
<td>0.076938</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.375000</td>
<td>1.437500</td>
</tr>
<tr>
<td>181</td>
<td>0.003100</td>
<td>1.522625</td>
<td>0.549491</td>
<td>161.156250</td>
<td>0.077974</td>
<td>0.038250</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.296875</td>
<td>1.187500</td>
</tr>
<tr>
<td>182</td>
<td>0.002300</td>
<td>2.018625</td>
<td>0.838069</td>
<td>162.187500</td>
<td>0.056574</td>
<td>-0.043875</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.437500</td>
<td>1.625000</td>
</tr>
<tr>
<td>183</td>
<td>0.003300</td>
<td>1.952188</td>
<td>0.067501</td>
<td>151.656250</td>
<td>0.083050</td>
<td>0.077187</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.375000</td>
<td>1.500000</td>
</tr>
<tr>
<td>184</td>
<td>0.003200</td>
<td>1.915406</td>
<td>0.588369</td>
<td>146.625000</td>
<td>0.080916</td>
<td>0.118531</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.359375</td>
<td>1.437500</td>
</tr>
<tr>
<td>185</td>
<td>0.003000</td>
<td>1.611500</td>
<td>0.397920</td>
<td>163.406250</td>
<td>0.074150</td>
<td>0.049000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.312500</td>
<td>1.250000</td>
</tr>
<tr>
<td>186</td>
<td>0.004800</td>
<td>1.944094</td>
<td>0.120428</td>
<td>142.812500</td>
<td>0.120602</td>
<td>0.069094</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.375000</td>
<td>1.500000</td>
</tr>
<tr>
<td>187</td>
<td>0.004200</td>
<td>1.794625</td>
<td>0.322431</td>
<td>156.375000</td>
<td>0.104972</td>
<td>-0.002250</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.359375</td>
<td>1.437500</td>
</tr>
<tr>
<td>188</td>
<td>0.003100</td>
<td>1.390000</td>
<td>0.233579</td>
<td>163.593750</td>
<td>0.078733</td>
<td>0.061875</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.265625</td>
<td>1.062500</td>
</tr>
<tr>
<td>189</td>
<td>0.004200</td>
<td>2.439969</td>
<td>0.312798</td>
<td>139.812500</td>
<td>0.105942</td>
<td>0.096219</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.468750</td>
<td>1.875000</td>
</tr>
<tr>
<td>190</td>
<td>0.003300</td>
<td>2.159250</td>
<td>0.763765</td>
<td>165.250000</td>
<td>0.083290</td>
<td>-0.028250</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.437500</td>
<td>1.750000</td>
</tr>
<tr>
<td>191</td>
<td>0.006300</td>
<td>2.551125</td>
<td>0.054667</td>
<td>136.125000</td>
<td>0.157735</td>
<td>0.051125</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.500000</td>
<td>2.000000</td>
</tr>
<tr>
<td>192</td>
<td>0.003800</td>
<td>2.033563</td>
<td>0.482005</td>
<td>146.250000</td>
<td>0.095691</td>
<td>0.064813</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.406250</td>
<td>1.562500</td>
</tr>
<tr>
<td>193</td>
<td>0.003700</td>
<td>1.528813</td>
<td>0.343776</td>
<td>160.156250</td>
<td>0.093565</td>
<td>0.060063</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.343750</td>
<td>1.125000</td>
</tr>
<tr>
<td>194</td>
<td>0.003400</td>
<td>2.250125</td>
<td>0.619515</td>
<td>149.781250</td>
<td>0.084903</td>
<td>0.062625</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.437500</td>
<td>1.750000</td>
</tr>
<tr>
<td>195</td>
<td>0.003700</td>
<td>2.154594</td>
<td>0.531447</td>
<td>153.718750</td>
<td>0.091290</td>
<td>0.045219</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.421875</td>
<td>1.687500</td>
</tr>
<tr>
<td>196</td>
<td>0.003000</td>
<td>0.998969</td>
<td>0.549875</td>
<td>174.750000</td>
<td>0.075860</td>
<td>-0.001031</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.312500</td>
<td>0.687500</td>
</tr>
<tr>
<td>197</td>
<td>0.004500</td>
<td>2.025719</td>
<td>0.533755</td>
<td>141.531250</td>
<td>0.112904</td>
<td>0.072594</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.390625</td>
<td>1.562500</td>
</tr>
<tr>
<td>198</td>
<td>0.003200</td>
<td>2.014812</td>
<td>0.784184</td>
<td>164.968750</td>
<td>0.080925</td>
<td>0.061687</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.390625</td>
<td>1.562500</td>
</tr>
<tr>
<td>199</td>
<td>0.003800</td>
<td>2.015688</td>
<td>0.753808</td>
<td>157.281250</td>
<td>0.095336</td>
<td>0.000063</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.453125</td>
<td>1.562500</td>
</tr>
<tr>
<td>200</td>
<td>0.004700</td>
<td>2.582094</td>
<td>0.081627</td>
<td>134.937500</td>
<td>0.117375</td>
<td>0.082094</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.500000</td>
<td>2.000000</td>
</tr>
<tr>
<td>201</td>
<td>0.005500</td>
<td>2.617125</td>
<td>0.052604</td>
<td>117.593750</td>
<td>0.137294</td>
<td>0.117125</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.500000</td>
<td>2.000000</td>
</tr>
<tr>
<td>202</td>
<td>0.002900</td>
<td>1.538594</td>
<td>0.726194</td>
<td>175.000000</td>
<td>0.072030</td>
<td>0.054219</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.296875</td>
<td>1.187500</td>
</tr>
<tr>
<td>203</td>
<td>0.005000</td>
<td>2.341625</td>
<td>0.230639</td>
<td>125.000000</td>
<td>0.125255</td>
<td>0.107250</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.421875</td>
<td>1.812500</td>
</tr>
<tr>
<td>204</td>
<td>0.003200</td>
<td>1.479344</td>
<td>0.693954</td>
<td>166.312500</td>
<td>0.080652</td>
<td>0.057469</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.296875</td>
<td>1.125000</td>
</tr>
<tr>
<td>205</td>
<td>0.006100</td>
<td>1.911000</td>
<td>0.508582</td>
<td>138.000000</td>
<td>0.152110</td>
<td>0.082875</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.453125</td>
<td>1.375000</td>
</tr>
<tr>
<td>206</td>
<td>0.004200</td>
<td>2.191469</td>
<td>0.566582</td>
<td>151.781250</td>
<td>0.105272</td>
<td>0.003969</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.437500</td>
<td>1.750000</td>
</tr>
<tr>
<td>207</td>
<td>0.005800</td>
<td>2.579594</td>
<td>0.054079</td>
<td>129.500000</td>
<td>0.145311</td>
<td>0.079594</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.500000</td>
<td>2.000000</td>
</tr>
<tr>
<td>208</td>
<td>0.005500</td>
<td>1.945406</td>
<td>0.051905</td>
<td>126.000000</td>
<td>0.136839</td>
<td>0.070406</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.375000</td>
<td>1.500000</td>
</tr>
<tr>
<td>209</td>
<td>0.005400</td>
<td>2.622750</td>
<td>0.034297</td>
<td>118.375000</td>
<td>0.133929</td>
<td>0.122750</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.500000</td>
<td>2.000000</td>
</tr>
<tr>
<td>210</td>
<td>0.003500</td>
<td>1.786437</td>
<td>0.333091</td>
<td>154.718750</td>
<td>0.088586</td>
<td>0.067688</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.343750</td>
<td>1.375000</td>
</tr>
<tr>
<td>211</td>
<td>0.005700</td>
<td>1.517031</td>
<td>0.872162</td>
<td>154.875000</td>
<td>0.141901</td>
<td>0.032656</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.296875</td>
<td>1.187500</td>
</tr>
<tr>
<td>212</td>
<td>0.005000</td>
<td>2.036375</td>
<td>0.079070</td>
<td>128.437500</td>
<td>0.124827</td>
<td>0.114500</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.421875</td>
<td>1.500000</td>
</tr>
<tr>
<td>213</td>
<td>0.005600</td>
<td>2.483187</td>
<td>0.293028</td>
<td>133.343750</td>
<td>0.140705</td>
<td>0.061313</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.484375</td>
<td>1.937500</td>
</tr>
<tr>
<td>214</td>
<td>0.004900</td>
<td>1.648875</td>
<td>0.830751</td>
<td>166.312500</td>
<td>0.122645</td>
<td>0.008250</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.328125</td>
<td>1.312500</td>
</tr>
<tr>
<td>215</td>
<td>0.005400</td>
<td>2.076156</td>
<td>0.733892</td>
<td>132.250000</td>
<td>0.135490</td>
<td>0.123031</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.390625</td>
<td>1.562500</td>
</tr>
<tr>
<td>216</td>
<td>0.005000</td>
<td>2.444750</td>
<td>0.460210</td>
<td>127.906250</td>
<td>0.124910</td>
<td>0.101000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.468750</td>
<td>1.875000</td>
</tr>
<tr>
<td>217</td>
<td>0.003100</td>
<td>1.585750</td>
<td>0.326160</td>
<td>164.843750</td>
<td>0.077131</td>
<td>0.101375</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.296875</td>
<td>1.187500</td>
</tr>
<tr>
<td>218</td>
<td>0.004700</td>
<td>2.034937</td>
<td>0.044813</td>
<td>132.562500</td>
<td>0.118740</td>
<td>0.144312</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.390625</td>
<td>1.500000</td>
</tr>
<tr>
<td>219</td>
<td>0.003600</td>
<td>1.324625</td>
<td>0.808525</td>
<td>153.437500</td>
<td>0.090733</td>
<td>0.074625</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.250000</td>
<td>1.000000</td>
</tr>
<tr>
<td>220</td>
<td>0.006800</td>
<td>2.000000</td>
<td>0.083942</td>
<td>141.843750</td>
<td>0.170198</td>
<td>0.078125</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.421875</td>
<td>1.500000</td>
</tr>
<tr>
<td>221</td>
<td>0.005100</td>
<td>2.008219</td>
<td>0.046265</td>
<td>142.531250</td>
<td>0.126283</td>
<td>0.133219</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.375000</td>
<td>1.500000</td>
</tr>
<tr>
<td>222</td>
<td>0.005500</td>
<td>1.650156</td>
<td>0.364033</td>
<td>147.906250</td>
<td>0.136476</td>
<td>0.009531</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.328125</td>
<td>1.312500</td>
</tr>
<tr>
<td>223</td>
<td>0.005800</td>
<td>2.438000</td>
<td>0.249815</td>
<td>148.187500</td>
<td>0.144775</td>
<td>0.016125</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.484375</td>
<td>1.937500</td>
</tr>
<tr>
<td>224</td>
<td>0.004900</td>
<td>2.217156</td>
<td>0.524031</td>
<td>153.281250</td>
<td>0.123049</td>
<td>0.014031</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.453125</td>
<td>1.750000</td>
</tr>
<tr>
<td>225</td>
<td>0.004000</td>
<td>1.285625</td>
<td>0.539269</td>
<td>175.250000</td>
<td>0.099108</td>
<td>0.020000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.328125</td>
<td>0.937500</td>
</tr>
<tr>
<td>226</td>
<td>0.005500</td>
<td>1.902281</td>
<td>0.062341</td>
<td>145.000000</td>
<td>0.138005</td>
<td>0.027281</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.375000</td>
<td>1.500000</td>
</tr>
<tr>
<td>227</td>
<td>0.005500</td>
<td>1.390406</td>
<td>0.427751</td>
<td>160.781250</td>
<td>0.137022</td>
<td>0.046656</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.343750</td>
<td>1.000000</td>
</tr>
<tr>
<td>228</td>
<td>0.007800</td>
<td>2.675313</td>
<td>0.040066</td>
<td>100.968750</td>
<td>0.195479</td>
<td>0.175312</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.500000</td>
<td>2.000000</td>
</tr>
<tr>
<td>229</td>
<td>0.008500</td>
<td>2.631281</td>
<td>0.047803</td>
<td>111.593750</td>
<td>0.213051</td>
<td>0.131281</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.500000</td>
<td>2.000000</td>
</tr>
<tr>
<td>230</td>
<td>0.005600</td>
<td>1.051094</td>
<td>0.523414</td>
<td>158.750000</td>
<td>0.139961</td>
<td>0.051094</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.250000</td>
<td>0.750000</td>
</tr>
<tr>
<td>231</td>
<td>0.006200</td>
<td>1.914906</td>
<td>0.275807</td>
<td>147.687500</td>
<td>0.155035</td>
<td>0.102406</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.375000</td>
<td>1.437500</td>
</tr>
<tr>
<td>232</td>
<td>0.005300</td>
<td>2.501469</td>
<td>0.257705</td>
<td>137.781250</td>
<td>0.133709</td>
<td>0.079594</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.484375</td>
<td>1.937500</td>
</tr>
<tr>
<td>233</td>
<td>0.005300</td>
<td>1.980094</td>
<td>0.051462</td>
<td>136.843750</td>
<td>0.132938</td>
<td>0.105094</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.375000</td>
<td>1.500000</td>
</tr>
<tr>
<td>234</td>
<td>0.004600</td>
<td>1.868750</td>
<td>0.237607</td>
<td>159.562500</td>
<td>0.114713</td>
<td>0.071875</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.359375</td>
<td>1.437500</td>
</tr>
<tr>
<td>235</td>
<td>0.004400</td>
<td>1.249719</td>
<td>0.252509</td>
<td>174.031250</td>
<td>0.108821</td>
<td>0.077844</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.234375</td>
<td>0.937500</td>
</tr>
<tr>
<td>236</td>
<td>0.006200</td>
<td>2.620219</td>
<td>0.063403</td>
<td>124.593750</td>
<td>0.155129</td>
<td>0.120219</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.500000</td>
<td>2.000000</td>
</tr>
<tr>
<td>237</td>
<td>0.003200</td>
<td>0.717625</td>
<td>0.305497</td>
<td>186.031250</td>
<td>0.079256</td>
<td>0.045750</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.234375</td>
<td>0.437500</td>
</tr>
<tr>
<td>238</td>
<td>0.004400</td>
<td>1.477250</td>
<td>0.779215</td>
<td>172.531250</td>
<td>0.110622</td>
<td>-0.007125</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.359375</td>
<td>1.125000</td>
</tr>
<tr>
<td>239</td>
<td>0.005700</td>
<td>1.629469</td>
<td>0.800205</td>
<td>161.875000</td>
<td>0.143016</td>
<td>0.066969</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.312500</td>
<td>1.250000</td>
</tr>
<tr>
<td>240</td>
<td>0.009200</td>
<td>2.291625</td>
<td>0.582222</td>
<td>120.093750</td>
<td>0.229014</td>
<td>0.104125</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.437500</td>
<td>1.750000</td>
</tr>
<tr>
<td>241</td>
<td>0.006600</td>
<td>1.529563</td>
<td>0.206794</td>
<td>124.281250</td>
<td>0.165024</td>
<td>0.092062</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.375000</td>
<td>1.062500</td>
</tr>
<tr>
<td>242</td>
<td>0.005900</td>
<td>2.274562</td>
<td>0.581583</td>
<td>137.093750</td>
<td>0.148296</td>
<td>0.087062</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.437500</td>
<td>1.750000</td>
</tr>
<tr>
<td>243</td>
<td>0.005000</td>
<td>1.453344</td>
<td>0.231155</td>
<td>145.437500</td>
<td>0.124141</td>
<td>0.093969</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.421875</td>
<td>0.937500</td>
</tr>
<tr>
<td>244</td>
<td>0.010400</td>
<td>2.685938</td>
<td>0.028580</td>
<td>91.187500</td>
<td>0.259130</td>
<td>0.185937</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.500000</td>
<td>2.000000</td>
</tr>
<tr>
<td>245</td>
<td>0.012700</td>
<td>2.246594</td>
<td>0.370442</td>
<td>123.343750</td>
<td>0.317108</td>
<td>0.137219</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.421875</td>
<td>1.687500</td>
</tr>
<tr>
<td>246</td>
<td>0.008800</td>
<td>1.797625</td>
<td>0.502293</td>
<td>148.468750</td>
<td>0.219323</td>
<td>0.078875</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.343750</td>
<td>1.375000</td>
</tr>
<tr>
<td>247</td>
<td>0.006700</td>
<td>1.631813</td>
<td>0.388426</td>
<td>150.937500</td>
<td>0.166549</td>
<td>0.069312</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.312500</td>
<td>1.250000</td>
</tr>
<tr>
<td>248</td>
<td>0.006000</td>
<td>1.315937</td>
<td>0.041215</td>
<td>155.812500</td>
<td>0.150767</td>
<td>0.065937</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.250000</td>
<td>1.000000</td>
</tr>
<tr>
<td>249</td>
<td>0.008400</td>
<td>2.571656</td>
<td>0.135375</td>
<td>120.875000</td>
<td>0.209356</td>
<td>0.071656</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.500000</td>
<td>2.000000</td>
</tr>
<tr>
<td>250</td>
<td>0.008300</td>
<td>2.176437</td>
<td>0.514214</td>
<td>142.312500</td>
<td>0.208007</td>
<td>0.067062</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.484375</td>
<td>1.625000</td>
</tr>
<tr>
<td>251</td>
<td>0.006300</td>
<td>2.523594</td>
<td>0.289065</td>
<td>122.156250</td>
<td>0.157367</td>
<td>0.101719</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.484375</td>
<td>1.937500</td>
</tr>
<tr>
<td>252</td>
<td>0.011300</td>
<td>2.660062</td>
<td>0.057394</td>
<td>104.250000</td>
<td>0.281868</td>
<td>0.160062</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.500000</td>
<td>2.000000</td>
</tr>
<tr>
<td>253</td>
<td>0.006300</td>
<td>2.090219</td>
<td>0.728129</td>
<td>158.812500</td>
<td>0.157074</td>
<td>0.043344</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.421875</td>
<td>1.625000</td>
</tr>
<tr>
<td>254</td>
<td>0.009700</td>
<td>1.952531</td>
<td>0.273928</td>
<td>100.968750</td>
<td>0.242104</td>
<td>0.202531</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.375000</td>
<td>1.375000</td>
</tr>
<tr>
<td>255</td>
<td>0.005300</td>
<td>1.614875</td>
<td>0.507088</td>
<td>149.437500</td>
<td>0.132968</td>
<td>0.130500</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.296875</td>
<td>1.187500</td>
</tr>
<tr>
<td>256</td>
<td>0.004600</td>
<td>2.410469</td>
<td>0.470044</td>
<td>143.781250</td>
<td>0.114553</td>
<td>0.066719</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.468750</td>
<td>1.875000</td>
</tr>
<tr>
<td>257</td>
<td>0.005600</td>
<td>1.957250</td>
<td>0.512706</td>
<td>160.656250</td>
<td>0.140188</td>
<td>0.004125</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.390625</td>
<td>1.562500</td>
</tr>
<tr>
<td>258</td>
<td>0.012400</td>
<td>2.033531</td>
<td>0.028032</td>
<td>129.031250</td>
<td>0.310667</td>
<td>0.158531</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.375000</td>
<td>1.500000</td>
</tr>
<tr>
<td>259</td>
<td>0.006900</td>
<td>2.486875</td>
<td>0.256204</td>
<td>143.375000</td>
<td>0.173558</td>
<td>0.065000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.484375</td>
<td>1.937500</td>
</tr>
<tr>
<td>260</td>
<td>0.006700</td>
<td>2.631969</td>
<td>0.049591</td>
<td>120.406250</td>
<td>0.168264</td>
<td>0.131969</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.500000</td>
<td>2.000000</td>
</tr>
<tr>
<td>261</td>
<td>0.006300</td>
<td>2.456062</td>
<td>0.285178</td>
<td>145.406250</td>
<td>0.156538</td>
<td>0.034188</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.484375</td>
<td>1.937500</td>
</tr>
<tr>
<td>262</td>
<td>0.007500</td>
<td>1.681875</td>
<td>0.527960</td>
<td>130.531250</td>
<td>0.186929</td>
<td>0.119375</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.312500</td>
<td>1.250000</td>
</tr>
<tr>
<td>263</td>
<td>0.006200</td>
<td>2.121219</td>
<td>0.502026</td>
<td>153.093750</td>
<td>0.155859</td>
<td>0.011844</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.484375</td>
<td>1.625000</td>
</tr>
<tr>
<td>264</td>
<td>0.004100</td>
<td>1.382219</td>
<td>0.089439</td>
<td>160.250000</td>
<td>0.102401</td>
<td>0.116594</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.265625</td>
<td>1.000000</td>
</tr>
<tr>
<td>265</td>
<td>0.008300</td>
<td>2.093438</td>
<td>0.411968</td>
<td>124.750000</td>
<td>0.207887</td>
<td>0.109063</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.484375</td>
<td>1.500000</td>
</tr>
<tr>
<td>266</td>
<td>0.008900</td>
<td>2.058906</td>
<td>0.034875</td>
<td>126.562500</td>
<td>0.222189</td>
<td>0.183906</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.375000</td>
<td>1.500000</td>
</tr>
<tr>
<td>267</td>
<td>0.007400</td>
<td>2.608875</td>
<td>0.073909</td>
<td>120.781250</td>
<td>0.183775</td>
<td>0.108875</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.500000</td>
<td>2.000000</td>
</tr>
<tr>
<td>268</td>
<td>0.006300</td>
<td>2.387469</td>
<td>0.332426</td>
<td>156.406250</td>
<td>0.157265</td>
<td>0.043719</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.468750</td>
<td>1.875000</td>
</tr>
<tr>
<td>269</td>
<td>0.006600</td>
<td>2.007313</td>
<td>0.126664</td>
<td>140.125000</td>
<td>0.165939</td>
<td>0.022938</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.484375</td>
<td>1.500000</td>
</tr>
<tr>
<td>270</td>
<td>0.007900</td>
<td>2.372312</td>
<td>0.598380</td>
<td>122.281250</td>
<td>0.197001</td>
<td>0.106688</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.453125</td>
<td>1.812500</td>
</tr>
<tr>
<td>271</td>
<td>0.008800</td>
<td>2.576531</td>
<td>0.264298</td>
<td>110.406250</td>
<td>0.219564</td>
<td>0.154656</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.484375</td>
<td>1.937500</td>
</tr>
<tr>
<td>272</td>
<td>0.008000</td>
<td>2.631000</td>
<td>0.057099</td>
<td>114.875000</td>
<td>0.200479</td>
<td>0.131000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.500000</td>
<td>2.000000</td>
</tr>
<tr>
<td>273</td>
<td>0.005600</td>
<td>2.336750</td>
<td>0.450358</td>
<td>156.406250</td>
<td>0.140186</td>
<td>-0.007000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.468750</td>
<td>1.875000</td>
</tr>
<tr>
<td>274</td>
<td>0.007000</td>
<td>2.073625</td>
<td>0.652751</td>
<td>145.812500</td>
<td>0.173851</td>
<td>0.042375</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.406250</td>
<td>1.625000</td>
</tr>
<tr>
<td>275</td>
<td>0.005300</td>
<td>1.513906</td>
<td>0.523808</td>
<td>155.281250</td>
<td>0.131418</td>
<td>0.107656</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.281250</td>
<td>1.125000</td>
</tr>
<tr>
<td>276</td>
<td>0.008500</td>
<td>2.319188</td>
<td>0.494408</td>
<td>145.781250</td>
<td>0.212100</td>
<td>0.053562</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.453125</td>
<td>1.812500</td>
</tr>
<tr>
<td>277</td>
<td>0.008600</td>
<td>2.180406</td>
<td>0.577412</td>
<td>136.781250</td>
<td>0.214137</td>
<td>0.133531</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.421875</td>
<td>1.625000</td>
</tr>
<tr>
<td>278</td>
<td>0.007500</td>
<td>2.448063</td>
<td>0.300101</td>
<td>110.593750</td>
<td>0.186933</td>
<td>0.166813</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.468750</td>
<td>1.812500</td>
</tr>
<tr>
<td>279</td>
<td>0.008200</td>
<td>1.882812</td>
<td>0.649189</td>
<td>146.125000</td>
<td>0.204620</td>
<td>0.054688</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.390625</td>
<td>1.437500</td>
</tr>
<tr>
<td>280</td>
<td>0.006000</td>
<td>2.545938</td>
<td>0.252563</td>
<td>128.875000</td>
<td>0.149440</td>
<td>0.124062</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.484375</td>
<td>1.937500</td>
</tr>
<tr>
<td>281</td>
<td>0.012900</td>
<td>2.379688</td>
<td>0.484250</td>
<td>131.000000</td>
<td>0.323048</td>
<td>0.098438</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.468750</td>
<td>1.812500</td>
</tr>
<tr>
<td>282</td>
<td>0.011500</td>
<td>2.340500</td>
<td>0.344941</td>
<td>95.031250</td>
<td>0.288345</td>
<td>0.231125</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.421875</td>
<td>1.687500</td>
</tr>
<tr>
<td>283</td>
<td>0.005700</td>
<td>2.508844</td>
<td>0.285010</td>
<td>134.562500</td>
<td>0.142858</td>
<td>0.086969</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.484375</td>
<td>1.937500</td>
</tr>
<tr>
<td>284</td>
<td>0.007000</td>
<td>2.177875</td>
<td>0.643062</td>
<td>133.593750</td>
<td>0.175080</td>
<td>0.146625</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.406250</td>
<td>1.625000</td>
</tr>
<tr>
<td>285</td>
<td>0.005000</td>
<td>2.036187</td>
<td>0.838778</td>
<td>175.062500</td>
<td>0.125452</td>
<td>0.004938</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.406250</td>
<td>1.625000</td>
</tr>
<tr>
<td>286</td>
<td>0.008400</td>
<td>2.154094</td>
<td>0.272045</td>
<td>143.531250</td>
<td>0.210086</td>
<td>0.075969</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.453125</td>
<td>1.625000</td>
</tr>
<tr>
<td>287</td>
<td>0.008500</td>
<td>2.649312</td>
<td>0.055325</td>
<td>107.875000</td>
<td>0.213008</td>
<td>0.149313</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.500000</td>
<td>2.000000</td>
</tr>
<tr>
<td>288</td>
<td>0.006300</td>
<td>2.443750</td>
<td>0.499017</td>
<td>128.562500</td>
<td>0.156478</td>
<td>0.100000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.468750</td>
<td>1.875000</td>
</tr>
<tr>
<td>289</td>
<td>0.009200</td>
<td>2.385531</td>
<td>0.404821</td>
<td>114.000000</td>
<td>0.229171</td>
<td>0.119906</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.453125</td>
<td>1.812500</td>
</tr>
<tr>
<td>290</td>
<td>0.006300</td>
<td>1.780125</td>
<td>0.517382</td>
<td>150.781250</td>
<td>0.157621</td>
<td>0.077000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.390625</td>
<td>1.312500</td>
</tr>
<tr>
<td>291</td>
<td>0.003900</td>
<td>2.370719</td>
<td>0.300337</td>
<td>171.031250</td>
<td>0.098286</td>
<td>0.026969</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.468750</td>
<td>1.875000</td>
</tr>
<tr>
<td>292</td>
<td>0.004600</td>
<td>1.308406</td>
<td>0.068198</td>
<td>170.750000</td>
<td>0.115032</td>
<td>0.042781</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.265625</td>
<td>1.000000</td>
</tr>
<tr>
<td>293</td>
<td>0.007400</td>
<td>2.651500</td>
<td>0.043233</td>
<td>106.656250</td>
<td>0.184049</td>
<td>0.151500</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.500000</td>
<td>2.000000</td>
</tr>
<tr>
<td>294</td>
<td>0.010600</td>
<td>2.305781</td>
<td>0.370243</td>
<td>126.500000</td>
<td>0.266168</td>
<td>0.102656</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.453125</td>
<td>1.750000</td>
</tr>
<tr>
<td>295</td>
<td>0.007600</td>
<td>2.330500</td>
<td>0.366948</td>
<td>144.093750</td>
<td>0.189974</td>
<td>0.064875</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.453125</td>
<td>1.812500</td>
</tr>
<tr>
<td>296</td>
<td>0.005900</td>
<td>1.667719</td>
<td>0.383545</td>
<td>149.000000</td>
<td>0.148483</td>
<td>0.058344</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.421875</td>
<td>1.187500</td>
</tr>
<tr>
<td>297</td>
<td>0.005600</td>
<td>2.016063</td>
<td>0.289297</td>
<td>155.687500</td>
<td>0.139351</td>
<td>0.062937</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.390625</td>
<td>1.562500</td>
</tr>
<tr>
<td>298</td>
<td>0.010600</td>
<td>2.625719</td>
<td>0.219611</td>
<td>94.312500</td>
<td>0.264362</td>
<td>0.188219</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.500000</td>
<td>1.937500</td>
</tr>
<tr>
<td>299</td>
<td>0.010600</td>
<td>2.524094</td>
<td>0.246387</td>
<td>128.343750</td>
<td>0.264156</td>
<td>0.102219</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.484375</td>
<td>1.937500</td>
</tr>
<tr>
<td>300</td>
<td>0.010200</td>
<td>2.690281</td>
<td>0.027626</td>
<td>101.812500</td>
<td>0.254426</td>
<td>0.190281</td>
<td>0.000000</td>
<td>0.000000</td>
<td>0.500000</td>
<td>2.000000</td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>unsloth</tag>
        <tag>grpo</tag>
        <tag>phi-4</tag>
      </tags>
  </entry>
  <entry>
    <title>conda常用命令</title>
    <url>/2025/01/22/conda%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>大致按日常使用频率来介绍conda的常用命令。</p>
<span id="more"></span>

<hr>
<h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><h5 id="创建环境"><a href="#创建环境" class="headerlink" title="创建环境"></a>创建环境</h5><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda create -n ENV_NAME python=<span class="number">3</span>.<span class="number">9</span></span><br></pre></td></tr></table></figure>

<ul>
<li>创建名为<code>ENV_NAME</code>的新环境，并指定<code>python版本</code>为<code>3.9</code>。</li>
</ul>
<h5 id="激活环境"><a href="#激活环境" class="headerlink" title="激活环境"></a>激活环境</h5><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda activate ENV_NAME</span><br></pre></td></tr></table></figure>

<ul>
<li>激活你的<code>ENV_NAME</code>环境。</li>
</ul>
<h5 id="退出环境"><a href="#退出环境" class="headerlink" title="退出环境"></a>退出环境</h5><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda deactivate</span><br></pre></td></tr></table></figure>

<!--more-->

<h5 id="安装包"><a href="#安装包" class="headerlink" title="安装包"></a>安装包</h5><h6 id="使用pip安装"><a href="#使用pip安装" class="headerlink" title="使用pip安装"></a>使用pip安装</h6><ul>
<li><p>安装单个包：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">pip install PACKAGE_NAME</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装依赖包列表</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure>

<p>这里的<code>-r</code>是选项<code>--requirement</code>的缩写，表示告诉<code>pip</code>从一个指定的文件中读取需要安装的依赖包列表。</p>
</li>
</ul>
<h6 id="使用conda包管理安装"><a href="#使用conda包管理安装" class="headerlink" title="使用conda包管理安装"></a>使用conda包管理安装</h6><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda install PACKAGE_NAME</span><br></pre></td></tr></table></figure>

<ul>
<li>安装<code>PACKAGE_NAME</code>包</li>
</ul>
<h5 id="列出所有环境"><a href="#列出所有环境" class="headerlink" title="列出所有环境"></a>列出所有环境</h5><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda env list</span><br><span class="line"></span><br><span class="line">or</span><br><span class="line"></span><br><span class="line">conda info -e   # conda info --env</span><br></pre></td></tr></table></figure>

<h5 id="删除环境"><a href="#删除环境" class="headerlink" title="删除环境"></a>删除环境</h5><figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">conda remove -n ENV_NAME --all</span><br></pre></td></tr></table></figure>

<h5 id="Jupyter-notebook下创建内核"><a href="#Jupyter-notebook下创建内核" class="headerlink" title="Jupyter notebook下创建内核"></a>Jupyter notebook下创建内核</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conda create -n ENV_NAME python=<span class="number">3.11</span></span><br><span class="line">conda activate ENV_NAME</span><br><span class="line">pip install xxx  <span class="comment"># 仅做示例哈</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 给conda环境创建特殊内核</span></span><br><span class="line">conda install ipykernel</span><br><span class="line">python -m ipykernel install --user --name ENV_NAME --display-name <span class="string">&quot;jnENV_NAME&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看已安装的Jupyter内核 base环境</span></span><br><span class="line">jupyter kernelspec <span class="built_in">list</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除指定内核</span></span><br><span class="line">jupyter kernelspec uninstall jnENV_NAME</span><br><span class="line"></span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">jupyter kernelspec remove jnENV_NAME</span><br><span class="line"></span><br><span class="line"><span class="comment"># 回到base环境</span></span><br><span class="line">jupyter kernelspec <span class="built_in">list</span> <span class="comment"># 即可看到jnENV_NAME</span></span><br><span class="line">jupyter notebook  <span class="comment"># 启动jupyter notebook </span></span><br></pre></td></tr></table></figure>

<p>上述命令只用动四个地方：</p>
<ul>
<li>python版本：python&#x3D;3.11</li>
<li>conda环境名：ENV_NAME</li>
<li>（可选）pip install xxx</li>
<li>jupyter notebook中显示的环境名（可与conda环境名一致）：jnENV_NAME</li>
</ul>
<blockquote>
<p> 注意点：启动jupyter notebook时，需在base环境下启动（在其他conda环境下启动不了）。</p>
</blockquote>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>conda</tag>
      </tags>
  </entry>
  <entry>
    <title>cursor接入DeepSeek-R1和DeepSeek-V3教程</title>
    <url>/2025/02/06/cursor%E6%8E%A5%E5%85%A5DeepSeek-R1%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>目前（2025&#x2F;2&#x2F;6），deepseek大火，超低训练成本取得了超高的性能表现，且cursor现已不能无限白嫖（锁机器码），想充值cursor还要申请个海外信用卡，本人对信用卡比较抵触，遂还是使用deepseek接入的方式吧。想申请海外信用卡的小友可参考<a href="https://www.youtube.com/watch?v=Ag5918UY-CM">这个视频</a>操作。</p>
<span id="more"></span>

<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><img src="/2025/02/06/cursor%E6%8E%A5%E5%85%A5DeepSeek-R1%E6%95%99%E7%A8%8B/image-20250206141315961.png" class="" title="image-20250206141315961">

<p><a href="https://api-docs.deepseek.com/zh-cn/news/news250120">图片来源</a>，从上图可以看出，<code>DeepSeek-R1</code>拥有比肩<code>OpenAI o1</code>的性能，且比<code>DeepSeek-V3</code>更强些，价格方面：</p>
<img src="/2025/02/06/cursor%E6%8E%A5%E5%85%A5DeepSeek-R1%E6%95%99%E7%A8%8B/image-20250206141754281.png" class="" title="image-20250206141754281">

<p><a href="https://api-docs.deepseek.com/zh-cn/quick_start/pricing">图片来源</a>，但是<code>DeepSeek-V3</code>比<code>DeepSeek-R1</code>价格要便宜的多，所以我打算两种模型都接入<code>cursor</code>实验效果。</p>
<p>好，开始操作：</p>
<img src="/2025/02/06/cursor%E6%8E%A5%E5%85%A5DeepSeek-R1%E6%95%99%E7%A8%8B/image-20250206142750109.png" class="" title="image-20250206142750109">

<p><a href="https://api-docs.deepseek.com/zh-cn/">图片来源</a></p>
<ul>
<li><p>打开<code>cursor设置</code>-&gt;<code>Models</code>-&gt;取消掉所有模型的勾选</p>
</li>
<li><p>点击<code>Model Names</code>栏最下面的<code>+Add model</code>，先添加<code>DeepSeek-V3</code>，输出<code>deepseek-chat</code></p>
</li>
<li><p>点击上方图片所示的<code>API key</code>-&gt;<code>创建API key</code>-&gt;<code>输入名称：deepseek-chat</code>，你将得到<code>API key:sk-xxxx....</code>，复制下来</p>
</li>
<li><p>在下方的<code>Override OpenAI Base URL(when using key)</code>栏中输入：<code>https://api.deepseek.com/v1</code></p>
</li>
<li><p>点击<code>Override OpenAI Base URL(when using key)</code>栏右方的<code>Save</code>，点击<code>OpenAI API Key</code>右方的<code>Verify</code>，你将看到：</p>
<img src="/2025/02/06/cursor%E6%8E%A5%E5%85%A5DeepSeek-R1%E6%95%99%E7%A8%8B/image-20250206143959966.png" class="" title="image-20250206143959966"></li>
</ul>
<p>好，实验一下：</p>
<p>不对劲，非常不对劲，由于现在deepseek依旧服务器压力很大（被攻击），后续再试吧。</p>
<p>TODO…</p>
<h2 id="试试魔法："><a href="#试试魔法：" class="headerlink" title="试试魔法："></a>试试魔法：</h2><ul>
<li>点击<a href="https://github.com/bestK/cursor-fake-machine/releases/download/v0.0.2/cursor-fake-machine-0.0.2.vsix">这里</a>下载插件</li>
<li>将下载的插件拖到cursor扩展中</li>
<li><code>ctrl+shift+p</code>输入<code>fake</code>，选择<code>Fake Cursor</code>，会提示你重启<code>cursor</code>，重启之后就能用了</li>
<li>进入<code>C:\Users\chr\AppData\Roaming\Cursor\User\globalStorage</code>文件夹，找到<code>storage.json</code>，右键属性，将其改为只读</li>
</ul>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://www.bilibili.com/video/BV1uVrCYEE1W/?vd_source=075a061948e76c87e2ee8754e264056e">https://www.bilibili.com/video/BV1uVrCYEE1W/?vd_source=075a061948e76c87e2ee8754e264056e</a></li>
<li><a href="https://blog.csdn.net/qq_43592352/article/details/145020410">https://blog.csdn.net/qq_43592352/article/details/145020410</a></li>
</ol>
]]></content>
      <categories>
        <category>theory</category>
      </categories>
      <tags>
        <tag>cursor</tag>
        <tag>deepseek</tag>
      </tags>
  </entry>
  <entry>
    <title>fastapi+request再探之：requests.post</title>
    <url>/2025/04/25/fastapi-request%E5%86%8D%E6%8E%A2%E4%B9%8B%EF%BC%9Arequests-post/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>之前构建微服务的demo，包括<a href="https://caihaoran-00.github.io/2025/02/21/cam-senseVoice%E6%9E%84%E5%BB%BA%E5%BE%AE%E6%9C%8D%E5%8A%A1/">cam+senseVoice构建微服务</a>，<a href="https://caihaoran-00.github.io/2025/02/11/%E8%AF%B4%E8%AF%9D%E4%BA%BA%E7%A1%AE%E8%AE%A4%E4%B9%8BCAM/">说话人确认之CAM++</a>，<a href="https://caihaoran-00.github.io/2025/02/05/fastapi-request%E6%9E%84%E5%BB%BA%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BE%AE%E6%9C%8D%E5%8A%A1/">fastapi+request构建语音识别微服务</a>，我传输音频数据都是通过类似于<code>response = requests.post(f&quot;&#123;BASE_URL&#125;/users/&quot;, json=user_data)</code>的形式，也就是使用<code>json</code>字段来传输音频数据，因为<code>json</code>数据为文本格式，所以需base64编码成字符串进行传输，这两天想在我主机上压测下funasr的http方式的并发情况，看了下<a href="https://github.com/modelscope/FunASR/blob/main/runtime/python/http/client.py">官方的示例</a>，发现他并没有转化成base64形式，意识到对<code>requests.post</code>的用法了解的不全面，遂补上本文，咱们一起学习下。</p>
<span id="more"></span>

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>本文一步步讲解 <code>requests.post</code>，从最基础的概念到深入的用法，尽量用通俗易懂的语言。<code>requests</code> 是 Python 中一个非常流行的 HTTP 库，用于发送 HTTP 请求，而 <code>requests.post</code> 是专门用来发送 <strong>POST 请求</strong> 的方法。让我们由浅入深地展开。</p>
<hr>
<h3 id="1-什么是-POST-请求？"><a href="#1-什么是-POST-请求？" class="headerlink" title="1. 什么是 POST 请求？"></a><strong>1. 什么是 POST 请求？</strong></h3><p>在讲解 <code>requests.post</code> 之前，先简单了解一下 POST 请求是什么。</p>
<ul>
<li><strong>HTTP 请求</strong>：当你在浏览器访问网页或提交表单时，浏览器会向服务器发送请求，服务器返回数据。HTTP 是这种通信的基础协议。</li>
<li><strong>POST 请求</strong>：是 HTTP 请求的一种，用于向服务器<strong>发送数据</strong>，通常用于提交表单、上传文件或创建资源。比如，你在网站上注册账号，填写的用户名、密码等信息通常通过 POST 请求发送到服务器。</li>
<li><strong>特点</strong>：<ul>
<li>数据放在请求的 <strong>body（正文）</strong> 中，而不是 URL 中（不像 GET 请求那样暴露在 URL）。</li>
<li>适合发送较大的数据（如文件）或敏感信息（如密码）。</li>
<li>服务器可能会根据 POST 请求创建或修改数据。</li>
</ul>
</li>
</ul>
<p><strong>对比 GET 请求</strong>：</p>
<ul>
<li>GET：从服务器获取数据，参数在 URL 中（比如搜索时）。</li>
<li>POST：向服务器发送数据，参数在请求正文中，安全性更高。</li>
</ul>
<hr>
<h3 id="2-什么是-requests-post？"><a href="#2-什么是-requests-post？" class="headerlink" title="2. 什么是 requests.post？"></a><strong>2. 什么是 <code>requests.post</code>？</strong></h3><p><code>requests.post</code> 是 Python <code>requests</code> 库中的一个函数，用来发送 POST 请求到指定的 URL。它可以让你通过 Python 代码向服务器提交数据。</p>
<p><strong>安装 requests 库</strong>：<br>如果你还没有安装 <code>requests</code>，需要先安装：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install requests</span><br></pre></td></tr></table></figure>
<p>然后在 Python 代码中导入：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br></pre></td></tr></table></figure>

<p><strong>基本用法</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;https://example.com/api&quot;</span></span><br><span class="line">data = &#123;<span class="string">&quot;username&quot;</span>: <span class="string">&quot;xiaobai&quot;</span>, <span class="string">&quot;password&quot;</span>: <span class="string">&quot;123456&quot;</span>&#125;</span><br><span class="line">response = requests.post(url, data=data)</span><br><span class="line"><span class="built_in">print</span>(response.text)</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>解释</strong>：<ul>
<li><code>url</code>：你要发送 POST 请求的目标地址（服务器的 API 地址）。</li>
<li><code>data</code>：你要发送的数据，通常是一个字典，包含键值对（如用户名和密码）。</li>
<li><code>response</code>：服务器返回的响应，包含状态码、返回的数据等。</li>
<li><code>response.text</code>：返回的响应内容的文本形式。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="3-基础示例：发送一个简单的-POST-请求"><a href="#3-基础示例：发送一个简单的-POST-请求" class="headerlink" title="3. 基础示例：发送一个简单的 POST 请求"></a><strong>3. 基础示例：发送一个简单的 POST 请求</strong></h3><p>我们用一个公开的测试 API（比如 <code>https://httpbin.org/post</code>）来演示 <code>requests.post</code> 的基本用法。这个 API 会把你发送的数据原样返回，方便学习。</p>
<p><strong>代码</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;https://httpbin.org/post&quot;</span></span><br><span class="line">data = &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;Xiaobai&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="number">18</span>&#125;</span><br><span class="line">response = requests.post(url, data=data)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;状态码:&quot;</span>, response.status_code)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;返回内容:&quot;</span>, response.text)</span><br></pre></td></tr></table></figure>

<p><strong>运行结果</strong>（大致）：</p>
<figure class="highlight nim"><table><tr><td class="code"><pre><span class="line">状态码: <span class="number">200</span></span><br><span class="line">返回内容: &#123;</span><br><span class="line">  <span class="string">&quot;args&quot;</span>: &#123;&#125;, </span><br><span class="line">  <span class="string">&quot;data&quot;</span>: <span class="string">&quot;&quot;</span>, </span><br><span class="line">  <span class="string">&quot;files&quot;</span>: &#123;&#125;, </span><br><span class="line">  <span class="string">&quot;form&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;age&quot;</span>: <span class="string">&quot;18&quot;</span>, </span><br><span class="line">    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;Xiaobai&quot;</span></span><br><span class="line">  &#125;, </span><br><span class="line">  <span class="string">&quot;headers&quot;</span>: <span class="meta">&#123;...&#125;</span>, </span><br><span class="line">  <span class="string">&quot;json&quot;</span>: null, </span><br><span class="line">  <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://httpbin.org/post&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>解释</strong>：</p>
<ul>
<li><strong>状态码 200</strong>：表示请求成功（常见的状态码还有 404 表示未找到，500 表示服务器错误）。</li>
<li><strong>返回内容</strong>：服务器把我们发送的 <code>data</code>（<code>name</code> 和 <code>age</code>）放在 <code>form</code> 字段中返回，说明 POST 请求成功发送了数据。</li>
<li><strong>form</strong>：表示数据以表单形式发送。</li>
</ul>
<hr>
<h3 id="4-深入一点：requests-post-的常用参数"><a href="#4-深入一点：requests-post-的常用参数" class="headerlink" title="4. 深入一点：requests.post 的常用参数"></a><strong>4. 深入一点：<code>requests.post</code> 的常用参数</strong></h3><p><code>requests.post</code> 支持很多参数，让你更灵活地控制请求。以下是几个常用的：</p>
<h4 id="4-1-data：发送表单数据"><a href="#4-1-data：发送表单数据" class="headerlink" title="4.1 data：发送表单数据"></a><strong>4.1 <code>data</code>：发送表单数据</strong></h4><p><code>data</code> 参数用于发送表单格式的数据（<code>application/x-www-form-urlencoded</code>），通常是一个字典。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">data = &#123;<span class="string">&quot;key1&quot;</span>: <span class="string">&quot;value1&quot;</span>, <span class="string">&quot;key2&quot;</span>: <span class="string">&quot;value2&quot;</span>&#125;</span><br><span class="line">response = requests.post(url, data=data)</span><br></pre></td></tr></table></figure>

<ul>
<li>服务器会把 <code>data</code> 解析为表单字段。</li>
<li>注意：<code>data</code> 的值会被转换为字符串，所以如果你需要发送复杂数据（比如嵌套字典），考虑用 <code>json</code> 参数。</li>
</ul>
<h4 id="4-2-json：发送-JSON-数据"><a href="#4-2-json：发送-JSON-数据" class="headerlink" title="4.2 json：发送 JSON 数据"></a><strong>4.2 <code>json</code>：发送 JSON 数据</strong></h4><p>如果服务器要求数据以 JSON 格式（<code>application/json</code>）发送，使用 <code>json</code> 参数。<code>requests</code> 会自动将 Python 字典序列化为 JSON。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;https://httpbin.org/post&quot;</span></span><br><span class="line">payload = &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;Xiaobai&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="number">18</span>&#125;</span><br><span class="line">response = requests.post(url, json=payload)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(response.json())</span><br></pre></td></tr></table></figure>

<p><strong>输出</strong>（大致）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&#x27;args&#x27;</span>: &#123;&#125;, </span><br><span class="line">  <span class="string">&#x27;data&#x27;</span>: <span class="string">&#x27;&#123;&quot;name&quot;: &quot;Xiaobai&quot;, &quot;age&quot;: 18&#125;&#x27;</span>, </span><br><span class="line">  <span class="string">&#x27;files&#x27;</span>: &#123;&#125;, </span><br><span class="line">  <span class="string">&#x27;form&#x27;</span>: &#123;&#125;, </span><br><span class="line">  <span class="string">&#x27;headers&#x27;</span>: &#123;...&#125;, </span><br><span class="line">  <span class="string">&#x27;json&#x27;</span>: &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;Xiaobai&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">18</span>&#125;, </span><br><span class="line">  <span class="string">&#x27;url&#x27;</span>: <span class="string">&#x27;https://httpbin.org/post&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>区别</strong>：<ul>
<li><code>data</code>：发送表单格式，适合传统网页表单。</li>
<li><code>json</code>：发送 JSON 格式，适合现代 API 接口。</li>
<li><code>response.json()</code>：将返回的 JSON 数据解析为 Python 字典，方便操作。</li>
</ul>
</li>
</ul>
<h4 id="4-3-headers：添加请求头"><a href="#4-3-headers：添加请求头" class="headerlink" title="4.3 headers：添加请求头"></a><strong>4.3 <code>headers</code>：添加请求头</strong></h4><p>有些服务器要求特定的请求头（比如认证 token 或指定内容类型）。可以用 <code>headers</code> 参数设置。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0&quot;</span>,  <span class="comment"># 模拟浏览器</span></span><br><span class="line">    <span class="string">&quot;Authorization&quot;</span>: <span class="string">&quot;Bearer your_token&quot;</span>  <span class="comment"># API 认证</span></span><br><span class="line">&#125;</span><br><span class="line">response = requests.post(url, json=payload, headers=headers)</span><br></pre></td></tr></table></figure>

<h4 id="4-4-files：上传文件"><a href="#4-4-files：上传文件" class="headerlink" title="4.4 files：上传文件"></a><strong>4.4 <code>files</code>：上传文件</strong></h4><p>如果需要上传文件（比如图片、文档），使用 <code>files</code> 参数。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">url = <span class="string">&quot;https://httpbin.org/post&quot;</span></span><br><span class="line">files = &#123;<span class="string">&quot;file&quot;</span>: <span class="built_in">open</span>(<span class="string">&quot;example.txt&quot;</span>, <span class="string">&quot;rb&quot;</span>)&#125;  <span class="comment"># 打开文件</span></span><br><span class="line">response = requests.post(url, files=files)</span><br><span class="line"><span class="built_in">print</span>(response.json())</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>注意</strong>：文件需要以二进制模式（<code>rb</code>）打开。</li>
<li>可以上传多个文件：<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">files = &#123;</span><br><span class="line">    <span class="string">&quot;file1&quot;</span>: <span class="built_in">open</span>(<span class="string">&quot;file1.txt&quot;</span>, <span class="string">&quot;rb&quot;</span>),</span><br><span class="line">    <span class="string">&quot;file2&quot;</span>: <span class="built_in">open</span>(<span class="string">&quot;file2.jpg&quot;</span>, <span class="string">&quot;rb&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="4-5-params：添加-URL-查询参数"><a href="#4-5-params：添加-URL-查询参数" class="headerlink" title="4.5 params：添加 URL 查询参数"></a><strong>4.5 <code>params</code>：添加 URL 查询参数</strong></h4><p>虽然 POST 请求的数据通常在 body 中，但有时也需要在 URL 中附加查询参数（比如 <code>?key=value</code>）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">params = &#123;<span class="string">&quot;key&quot;</span>: <span class="string">&quot;value&quot;</span>&#125;</span><br><span class="line">response = requests.post(url, data=data, params=params)</span><br></pre></td></tr></table></figure>

<ul>
<li>实际请求的 URL 会变成：<code>https://httpbin.org/post?key=value</code>。</li>
</ul>
<h4 id="4-6-timeout：设置超时"><a href="#4-6-timeout：设置超时" class="headerlink" title="4.6 timeout：设置超时"></a><strong>4.6 <code>timeout</code>：设置超时</strong></h4><p>为了避免请求卡住，可以设置超时时间（秒）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">response = requests.post(url, data=data, timeout=<span class="number">5</span>)  <span class="comment"># 5秒超时</span></span><br></pre></td></tr></table></figure>

<ul>
<li>如果 5 秒内没有响应，会抛出 <code>requests.exceptions.Timeout</code> 异常。</li>
</ul>
<hr>
<h3 id="5-处理响应"><a href="#5-处理响应" class="headerlink" title="5. 处理响应"></a><strong>5. 处理响应</strong></h3><p>发送 POST 请求后，服务器会返回一个 <code>Response</code> 对象，包含状态码、响应内容等信息。以下是常用的属性和方法：</p>
<ul>
<li><p><strong>状态码</strong>：<code>response.status_code</code></p>
<ul>
<li>200：成功</li>
<li>400：请求错误</li>
<li>401：未授权</li>
<li>404：资源未找到</li>
<li>500：服务器错误</li>
</ul>
</li>
<li><p><strong>响应内容</strong>：</p>
<ul>
<li><code>response.text</code>：返回文本（字符串）。</li>
<li><code>response.json()</code>：如果返回的是 JSON 格式，解析为 Python 字典。</li>
<li><code>response.content</code>：返回二进制内容（比如图片、文件）。</li>
</ul>
</li>
<li><p><strong>响应头</strong>：<code>response.headers</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(response.headers[<span class="string">&quot;Content-Type&quot;</span>])  <span class="comment"># 查看响应类型</span></span><br></pre></td></tr></table></figure></li>
</ul>
<p><strong>示例：检查响应</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;成功！&quot;</span>, response.json())</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;失败，状态码:&quot;</span>, response.status_code)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="6-进阶：错误处理"><a href="#6-进阶：错误处理" class="headerlink" title="6. 进阶：错误处理"></a><strong>6. 进阶：错误处理</strong></h3><p>在实际使用中，POST 请求可能会失败，需要妥善处理异常。</p>
<p><strong>常见异常</strong>：</p>
<ul>
<li><code>requests.exceptions.RequestException</code>：所有请求错误的基类。</li>
<li><code>requests.exceptions.ConnectionError</code>：网络连接问题。</li>
<li><code>requests.exceptions.Timeout</code>：请求超时。</li>
<li><code>requests.exceptions.HTTPError</code>：HTTP 错误（如 404、500）。</li>
</ul>
<p><strong>示例：带错误处理的 POST 请求</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;https://httpbin.org/post&quot;</span></span><br><span class="line">data = &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;Xiaobai&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = requests.post(url, data=data, timeout=<span class="number">5</span>)</span><br><span class="line">    response.raise_for_status()  <span class="comment"># 如果状态码不是 200，抛出 HTTPError</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;成功！&quot;</span>, response.json())</span><br><span class="line"><span class="keyword">except</span> requests.exceptions.HTTPError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;HTTP 错误:&quot;</span>, e)</span><br><span class="line"><span class="keyword">except</span> requests.exceptions.ConnectionError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;连接错误:&quot;</span>, e)</span><br><span class="line"><span class="keyword">except</span> requests.exceptions.Timeout <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;请求超时:&quot;</span>, e)</span><br><span class="line"><span class="keyword">except</span> requests.exceptions.RequestException <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;其他错误:&quot;</span>, e)</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="7-实战示例：调用真实-API"><a href="#7-实战示例：调用真实-API" class="headerlink" title="7. 实战示例：调用真实 API"></a><strong>7. 实战示例：调用真实 API</strong></h3><p>假设我们要调用一个公开的 API（比如一个用户注册接口）。以下是一个模拟的例子：</p>
<p><strong>场景</strong>：向服务器注册一个新用户。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;https://api.example.com/register&quot;</span>  <span class="comment"># 假设的 API 地址</span></span><br><span class="line">payload = &#123;</span><br><span class="line">    <span class="string">&quot;username&quot;</span>: <span class="string">&quot;xiaobai&quot;</span>,</span><br><span class="line">    <span class="string">&quot;password&quot;</span>: <span class="string">&quot;123456&quot;</span>,</span><br><span class="line">    <span class="string">&quot;email&quot;</span>: <span class="string">&quot;xiaobai@example.com&quot;</span></span><br><span class="line">&#125;</span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;application/json&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Authorization&quot;</span>: <span class="string">&quot;Bearer your_api_key&quot;</span>  <span class="comment"># 如果需要</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = requests.post(url, json=payload, headers=headers, timeout=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">if</span> response.status_code == <span class="number">201</span>:  <span class="comment"># 201 表示创建成功</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;注册成功！&quot;</span>, response.json())</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;注册失败:&quot;</span>, response.status_code, response.text)</span><br><span class="line"><span class="keyword">except</span> requests.exceptions.RequestException <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;请求失败:&quot;</span>, e)</span><br></pre></td></tr></table></figure>

<p><strong>说明</strong>：</p>
<ul>
<li>使用 <code>json</code> 参数发送 JSON 数据。</li>
<li>添加 <code>headers</code> 指定内容类型和认证信息。</li>
<li>检查状态码 <code>201</code>（表示资源创建成功）。</li>
<li>使用 <code>try-except</code> 捕获可能的错误。</li>
</ul>
<hr>
<h3 id="8-常见问题与解答"><a href="#8-常见问题与解答" class="headerlink" title="8. 常见问题与解答"></a><strong>8. 常见问题与解答</strong></h3><ol>
<li><p><strong>什么时候用 <code>data</code> 和 <code>json</code>？</strong></p>
<ul>
<li>如果 API 要求表单数据（<code>application/x-www-form-urlencoded</code>），用 <code>data</code>。</li>
<li>如果 API 要求 JSON 数据（<code>application/json</code>），用 <code>json</code>。</li>
<li>看 API 文档确认，或者试试看（一般现代 API 用 JSON）。</li>
</ul>
</li>
<li><p><strong>为什么状态码是 400 或 401？</strong></p>
<ul>
<li>400：请求参数错误（比如缺少必填字段）。</li>
<li>401：未授权（可能是 token 错误或缺失）。</li>
<li>检查 API 文档，确认参数和认证方式。</li>
</ul>
</li>
<li><p><strong>如何调试 POST 请求？</strong></p>
<ul>
<li>打印 <code>response.text</code> 或 <code>response.json()</code> 查看服务器返回的错误信息。</li>
<li>使用 <code>print(response.request.body)</code> 查看发送的请求体。</li>
<li>使用工具（如 Postman）测试 API，确保请求格式正确。</li>
</ul>
</li>
<li><p><strong>如何发送复杂嵌套数据？</strong><br>用 <code>json</code> 参数，<code>requests</code> 会自动处理：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">payload = &#123;</span><br><span class="line">    <span class="string">&quot;user&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;name&quot;</span>: <span class="string">&quot;Xiaobai&quot;</span>,</span><br><span class="line">        <span class="string">&quot;info&quot;</span>: &#123;<span class="string">&quot;age&quot;</span>: <span class="number">18</span>, <span class="string">&quot;city&quot;</span>: <span class="string">&quot;Beijing&quot;</span>&#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">response = requests.post(url, json=payload)</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h3 id="9-总结与学习建议"><a href="#9-总结与学习建议" class="headerlink" title="9. 总结与学习建议"></a><strong>9. 总结与学习建议</strong></h3><ul>
<li><p><strong>总结</strong>：</p>
<ul>
<li><code>requests.post</code> 是用来发送 POST 请求的，适合提交数据到服务器。</li>
<li>基本用法：<code>requests.post(url, data=data)</code> 或 <code>requests.post(url, json=json)</code>。</li>
<li>支持多种参数：<code>headers</code>、<code>files</code>、<code>params</code>、<code>timeout</code> 等。</li>
<li>响应处理：检查 <code>status_code</code>、<code>text</code>、<code>json()</code>。</li>
<li>错误处理：用 <code>try-except</code> 捕获异常。</li>
</ul>
</li>
<li><p><strong>学习建议</strong>：</p>
<ul>
<li><strong>实践</strong>：找一个公开的 API（比如 <code>https://httpbin.org</code> 或 <code>https://jsonplaceholder.typicode.com</code>）多试几次。</li>
<li><strong>读文档</strong>：查看 <code>requests</code> 官方文档（<a href="https://requests.readthedocs.io)或/">https://requests.readthedocs.io）或</a> API 文档。</li>
<li><strong>用工具</strong>：用 Postman 或 cURL 测试 API，理解请求和响应的结构。</li>
<li><strong>进阶</strong>：学习 <code>requests.Session</code>（用于保持会话）、异步请求（<code>aiohttp</code>）或更复杂的认证机制（如 OAuth）。</li>
</ul>
</li>
</ul>
<hr>
<h2 id="实际的问题"><a href="#实际的问题" class="headerlink" title="实际的问题"></a>实际的问题</h2><p>好的，回到我们最初的问题，怎么通过http传输字节流，目前使用的是base64编码+json字段，现在有其他想法吗？</p>
<p>两种方式，一是使用data字段+ <code>headers=&#123;&quot;Content-Type&quot;: &quot;application/octet-stream&quot;&#125;</code>指定二进制流；二是使用files字段，虽然此方法也能实现，但方式一更加简洁明了，我打算使用方式一，<a href="https://caihaoran-00.github.io/2025/02/05/fastapi-request%E6%9E%84%E5%BB%BA%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BE%AE%E6%9C%8D%E5%8A%A1/">修改前的示例</a>：</p>
<p><strong>服务端修改后：</strong></p>
<blockquote>
<p>仅修改asr_endpoint函数。</p>
</blockquote>
<figure class="highlight python"><figcaption><span>fastapi_sensevoice_nobase64.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> funasr <span class="keyword">import</span> AutoModel</span><br><span class="line"><span class="keyword">from</span> funasr.utils.postprocess_utils <span class="keyword">import</span> rich_transcription_postprocess</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, Request</span><br><span class="line"><span class="keyword">import</span> uvicorn</span><br><span class="line"><span class="keyword">import</span> soundfile <span class="keyword">as</span> sf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化模型</span></span><br><span class="line">model = AutoModel(</span><br><span class="line">    model=<span class="string">&quot;iic/SenseVoiceSmall&quot;</span>,</span><br><span class="line">    vad_model=<span class="string">&quot;fsmn-vad&quot;</span>,</span><br><span class="line">    vad_kwargs=&#123;<span class="string">&quot;max_single_segment_time&quot;</span>: <span class="number">30000</span>&#125;,</span><br><span class="line">    disable_update=<span class="literal">True</span>,</span><br><span class="line">    device=<span class="string">&quot;cuda:0&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建FASTAPI实例</span></span><br><span class="line">app = FastAPI(title=<span class="string">&quot;Sensevoice+KWS&quot;</span>)</span><br><span class="line"></span><br><span class="line">SAVE_AUDIO = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/asr/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">asr_endpoint</span>(<span class="params">request: Request</span>):</span><br><span class="line">    <span class="comment"># 直接读裸字节流</span></span><br><span class="line">    audio_bytes = <span class="keyword">await</span> request.body()</span><br><span class="line">    <span class="keyword">if</span> SAVE_AUDIO:</span><br><span class="line">        audio_np = np.frombuffer(audio_bytes, dtype=np.int16)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 写入为 WAV 文件</span></span><br><span class="line">        sf.write(<span class="string">&quot;received_audio.wav&quot;</span>, audio_np, samplerate=<span class="number">16000</span>, subtype=<span class="string">&quot;PCM_16&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Save Audio success!&quot;</span>)</span><br><span class="line"></span><br><span class="line">    res = model.generate(</span><br><span class="line">        <span class="built_in">input</span>=audio_bytes,</span><br><span class="line">        cache=&#123;&#125;,</span><br><span class="line">        language=<span class="string">&quot;auto&quot;</span>,  <span class="comment"># &quot;zn&quot;, &quot;en&quot;, &quot;yue&quot;, &quot;ja&quot;, &quot;ko&quot;, &quot;nospeech&quot;</span></span><br><span class="line">        use_itn=<span class="literal">True</span>,</span><br><span class="line">        batch_size_s=<span class="number">60</span>,</span><br><span class="line">        merge_vad=<span class="literal">True</span>,</span><br><span class="line">        merge_length_s=<span class="number">15</span>,</span><br><span class="line">    )</span><br><span class="line">    text = rich_transcription_postprocess(res[<span class="number">0</span>][<span class="string">&quot;text&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;res&quot;</span>: text&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    uvicorn.run(app, host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="number">8000</span>)</span><br></pre></td></tr></table></figure>

<p><strong>客户端修改后（注意这里的客户端代码也修改了原参考链接的recording_and_vad_thread函数的bug）：</strong></p>
<blockquote>
<p>send_audio_to_server-&gt;base64改为传字节流<br>修复了recording_and_vad_thread函数的逻辑bug</p>
</blockquote>
<figure class="highlight python"><figcaption><span>silero_vad_mic_basic_request_nobase64.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> soundfile <span class="keyword">as</span> sf</span><br><span class="line"></span><br><span class="line">torch.set_num_threads(<span class="number">1</span>)</span><br><span class="line">debug_mode = <span class="literal">False</span>  <span class="comment"># 控制是否保存部分音频及打印信息</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pyaudio</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">from</span> queue <span class="keyword">import</span> Queue</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载 Silero VAD 模型</span></span><br><span class="line">model, utils = torch.hub.load(repo_or_dir=<span class="string">&#x27;snakers4/silero-vad&#x27;</span>,</span><br><span class="line">                              model=<span class="string">&#x27;silero_vad&#x27;</span>,</span><br><span class="line">                              trust_repo=<span class="literal">True</span>,</span><br><span class="line">                              onnx=<span class="literal">True</span>,</span><br><span class="line">                              <span class="comment"># force_reload=True</span></span><br><span class="line">                              )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 录音参数</span></span><br><span class="line">FORMAT = pyaudio.paFloat32</span><br><span class="line">CHANNELS = <span class="number">1</span></span><br><span class="line">SAMPLE_RATE = <span class="number">16000</span></span><br><span class="line">num_samples = <span class="number">512</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 PyAudio</span></span><br><span class="line">audio = pyaudio.PyAudio()</span><br><span class="line">stream = audio.<span class="built_in">open</span>(<span class="built_in">format</span>=FORMAT,</span><br><span class="line">                    channels=CHANNELS,</span><br><span class="line">                    rate=SAMPLE_RATE,</span><br><span class="line">                    <span class="built_in">input</span>=<span class="literal">True</span>,</span><br><span class="line">                    frames_per_buffer=num_samples)</span><br><span class="line"></span><br><span class="line">audio_record_queue = Queue()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># BASE_URL = &quot;http://192.168.0.138:8000&quot;</span></span><br><span class="line">BASE_URL = <span class="string">&quot;http://192.168.0.138:8000&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">StateManage</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.threshold = <span class="number">0.5</span></span><br><span class="line">        <span class="variable language_">self</span>.min_speech_duration_ms = <span class="number">64</span></span><br><span class="line">        <span class="variable language_">self</span>.min_silence_duration_ms = <span class="number">480</span></span><br><span class="line">        <span class="variable language_">self</span>.pre_chunk_add = <span class="number">4</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">state_manage = StateManage()</span><br><span class="line"></span><br><span class="line">pre_speech_buffer = collections.deque(maxlen=state_manage.min_speech_duration_ms // <span class="number">32</span> + state_manage.pre_chunk_add)</span><br><span class="line"><span class="built_in">print</span>(state_manage.min_speech_duration_ms // <span class="number">32</span> + state_manage.pre_chunk_add)</span><br><span class="line">first_chunk_detected = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">send_audio_to_server</span>(<span class="params">audio_fragment</span>):</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;application/octet-stream&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">    response = requests.post(<span class="string">f&quot;<span class="subst">&#123;BASE_URL&#125;</span>/asr/&quot;</span>, headers=headers, data=audio_fragment)</span><br><span class="line">    <span class="keyword">return</span> response.json()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VADContext</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 threshold=<span class="number">0.5</span>,</span></span><br><span class="line"><span class="params">                 min_speech_duration_ms=<span class="number">64</span>,</span></span><br><span class="line"><span class="params">                 min_silence_duration_ms=<span class="number">480</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.threshold = threshold</span><br><span class="line">        <span class="variable language_">self</span>.min_speech_frames = <span class="built_in">int</span>(min_speech_duration_ms * SAMPLE_RATE / <span class="number">1000</span> / num_samples)</span><br><span class="line">        <span class="variable language_">self</span>.min_silence_frames = <span class="built_in">int</span>(min_silence_duration_ms * SAMPLE_RATE / <span class="number">1000</span> / num_samples)</span><br><span class="line">        <span class="variable language_">self</span>.speech_frame_count = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.silence_frame_count = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.is_speech = <span class="literal">False</span></span><br><span class="line">        <span class="variable language_">self</span>.was_speech = <span class="literal">False</span>  <span class="comment"># 跟踪上一帧是否是语音</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, confidence</span>):</span><br><span class="line">        <span class="variable language_">self</span>.was_speech = <span class="variable language_">self</span>.is_speech  <span class="comment"># 保存上一帧的状态</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.is_speech:</span><br><span class="line">            <span class="keyword">if</span> confidence &gt;= <span class="variable language_">self</span>.threshold:</span><br><span class="line">                <span class="variable language_">self</span>.speech_frame_count += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> <span class="variable language_">self</span>.speech_frame_count &gt;= <span class="variable language_">self</span>.min_speech_frames:</span><br><span class="line">                    <span class="variable language_">self</span>.is_speech = <span class="literal">True</span></span><br><span class="line">                    <span class="variable language_">self</span>.silence_frame_count = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.speech_frame_count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> confidence &lt;= <span class="variable language_">self</span>.threshold - <span class="number">0.15</span>:</span><br><span class="line">                <span class="variable language_">self</span>.silence_frame_count += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> <span class="variable language_">self</span>.silence_frame_count &gt;= <span class="variable language_">self</span>.min_silence_frames:</span><br><span class="line">                    <span class="variable language_">self</span>.is_speech = <span class="literal">False</span></span><br><span class="line">                    <span class="variable language_">self</span>.speech_frame_count = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.silence_frame_count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.is_speech</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_speech_end</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;检查是否是语音结束&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.was_speech <span class="keyword">and</span> <span class="keyword">not</span> <span class="variable language_">self</span>.is_speech</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">recording_and_vad_thread</span>():</span><br><span class="line">    <span class="keyword">global</span> first_chunk_detected</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Recording...\n&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">    vad_context = VADContext(</span><br><span class="line">        threshold=state_manage.threshold,</span><br><span class="line">        min_speech_duration_ms=state_manage.min_speech_duration_ms,</span><br><span class="line">        min_silence_duration_ms=state_manage.min_silence_duration_ms,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> debug_mode:</span><br><span class="line">        raw_audio_chunks = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        data = stream.read(num_samples)</span><br><span class="line">        audio_chunk = np.frombuffer(data, dtype=np.float32)</span><br><span class="line">        speech_prob = model(torch.from_numpy(audio_chunk.copy()), SAMPLE_RATE).item()</span><br><span class="line">        is_speech = vad_context.update(speech_prob)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 放入缓冲区</span></span><br><span class="line">        pre_speech_buffer.append(audio_chunk)</span><br><span class="line">        <span class="keyword">if</span> is_speech:</span><br><span class="line">            <span class="comment"># 如果刚检测到语音</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> first_chunk_detected:</span><br><span class="line">                first_chunk_detected = <span class="literal">True</span></span><br><span class="line">                <span class="keyword">while</span> pre_speech_buffer:</span><br><span class="line">                    pre_chunk = pre_speech_buffer.popleft()</span><br><span class="line">                    int16_chunk = (pre_chunk * <span class="number">32767</span>).astype(np.int16)</span><br><span class="line">                    audio_record_queue.put(int16_chunk)</span><br><span class="line">                    <span class="keyword">if</span> debug_mode:</span><br><span class="line">                        raw_audio_chunks.append(int16_chunk)  <span class="comment"># 保存原始数据</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                audio_chunk_int16 = (audio_chunk * <span class="number">32767</span>).astype(np.int16)</span><br><span class="line">                audio_record_queue.put(audio_chunk_int16)</span><br><span class="line">                <span class="keyword">if</span> debug_mode:</span><br><span class="line">                    raw_audio_chunks.append(audio_chunk_int16)   <span class="comment"># 保存原始数据</span></span><br><span class="line">        <span class="keyword">elif</span> vad_context.is_speech_end():</span><br><span class="line">            audio_record_queue.put(<span class="literal">None</span>)</span><br><span class="line">            first_chunk_detected = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> debug_mode <span class="keyword">and</span> raw_audio_chunks:</span><br><span class="line">                raw_audio_data = np.concatenate(raw_audio_chunks)</span><br><span class="line">                sf.write(<span class="string">&quot;debug_raw_audio.wav&quot;</span>, raw_audio_data, samplerate=<span class="number">16000</span>, subtype=<span class="string">&quot;PCM_16&quot;</span>)</span><br><span class="line">                raw_audio_chunks.clear()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动录音线程</span></span><br><span class="line">recording_thread = threading.Thread(target=recording_and_vad_thread, daemon=<span class="literal">True</span>)</span><br><span class="line">recording_thread.start()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">send_audio</span>():</span><br><span class="line">    audio_chunks = []</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        chunk = audio_record_queue.get()</span><br><span class="line">        <span class="keyword">if</span> chunk <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> audio_chunks:</span><br><span class="line">                audio_data = np.concatenate(audio_chunks)</span><br><span class="line">                audio_data_bytes = audio_data.tobytes()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 发送到ASR服务器</span></span><br><span class="line">                result = send_audio_to_server(audio_data_bytes)</span><br><span class="line">                <span class="keyword">if</span> result:</span><br><span class="line">                    asr_text = result[<span class="string">&#x27;res&#x27;</span>]</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;\nres: <span class="subst">&#123;asr_text&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">                audio_chunks.clear()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            audio_chunks.append(chunk)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    send_audio()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>fastapi</tag>
        <tag>request</tag>
      </tags>
  </entry>
  <entry>
    <title>fastapi+request构建语音识别微服务</title>
    <url>/2025/02/05/fastapi-request%E6%9E%84%E5%BB%BA%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BE%AE%E6%9C%8D%E5%8A%A1/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文介绍如何使用<strong>fastapi+request</strong>构建<strong>HTTP微服务</strong>，给出两个示例，首先是基础的例子用以展示基础用法，然后搭配<strong>silero vad</strong>和<strong>funasr</strong>实现语音识别微服务，并实现类似于<b>关键词识别(KWS)</b>的功能，通过将汉字转化为拼音实现更高的匹配率。</p>
<span id="more"></span>

<hr>
<h3 id="一、基础用法"><a href="#一、基础用法" class="headerlink" title="一、基础用法"></a>一、基础用法</h3><p>Python发送HTTP请求可以使用request库，这是一个简单易用的HTTP库，FastAPI和Flask都是Python的Web框架，用于构建HTTP服务器，FastAPI基于ASGI(Asynchronous Server Gateway Interface,异步服务器网关接口）原生支持async&#x2F;await，所以可以同时处理多个请求，提高并发能力，搭配<code>uvicorn</code>作为高性能ASGI服务器；而Flask基于WSGI(同步网关接口)，一次只能处理一个请求。更具体的对比见下表。</p>
<table>
<thead>
<tr>
<th align="center"><strong>特点</strong></th>
<th align="center"><strong>Flask</strong> 🐍</th>
<th align="center"><strong>FastAPI</strong> 🚀</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong>性能</strong></td>
<td align="center">较慢（基于 WSGI，同步）</td>
<td align="center"><strong>非常快</strong>（基于 ASGI，异步）</td>
</tr>
<tr>
<td align="center"><strong>异步支持</strong></td>
<td align="center">需要手动用 <code>gevent</code>、<code>asyncio</code></td>
<td align="center"><strong>原生支持 <code>async/await</code></strong></td>
</tr>
<tr>
<td align="center"><strong>数据校验</strong></td>
<td align="center">需要手写校验逻辑（配合 <code>marshmallow</code> 或 <code>pydantic</code>）</td>
<td align="center"><strong>内置 <code>Pydantic</code> 自动校验数据</strong></td>
</tr>
<tr>
<td align="center"><strong>API 文档</strong></td>
<td align="center">需要额外工具，如 <code>Flasgger</code></td>
<td align="center"><strong>自动生成 Swagger 和 Redoc</strong></td>
</tr>
<tr>
<td align="center"><strong>学习成本</strong></td>
<td align="center">简单，上手快</td>
<td align="center"><strong>稍高，但开发效率更高</strong></td>
</tr>
<tr>
<td align="center"><strong>适用场景</strong></td>
<td align="center">传统 Web、简单 API</td>
<td align="center"><strong>高性能 API，微服务，异步应用</strong></td>
</tr>
</tbody></table>
<p>所以我选择FastAPI，客户端代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Optional</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 FastAPI 实例</span></span><br><span class="line">app = FastAPI(title=<span class="string">&quot;Basic FastAPI Example&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义请求数据模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">User</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    name: <span class="built_in">str</span></span><br><span class="line">    age: <span class="built_in">int</span></span><br><span class="line">    email: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span>  <span class="comment"># 可选字段</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># GET 接口，带路径参数</span></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/users/&#123;user_id&#125;&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_user</span>(<span class="params">user_id: <span class="built_in">int</span></span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;message&quot;</span>: <span class="string">f&quot;获取用户信息&quot;</span>, <span class="string">&quot;user_id&quot;</span>: user_id&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># GET 接口，带查询参数</span></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/search/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">search_users</span>(<span class="params">name: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span>, age: <span class="type">Optional</span>[<span class="built_in">int</span>] = <span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;message&quot;</span>: <span class="string">&quot;搜索用户&quot;</span>, <span class="string">&quot;name&quot;</span>: name, <span class="string">&quot;age&quot;</span>: age&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># POST 接口，接收 JSON 请求体</span></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/users/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_user</span>(<span class="params">user: User</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;message&quot;</span>: <span class="string">&quot;用户已创建&quot;</span>, <span class="string">&quot;user&quot;</span>: user&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行 FastAPI 服务器（直接运行 `python server.py`）</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">import</span> uvicorn</span><br><span class="line">    uvicorn.run(app, host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="number">8000</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>这个时候就可以打开：</p>
<ul>
<li><strong>Swagger UI</strong>: <a href="http://192.168.0.138:8000/docs">http://192.168.0.138:8000/docs</a></li>
<li><strong>Redoc 文档</strong>: <a href="http://192.168.0.138:8000/redoc">http://192.168.0.138:8000/redoc</a></li>
</ul>
<p>注意，<code>url</code>根据自己情况设置。</p>
<p>客户端代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">BASE_URL = <span class="string">&quot;http://0.0.0.0:8000&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送 GET 请求（路径参数）</span></span><br><span class="line">response = requests.get(<span class="string">f&quot;<span class="subst">&#123;BASE_URL&#125;</span>/users/123&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;GET /users/123:&quot;</span>, response.json())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送 GET 请求（查询参数）</span></span><br><span class="line">params = &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;Alice&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="number">25</span>&#125;</span><br><span class="line">response = requests.get(<span class="string">f&quot;<span class="subst">&#123;BASE_URL&#125;</span>/search/&quot;</span>, params=params)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;GET /search:&quot;</span>, response.json())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送 POST 请求（JSON 请求体）</span></span><br><span class="line">user_data = &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;Bob&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="number">30</span>, <span class="string">&quot;email&quot;</span>: <span class="string">&quot;bob@example.com&quot;</span>&#125;</span><br><span class="line">response = requests.post(<span class="string">f&quot;<span class="subst">&#123;BASE_URL&#125;</span>/users/&quot;</span>, json=user_data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;POST /users:&quot;</span>, response.json())</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">GET /users/<span class="number">123</span>: &#123;<span class="string">&#x27;message&#x27;</span>: <span class="string">&#x27;获取用户信息&#x27;</span>, <span class="string">&#x27;user_id&#x27;</span>: <span class="number">123</span>&#125;</span><br><span class="line">GET /search: &#123;<span class="string">&#x27;message&#x27;</span>: <span class="string">&#x27;搜索用户&#x27;</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;Alice&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">25</span>&#125;</span><br><span class="line">POST /users: &#123;<span class="string">&#x27;message&#x27;</span>: <span class="string">&#x27;用户已创建&#x27;</span>, <span class="string">&#x27;user&#x27;</span>: &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">30</span>, <span class="string">&#x27;email&#x27;</span>: <span class="string">&#x27;bob@example.com&#x27;</span>&#125;&#125;</span><br></pre></td></tr></table></figure>

<h3 id="二、微服务用法"><a href="#二、微服务用法" class="headerlink" title="二、微服务用法"></a>二、微服务用法</h3><p>本案例准备实现：</p>
<ul>
<li>客户端：通过silero vad判断有效语音，有则进行base64编码后发送(HTTP)到服务端进行语音识别。</li>
<li>服务端：是一个微服务，重点在于ASR服务，顺便实现一个KWS功能。</li>
</ul>
<p>服务端代码，<a href="https://github.com/modelscope/FunASR">参考</a>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> funasr <span class="keyword">import</span> AutoModel</span><br><span class="line"><span class="keyword">from</span> funasr.utils.postprocess_utils <span class="keyword">import</span> rich_transcription_postprocess</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> base64</span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = AutoModel(</span><br><span class="line">    model=<span class="string">&quot;iic/SenseVoiceSmall&quot;</span>,</span><br><span class="line">    vad_model=<span class="string">&quot;fsmn-vad&quot;</span>,</span><br><span class="line">    vad_kwargs=&#123;<span class="string">&quot;max_single_segment_time&quot;</span>: <span class="number">30000</span>&#125;,</span><br><span class="line">    disable_update=<span class="literal">True</span>,</span><br><span class="line">    device=<span class="string">&quot;cuda:0&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建FASTAPI实例</span></span><br><span class="line">app = FastAPI(title=<span class="string">&quot;Sensevoice+KWS&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AudioData</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    audio_base64: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/asr/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">asr_endpoint</span>(<span class="params">audio_data: AudioData</span>):</span><br><span class="line">    audio_bytes = base64.b64decode(audio_data.audio_base64)</span><br><span class="line"></span><br><span class="line">    res = model.generate(</span><br><span class="line">        <span class="built_in">input</span>=audio_bytes,</span><br><span class="line">        cache=&#123;&#125;,</span><br><span class="line">        language=<span class="string">&quot;auto&quot;</span>,  <span class="comment"># &quot;zn&quot;, &quot;en&quot;, &quot;yue&quot;, &quot;ja&quot;, &quot;ko&quot;, &quot;nospeech&quot;</span></span><br><span class="line">        use_itn=<span class="literal">True</span>,</span><br><span class="line">        batch_size_s=<span class="number">60</span>,</span><br><span class="line">        merge_vad=<span class="literal">True</span>,</span><br><span class="line">        merge_length_s=<span class="number">15</span>,</span><br><span class="line">    )</span><br><span class="line">    text = rich_transcription_postprocess(res[<span class="number">0</span>][<span class="string">&quot;text&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;transcription&quot;</span>: text&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">import</span> uvicorn</span><br><span class="line">    uvicorn.run(app, host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="number">8000</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>关于<strong>silero vad</strong>的使用示例，请参考<a href="https://caihaoran-00.github.io/2025/02/07/silerovadonnx%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/">silero_vad onnx方式使用示例</a>，对其进行修改，得到客户端代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> base64</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">torch.set_num_threads(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pyaudio</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">from</span> queue <span class="keyword">import</span> Queue</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载 Silero VAD 模型</span></span><br><span class="line">model, utils = torch.hub.load(repo_or_dir=<span class="string">&#x27;snakers4/silero-vad&#x27;</span>,</span><br><span class="line">                              model=<span class="string">&#x27;silero_vad&#x27;</span>,</span><br><span class="line">                              trust_repo=<span class="literal">True</span>,</span><br><span class="line">                              onnx=<span class="literal">True</span>,</span><br><span class="line">                              <span class="comment"># force_reload=True</span></span><br><span class="line">                              )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 录音参数</span></span><br><span class="line">FORMAT = pyaudio.paFloat32</span><br><span class="line">CHANNELS = <span class="number">1</span></span><br><span class="line">SAMPLE_RATE = <span class="number">16000</span></span><br><span class="line">num_samples = <span class="number">512</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 PyAudio</span></span><br><span class="line">audio = pyaudio.PyAudio()</span><br><span class="line">stream = audio.<span class="built_in">open</span>(<span class="built_in">format</span>=FORMAT,</span><br><span class="line">                    channels=CHANNELS,</span><br><span class="line">                    rate=SAMPLE_RATE,</span><br><span class="line">                    <span class="built_in">input</span>=<span class="literal">True</span>,</span><br><span class="line">                    frames_per_buffer=num_samples)</span><br><span class="line"></span><br><span class="line">audio_record_queue = Queue()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">BASE_URL = <span class="string">&quot;http://192.168.0.138:8000&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">send_audio_to_server</span>(<span class="params">audio_fragment</span>):</span><br><span class="line">    audio_base64 = base64.b64encode(audio_fragment).decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">&#x27;audio_base64&#x27;</span>: audio_base64,</span><br><span class="line">    &#125;</span><br><span class="line">    response = requests.post(<span class="string">f&quot;<span class="subst">&#123;BASE_URL&#125;</span>/asr/&quot;</span>, json=data)</span><br><span class="line">    <span class="keyword">return</span> response.json()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VADContext</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 threshold=<span class="number">0.5</span>,</span></span><br><span class="line"><span class="params">                 min_speech_duration_ms=<span class="number">64</span>,</span></span><br><span class="line"><span class="params">                 min_silence_duration_ms=<span class="number">480</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.threshold = threshold</span><br><span class="line">        <span class="variable language_">self</span>.min_speech_frames = <span class="built_in">int</span>(min_speech_duration_ms * SAMPLE_RATE / <span class="number">1000</span> / num_samples)</span><br><span class="line">        <span class="variable language_">self</span>.min_silence_frames = <span class="built_in">int</span>(min_silence_duration_ms * SAMPLE_RATE / <span class="number">1000</span> / num_samples)</span><br><span class="line">        <span class="variable language_">self</span>.speech_frame_count = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.silence_frame_count = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.is_speech = <span class="literal">False</span></span><br><span class="line">        <span class="variable language_">self</span>.was_speech = <span class="literal">False</span>  <span class="comment"># 跟踪上一帧是否是语音</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, confidence</span>):</span><br><span class="line">        <span class="variable language_">self</span>.was_speech = <span class="variable language_">self</span>.is_speech  <span class="comment"># 保存上一帧的状态</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.is_speech:</span><br><span class="line">            <span class="keyword">if</span> confidence &gt;= <span class="variable language_">self</span>.threshold:</span><br><span class="line">                <span class="variable language_">self</span>.speech_frame_count += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> <span class="variable language_">self</span>.speech_frame_count &gt;= <span class="variable language_">self</span>.min_speech_frames:</span><br><span class="line">                    <span class="variable language_">self</span>.is_speech = <span class="literal">True</span></span><br><span class="line">                    <span class="variable language_">self</span>.silence_frame_count = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.speech_frame_count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> confidence &lt;= <span class="variable language_">self</span>.threshold - <span class="number">0.15</span>:</span><br><span class="line">                <span class="variable language_">self</span>.silence_frame_count += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> <span class="variable language_">self</span>.silence_frame_count &gt;= <span class="variable language_">self</span>.min_silence_frames:</span><br><span class="line">                    <span class="variable language_">self</span>.is_speech = <span class="literal">False</span></span><br><span class="line">                    <span class="variable language_">self</span>.speech_frame_count = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.silence_frame_count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.is_speech</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_speech_end</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;检查是否是语音结束&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.was_speech <span class="keyword">and</span> <span class="keyword">not</span> <span class="variable language_">self</span>.is_speech</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">recording_and_vad_thread</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Recording...\n&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">    vad_context = VADContext(</span><br><span class="line">        threshold=<span class="number">0.5</span>,</span><br><span class="line">        min_speech_duration_ms=<span class="number">0</span>,</span><br><span class="line">        min_silence_duration_ms=<span class="number">480</span>,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        data = stream.read(num_samples)</span><br><span class="line">        audio_chunk = np.frombuffer(data, dtype=np.float32)</span><br><span class="line">        speech_prob = model(torch.from_numpy(audio_chunk.copy()), SAMPLE_RATE).item()</span><br><span class="line">        is_speech = vad_context.update(speech_prob)</span><br><span class="line">        <span class="keyword">if</span> is_speech:</span><br><span class="line">            audio_chunk_int16 = (audio_chunk * <span class="number">32767</span>).astype(np.int16)</span><br><span class="line">            audio_record_queue.put(audio_chunk_int16)</span><br><span class="line">        <span class="keyword">elif</span> vad_context.is_speech_end():</span><br><span class="line">            audio_record_queue.put(<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动录音线程</span></span><br><span class="line">recording_thread = threading.Thread(target=recording_and_vad_thread, daemon=<span class="literal">True</span>)</span><br><span class="line">recording_thread.start()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">send_audio</span>():</span><br><span class="line">    audio_chunks = []</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        chunk = audio_record_queue.get()</span><br><span class="line">        <span class="keyword">if</span> chunk <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> audio_chunks:</span><br><span class="line">                audio_data = np.concatenate(audio_chunks)</span><br><span class="line">                audio_data_bytes = audio_data.tobytes()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 发送到ASR服务器</span></span><br><span class="line">                result = send_audio_to_server(audio_data_bytes)</span><br><span class="line">                <span class="keyword">if</span> result:</span><br><span class="line">                    asr_text = result[<span class="string">&#x27;res&#x27;</span>]</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;\nres: <span class="subst">&#123;asr_text&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">                audio_chunks.clear()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            audio_chunks.append(chunk)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    send_audio()</span><br></pre></td></tr></table></figure>

<img src="/2025/02/05/fastapi-request%E6%9E%84%E5%BB%BA%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BE%AE%E6%9C%8D%E5%8A%A1/image-20250208153324529.png" class="" title="image-20250208153324529">

<p>效果还行，但对于<strong>锄禾日当午</strong>的<strong>锄</strong>老是识别不到，我认为是这个VAD的问题（不知道webrtcvad会不会有这个问题）,解决方案</p>
<ul>
<li>识别到人声时，将前面不被认为是人声的一个或几个（可配置）512段拼接在人生端之前</li>
</ul>
<p>另外，我目前的代码<code>min_speech_duration_ms</code>配置的是<code>0</code>，这会引入一个问题</p>
<ul>
<li>有声段太短也会发送到服务器进行处理，但这时候就不一定能得到有效结果</li>
</ul>
<p>应当将此值设置大一些，如<code>64</code>，但在当前代码情况下启用该配置会加重首字吞字的问题，故终极解决方案：</p>
<ul>
<li>将<code>min_speech_duration_ms</code>配置为64（按需或按试验设置）</li>
<li>64ms代表两个512样本点段，所以需要保存这两段，识别到人声时需将这两端拼接在人声前</li>
<li>在这两段512样本点段之前的段也需要按需拼接在语音开始处。</li>
</ul>
<p>好的，目标明确，开干：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> base64</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">torch.set_num_threads(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pyaudio</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">from</span> queue <span class="keyword">import</span> Queue</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载 Silero VAD 模型</span></span><br><span class="line">model, utils = torch.hub.load(repo_or_dir=<span class="string">&#x27;snakers4/silero-vad&#x27;</span>,</span><br><span class="line">                              model=<span class="string">&#x27;silero_vad&#x27;</span>,</span><br><span class="line">                              trust_repo=<span class="literal">True</span>,</span><br><span class="line">                              onnx=<span class="literal">True</span>,</span><br><span class="line">                              <span class="comment"># force_reload=True</span></span><br><span class="line">                              )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 录音参数</span></span><br><span class="line">FORMAT = pyaudio.paFloat32</span><br><span class="line">CHANNELS = <span class="number">1</span></span><br><span class="line">SAMPLE_RATE = <span class="number">16000</span></span><br><span class="line">num_samples = <span class="number">512</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 PyAudio</span></span><br><span class="line">audio = pyaudio.PyAudio()</span><br><span class="line">stream = audio.<span class="built_in">open</span>(<span class="built_in">format</span>=FORMAT,</span><br><span class="line">                    channels=CHANNELS,</span><br><span class="line">                    rate=SAMPLE_RATE,</span><br><span class="line">                    <span class="built_in">input</span>=<span class="literal">True</span>,</span><br><span class="line">                    frames_per_buffer=num_samples)</span><br><span class="line"></span><br><span class="line">audio_record_queue = Queue()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">BASE_URL = <span class="string">&quot;http://192.168.0.138:8000&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">StateManage</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.threshold = <span class="number">0.5</span></span><br><span class="line">        <span class="variable language_">self</span>.min_speech_duration_ms = <span class="number">64</span></span><br><span class="line">        <span class="variable language_">self</span>.min_silence_duration_ms = <span class="number">480</span></span><br><span class="line">        <span class="variable language_">self</span>.pre_chunk_add = <span class="number">4</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">state_manage = StateManage()</span><br><span class="line"></span><br><span class="line">pre_speech_buffer = collections.deque(maxlen=state_manage.min_speech_duration_ms // <span class="number">32</span> + state_manage.pre_chunk_add)</span><br><span class="line"><span class="built_in">print</span>(state_manage.min_speech_duration_ms // <span class="number">32</span> + state_manage.pre_chunk_add)</span><br><span class="line">first_chunk_detected = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">send_audio_to_server</span>(<span class="params">audio_fragment</span>):</span><br><span class="line">    audio_base64 = base64.b64encode(audio_fragment).decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">&#x27;audio_base64&#x27;</span>: audio_base64,</span><br><span class="line">    &#125;</span><br><span class="line">    response = requests.post(<span class="string">f&quot;<span class="subst">&#123;BASE_URL&#125;</span>/asr/&quot;</span>, json=data)</span><br><span class="line">    <span class="keyword">return</span> response.json()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VADContext</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 threshold=<span class="number">0.5</span>,</span></span><br><span class="line"><span class="params">                 min_speech_duration_ms=<span class="number">64</span>,</span></span><br><span class="line"><span class="params">                 min_silence_duration_ms=<span class="number">480</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.threshold = threshold</span><br><span class="line">        <span class="variable language_">self</span>.min_speech_frames = <span class="built_in">int</span>(min_speech_duration_ms * SAMPLE_RATE / <span class="number">1000</span> / num_samples)</span><br><span class="line">        <span class="variable language_">self</span>.min_silence_frames = <span class="built_in">int</span>(min_silence_duration_ms * SAMPLE_RATE / <span class="number">1000</span> / num_samples)</span><br><span class="line">        <span class="variable language_">self</span>.speech_frame_count = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.silence_frame_count = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.is_speech = <span class="literal">False</span></span><br><span class="line">        <span class="variable language_">self</span>.was_speech = <span class="literal">False</span>  <span class="comment"># 跟踪上一帧是否是语音</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, confidence</span>):</span><br><span class="line">        <span class="variable language_">self</span>.was_speech = <span class="variable language_">self</span>.is_speech  <span class="comment"># 保存上一帧的状态</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.is_speech:</span><br><span class="line">            <span class="keyword">if</span> confidence &gt;= <span class="variable language_">self</span>.threshold:</span><br><span class="line">                <span class="variable language_">self</span>.speech_frame_count += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> <span class="variable language_">self</span>.speech_frame_count &gt;= <span class="variable language_">self</span>.min_speech_frames:</span><br><span class="line">                    <span class="variable language_">self</span>.is_speech = <span class="literal">True</span></span><br><span class="line">                    <span class="variable language_">self</span>.silence_frame_count = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.speech_frame_count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> confidence &lt;= <span class="variable language_">self</span>.threshold - <span class="number">0.15</span>:</span><br><span class="line">                <span class="variable language_">self</span>.silence_frame_count += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> <span class="variable language_">self</span>.silence_frame_count &gt;= <span class="variable language_">self</span>.min_silence_frames:</span><br><span class="line">                    <span class="variable language_">self</span>.is_speech = <span class="literal">False</span></span><br><span class="line">                    <span class="variable language_">self</span>.speech_frame_count = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.silence_frame_count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.is_speech</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_speech_end</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;检查是否是语音结束&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.was_speech <span class="keyword">and</span> <span class="keyword">not</span> <span class="variable language_">self</span>.is_speech</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">recording_and_vad_thread</span>():</span><br><span class="line">    <span class="keyword">global</span> first_chunk_detected</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Recording...\n&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">    vad_context = VADContext(</span><br><span class="line">        threshold=state_manage.threshold,</span><br><span class="line">        min_speech_duration_ms=state_manage.min_speech_duration_ms,</span><br><span class="line">        min_silence_duration_ms=state_manage.min_silence_duration_ms,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        data = stream.read(num_samples)</span><br><span class="line">        audio_chunk = np.frombuffer(data, dtype=np.float32)</span><br><span class="line">        speech_prob = model(torch.from_numpy(audio_chunk.copy()), SAMPLE_RATE).item()</span><br><span class="line">        is_speech = vad_context.update(speech_prob)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 放入缓冲区</span></span><br><span class="line">        pre_speech_buffer.append(audio_chunk)</span><br><span class="line">        <span class="keyword">if</span> is_speech:</span><br><span class="line">            <span class="comment"># 如果是语音的第一块</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> first_chunk_detected:</span><br><span class="line">                <span class="keyword">while</span> pre_speech_buffer:</span><br><span class="line">                    pre_chunk = pre_speech_buffer.popleft()</span><br><span class="line">                    audio_record_queue.put((pre_chunk * <span class="number">32767</span>).astype(np.int16))</span><br><span class="line"></span><br><span class="line">            audio_chunk_int16 = (audio_chunk * <span class="number">32767</span>).astype(np.int16)</span><br><span class="line">            audio_record_queue.put(audio_chunk_int16)</span><br><span class="line">        <span class="keyword">elif</span> vad_context.is_speech_end():</span><br><span class="line">            audio_record_queue.put(<span class="literal">None</span>)</span><br><span class="line">            first_chunk_detected = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动录音线程</span></span><br><span class="line">recording_thread = threading.Thread(target=recording_and_vad_thread, daemon=<span class="literal">True</span>)</span><br><span class="line">recording_thread.start()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">send_audio</span>():</span><br><span class="line">    audio_chunks = []</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        chunk = audio_record_queue.get()</span><br><span class="line">        <span class="keyword">if</span> chunk <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> audio_chunks:</span><br><span class="line">                audio_data = np.concatenate(audio_chunks)</span><br><span class="line">                audio_data_bytes = audio_data.tobytes()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 发送到ASR服务器</span></span><br><span class="line">                result = send_audio_to_server(audio_data_bytes)</span><br><span class="line">                <span class="keyword">if</span> result:</span><br><span class="line">                    asr_text = result[<span class="string">&#x27;res&#x27;</span>]</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;\nres: <span class="subst">&#123;asr_text&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">                audio_chunks.clear()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            audio_chunks.append(chunk)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    send_audio()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<img src="/2025/02/05/fastapi-request%E6%9E%84%E5%BB%BA%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BE%AE%E6%9C%8D%E5%8A%A1/image-20250208170903482.png" class="" title="image-20250208170903482">

<p>可看出效果还是不错的，一些<strong>小细节</strong>：</p>
<ul>
<li>通过<code>pre_chunk_add</code>控制添加在语音段前方的段数，目前设置的是4</li>
<li>通过deque，而不是list来管理前方段数，因为<code>deque.popleft()</code>比<code>list.pop(0)</code>快， <code>list.pop(0)</code> <strong>会导致 O(n) 复杂度</strong>，而 <code>deque.popleft()</code> <strong>只需 O(1) 时间</strong>。<strong><code>deque</code> 可以设定 <code>maxlen</code></strong>，超出长度时会自动删除最早的元素，防止无限增长，占用过多内存</li>
<li>通过<code>first_chunk_detected</code>判断是否是第一次检测到语音块（针对单段语音）</li>
<li>使用<code>None</code>作为当前段语音的结束标志</li>
</ul>
<p>服务端和客户端都是用同步方式，后续有需要再改成异步形式。</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><p><a href="https://github.com/modelscope/FunASR">https://github.com/modelscope/FunASR</a></p>
</li>
<li><p><a href="https://caihaoran-00.github.io/2025/02/07/silerovadonnx%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/">https://caihaoran-00.github.io/2025/02/07/silerovadonnx%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/</a></p>
</li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>funasr</tag>
        <tag>sensevoice</tag>
        <tag>fastapi</tag>
      </tags>
  </entry>
  <entry>
    <title>fastapi+request构建语音识别微服务2</title>
    <url>/2025/04/28/fastapi-request%E6%9E%84%E5%BB%BA%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BE%AE%E6%9C%8D%E5%8A%A12/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最初写过一篇<a href="https://caihaoran-00.github.io/2025/02/05/fastapi-request%E6%9E%84%E5%BB%BA%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BE%AE%E6%9C%8D%E5%8A%A1/">fastapi+request构建语音识别微服务</a>，此开篇之作在库的使用和逻辑方面都有问题，在库（<code>requests.post</code>）使用方面，我使用了该库的json字段，所以传音频前需要先将其进行base64编码转化成字符串形式，后发现可以使用data字段+headers形式传输二进制流（base64编码比原始二进制流大$33%$的样子）；在代码逻辑方面，由于缓存了被识别成语音前的几块，将其拼接到语音块之前用于防止语音开头少字现象，思路是对的，但是代码实现上写成对每个语音块都拼接缓存块了，所以出现了异常，两个bug都在<a href="https://caihaoran-00.github.io/2025/04/25/fastapi-request%E5%86%8D%E6%8E%A2%E4%B9%8B%EF%BC%9Arequests-post/#%E5%89%8D%E8%A8%80">fastapi+request再探之：requests.post</a>一文中进行了修复，语音识别算法使用的是sensevoice，本文想在同一个客户端的前提下，写个paraformer的服务端，并对代码进行解析。</p>
<span id="more"></span>

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="官方简单示例"><a href="#官方简单示例" class="headerlink" title="官方简单示例"></a>官方简单示例</h3><p>先说下思路吧，来到<a href="https://github.com/modelscope/FunASR">funasr的git官网</a>，往下滑动，来到下方的非实时语音识别栏，首先是SenseVoice的介绍：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> funasr <span class="keyword">import</span> AutoModel</span><br><span class="line"><span class="keyword">from</span> funasr.utils.postprocess_utils <span class="keyword">import</span> rich_transcription_postprocess</span><br><span class="line"></span><br><span class="line">model_dir = <span class="string">&quot;iic/SenseVoiceSmall&quot;</span></span><br><span class="line"></span><br><span class="line">model = AutoModel(</span><br><span class="line">    model=model_dir,</span><br><span class="line">    vad_model=<span class="string">&quot;fsmn-vad&quot;</span>,</span><br><span class="line">    vad_kwargs=&#123;<span class="string">&quot;max_single_segment_time&quot;</span>: <span class="number">30000</span>&#125;,</span><br><span class="line">    device=<span class="string">&quot;cuda:0&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># en</span></span><br><span class="line">res = model.generate(</span><br><span class="line">    <span class="built_in">input</span>=<span class="string">f&quot;<span class="subst">&#123;model.model_path&#125;</span>/example/en.mp3&quot;</span>,</span><br><span class="line">    cache=&#123;&#125;,</span><br><span class="line">    language=<span class="string">&quot;auto&quot;</span>,  <span class="comment"># &quot;zn&quot;, &quot;en&quot;, &quot;yue&quot;, &quot;ja&quot;, &quot;ko&quot;, &quot;nospeech&quot;</span></span><br><span class="line">    use_itn=<span class="literal">True</span>,</span><br><span class="line">    batch_size_s=<span class="number">60</span>,</span><br><span class="line">    merge_vad=<span class="literal">True</span>,  <span class="comment">#</span></span><br><span class="line">    merge_length_s=<span class="number">15</span>,</span><br><span class="line">)</span><br><span class="line">text = rich_transcription_postprocess(res[<span class="number">0</span>][<span class="string">&quot;text&quot;</span>])</span><br><span class="line"><span class="built_in">print</span>(text)</span><br></pre></td></tr></table></figure>

<p>参数说明：</p>
<ul>
<li><code>model_dir</code>：模型名称，或本地磁盘中的模型路径。</li>
<li><code>vad_model</code>：表示开启VAD，VAD的作用是将长音频切割成短音频，此时推理耗时包括了VAD与SenseVoice总耗时，为链路耗时，如果需要单独测试SenseVoice模型耗时，可以关闭VAD模型。</li>
<li><code>vad_kwargs</code>：表示VAD模型配置,<code>max_single_segment_time</code>: 表示<code>vad_model</code>最大切割音频时长, 单位是毫秒ms。</li>
<li><code>cache</code>：传入一个空的缓存字典，用来保存一些中间推理结果，以提高连续推理的效率。</li>
<li><code>use_itn</code>：输出结果中是否包含标点与逆文本正则化。</li>
<li><code>batch_size_s</code> 表示采用动态batch，batch中总音频时长，单位为秒s。</li>
<li><code>merge_vad</code>：是否将 vad 模型切割的短音频碎片合成，合并后长度为<code>merge_length_s</code>，单位为秒s。</li>
<li><code>ban_emo_unk</code>：禁用emo_unk标签，禁用后所有的句子都会被赋与情感标签。</li>
</ul>
<blockquote>
<p>这里我有一个疑问，英文原文<code>ban_emo_unk</code>: Whether to ban the output of the <code>emo_unk</code> token.似乎与中文版的readme的解释矛盾。待会试验下到底哪样才是对的。</p>
</blockquote>
<hr>
<p>接着是Paraformer的介绍：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> funasr <span class="keyword">import</span> AutoModel</span><br><span class="line"><span class="comment"># paraformer-zh is a multi-functional asr model</span></span><br><span class="line"><span class="comment"># use vad, punc, spk or not as you need</span></span><br><span class="line">model = AutoModel(model=<span class="string">&quot;paraformer-zh&quot;</span>,  vad_model=<span class="string">&quot;fsmn-vad&quot;</span>,  punc_model=<span class="string">&quot;ct-punc&quot;</span>, </span><br><span class="line">                  <span class="comment"># spk_model=&quot;cam++&quot;, </span></span><br><span class="line">                  )</span><br><span class="line">res = model.generate(<span class="built_in">input</span>=<span class="string">f&quot;<span class="subst">&#123;model.model_path&#125;</span>/example/asr_example.wav&quot;</span>, </span><br><span class="line">                     batch_size_s=<span class="number">300</span>, </span><br><span class="line">                     hotword=<span class="string">&#x27;魔搭&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(res)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注：<code>hub</code>：表示模型仓库，<code>ms</code>为选择modelscope下载，<code>hf</code>为选择huggingface下载。如hub &#x3D; “ms”写在AutoModel中。</p>
<p>这里我也有个疑问，相较于SenseVoice，这里的model.generate中并未使用use_itn&#x3D;True（逆文本正则化，用于将时间，数字等转化为数字标准格式，而不是汉字形式），但在AutoModel中使用了punc_model&#x3D;”ct-punc”（标点符号模型，更可读）。</p>
<p>那SenseVoice识别结果是否有标点符号，Paraformer识别结果是否有逆文本正则化？</p>
</blockquote>
<p>好的，带着疑问，咱们一起来写个代码试验下。</p>
<p>首先，SenseVoice的代码已在<a href="https://caihaoran-00.github.io/2025/04/25/fastapi-request%E5%86%8D%E6%8E%A2%E4%B9%8B%EF%BC%9Arequests-post/#%E5%89%8D%E8%A8%80">fastapi+request再探之：requests.post</a>中描述，这里做一点无伤大雅的改动，并给出Paraformer的服务端代码。</p>
<hr>
<h3 id="改写成微服务形式"><a href="#改写成微服务形式" class="headerlink" title="改写成微服务形式"></a>改写成微服务形式</h3><p><strong>SenseVoice服务端：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> funasr <span class="keyword">import</span> AutoModel</span><br><span class="line"><span class="keyword">from</span> funasr.utils.postprocess_utils <span class="keyword">import</span> rich_transcription_postprocess</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, Request</span><br><span class="line"><span class="keyword">import</span> uvicorn</span><br><span class="line"><span class="keyword">import</span> soundfile <span class="keyword">as</span> sf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化模型</span></span><br><span class="line">model = AutoModel(</span><br><span class="line">    model=<span class="string">&quot;iic/SenseVoiceSmall&quot;</span>,</span><br><span class="line">    vad_model=<span class="string">&quot;fsmn-vad&quot;</span>,</span><br><span class="line">    vad_kwargs=&#123;<span class="string">&quot;max_single_segment_time&quot;</span>: <span class="number">30000</span>&#125;,</span><br><span class="line">    disable_update=<span class="literal">True</span>,</span><br><span class="line">    device=<span class="string">&quot;cuda:0&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建FASTAPI实例</span></span><br><span class="line">app = FastAPI(title=<span class="string">&quot;Sensevoice&quot;</span>)</span><br><span class="line"></span><br><span class="line">SAVE_AUDIO = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/asr/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">asr_endpoint</span>(<span class="params">request: Request</span>):</span><br><span class="line">    <span class="comment"># 直接读裸字节流</span></span><br><span class="line">    audio_bytes = <span class="keyword">await</span> request.body()</span><br><span class="line">    <span class="keyword">if</span> SAVE_AUDIO:</span><br><span class="line">        audio_np = np.frombuffer(audio_bytes, dtype=np.int16)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 写入为 WAV 文件</span></span><br><span class="line">        sf.write(<span class="string">&quot;received_audio.wav&quot;</span>, audio_np, samplerate=<span class="number">16000</span>, subtype=<span class="string">&quot;PCM_16&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Save Audio success!&quot;</span>)</span><br><span class="line"></span><br><span class="line">    res = model.generate(</span><br><span class="line">        <span class="built_in">input</span>=audio_bytes,</span><br><span class="line">        cache=&#123;&#125;,</span><br><span class="line">        language=<span class="string">&quot;auto&quot;</span>,  <span class="comment"># &quot;zn&quot;, &quot;en&quot;, &quot;yue&quot;, &quot;ja&quot;, &quot;ko&quot;, &quot;nospeech&quot;</span></span><br><span class="line">        use_itn=<span class="literal">True</span>,</span><br><span class="line">        batch_size_s=<span class="number">60</span>,</span><br><span class="line">        merge_vad=<span class="literal">True</span>,</span><br><span class="line">        merge_length_s=<span class="number">15</span>,</span><br><span class="line">        </span><br><span class="line">    )</span><br><span class="line">    text = rich_transcription_postprocess(res[<span class="number">0</span>][<span class="string">&quot;text&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;res&quot;</span>: text&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    uvicorn.run(app, host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="number">8000</span>)</span><br></pre></td></tr></table></figure>

<p><strong>Paraformer服务端：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> funasr <span class="keyword">import</span> AutoModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, Request</span><br><span class="line"><span class="keyword">import</span> uvicorn</span><br><span class="line"><span class="keyword">import</span> soundfile <span class="keyword">as</span> sf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化模型</span></span><br><span class="line">model = AutoModel(</span><br><span class="line">    model=<span class="string">&quot;paraformer-zh&quot;</span>, </span><br><span class="line">    vad_model=<span class="string">&quot;fsmn-vad&quot;</span>,</span><br><span class="line">    punc_model=<span class="string">&quot;ct-punc&quot;</span>,</span><br><span class="line">    device=<span class="string">&quot;cuda:0&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建FASTAPI实例</span></span><br><span class="line">app = FastAPI(title=<span class="string">&quot;Paraformer&quot;</span>)</span><br><span class="line"></span><br><span class="line">SAVE_AUDIO = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/asr/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">asr_endpoint</span>(<span class="params">request: Request</span>):</span><br><span class="line">    <span class="comment"># 直接读裸字节流</span></span><br><span class="line">    audio_bytes = <span class="keyword">await</span> request.body()</span><br><span class="line">    <span class="keyword">if</span> SAVE_AUDIO:</span><br><span class="line">        audio_np = np.frombuffer(audio_bytes, dtype=np.int16)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 写入为 WAV 文件</span></span><br><span class="line">        sf.write(<span class="string">&quot;received_audio.wav&quot;</span>, audio_np, samplerate=<span class="number">16000</span>, subtype=<span class="string">&quot;PCM_16&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Save Audio success!&quot;</span>)</span><br><span class="line"></span><br><span class="line">    res = model.generate(</span><br><span class="line">        <span class="built_in">input</span>=audio_bytes,</span><br><span class="line">        batch_size_s=<span class="number">300</span>,</span><br><span class="line">        hotword=<span class="string">&#x27;魔搭&#x27;</span>,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;res&quot;</span>: res[<span class="number">0</span>][<span class="string">&quot;text&quot;</span>]&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    uvicorn.run(app, host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="number">8000</span>)</span><br></pre></td></tr></table></figure>



<p><strong>客户端代码：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> soundfile <span class="keyword">as</span> sf</span><br><span class="line"></span><br><span class="line">torch.set_num_threads(<span class="number">1</span>)</span><br><span class="line">debug_mode = <span class="literal">False</span>  <span class="comment"># 控制是否保存部分音频及打印信息</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pyaudio</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">from</span> queue <span class="keyword">import</span> Queue</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载 Silero VAD 模型</span></span><br><span class="line">model, utils = torch.hub.load(repo_or_dir=<span class="string">&#x27;snakers4/silero-vad&#x27;</span>,</span><br><span class="line">                              model=<span class="string">&#x27;silero_vad&#x27;</span>,</span><br><span class="line">                              trust_repo=<span class="literal">True</span>,</span><br><span class="line">                              onnx=<span class="literal">True</span>,</span><br><span class="line">                              <span class="comment"># force_reload=True</span></span><br><span class="line">                              )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 录音参数</span></span><br><span class="line">FORMAT = pyaudio.paFloat32</span><br><span class="line">CHANNELS = <span class="number">1</span></span><br><span class="line">SAMPLE_RATE = <span class="number">16000</span></span><br><span class="line">num_samples = <span class="number">512</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 PyAudio</span></span><br><span class="line">audio = pyaudio.PyAudio()</span><br><span class="line">stream = audio.<span class="built_in">open</span>(<span class="built_in">format</span>=FORMAT,</span><br><span class="line">                    channels=CHANNELS,</span><br><span class="line">                    rate=SAMPLE_RATE,</span><br><span class="line">                    <span class="built_in">input</span>=<span class="literal">True</span>,</span><br><span class="line">                    frames_per_buffer=num_samples)</span><br><span class="line"></span><br><span class="line">audio_record_queue = Queue()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># BASE_URL = &quot;http://192.168.0.138:8000&quot;</span></span><br><span class="line">BASE_URL = <span class="string">&quot;http://192.168.0.138:8000&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">StateManage</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.threshold = <span class="number">0.5</span></span><br><span class="line">        <span class="variable language_">self</span>.min_speech_duration_ms = <span class="number">64</span></span><br><span class="line">        <span class="variable language_">self</span>.min_silence_duration_ms = <span class="number">480</span></span><br><span class="line">        <span class="variable language_">self</span>.pre_chunk_add = <span class="number">4</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">state_manage = StateManage()</span><br><span class="line"></span><br><span class="line">pre_speech_buffer = collections.deque(maxlen=state_manage.min_speech_duration_ms // <span class="number">32</span> + state_manage.pre_chunk_add)</span><br><span class="line"><span class="built_in">print</span>(state_manage.min_speech_duration_ms // <span class="number">32</span> + state_manage.pre_chunk_add)</span><br><span class="line">first_chunk_detected = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">send_audio_to_server</span>(<span class="params">audio_fragment</span>):</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;application/octet-stream&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">    response = requests.post(<span class="string">f&quot;<span class="subst">&#123;BASE_URL&#125;</span>/asr/&quot;</span>, headers=headers, data=audio_fragment)</span><br><span class="line">    <span class="keyword">return</span> response.json()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VADContext</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 threshold=<span class="number">0.5</span>,</span></span><br><span class="line"><span class="params">                 min_speech_duration_ms=<span class="number">64</span>,</span></span><br><span class="line"><span class="params">                 min_silence_duration_ms=<span class="number">480</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.threshold = threshold</span><br><span class="line">        <span class="variable language_">self</span>.min_speech_frames = <span class="built_in">int</span>(min_speech_duration_ms * SAMPLE_RATE / <span class="number">1000</span> / num_samples)</span><br><span class="line">        <span class="variable language_">self</span>.min_silence_frames = <span class="built_in">int</span>(min_silence_duration_ms * SAMPLE_RATE / <span class="number">1000</span> / num_samples)</span><br><span class="line">        <span class="variable language_">self</span>.speech_frame_count = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.silence_frame_count = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.is_speech = <span class="literal">False</span></span><br><span class="line">        <span class="variable language_">self</span>.was_speech = <span class="literal">False</span>  <span class="comment"># 跟踪上一帧是否是语音</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, confidence</span>):</span><br><span class="line">        <span class="variable language_">self</span>.was_speech = <span class="variable language_">self</span>.is_speech  <span class="comment"># 保存上一帧的状态</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.is_speech:</span><br><span class="line">            <span class="keyword">if</span> confidence &gt;= <span class="variable language_">self</span>.threshold:</span><br><span class="line">                <span class="variable language_">self</span>.speech_frame_count += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> <span class="variable language_">self</span>.speech_frame_count &gt;= <span class="variable language_">self</span>.min_speech_frames:</span><br><span class="line">                    <span class="variable language_">self</span>.is_speech = <span class="literal">True</span></span><br><span class="line">                    <span class="variable language_">self</span>.silence_frame_count = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.speech_frame_count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> confidence &lt;= <span class="variable language_">self</span>.threshold - <span class="number">0.15</span>:</span><br><span class="line">                <span class="variable language_">self</span>.silence_frame_count += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> <span class="variable language_">self</span>.silence_frame_count &gt;= <span class="variable language_">self</span>.min_silence_frames:</span><br><span class="line">                    <span class="variable language_">self</span>.is_speech = <span class="literal">False</span></span><br><span class="line">                    <span class="variable language_">self</span>.speech_frame_count = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.silence_frame_count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.is_speech</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_speech_end</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;检查是否是语音结束&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.was_speech <span class="keyword">and</span> <span class="keyword">not</span> <span class="variable language_">self</span>.is_speech</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">recording_and_vad_thread</span>():</span><br><span class="line">    <span class="keyword">global</span> first_chunk_detected</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Recording...\n&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">    vad_context = VADContext(</span><br><span class="line">        threshold=state_manage.threshold,</span><br><span class="line">        min_speech_duration_ms=state_manage.min_speech_duration_ms,</span><br><span class="line">        min_silence_duration_ms=state_manage.min_silence_duration_ms,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> debug_mode:</span><br><span class="line">        raw_audio_chunks = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        data = stream.read(num_samples)</span><br><span class="line">        audio_chunk = np.frombuffer(data, dtype=np.float32)</span><br><span class="line">        speech_prob = model(torch.from_numpy(audio_chunk.copy()), SAMPLE_RATE).item()</span><br><span class="line">        is_speech = vad_context.update(speech_prob)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 放入缓冲区</span></span><br><span class="line">        pre_speech_buffer.append(audio_chunk)</span><br><span class="line">        <span class="keyword">if</span> is_speech:</span><br><span class="line">            <span class="comment"># 如果刚检测到语音</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> first_chunk_detected:</span><br><span class="line">                first_chunk_detected = <span class="literal">True</span></span><br><span class="line">                <span class="keyword">while</span> pre_speech_buffer:</span><br><span class="line">                    pre_chunk = pre_speech_buffer.popleft()</span><br><span class="line">                    int16_chunk = (pre_chunk * <span class="number">32767</span>).astype(np.int16)</span><br><span class="line">                    audio_record_queue.put(int16_chunk)</span><br><span class="line">                    <span class="keyword">if</span> debug_mode:</span><br><span class="line">                        raw_audio_chunks.append(int16_chunk)  <span class="comment"># 保存原始数据</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                audio_chunk_int16 = (audio_chunk * <span class="number">32767</span>).astype(np.int16)</span><br><span class="line">                audio_record_queue.put(audio_chunk_int16)</span><br><span class="line">                <span class="keyword">if</span> debug_mode:</span><br><span class="line">                    raw_audio_chunks.append(audio_chunk_int16)   <span class="comment"># 保存原始数据</span></span><br><span class="line">        <span class="keyword">elif</span> vad_context.is_speech_end():</span><br><span class="line">            audio_record_queue.put(<span class="literal">None</span>)</span><br><span class="line">            first_chunk_detected = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> debug_mode <span class="keyword">and</span> raw_audio_chunks:</span><br><span class="line">                raw_audio_data = np.concatenate(raw_audio_chunks)</span><br><span class="line">                sf.write(<span class="string">&quot;debug_raw_audio.wav&quot;</span>, raw_audio_data, samplerate=<span class="number">16000</span>, subtype=<span class="string">&quot;PCM_16&quot;</span>)</span><br><span class="line">                raw_audio_chunks.clear()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动录音线程</span></span><br><span class="line">recording_thread = threading.Thread(target=recording_and_vad_thread, daemon=<span class="literal">True</span>)</span><br><span class="line">recording_thread.start()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">send_audio</span>():</span><br><span class="line">    audio_chunks = []</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        chunk = audio_record_queue.get()</span><br><span class="line">        <span class="keyword">if</span> chunk <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> audio_chunks:</span><br><span class="line">                audio_data = np.concatenate(audio_chunks)</span><br><span class="line">                audio_data_bytes = audio_data.tobytes()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 发送到ASR服务器</span></span><br><span class="line">                result = send_audio_to_server(audio_data_bytes)</span><br><span class="line">                <span class="keyword">if</span> result:</span><br><span class="line">                    asr_text = result[<span class="string">&#x27;res&#x27;</span>]</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;\nres: <span class="subst">&#123;asr_text&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">                audio_chunks.clear()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            audio_chunks.append(chunk)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    send_audio()</span><br></pre></td></tr></table></figure>



<p><strong>服务端为paraformer时输出：</strong></p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">D:<span class="keyword">\Anaconda</span>3<span class="keyword">\envs</span><span class="keyword">\langchain</span><span class="keyword">\python</span>.exe E:<span class="keyword">\chr</span><span class="built_in">_</span>git<span class="keyword">\speech</span><span class="built_in">_</span>dialogue<span class="built_in">_</span>demo<span class="keyword">\stream</span><span class="keyword">\silero</span><span class="built_in">_</span>vad<span class="built_in">_</span>mic<span class="built_in">_</span>basic<span class="built_in">_</span>request<span class="built_in">_</span>nobase64.py </span><br><span class="line">Using cache found in C:<span class="keyword">\Users</span><span class="keyword">\chr</span>/.cache<span class="keyword">\torch</span><span class="keyword">\hub</span><span class="keyword">\snakers</span>4<span class="built_in">_</span>silero-vad<span class="built_in">_</span>master</span><br><span class="line">6</span><br><span class="line">Recording...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">res: 春眠不觉晓，处处闻啼鸟。</span><br><span class="line"></span><br><span class="line">res: 夜来风雨声花落知多少。</span><br><span class="line"></span><br><span class="line">res: 现在是北京时间十五点五十七分。</span><br><span class="line"></span><br><span class="line">res: 四月二十八号。</span><br><span class="line"></span><br><span class="line">进程已结束，退出代码为 -1</span><br></pre></td></tr></table></figure>

<p>可以看出只有标点符号，但并没有逆文本正则化。</p>
<p><strong>服务端为sensevoice时输出：</strong></p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">D:<span class="keyword">\Anaconda</span>3<span class="keyword">\envs</span><span class="keyword">\langchain</span><span class="keyword">\python</span>.exe E:<span class="keyword">\chr</span><span class="built_in">_</span>git<span class="keyword">\speech</span><span class="built_in">_</span>dialogue<span class="built_in">_</span>demo<span class="keyword">\stream</span><span class="keyword">\silero</span><span class="built_in">_</span>vad<span class="built_in">_</span>mic<span class="built_in">_</span>basic<span class="built_in">_</span>request<span class="built_in">_</span>nobase64.py </span><br><span class="line">Using cache found in C:<span class="keyword">\Users</span><span class="keyword">\chr</span>/.cache<span class="keyword">\torch</span><span class="keyword">\hub</span><span class="keyword">\snakers</span>4<span class="built_in">_</span>silero-vad<span class="built_in">_</span>master</span><br><span class="line">6</span><br><span class="line">Recording...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">res: 春眠不觉晓，处处闻定。</span><br><span class="line"></span><br><span class="line">res: 春眠不觉晓，处处闻啼鸟，夜来风雨声花落知多少。</span><br><span class="line"></span><br><span class="line">res: 人之初性本善，性相近习相远，苟教相乃迁。</span><br><span class="line"></span><br><span class="line">res: 锄禾日当午。😔</span><br><span class="line"></span><br><span class="line">res: 现在是北京时间16点06分。</span><br><span class="line"></span><br><span class="line">res: 今天是4月28号。</span><br><span class="line"></span><br><span class="line">进程已结束，退出代码为 -1</span><br></pre></td></tr></table></figure>

<p>可见既有标点符号，又有逆文本正则化。现在有emoji表情，添加上<code>ban_emo_unk=True</code>试下效果：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">D:<span class="keyword">\Anaconda</span>3<span class="keyword">\envs</span><span class="keyword">\langchain</span><span class="keyword">\python</span>.exe E:<span class="keyword">\chr</span><span class="built_in">_</span>git<span class="keyword">\speech</span><span class="built_in">_</span>dialogue<span class="built_in">_</span>demo<span class="keyword">\stream</span><span class="keyword">\silero</span><span class="built_in">_</span>vad<span class="built_in">_</span>mic<span class="built_in">_</span>basic<span class="built_in">_</span>request<span class="built_in">_</span>nobase64.py </span><br><span class="line">Using cache found in C:<span class="keyword">\Users</span><span class="keyword">\chr</span>/.cache<span class="keyword">\torch</span><span class="keyword">\hub</span><span class="keyword">\snakers</span>4<span class="built_in">_</span>silero-vad<span class="built_in">_</span>master</span><br><span class="line">6</span><br><span class="line">Recording...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">res: 锄禾日当午。😔</span><br><span class="line"></span><br><span class="line">res: 海迪和下土。</span><br><span class="line"></span><br><span class="line">res: 谁知盘中餐。</span><br><span class="line"></span><br><span class="line">res: 锄禾日当午。😔</span><br><span class="line"></span><br><span class="line">进程已结束，退出代码为 -1</span><br></pre></td></tr></table></figure>

<p>可见现在还是有emoji表情，那设置成<code>False</code>看看：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">D:<span class="keyword">\Anaconda</span>3<span class="keyword">\envs</span><span class="keyword">\langchain</span><span class="keyword">\python</span>.exe E:<span class="keyword">\chr</span><span class="built_in">_</span>git<span class="keyword">\speech</span><span class="built_in">_</span>dialogue<span class="built_in">_</span>demo<span class="keyword">\stream</span><span class="keyword">\silero</span><span class="built_in">_</span>vad<span class="built_in">_</span>mic<span class="built_in">_</span>basic<span class="built_in">_</span>request<span class="built_in">_</span>nobase64.py </span><br><span class="line">Using cache found in C:<span class="keyword">\Users</span><span class="keyword">\chr</span>/.cache<span class="keyword">\torch</span><span class="keyword">\hub</span><span class="keyword">\snakers</span>4<span class="built_in">_</span>silero-vad<span class="built_in">_</span>master</span><br><span class="line">6</span><br><span class="line">Recording...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">res: 锄禾日当午。😔</span><br><span class="line"></span><br><span class="line">进程已结束，退出代码为 -1</span><br></pre></td></tr></table></figure>

<p>🤷‍♂️怎么还有，算了，去钉钉群问问去。</p>
<hr>
<h3 id="官方HTTP示例"><a href="#官方HTTP示例" class="headerlink" title="官方HTTP示例"></a>官方HTTP示例</h3><p>就是因为看了下官方的HTTP示例才知道requests.post可以不使用json字段传音频数据，那么咱们现在一起好好看看<a href="https://github.com/modelscope/FunASR/tree/main/runtime/python/http">官方的HTTP示例</a>吧：</p>
<p>首先看下<strong>客户端代码</strong>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">&quot;--host&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&quot;127.0.0.1&quot;</span>, required=<span class="literal">False</span>, <span class="built_in">help</span>=<span class="string">&quot;sever ip&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--port&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">8000</span>, required=<span class="literal">False</span>, <span class="built_in">help</span>=<span class="string">&quot;server port&quot;</span>)</span><br><span class="line">parser.add_argument(</span><br><span class="line">    <span class="string">&quot;--audio_path&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&quot;asr_example_zh.wav&quot;</span>, required=<span class="literal">False</span>, <span class="built_in">help</span>=<span class="string">&quot;use audio path&quot;</span></span><br><span class="line">)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;-----------  Configuration Arguments -----------&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> arg, value <span class="keyword">in</span> <span class="built_in">vars</span>(args).items():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;%s: %s&quot;</span> % (arg, value))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;------------------------------------------------&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">url = <span class="string">f&quot;http://<span class="subst">&#123;args.host&#125;</span>:<span class="subst">&#123;args.port&#125;</span>/recognition&quot;</span></span><br><span class="line">headers = &#123;&#125;</span><br><span class="line">files = [</span><br><span class="line">    (</span><br><span class="line">        <span class="string">&quot;audio&quot;</span>,</span><br><span class="line">        (</span><br><span class="line">            os.path.basename(args.audio_path),</span><br><span class="line">            <span class="built_in">open</span>(args.audio_path, <span class="string">&quot;rb&quot;</span>),</span><br><span class="line">            <span class="string">&quot;application/octet-stream&quot;</span>,</span><br><span class="line">        ),</span><br><span class="line">    )</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">response = requests.post(url, headers=headers, files=files)</span><br><span class="line"><span class="built_in">print</span>(response.text)</span><br></pre></td></tr></table></figure>

<p><strong>服务端代码：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse		<span class="comment"># 用来处理命令行参数的</span></span><br><span class="line"><span class="keyword">import</span> logging		<span class="comment"># 用来输出日志信息的</span></span><br><span class="line"><span class="keyword">import</span> os			<span class="comment"># 用来操作文件系统，比如创建文件夹</span></span><br><span class="line"><span class="keyword">import</span> uuid			<span class="comment"># 用来生成随机的、独一无二的ID</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> aiofiles		<span class="comment"># 用来异步读写文件（非阻塞，不卡主程序）</span></span><br><span class="line"><span class="keyword">import</span> ffmpeg		<span class="comment"># 用来处理音频文件，比如重采样等</span></span><br><span class="line"><span class="keyword">import</span> uvicorn		<span class="comment"># 用来启动FastAPI服务器的工具</span></span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, File, UploadFile  <span class="comment"># FastAPI框架相关，处理HTTP请求</span></span><br><span class="line"><span class="keyword">from</span> modelscope.utils.logger <span class="keyword">import</span> get_logger <span class="comment"># 引入modelscope里的日志工具</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> funasr <span class="keyword">import</span> AutoModel	<span class="comment"># 引入FunASR库，自动加载语音识别模型</span></span><br><span class="line"></span><br><span class="line">logger = get_logger(log_level=logging.INFO)  <span class="comment"># 获取一个日志记录器，日志级别是INFO</span></span><br><span class="line">logger.setLevel(logging.INFO)  <span class="comment"># 设定日志输出级别为INFO</span></span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser()  <span class="comment"># 创建一个参数解析器，用于从命令行读取一些配置</span></span><br><span class="line">parser.add_argument(</span><br><span class="line">    <span class="string">&quot;--host&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&quot;0.0.0.0&quot;</span>, required=<span class="literal">False</span>, <span class="built_in">help</span>=<span class="string">&quot;host ip, localhost, 0.0.0.0&quot;</span></span><br><span class="line">)  <span class="comment"># --host: 指定服务器IP地址</span></span><br><span class="line">parser.add_argument(<span class="string">&quot;--port&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">8000</span>, required=<span class="literal">False</span>, <span class="built_in">help</span>=<span class="string">&quot;server port&quot;</span>)  <span class="comment"># --port: 指定服务器端口</span></span><br><span class="line">parser.add_argument(</span><br><span class="line">    <span class="string">&quot;--asr_model&quot;</span>,</span><br><span class="line">    <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">    default=<span class="string">&quot;paraformer-zh&quot;</span>,</span><br><span class="line">    <span class="built_in">help</span>=<span class="string">&quot;asr model from https://github.com/alibaba-damo-academy/FunASR?tab=readme-ov-file#model-zoo&quot;</span>,</span><br><span class="line">)  <span class="comment"># --asr_model: 指定要加载的ASR模型名称</span></span><br><span class="line">parser.add_argument(<span class="string">&quot;--asr_model_revision&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&quot;v2.0.4&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;&quot;</span>)  <span class="comment"># --asr_model_revision：指定要加载的ASR模型的版本号</span></span><br><span class="line">parser.add_argument(</span><br><span class="line">    <span class="string">&quot;--vad_model&quot;</span>,</span><br><span class="line">    <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">    default=<span class="string">&quot;fsmn-vad&quot;</span>,</span><br><span class="line">    <span class="built_in">help</span>=<span class="string">&quot;vad model from https://github.com/alibaba-damo-academy/FunASR?tab=readme-ov-file#model-zoo&quot;</span>,</span><br><span class="line">) </span><br><span class="line">parser.add_argument(<span class="string">&quot;--vad_model_revision&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&quot;v2.0.4&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;&quot;</span>)</span><br><span class="line">parser.add_argument(</span><br><span class="line">    <span class="string">&quot;--punc_model&quot;</span>,</span><br><span class="line">    <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">    default=<span class="string">&quot;ct-punc-c&quot;</span>,</span><br><span class="line">    <span class="built_in">help</span>=<span class="string">&quot;model from https://github.com/alibaba-damo-academy/FunASR?tab=readme-ov-file#model-zoo&quot;</span>,</span><br><span class="line">)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--punc_model_revision&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&quot;v2.0.4&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--ngpu&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">1</span>, <span class="built_in">help</span>=<span class="string">&quot;0 for cpu, 1 for gpu&quot;</span>)  <span class="comment"># 选择使用cpu还是gpu</span></span><br><span class="line">parser.add_argument(<span class="string">&quot;--device&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&quot;cuda&quot;</span>, <span class="built_in">help</span>=<span class="string">&quot;cuda, cpu&quot;</span>)		<span class="comment"># 同上</span></span><br><span class="line">parser.add_argument(<span class="string">&quot;--ncpu&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">4</span>, <span class="built_in">help</span>=<span class="string">&quot;cpu cores&quot;</span>)		<span class="comment"># 使用几个cpu核</span></span><br><span class="line">parser.add_argument(</span><br><span class="line">    <span class="string">&quot;--hotword_path&quot;</span>,</span><br><span class="line">    <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">    default=<span class="string">&quot;hotwords.txt&quot;</span>,</span><br><span class="line">    <span class="built_in">help</span>=<span class="string">&quot;hot word txt path, only the hot word model works&quot;</span>,</span><br><span class="line">)  <span class="comment"># 指定热词文件路径</span></span><br><span class="line">parser.add_argument(<span class="string">&quot;--certfile&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="literal">None</span>, required=<span class="literal">False</span>, <span class="built_in">help</span>=<span class="string">&quot;certfile for ssl&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--keyfile&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="literal">None</span>, required=<span class="literal">False</span>, <span class="built_in">help</span>=<span class="string">&quot;keyfile for ssl&quot;</span>)</span><br><span class="line">parser.add_argument(<span class="string">&quot;--temp_dir&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&quot;temp_dir/&quot;</span>, required=<span class="literal">False</span>, <span class="built_in">help</span>=<span class="string">&quot;temp dir&quot;</span>)  <span class="comment"># 上传的临时音频保存目录</span></span><br><span class="line">args = parser.parse_args()  <span class="comment"># 解析参数</span></span><br><span class="line">logger.info(<span class="string">&quot;-----------  Configuration Arguments -----------&quot;</span>) <span class="comment"># 打印当前配置，方便确认</span></span><br><span class="line"><span class="keyword">for</span> arg, value <span class="keyword">in</span> <span class="built_in">vars</span>(args).items():</span><br><span class="line">    logger.info(<span class="string">&quot;%s: %s&quot;</span> % (arg, value))</span><br><span class="line">logger.info(<span class="string">&quot;------------------------------------------------&quot;</span>)</span><br><span class="line"></span><br><span class="line">os.makedirs(args.temp_dir, exist_ok=<span class="literal">True</span>) <span class="comment"># 创建一个临时文件夹，用来保存上传的音频，exist_ok=True 表示如果文件夹已经存在不报错</span></span><br><span class="line"></span><br><span class="line">logger.info(<span class="string">&quot;model loading&quot;</span>)</span><br><span class="line"><span class="comment"># load funasr model 加载模型</span></span><br><span class="line">model = AutoModel(</span><br><span class="line">    model=args.asr_model,</span><br><span class="line">    model_revision=args.asr_model_revision,</span><br><span class="line">    vad_model=args.vad_model,</span><br><span class="line">    vad_model_revision=args.vad_model_revision,</span><br><span class="line">    punc_model=args.punc_model,</span><br><span class="line">    punc_model_revision=args.punc_model_revision,</span><br><span class="line">    ngpu=args.ngpu,</span><br><span class="line">    ncpu=args.ncpu,</span><br><span class="line">    device=args.device,</span><br><span class="line">    disable_pbar=<span class="literal">True</span>,	<span class="comment"># 关闭进度条</span></span><br><span class="line">    disable_log=<span class="literal">True</span>,	<span class="comment"># 关闭模型内部的日志打印</span></span><br><span class="line">)</span><br><span class="line">logger.info(<span class="string">&quot;loaded models!&quot;</span>)</span><br><span class="line"></span><br><span class="line">app = FastAPI(title=<span class="string">&quot;FunASR&quot;</span>)	<span class="comment"># 创建 FastAPI Web服务应用，准备对外提供接口</span></span><br><span class="line"></span><br><span class="line">param_dict = &#123;<span class="string">&quot;sentence_timestamp&quot;</span>: <span class="literal">True</span>, <span class="string">&quot;batch_size_s&quot;</span>: <span class="number">300</span>&#125;  <span class="comment"># 打开时间戳信息</span></span><br><span class="line"><span class="keyword">if</span> args.hotword_path <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> os.path.exists(args.hotword_path):		<span class="comment"># 热词处理</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(args.hotword_path, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        lines = f.readlines()</span><br><span class="line">        lines = [line.strip() <span class="keyword">for</span> line <span class="keyword">in</span> lines]</span><br><span class="line">    hotword = <span class="string">&quot; &quot;</span>.join(lines)</span><br><span class="line">    logger.info(<span class="string">f&quot;热词：<span class="subst">&#123;hotword&#125;</span>&quot;</span>)</span><br><span class="line">    param_dict[<span class="string">&quot;hotword&quot;</span>] = hotword</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/recognition&quot;</span></span>)  </span><span class="comment"># 定义POST接口，接收上传的音频文件</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">api_recognition</span>(<span class="params">audio: UploadFile = File(<span class="params">..., description=<span class="string">&quot;audio file&quot;</span></span>)</span>):</span><br><span class="line">    suffix = audio.filename.split(<span class="string">&quot;.&quot;</span>)[-<span class="number">1</span>]  <span class="comment"># 提取文件后缀</span></span><br><span class="line">    audio_path = <span class="string">f&quot;<span class="subst">&#123;args.temp_dir&#125;</span>/<span class="subst">&#123;<span class="built_in">str</span>(uuid.uuid1())&#125;</span>.<span class="subst">&#123;suffix&#125;</span>&quot;</span>  <span class="comment"># 生成随机文件名保存上传的音频</span></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> aiofiles.<span class="built_in">open</span>(audio_path, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> out_file:  <span class="comment"># 异步保存文件到磁盘</span></span><br><span class="line">        content = <span class="keyword">await</span> audio.read()</span><br><span class="line">        <span class="keyword">await</span> out_file.write(content)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        audio_bytes, _ = (  <span class="comment"># 用ffmpeg把音频转成16k采样率、单声道、16bit PCM格式</span></span><br><span class="line">            ffmpeg.<span class="built_in">input</span>(audio_path, threads=<span class="number">0</span>)</span><br><span class="line">            .output(<span class="string">&quot;-&quot;</span>, <span class="built_in">format</span>=<span class="string">&quot;s16le&quot;</span>, acodec=<span class="string">&quot;pcm_s16le&quot;</span>, ac=<span class="number">1</span>, ar=<span class="number">16000</span>)</span><br><span class="line">            .run(cmd=[<span class="string">&quot;ffmpeg&quot;</span>, <span class="string">&quot;-nostdin&quot;</span>], capture_stdout=<span class="literal">True</span>, capture_stderr=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        logger.error(<span class="string">f&quot;读取音频文件发生错误，错误信息：<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&quot;msg&quot;</span>: <span class="string">&quot;读取音频文件发生错误&quot;</span>, <span class="string">&quot;code&quot;</span>: <span class="number">1</span>&#125;</span><br><span class="line">    rec_results = model.generate(<span class="built_in">input</span>=audio_bytes, is_final=<span class="literal">True</span>, **param_dict)  <span class="comment"># 用模型进行识别</span></span><br><span class="line">    <span class="comment"># 结果为空</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(rec_results) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&quot;text&quot;</span>: <span class="string">&quot;&quot;</span>, <span class="string">&quot;sentences&quot;</span>: [], <span class="string">&quot;code&quot;</span>: <span class="number">0</span>&#125;</span><br><span class="line">    <span class="keyword">elif</span> <span class="built_in">len</span>(rec_results) == <span class="number">1</span>:</span><br><span class="line">        <span class="comment"># 解析识别结果</span></span><br><span class="line">        rec_result = rec_results[<span class="number">0</span>]</span><br><span class="line">        text = rec_result[<span class="string">&quot;text&quot;</span>]</span><br><span class="line">        sentences = []</span><br><span class="line">        <span class="keyword">for</span> sentence <span class="keyword">in</span> rec_result[<span class="string">&quot;sentence_info&quot;</span>]:</span><br><span class="line">            <span class="comment"># 每句话的时间戳</span></span><br><span class="line">            sentences.append(</span><br><span class="line">                &#123;<span class="string">&quot;text&quot;</span>: sentence[<span class="string">&quot;text&quot;</span>], <span class="string">&quot;start&quot;</span>: sentence[<span class="string">&quot;start&quot;</span>], <span class="string">&quot;end&quot;</span>: sentence[<span class="string">&quot;end&quot;</span>]&#125;</span><br><span class="line">            )</span><br><span class="line">        ret = &#123;<span class="string">&quot;text&quot;</span>: text, <span class="string">&quot;sentences&quot;</span>: sentences, <span class="string">&quot;code&quot;</span>: <span class="number">0</span>&#125;</span><br><span class="line">        logger.info(<span class="string">f&quot;识别结果：<span class="subst">&#123;ret&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> ret</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        logger.info(<span class="string">f&quot;识别结果：<span class="subst">&#123;rec_results&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&quot;msg&quot;</span>: <span class="string">&quot;未知错误&quot;</span>, <span class="string">&quot;code&quot;</span>: -<span class="number">1</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    uvicorn.run(</span><br><span class="line">        app, host=args.host, port=args.port, ssl_keyfile=args.keyfile, ssl_certfile=args.certfile</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>funasr</tag>
        <tag>sensevoice</tag>
        <tag>fastapi</tag>
        <tag>request</tag>
        <tag>paraformer</tag>
      </tags>
  </entry>
  <entry>
    <title>gRPC基础一起看</title>
    <url>/2025/04/21/gRPC%E5%9F%BA%E7%A1%80%E4%B8%80%E8%B5%B7%E7%9C%8B/</url>
    <content><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>最近在探索高并发下的<code>TTS</code>服务(可能并发也不算高，目标是20个)，但是目前10个并发都勉强（<code>13600KF+4090</code>），目前使用的是<code>Gpt-Sovits</code>，在了解别的<code>TTS</code>时，目前主要关注的是<code>Spark-tts</code>和<code>F5-tts</code>，这两个TTS都有基于<code>Nvidia Triton</code>的使用方式（出自同一个作者），发现<code>Triton</code>支持客户端使用HTTP(requests)和gRPC的方式进行连接，之前看<a href="https://github.com/modelscope/FunASR/tree/main">funasr</a>库的时候就看到官方提供了<a href="https://github.com/modelscope/FunASR/tree/main/runtime/python/grpc">gRPC连接方式</a>，最近在<a href="">F5-TTS</a>的Issues中看到了问<a href="https://github.com/SWivid/F5-TTS/issues/945">如何高并发</a>的问题，作者让<a href="https://github.com/SWivid/F5-TTS/issues/945#issuecomment-2774777083">查看库中grpc的相关代码</a>，我觉得是时候了，必须得学学gRPC这个框架了。本文将从：</p>
<ol>
<li><strong>核心概念理解:</strong> 了解 gRPC 是什么，解决什么问题，以及它的关键组成部分。</li>
<li><strong>基础工作流:</strong> 学习如何定义服务、生成代码，并运行一个最简单的 gRPC 服务（一元 RPC）。</li>
<li><strong>深入 RPC 类型:</strong> 学习并实践不同的流式 RPC。</li>
<li><strong>进阶特性:</strong> 了解错误处理、元数据、超时、认证等。</li>
<li><strong>与 FastAPI 对比与选择:</strong> 理解两者的优劣势和适用场景。</li>
</ol>
<p>以切点展开介绍gRPC这个框架，Let’s go!</p>
<span id="more"></span>

<hr>
<h3 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h3><h4 id="第一步：核心概念理解"><a href="#第一步：核心概念理解" class="headerlink" title="第一步：核心概念理解"></a>第一步：核心概念理解</h4><p>gRPC 是一个由 Google 开发的高性能、开源的通用 <strong>远程过程调用 (RPC, Remote Procedure Call)</strong> 框架。它旨在实现服务之间（尤其是在微服务架构中）高效、可靠的通信。</p>
<p>以下是关于 gRPC 的一些关键点：</p>
<ol>
<li><strong>高性能:</strong> gRPC 使用 <strong>HTTP&#x2F;2</strong> 作为传输协议。HTTP&#x2F;2 提供了多路复用、头部压缩、服务器推送和双向流式通信等特性，相比 HTTP&#x2F;1.1 效率更高。此外，它默认使用 <strong>Protocol Buffers (protobuf)</strong> 作为接口定义语言 (IDL) 和消息序列化格式。Protobuf 是一种二进制序列化格式，比基于文本的格式（如 JSON）更小、更快。</li>
<li><strong>跨语言和平台:</strong> gRPC 的核心理念是定义一个服务契约（.proto 文件），然后可以使用官方提供的工具为多种语言（如 Java, C++, Python, Go, Ruby, C#, Node.js, Android Java, Objective-C, PHP 等）自动生成客户端和服务器端的代码存根 (stub)。这使得用不同语言编写的服务可以轻松地相互通信。</li>
<li><strong>强类型契约:</strong> 使用 Protocol Buffers 定义服务接口和消息结构，提供了严格的模式（schema）。这有助于在编译时捕获错误，并确保客户端和服务器之间的数据结构一致性，减少了运行时错误。</li>
<li><strong>支持多种 RPC 类型:</strong><ul>
<li><strong>一元 RPC (Unary RPC):</strong> 客户端发送单个请求，服务器返回单个响应，类似于传统的 RESTful 调用。</li>
<li><strong>服务器流式 RPC (Server streaming RPC):</strong> 客户端发送单个请求，服务器返回一个响应流。</li>
<li><strong>客户端流式 RPC (Client streaming RPC):</strong> 客户端发送一个请求流，服务器在接收完所有请求后返回单个响应。</li>
<li><strong>双向流式 RPC (Bidirectional streaming RPC):</strong> 客户端和服务器都可以独立地发送消息流。</li>
</ul>
</li>
<li><strong>内置特性:</strong> gRPC 内建了对认证、负载均衡、超时与截止时间 (Deadlines)、取消、元数据交换等高级功能的支持。</li>
<li><strong>主要应用场景:</strong><ul>
<li>微服务之间的内部通信。</li>
<li>连接移动设备、浏览器客户端与后端服务。</li>
<li>需要高性能、低延迟通信的场景。</li>
<li>需要处理流式数据的场景。</li>
</ul>
</li>
</ol>
<p>总的来说，gRPC 是一个现代化的、功能强大的 RPC 框架，特别适合构建分布式系统和微服务架构。</p>
<hr>
<h5 id="与-FastAPI-对比"><a href="#与-FastAPI-对比" class="headerlink" title="与 FastAPI 对比"></a><strong>与 FastAPI 对比</strong></h5><ul>
<li><strong>RPC (Remote Procedure Call):</strong><ul>
<li><strong>gRPC:</strong> 核心是 RPC。你可以像调用本地函数一样调用远程服务器上的函数。你不需要关心底层的网络通信细节（如 HTTP 方法、URL 路径、请求&#x2F;响应体格式）。</li>
<li><strong>FastAPI:</strong> 通常基于 RESTful 架构。你通过 HTTP 方法 (GET, POST, PUT, DELETE) 和 URL 路径来定义操作，数据通常用 JSON 格式在请求体或响应体中传输。</li>
<li><strong>关键区别:</strong> gRPC 隐藏了更多的底层细节，更像函数调用；FastAPI 更显式地使用 HTTP 协议。</li>
</ul>
</li>
<li><strong>Protocol Buffers (Protobuf):</strong><ul>
<li><strong>gRPC:</strong> 这是 gRPC 默认的<strong>接口定义语言 (IDL)</strong> 和<strong>数据序列化格式</strong>。你需要在一个 .proto 文件中定义你的服务（有哪些函数）和消息结构（函数的参数和返回值长什么样）。</li>
<li><strong>FastAPI:</strong> 通常使用 Python 的类型注解 (Type Hints) 结合 Pydantic 来定义数据模型和验证。数据序列化通常是 <code>JSON</code>。</li>
<li><strong>关键区别:</strong><ul>
<li><strong>定义方式:</strong> gRPC 使用独立的 .proto 文件定义契约；FastAPI 在 Python 代码中使用类型注解<code>Pydantic</code>。</li>
<li><strong>序列化格式:</strong> gRPC 默认使用 Protobuf (二进制，高效)；FastAPI 默认使用 JSON (文本，人类可读)。</li>
<li><strong>强类型契约:</strong> Protobuf 提供了语言无关的、严格的模式定义。</li>
</ul>
</li>
</ul>
</li>
<li><strong>HTTP&#x2F;2:</strong><ul>
<li><strong>gRPC:</strong> <strong>必须</strong>在 HTTP&#x2F;2 上运行。这带来了性能优势，如多路复用（在单个连接上处理多个请求）、头部压缩、服务器推送，并为流式 RPC 提供了基础。</li>
<li><strong>FastAPI:</strong> 可以运行在 HTTP&#x2F;1.1 或 HTTP&#x2F;2 上（取决于 ASGI 服务器如 Uvicorn&#x2F;Hypercorn 的配置）。</li>
<li><strong>关键区别:</strong> gRPC 强制使用更高效的 HTTP&#x2F;2。</li>
</ul>
</li>
<li><strong>代码生成:</strong><ul>
<li><strong>gRPC:</strong> 这是 gRPC 工作流的<strong>核心部分</strong>。你需要使用 protoc (Protocol Buffer 编译器) 和特定语言的插件，根据 .proto 文件自动生成客户端和服务端的代码骨架（stubs&#x2F;skeletons）。</li>
<li><strong>FastAPI:</strong> 通常不需要显式的代码生成步骤来定义 API 接口本身（虽然 OpenAPI 文档是自动生成的）。</li>
<li><strong>关键区别:</strong> gRPC 严重依赖代码生成来简化开发。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="第二步：基础工作流-第一个-gRPC-应用-Python"><a href="#第二步：基础工作流-第一个-gRPC-应用-Python" class="headerlink" title="第二步：基础工作流 - 第一个 gRPC 应用 (Python)"></a><strong>第二步：基础工作流 - 第一个 gRPC 应用 (Python)</strong></h4><p>让我们创建一个简单的 “Greeter” 服务，客户端发送一个名字，服务器返回一句问候语。</p>
<h5 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a><strong>环境准备</strong></h5><ul>
<li><p>安装 Python (假设你已经有了)。</p>
</li>
<li><p>安装必要的 gRPC 库：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">pip <span class="keyword">install</span> grpcio grpcio-tools</span><br></pre></td></tr></table></figure>

<ul>
<li>grpcio: 核心 gRPC 库。</li>
<li>grpcio-tools: 包含 protoc 编译器和 Python 插件，用于从 .proto 文件生成代码。</li>
</ul>
</li>
</ul>
<h5 id="定义服务-proto-文件"><a href="#定义服务-proto-文件" class="headerlink" title="定义服务 (.proto 文件)"></a><strong>定义服务 (.proto 文件)</strong></h5><p>创建一个名为 greeter.proto 的文件，内容如下：</p>
<figure class="highlight protobuf"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 指定使用 proto3 语法</span></span><br><span class="line">syntax = <span class="string">&quot;proto3&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义包名，可选，但推荐，用于避免命名冲突</span></span><br><span class="line"><span class="keyword">package</span> greeter;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义服务 &quot;Greeter&quot;</span></span><br><span class="line"><span class="keyword">service </span><span class="title class_">Greeter</span> &#123;</span><br><span class="line">  <span class="comment">// 定义一个 RPC 方法 &quot;SayHello&quot;</span></span><br><span class="line">  <span class="comment">// 它接收 HelloRequest 消息，返回 HelloReply 消息</span></span><br><span class="line">  <span class="comment">// 这是最简单的 Unary RPC (一元 RPC)</span></span><br><span class="line">  <span class="function"><span class="keyword">rpc</span> SayHello (HelloRequest) <span class="keyword">returns</span> (HelloReply)</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义请求消息结构</span></span><br><span class="line"><span class="keyword">message </span><span class="title class_">HelloRequest</span> &#123;</span><br><span class="line">  <span class="type">string</span> name = <span class="number">1</span>; <span class="comment">// 字段类型是 string，字段名叫 name，字段编号是 1</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义响应消息结构</span></span><br><span class="line"><span class="keyword">message </span><span class="title class_">HelloReply</span> &#123;</span><br><span class="line">  <span class="type">string</span> message = <span class="number">1</span>; <span class="comment">// 字段类型是 string，字段名叫 message，字段编号是 1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>syntax &#x3D; “proto3”;</strong>: 声明使用 Protobuf 的第 3 版语法。</li>
<li><strong>service Greeter { … }</strong>: 定义一个名为 Greeter 的服务。</li>
<li><strong>rpc SayHello (…) returns (…);</strong>: 定义一个名为 SayHello 的远程过程调用。</li>
<li><strong>message HelloRequest { … } &#x2F; message HelloReply { … }</strong>: 定义请求和响应的数据结构。每个字段有类型、名称和唯一的编号。</li>
</ul>
<h5 id="生成代码"><a href="#生成代码" class="headerlink" title="生成代码"></a><strong>生成代码</strong></h5><p>在包含 <code>greeter.proto</code> 文件的目录下，运行以下命令：</p>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">python -m grpc_tools.protoc -I. <span class="attribute">--python_out</span>=. <span class="attribute">--grpc_python_out</span>=. greeter.proto</span><br></pre></td></tr></table></figure>

<ul>
<li><code>python -m grpc_tools.protoc</code>: 调用 Python 的 <code>protoc</code> 工具。</li>
<li>-I.: 指定 <code>.proto</code> 文件的搜索路径（. 表示当前目录）。</li>
<li>–python_out&#x3D;.: 指定生成的 Python 消息代码 (_pb2.py) 的输出目录。</li>
<li>–grpc_python_out&#x3D;.: 指定生成的 Python gRPC 服务&#x2F;客户端代码 (_pb2_grpc.py) 的输出目录。</li>
<li>greeter.proto: 要编译的 .proto 文件。</li>
</ul>
<p>执行成功后，你会看到当前目录下多了两个文件：</p>
<ul>
<li>greeter_pb2.py（数据结构类）: 包含 Protobuf 消息类的 Python 代码（HelloRequest, HelloReply）。</li>
<li>greeter_pb2_grpc.py（服务和客户端基类）: 包含：<ul>
<li>GreeterStub: 客户端用来调用服务的类。</li>
<li>GreeterServicer: 服务器需要实现的基类（定义了 SayHello 方法的接口）。</li>
<li>add_GreeterServicer_to_server: 将服务实现注册到服务器的函数。</li>
</ul>
</li>
</ul>
<h5 id="实现服务器-grpc-server-py"><a href="#实现服务器-grpc-server-py" class="headerlink" title="实现服务器 (grpc_server.py)"></a><strong>实现服务器 (grpc_server.py)</strong></h5><p>创建一个 <code>grpc_server.py</code> 文件：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> grpc</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> concurrent <span class="keyword">import</span> futures</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入生成的代码</span></span><br><span class="line"><span class="keyword">import</span> greeter_pb2</span><br><span class="line"><span class="keyword">import</span> greeter_pb2_grpc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实现 .proto 文件中定义的服务接口</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GreeterServicer</span>(greeter_pb2_grpc.GreeterServicer):</span><br><span class="line">    <span class="comment"># 实现 SayHello 方法</span></span><br><span class="line">    <span class="comment"># 在方法定义的末尾传入 context为使用 gRPC Python 框架来实现服务端 RPC 方法时的一个固定、标准的写法。</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">SayHello</span>(<span class="params">self, request, context</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;收到请求: name=&#x27;<span class="subst">&#123;request.name&#125;</span>&#x27;&quot;</span>)</span><br><span class="line">        <span class="comment"># 构建响应消息</span></span><br><span class="line">        reply = greeter_pb2.HelloReply(message=<span class="string">f&quot;你好, <span class="subst">&#123;request.name&#125;</span>!&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> reply</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">serve</span>():</span><br><span class="line">    <span class="comment"># 创建一个 gRPC 服务器，使用线程池处理请求</span></span><br><span class="line">    server = grpc.server(futures.ThreadPoolExecutor(max_workers=<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将我们实现的服务注册到服务器中</span></span><br><span class="line">    greeter_pb2_grpc.add_GreeterServicer_to_server(GreeterServicer(), server)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 监听端口 50051 (不安全的连接，用于测试)</span></span><br><span class="line">    server.add_insecure_port(<span class="string">&#x27;[::]:50051&#x27;</span>) <span class="comment"># [::] 监听所有 IPv4 和 IPv6 地址</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;服务器启动，监听端口 50051...&quot;</span>)</span><br><span class="line">    <span class="comment"># 启动服务器</span></span><br><span class="line">    server.start()</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;服务已启动，等待终止信号...&quot;</span>)</span><br><span class="line">    <span class="comment"># 使用 wait_for_termination() 来阻塞主线程，直到服务器停止</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">       server.wait_for_termination()</span><br><span class="line">    <span class="keyword">except</span> KeyboardInterrupt:</span><br><span class="line">    	<span class="comment"># 收到 Ctrl+C信号</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;收到键盘中断信号，开始停止服务器...&quot;</span>)</span><br><span class="line">        <span class="comment"># 调用 server.stop() 来触发优雅关闭，可以给一个宽限期</span></span><br><span class="line">        <span class="comment"># wait_for_termination 会在 stop 完成后解除阻塞</span></span><br><span class="line">        server.stop(<span class="number">5</span>) <span class="comment"># 优雅停止，最多等待 5S 让请求完成</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;服务器已停止&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    serve()</span><br></pre></td></tr></table></figure>

<h5 id="实现客户端-client-py"><a href="#实现客户端-client-py" class="headerlink" title="实现客户端 (client.py)"></a><strong>实现客户端 (client.py)</strong></h5><p>创建一个 client.py 文件：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> grpc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入生成的代码</span></span><br><span class="line"><span class="keyword">import</span> greeter_pb2</span><br><span class="line"><span class="keyword">import</span> greeter_pb2_grpc</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>():</span><br><span class="line">    <span class="comment"># 连接到 gRPC 服务器 (注意地址和端口要匹配服务器)</span></span><br><span class="line">    <span class="comment"># grpc.insecure_channel 表示不使用 TLS 加密，用于测试</span></span><br><span class="line">    <span class="keyword">with</span> grpc.insecure_channel(<span class="string">&#x27;localhost:50051&#x27;</span>) <span class="keyword">as</span> channel:</span><br><span class="line">        <span class="comment"># 创建一个客户端 stub (存根)</span></span><br><span class="line">        stub = greeter_pb2_grpc.GreeterStub(channel)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;--- 调用 SayHello ---&quot;</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># 创建请求消息</span></span><br><span class="line">            request = greeter_pb2.HelloRequest(name=<span class="string">&#x27;gRPC 小白&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 调用远程方法，就像调用本地方法一样</span></span><br><span class="line">            response = stub.SayHello(request, timeout=<span class="number">10</span>) <span class="comment"># 设置10秒超时</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 打印服务器返回的响应</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;服务器响应: <span class="subst">&#123;response.message&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">except</span> grpc.RpcError <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;RPC 调用失败: <span class="subst">&#123;e.code()&#125;</span> - <span class="subst">&#123;e.details()&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    run()</span><br></pre></td></tr></table></figure>

<h5 id="运行"><a href="#运行" class="headerlink" title="运行:"></a><strong>运行:</strong></h5><ul>
<li>先在一个终端启动服务器：python grpc_server.py</li>
<li>然后在另一个终端启动客户端：python grpc_client.py</li>
</ul>
<p>你应该能看到服务器打印收到请求，客户端打印收到的响应 “你好, gRPC 小白!”。</p>
<p><strong>恭喜！你已经成功运行了你的第一个 gRPC 应用！</strong></p>
<hr>
<h4 id="第三步：深入-RPC-类型"><a href="#第三步：深入-RPC-类型" class="headerlink" title="第三步：深入 RPC 类型"></a><strong>第三步：深入 RPC 类型</strong></h4><p>gRPC 不仅仅支持上面这种简单的一对一请求响应（Unary RPC），还支持流式 RPC：</p>
<ol>
<li><strong>服务器流式 RPC (Server Streaming RPC):</strong><ul>
<li><strong>场景:</strong> 客户端发送一个请求，服务器返回一个数据流。例如，客户端请求股票价格，服务器持续推送更新。</li>
<li><strong>.proto 定义:</strong> rpc ListFeatures (Point) returns (stream Feature); (注意 stream 关键字在返回值前)</li>
<li><strong>实现:</strong> 服务器端的 RPC 方法需要返回一个迭代器或生成器 (yield 数据)。客户端会迭代接收服务器发送的消息。</li>
</ul>
</li>
<li><strong>客户端流式 RPC (Client Streaming RPC):</strong><ul>
<li><strong>场景:</strong> 客户端发送一个数据流给服务器，服务器处理完所有数据后返回一个响应。例如，客户端上传一个大文件（分块发送），服务器接收完后返回确认信息。</li>
<li><strong>.proto 定义:</strong> rpc RecordRoute (stream Point) returns (RouteSummary); (注意 stream 关键字在参数前)</li>
<li><strong>实现:</strong> 服务器端的 RPC 方法接收一个请求迭代器。客户端需要提供一个迭代器或生成器来发送数据流。</li>
</ul>
</li>
<li><strong>双向流式 RPC (Bidirectional Streaming RPC):</strong><ul>
<li><strong>场景:</strong> 客户端和服务器可以互相独立地发送消息流。例如，一个聊天应用，客户端和服务器都可以随时发送消息。</li>
<li><strong>.proto 定义:</strong> rpc RouteChat (stream RouteNote) returns (stream RouteNote); (参数和返回值前都有 stream)</li>
<li><strong>实现:</strong> 服务器端接收请求迭代器，并返回响应迭代器。客户端也使用迭代器发送和接收。</li>
</ul>
</li>
</ol>
<p><strong>建议:</strong> 先完全掌握 Unary RPC，然后尝试实现一个 Server Streaming 的例子，再逐步尝试 Client Streaming 和 Bidirectional Streaming。官方 gRPC Python 教程中有这些类型的示例。</p>
<p>好！那我就按照顺序，<strong>先从第一种到第四种</strong>，每种都用<strong>简单易懂的小例子</strong>来讲，帮助你快速理解。</p>
<hr>
<h4 id="🌟🌟-gRPC-四种通信方式小课堂！"><a href="#🌟🌟-gRPC-四种通信方式小课堂！" class="headerlink" title="🌟🌟 gRPC 四种通信方式小课堂！"></a>🌟🌟 gRPC 四种通信方式小课堂！</h4><h5 id="1️⃣-单请求-单响应（Unary-RPC）"><a href="#1️⃣-单请求-单响应（Unary-RPC）" class="headerlink" title="1️⃣ 单请求 - 单响应（Unary RPC）"></a>1️⃣ 单请求 - 单响应（Unary RPC）</h5><p>最简单，像 HTTP 请求一样。</p>
<p>客户端发出一个请求，服务器返回一个结果。</p>
<figure class="highlight proto"><table><tr><td class="code"><pre><span class="line"><span class="keyword">service </span><span class="title class_">Greeter</span> &#123;</span><br><span class="line">  <span class="function"><span class="keyword">rpc</span> SayHello (HelloRequest) <span class="keyword">returns</span> (HelloReply)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>✅ 用法场景：</p>
<ul>
<li>登录验证</li>
<li>获取用户信息</li>
<li>获取天气数据</li>
</ul>
<p>刚刚写的 <code>SayHello</code> 就是这种类型！</p>
<hr>
<h5 id="2️⃣-服务端流式（Server-Streaming）"><a href="#2️⃣-服务端流式（Server-Streaming）" class="headerlink" title="2️⃣ 服务端流式（Server Streaming）"></a>2️⃣ 服务端流式（Server Streaming）</h5><p>客户端发出一次请求，服务器<strong>连续返回多条数据</strong>，直到发完。</p>
<figure class="highlight proto"><table><tr><td class="code"><pre><span class="line"><span class="keyword">service </span><span class="title class_">Greeter</span> &#123;</span><br><span class="line">  <span class="function"><span class="keyword">rpc</span> StreamHello (HelloRequest) <span class="keyword">returns</span> (stream HelloReply)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Python 服务端示范：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">StreamHello</span>(<span class="params">self, request, context</span>):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        <span class="keyword">yield</span> greeter_pb2.HelloReply(message=<span class="string">f&quot;Hello <span class="subst">&#123;request.name&#125;</span>! <span class="subst">&#123;i&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>客户端调用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">responses = stub.StreamHello(greeter_pb2.HelloRequest(name=<span class="string">&#x27;Streamer&#x27;</span>))</span><br><span class="line"><span class="keyword">for</span> response <span class="keyword">in</span> responses:</span><br><span class="line">    <span class="built_in">print</span>(response.message)</span><br></pre></td></tr></table></figure>

<p>✅ 用法场景：</p>
<ul>
<li>实时日志推送</li>
<li>服务器通知</li>
<li>视频流 &#x2F; 数据流发送</li>
</ul>
<hr>
<h5 id="3️⃣-客户端流式（Client-Streaming）"><a href="#3️⃣-客户端流式（Client-Streaming）" class="headerlink" title="3️⃣ 客户端流式（Client Streaming）"></a>3️⃣ 客户端流式（Client Streaming）</h5><p>客户端<strong>连续发多条消息</strong>，服务器收到后，最后返回一个结果。</p>
<figure class="highlight proto"><table><tr><td class="code"><pre><span class="line"><span class="keyword">service </span><span class="title class_">Greeter</span> &#123;</span><br><span class="line">  <span class="function"><span class="keyword">rpc</span> CollectHello (stream HelloRequest) <span class="keyword">returns</span> (HelloReply)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Python 客户端示范：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">generate_requests</span>():</span><br><span class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> [<span class="string">&#x27;Alice&#x27;</span>, <span class="string">&#x27;Bob&#x27;</span>, <span class="string">&#x27;Carol&#x27;</span>]:</span><br><span class="line">        <span class="keyword">yield</span> greeter_pb2.HelloRequest(name=name)</span><br><span class="line"></span><br><span class="line">response = stub.CollectHello(generate_requests())</span><br><span class="line"><span class="built_in">print</span>(response.message)</span><br></pre></td></tr></table></figure>

<p>服务器端示范：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">CollectHello</span>(<span class="params">self, request_iterator, context</span>):</span><br><span class="line">    names = [request.name <span class="keyword">for</span> request <span class="keyword">in</span> request_iterator]</span><br><span class="line">    <span class="keyword">return</span> greeter_pb2.HelloReply(message=<span class="string">f&quot;Hello <span class="subst">&#123;<span class="string">&#x27;, &#x27;</span>.join(names)&#125;</span>!&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>✅ 用法场景：</p>
<ul>
<li>批量上传文件</li>
<li>多个小请求聚合</li>
<li>IoT 设备上报数据</li>
</ul>
<hr>
<h5 id="4️⃣-双向流式（Bidirectional-Streaming）"><a href="#4️⃣-双向流式（Bidirectional-Streaming）" class="headerlink" title="4️⃣ 双向流式（Bidirectional Streaming）"></a>4️⃣ 双向流式（Bidirectional Streaming）</h5><p>客户端和服务端都能<strong>同时发消息，互相流动</strong>，像聊天室一样！</p>
<figure class="highlight proto"><table><tr><td class="code"><pre><span class="line"><span class="keyword">service </span><span class="title class_">Greeter</span> &#123;</span><br><span class="line">  <span class="function"><span class="keyword">rpc</span> ChatHello (stream HelloRequest) <span class="keyword">returns</span> (stream HelloReply)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>服务端示范：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">ChatHello</span>(<span class="params">self, request_iterator, context</span>):</span><br><span class="line">    <span class="keyword">for</span> request <span class="keyword">in</span> request_iterator:</span><br><span class="line">        <span class="keyword">yield</span> greeter_pb2.HelloReply(message=<span class="string">f&quot;Hello <span class="subst">&#123;request.name&#125;</span>!&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>客户端示范：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">generate_requests</span>():</span><br><span class="line">    <span class="keyword">for</span> name <span class="keyword">in</span> [<span class="string">&#x27;Tom&#x27;</span>, <span class="string">&#x27;Jerry&#x27;</span>, <span class="string">&#x27;Spike&#x27;</span>]:</span><br><span class="line">        <span class="keyword">yield</span> greeter_pb2.HelloRequest(name=name)</span><br><span class="line"></span><br><span class="line">responses = stub.ChatHello(generate_requests())</span><br><span class="line"><span class="keyword">for</span> response <span class="keyword">in</span> responses:</span><br><span class="line">    <span class="built_in">print</span>(response.message)</span><br></pre></td></tr></table></figure>

<p>✅ 用法场景：</p>
<ul>
<li>聊天软件</li>
<li>实时音频 &#x2F; 视频</li>
<li>多设备双向数据交换</li>
</ul>
<hr>
<p>✅ 到这里你应该能看出来了：</p>
<table>
<thead>
<tr>
<th>模式</th>
<th>类比</th>
<th>特点</th>
</tr>
</thead>
<tbody><tr>
<td>单请求单响应</td>
<td>普通 HTTP 请求</td>
<td>简单稳定</td>
</tr>
<tr>
<td>服务端流式</td>
<td>点播视频</td>
<td>一次请求，多次返回</td>
</tr>
<tr>
<td>客户端流式</td>
<td>批量文件上传</td>
<td>多次请求，一次返回</td>
</tr>
<tr>
<td>双向流式</td>
<td>微信聊天 &#x2F; 音视频通话</td>
<td>一边发一边收，像对讲机</td>
</tr>
</tbody></table>
<hr>
<h4 id="第四步：进阶特性-了解即可，后续深入"><a href="#第四步：进阶特性-了解即可，后续深入" class="headerlink" title="第四步：进阶特性 (了解即可，后续深入)"></a><strong>第四步：进阶特性 (了解即可，后续深入)</strong></h4><ul>
<li><strong>错误处理:</strong> gRPC 通过状态码和可选的错误详情来传递错误信息。你需要在服务器端设置状态码和详情，在客户端捕获 grpc.RpcError。</li>
<li><strong>元数据 (Metadata):</strong> 类似于 HTTP Headers，用于传递请求&#x2F;响应的附加信息，如认证令牌、追踪 ID 等。</li>
<li><strong>截止时间&#x2F;超时 (Deadlines&#x2F;Timeouts):</strong> 客户端可以指定一个 RPC 调用的最长等待时间。服务器可以检查调用是否已超时。</li>
<li><strong>认证 (Authentication):</strong> gRPC 支持多种认证机制，如 SSL&#x2F;TLS (加密传输)、基于 Token 的认证 (如 JWT) 等。</li>
<li><strong>拦截器 (Interceptors):</strong> 类似于 Web 框架中的中间件 (Middleware)，可以在 RPC 调用之前或之后执行通用逻辑，如日志记录、认证检查、度量收集等。</li>
<li><strong>健康检查 (Health Checking):</strong> gRPC 标准化了服务健康检查的协议。</li>
<li><strong>负载均衡 (Load Balancing):</strong> gRPC 客户端可以配置负载均衡策略，将请求分发到多个后端服务器实例。</li>
</ul>
<hr>
<h4 id="第五步：与-FastAPI-对比与选择"><a href="#第五步：与-FastAPI-对比与选择" class="headerlink" title="第五步：与 FastAPI 对比与选择"></a><strong>第五步：与 FastAPI 对比与选择</strong></h4><table>
<thead>
<tr>
<th>特性</th>
<th>gRPC (通常 Protobuf + HTTP&#x2F;2)</th>
<th>FastAPI (通常 JSON + HTTP&#x2F;1.1&#x2F;2)</th>
</tr>
</thead>
<tbody><tr>
<td><strong>范式</strong></td>
<td>RPC</td>
<td>RESTful (或 GraphQL 等)</td>
</tr>
<tr>
<td><strong>协议</strong></td>
<td>HTTP&#x2F;2 (强制)</td>
<td>HTTP&#x2F;1.1 或 HTTP&#x2F;2</td>
</tr>
<tr>
<td><strong>数据格式</strong></td>
<td>Protobuf (二进制, 高效)</td>
<td>JSON (文本, 可读性好)</td>
</tr>
<tr>
<td><strong>契约定义</strong></td>
<td>.proto 文件 (语言无关)</td>
<td>Python 类型注解&#x2F;Pydantic</td>
</tr>
<tr>
<td><strong>代码生成</strong></td>
<td>核心，必需</td>
<td>通常不需要 (除了 OpenAPI)</td>
</tr>
<tr>
<td><strong>性能</strong></td>
<td>通常更高 (尤其网络&#x2F;序列化)</td>
<td>良好，但可能低于 gRPC</td>
</tr>
<tr>
<td><strong>流处理</strong></td>
<td>原生支持四种类型</td>
<td>服务器流 (StreamingResponse), 其他需 WebSocket 等</td>
</tr>
<tr>
<td><strong>浏览器支持</strong></td>
<td>需要代理 (gRPC-Web)</td>
<td>原生支持</td>
</tr>
<tr>
<td><strong>开发体验</strong></td>
<td>契约先行，较严格</td>
<td>代码即文档，更灵活</td>
</tr>
<tr>
<td><strong>生态&#x2F;工具</strong></td>
<td>跨语言，工具链成熟</td>
<td>Python 生态丰富，集成方便</td>
</tr>
</tbody></table>
<p><strong>何时选择 gRPC?</strong></p>
<ul>
<li>微服务之间的内部通信，追求高性能、低延迟。</li>
<li>需要严格的 API 契约和强类型检查。</li>
<li>需要高效的流式数据处理（双向流等）。</li>
<li>跨语言通信是主要需求。</li>
</ul>
<p><strong>何时选择 FastAPI?</strong></p>
<ul>
<li>需要构建面向公众的 Web API，尤其需要浏览器直接访问。</li>
<li>开发速度和灵活性是首要考虑。</li>
<li>团队更熟悉 REST 和 JSON。</li>
<li>希望利用丰富的 Python Web 生态（数据库 ORM、模板引擎等）。</li>
<li>需要自动生成交互式 API 文档 (Swagger UI&#x2F;ReDoc)。</li>
</ul>
<hr>
<p><strong>学习建议:</strong></p>
<ol>
<li><strong>动手实践:</strong> 跟着官方教程或上面的例子，亲自编写、生成、运行代码。</li>
<li><strong>理解 .proto:</strong> 这是 gRPC 的基础，花时间学习它的语法和最佳实践。</li>
<li><strong>从小处着手:</strong> 先精通 Unary RPC，再逐步学习流式 RPC。</li>
<li><strong>阅读官方文档:</strong> gRPC.io 网站是最好的资源，特别是 Python 部分。</li>
<li><strong>看示例代码:</strong> gRPC 的 GitHub 仓库 (grpc&#x2F;grpc) 包含各种语言的示例。</li>
</ol>
<hr>
<h4 id="🌟🌟上点强度"><a href="#🌟🌟上点强度" class="headerlink" title="🌟🌟上点强度"></a>🌟🌟上点强度</h4><p>相信上面的东西对你来说难度不大，咱们一起来上点强度：</p>
<p><strong>streaming.proto：</strong></p>
<figure class="highlight protobuf"><table><tr><td class="code"><pre><span class="line">syntax = <span class="string">&quot;proto3&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 可选的包名</span></span><br><span class="line"><span class="keyword">package</span> streaming_example;</span><br><span class="line"></span><br><span class="line"><span class="comment">// --- 1. 服务器流式 RPC ---</span></span><br><span class="line"><span class="comment">// 请求：客户端告诉服务器要数到几</span></span><br><span class="line"><span class="keyword">message </span><span class="title class_">CountRequest</span> &#123;</span><br><span class="line">  <span class="type">int32</span> limit = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 响应：服务器每次发送一个数字</span></span><br><span class="line"><span class="keyword">message </span><span class="title class_">CountResponse</span> &#123;</span><br><span class="line">  <span class="type">int32</span> count = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// --- 2. 客户端流式 RPC ---</span></span><br><span class="line"><span class="comment">// 请求：客户端每次发送一个要相加的数字</span></span><br><span class="line"><span class="keyword">message </span><span class="title class_">Number</span> &#123;</span><br><span class="line">  <span class="type">int32</span> value = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 响应：服务器在接收完所有数字后返回总和</span></span><br><span class="line"><span class="keyword">message </span><span class="title class_">SumResponse</span> &#123;</span><br><span class="line">  <span class="type">int32</span> total = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// --- 3. 双向流式 RPC ---</span></span><br><span class="line"><span class="comment">// 消息：客户端和服务器互相发送的消息</span></span><br><span class="line"><span class="keyword">message </span><span class="title class_">ChatMessage</span> &#123;</span><br><span class="line">  <span class="type">string</span> message = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 定义服务</span></span><br><span class="line"><span class="keyword">service </span><span class="title class_">Streamer</span> &#123;</span><br><span class="line">  <span class="comment">// 1. 服务器流式 RPC</span></span><br><span class="line">  <span class="function"><span class="keyword">rpc</span> GetServerStream (CountRequest) <span class="keyword">returns</span> (stream CountResponse)</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 2. 客户端流式 RPC</span></span><br><span class="line">  <span class="function"><span class="keyword">rpc</span> SendClientStream (stream Number) <span class="keyword">returns</span> (SumResponse)</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 3. 双向流式 RPC</span></span><br><span class="line">  <span class="function"><span class="keyword">rpc</span> BidirectionalStream (stream ChatMessage) <span class="keyword">returns</span> (stream ChatMessage)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>生成streaming_pb2.py 和 streaming_pb2_grpc.py 两个文件</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. streaming.proto</span><br></pre></td></tr></table></figure>

<p><strong>grpc_server.py</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> grpc</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> concurrent <span class="keyword">import</span> futures</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入生成的代码</span></span><br><span class="line"><span class="keyword">import</span> streaming_pb2</span><br><span class="line"><span class="keyword">import</span> streaming_pb2_grpc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实现 .proto 文件中定义的服务接口</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">StreamerServicer</span>(streaming_pb2_grpc.StreamerServicer):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1. 服务器流式 RPC 实现</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">GetServerStream</span>(<span class="params">self, request, context</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;服务器流: 收到请求，计数到 <span class="subst">&#123;request.limit&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, request.limit + <span class="number">1</span>):</span><br><span class="line">            <span class="comment"># 使用 yield 返回流中的每一个消息</span></span><br><span class="line">            response = streaming_pb2.CountResponse(count=i)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;服务器流: 发送 <span class="subst">&#123;i&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">yield</span> response</span><br><span class="line">            time.sleep(<span class="number">0.5</span>) <span class="comment"># 模拟处理延迟</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;服务器流: 发送完毕&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. 客户端流式 RPC 实现</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">SendClientStream</span>(<span class="params">self, request_iterator, context</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;客户端流: 开始接收客户端数据流...&quot;</span>)</span><br><span class="line">        total_sum = <span class="number">0</span></span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        <span class="comment"># request_iterator 是一个迭代器，用于接收客户端发送的消息流</span></span><br><span class="line">        <span class="keyword">for</span> number_message <span class="keyword">in</span> request_iterator:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;客户端流: 收到数字 <span class="subst">&#123;number_message.value&#125;</span>&quot;</span>)</span><br><span class="line">            total_sum += number_message.value</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;客户端流: 接收完毕，共 <span class="subst">&#123;count&#125;</span> 个数字&quot;</span>)</span><br><span class="line">        <span class="comment"># 所有消息接收完毕后，返回单个响应</span></span><br><span class="line">        response = streaming_pb2.SumResponse(total=total_sum)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;客户端流: 返回总和 <span class="subst">&#123;total_sum&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. 双向流式 RPC 实现</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">BidirectionalStream</span>(<span class="params">self, request_iterator, context</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;双向流: 服务端启动，等待客户端消息...&quot;</span>)</span><br><span class="line">        <span class="comment"># request_iterator 用于接收客户端消息流</span></span><br><span class="line">        <span class="keyword">for</span> chat_message <span class="keyword">in</span> request_iterator:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;双向流: 收到客户端消息 &#x27;<span class="subst">&#123;chat_message.message&#125;</span>&#x27;&quot;</span>)</span><br><span class="line">            <span class="comment"># 处理收到的消息，并准备响应</span></span><br><span class="line">            response_message = <span class="string">f&quot;服务器收到: &#x27;<span class="subst">&#123;chat_message.message&#125;</span>&#x27;&quot;</span></span><br><span class="line">            response = streaming_pb2.ChatMessage(message=response_message)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;双向流: 发送响应 &#x27;<span class="subst">&#123;response_message&#125;</span>&#x27;&quot;</span>)</span><br><span class="line">            <span class="comment"># 使用 yield 发送响应消息回客户端</span></span><br><span class="line">            <span class="keyword">yield</span> response</span><br><span class="line">            time.sleep(<span class="number">0.3</span>) <span class="comment"># 模拟处理</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;双向流: 客户端消息流结束&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">serve</span>():</span><br><span class="line">    server = grpc.server(futures.ThreadPoolExecutor(max_workers=<span class="number">10</span>))</span><br><span class="line">    <span class="comment"># 将实现的服务注册到服务器</span></span><br><span class="line">    streaming_pb2_grpc.add_StreamerServicer_to_server(StreamerServicer(), server)</span><br><span class="line">    server.add_insecure_port(<span class="string">&#x27;[::]:50051&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;服务器启动，监听端口 50051...&quot;</span>)</span><br><span class="line">    server.start()</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        server.wait_for_termination()</span><br><span class="line">    <span class="keyword">except</span> KeyboardInterrupt:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;服务器停止...&quot;</span>)</span><br><span class="line">        server.stop(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    serve()</span><br></pre></td></tr></table></figure>

<p><strong>grpc_client.py</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> grpc</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入生成的代码</span></span><br><span class="line"><span class="keyword">import</span> streaming_pb2</span><br><span class="line"><span class="keyword">import</span> streaming_pb2_grpc</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- 客户端流式 RPC 的辅助函数 ---</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_numbers_to_sum</span>(<span class="params">count=<span class="number">5</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;一个生成器函数，模拟客户端发送数字流&quot;&quot;&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;客户端流: 开始发送数字...&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, count + <span class="number">1</span>):</span><br><span class="line">        number = i * <span class="number">10</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;客户端流: 发送数字 <span class="subst">&#123;number&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">yield</span> streaming_pb2.Number(value=number)</span><br><span class="line">        time.sleep(<span class="number">0.4</span>) <span class="comment"># 模拟间隔</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;客户端流: 发送完毕&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- 双向流式 RPC 的辅助函数 ---</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_chat_messages</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;一个生成器函数，模拟客户端发送聊天消息&quot;&quot;&quot;</span></span><br><span class="line">    messages = [<span class="string">&quot;你好！&quot;</span>, <span class="string">&quot;最近怎么样？&quot;</span>, <span class="string">&quot;gRPC 流式很酷！&quot;</span>, <span class="string">&quot;再见！&quot;</span>]</span><br><span class="line">    <span class="keyword">for</span> msg <span class="keyword">in</span> messages:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;双向流: 客户端发送 -&gt; &#x27;<span class="subst">&#123;msg&#125;</span>&#x27;&quot;</span>)</span><br><span class="line">        <span class="keyword">yield</span> streaming_pb2.ChatMessage(message=msg)</span><br><span class="line">        time.sleep(<span class="number">1</span>) <span class="comment"># 模拟思考时间</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>():</span><br><span class="line">    <span class="comment"># 连接到服务器</span></span><br><span class="line">    <span class="keyword">with</span> grpc.insecure_channel(<span class="string">&#x27;localhost:50051&#x27;</span>) <span class="keyword">as</span> channel:</span><br><span class="line">        stub = streaming_pb2_grpc.StreamerStub(channel)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># === 1. 测试服务器流式 RPC ===</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n--- 1. 测试服务器流式 RPC ---&quot;</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            limit_request = streaming_pb2.CountRequest(limit=<span class="number">5</span>)</span><br><span class="line">            <span class="comment"># 调用返回的是一个迭代器</span></span><br><span class="line">            response_stream = stub.GetServerStream(limit_request)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;服务器流: 客户端开始接收...&quot;</span>)</span><br><span class="line">            <span class="keyword">for</span> response <span class="keyword">in</span> response_stream:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;服务器流: 客户端收到数字 <span class="subst">&#123;response.count&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;服务器流: 客户端接收完毕&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> grpc.RpcError <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;服务器流 RPC 调用失败: <span class="subst">&#123;e.code()&#125;</span> - <span class="subst">&#123;e.details()&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        time.sleep(<span class="number">1</span>) <span class="comment"># 等待一下，区分不同测试</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># === 2. 测试客户端流式 RPC ===</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n--- 2. 测试客户端流式 RPC ---&quot;</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># 调用时传入一个生成器或迭代器</span></span><br><span class="line">            <span class="comment"># 注意：这里传递的是 generate_numbers_to_sum() 的调用结果（一个生成器对象）</span></span><br><span class="line">            response_future = stub.SendClientStream(generate_numbers_to_sum(count=<span class="number">4</span>))</span><br><span class="line">            <span class="comment"># 等待服务器处理完所有流数据并返回最终结果</span></span><br><span class="line">            final_response = response_future <span class="comment"># 对于Unary-Stream, 结果直接返回</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;客户端流: 收到服务器最终响应，总和 = <span class="subst">&#123;final_response.total&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> grpc.RpcError <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;客户端流 RPC 调用失败: <span class="subst">&#123;e.code()&#125;</span> - <span class="subst">&#123;e.details()&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        time.sleep(<span class="number">1</span>) <span class="comment"># 等待一下</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># === 3. 测试双向流式 RPC ===</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n--- 3. 测试双向流式 RPC ---&quot;</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># 调用时传入发送消息的生成器，返回接收消息的迭代器</span></span><br><span class="line">            <span class="comment"># 注意：传递 generate_chat_messages() 的调用结果</span></span><br><span class="line">            response_iterator = stub.BidirectionalStream(generate_chat_messages())</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;双向流: 客户端启动，准备接收服务器消息...&quot;</span>)</span><br><span class="line">            <span class="keyword">for</span> server_response <span class="keyword">in</span> response_iterator:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;双向流: 客户端收到 &lt;- &#x27;<span class="subst">&#123;server_response.message&#125;</span>&#x27;&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;双向流: 服务器消息流结束，客户端接收完毕&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> grpc.RpcError <span class="keyword">as</span> e:</span><br><span class="line">             <span class="built_in">print</span>(<span class="string">f&quot;双向流 RPC 调用失败: <span class="subst">&#123;e.code()&#125;</span> - <span class="subst">&#123;e.details()&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    run()</span><br></pre></td></tr></table></figure>

<p>我们来按照代码的实际执行顺序，一步步讲解服务器 (<code>grpc_server.py</code>) 和客户端 (<code>grpc_client.py</code>) 的交互流程。</p>
<p><strong>阶段一：服务器启动 (<code>python server.py</code>)</strong></p>
<ol>
<li><strong>导入模块:</strong> Python 解释器执行 <code>server.py</code>，首先导入所需的库 (<code>grpc</code>, <code>time</code>, <code>concurrent.futures</code>) 以及我们生成的代码 (<code>streaming_pb2</code>, <code>streaming_pb2_grpc</code>)。</li>
<li><strong>定义 <code>StreamerServicer</code> 类:</strong><ul>
<li>解释器读取并定义 <code>StreamerServicer</code> 这个类。</li>
<li>这个类继承自 <code>streaming_pb2_grpc.StreamerServicer</code>（这是代码生成器创建的基类）。</li>
<li>它包含了 <code>GetServerStream</code>, <code>SendClientStream</code>, <code>BidirectionalStream</code> 三个方法的<strong>定义</strong>。此时这些方法体内的代码<strong>还未执行</strong>，只是准备好了，知道有这些方法存在。</li>
</ul>
</li>
<li><strong>定义 serve() 函数:</strong> 解释器读取并定义 serve() 函数。</li>
<li><strong>执行 serve() 函数:</strong><ul>
<li><code>if __name__ == &#39;__main__&#39;</code>: 条件为真，因此调用 serve() 函数。</li>
<li><code>server = grpc.server(...)</code>: 创建一个 <code>gRPC</code> 服务器实例。配置了一个线程池 (<code>futures.ThreadPoolExecutor</code>) 来处理未来的客户端请求。这个服务器对象现在存在内存中，但还没开始工作。</li>
<li><code>streaming_pb2_grpc.add_StreamerServicer_to_server(...)</code>: <strong>关键步骤</strong>。将我们上面定义的 <code>StreamerServicer</code> 类的一个<strong>实例</strong>注册到 server 对象中。这告诉服务器：“如果将来收到针对 Streamer 服务的请求，就调用这个实例里的对应方法来处理”。</li>
<li><code>server.add_insecure_port(&#39;[::]:50051&#39;)</code>: 配置服务器监听在本地所有 <code>IP</code> 地址的 50051 端口，使用不安全的连接（无加密）。</li>
<li>print(“服务器启动，监听端口 50051…”): 在服务器的控制台打印启动信息。</li>
<li><code>server.start()</code>: <strong>核心启动命令</strong>。这个方法启动服务器的后台线程（由线程池管理），让服务器<strong>开始真正地监听</strong>指定的端口，等待客户端连接和发送请求。<code>server.start()</code> 本身是<strong>非阻塞</strong>的，它启动后台任务后会立即返回。</li>
<li><code>server.wait_for_termination()</code>: <strong>关键步骤</strong>。这个方法会<strong>阻塞</strong> <code>server.py</code> 脚本的<strong>主线程</strong>。脚本会停留在这里，不会退出。这使得服务器进程能够持续运行，让后台的 <code>gRPC</code> 线程可以持续处理客户端请求。主线程会一直等到服务器被明确停止（例如通过 <code>server.stop()</code> 或接收到中断信号）。</li>
</ul>
</li>
<li><strong>服务器状态:</strong> 服务器现在处于运行状态，监听 50051 端口，准备接收来自客户端的请求。主线程阻塞在 wait_for_termination()，后台线程池待命。</li>
</ol>
<p><strong>阶段二：客户端启动与执行 (<code>python grpc_client.py</code>)</strong></p>
<ol>
<li><strong>导入模块:</strong> Python 解释器执行 <code>grpc_client.py</code>，导入所需库 (<code>grpc</code>, <code>time</code>) 和生成的代码 (<code>streaming_pb2</code>, <code>streaming_pb2_grpc</code>)。</li>
<li><strong>定义辅助生成器函数:</strong><ul>
<li>解释器读取并定义 <code>generate_numbers_to_sum()</code> 和 <code>generate_chat_messages()</code> 这两个<strong>生成器函数</strong>。这些函数定义了如何按需产生一系列数据，但此时它们内部的代码也<strong>还未执行</strong>。</li>
</ul>
</li>
<li><strong>定义 run() 函数:</strong> 解释器读取并定义 <code>run()</code> 函数。</li>
<li><strong>执行 run() 函数:</strong><ul>
<li><code>if __name__ == &#39;__main__&#39;</code>: 条件为真，调用 <code>run()</code> 函数。</li>
<li><code>with grpc.insecure_channel(&#39;localhost:50051&#39;) as channel:</code>:<ul>
<li><code>grpc.insecure_channel(...)</code>: 创建一个到服务器 <code>localhost:50051</code> 的通信<strong>通道 (Channel)</strong>。此时可能会尝试建立 TCP 连接。</li>
<li><code>with ... as channel:</code>: 使用上下文管理器确保无论后续代码是否成功，通道最终都会被正确关闭 (<code>channel.close()</code>)。</li>
</ul>
</li>
<li><code>stub = streaming_pb2_grpc.StreamerStub(channel)</code>: 基于创建的通道，创建一个<strong>客户端存根 (Stub)</strong>。<code>stub</code> 对象就像是远程 <code>Streamer</code> 服务在本地的一个代理。调用 <code>stub</code> 上的方法，实际上会通过 <code>channel</code> 向服务器发送 <code>RPC</code> 请求。</li>
<li><strong>— 执行测试 1：服务器流式 RPC —</strong><ul>
<li><code>print(&quot;\n--- 1. ...&quot;)</code></li>
<li><code>limit_request = streaming_pb2.CountRequest(limit=5)</code>: 创建请求消息对象，设置 limit 为 5。</li>
<li><code>response_stream = stub.GetServerStream(limit_request)</code>: <strong>客户端发起 RPC 调用！</strong><ul>
<li><strong>客户端:</strong> 将 <code>limit_request</code> 序列化并通过 <code>channel</code> 发送给服务器。</li>
<li><strong>服务器:</strong> 某个后台线程接收到请求，识别出是针对 <code>Streamer</code> 服务的 <code>GetServerStream</code> 方法。</li>
<li><strong>服务器:</strong> 调用之前注册的 <code>StreamerServicer</code> 实例的 <code>GetServerStream</code> 方法，并将反序列化后的 <code>CountRequest</code> 对象作为 request 参数传入。</li>
<li><strong>服务器:</strong> <code>GetServerStream</code> 方法开始执行：<ul>
<li><code>print(f&quot;服务器流: 收到请求...&quot;)</code></li>
<li>进入 for 循环。</li>
<li>第一次循环：<code>response = ..., print(f&quot;服务器流: 发送 1&quot;), yield response</code> (<strong>服务器发送第一个 <code>CountResponse</code> 消息给客户端</strong>), <code>time.sleep(0.5)</code>。</li>
</ul>
</li>
<li><strong>客户端:</strong> <code>stub.GetServerStream</code> 调用<strong>几乎立即返回</strong>一个<strong>迭代器</strong> (<code>response_stream</code>)。它不会等待所有数据都回来。</li>
<li><code>print(&quot;服务器流: 客户端开始接收...&quot;)</code></li>
<li><code>for response in response_stream:</code>: <strong>客户端开始迭代</strong>。它会阻塞，等待服务器发送第一条消息。</li>
<li><strong>客户端:</strong> 收到服务器发来的第一个 <code>CountResponse </code>(包含 count&#x3D;1)。</li>
<li>print(f”服务器流: 客户端收到数字 1”)。循环继续，等待下一条。</li>
<li><strong>服务器:</strong><code> time.sleep(0.5)</code> 结束，进入第二次循环，yield 第二个 <code>CountResponse</code> (包含 count&#x3D;2)。</li>
<li><strong>客户端:</strong> 收到第二个消息，打印 “客户端收到数字 2”。</li>
<li>… 这个过程重复进行，服务器 yield 一次，客户端的 for 循环就迭代一次 …</li>
<li><strong>服务器:</strong> for 循环结束 (i 达到 5)。</li>
<li>print(“服务器流: 发送完毕”)。服务器端的 <code>GetServerStream</code> 方法执行完毕。服务器自动关闭这个响应流。</li>
<li><strong>客户端:</strong> 收到最后一个 <code>CountResponse</code> (包含 count&#x3D;5)，打印 “客户端收到数字 5”。由于服务器关闭了流，客户端的 for 循环结束。</li>
<li>print(“服务器流: 客户端接收完毕”)。</li>
</ul>
</li>
<li>(如果发生错误，会进入 except 块)</li>
<li><code>time.sleep(1)</code>: 客户端主线程暂停 1 秒。</li>
</ul>
</li>
<li><strong>— 执行测试 2：客户端流式 RPC —</strong><ul>
<li><code>print(&quot;\n--- 2. ...&quot;)</code></li>
<li><code>response_future = stub.SendClientStream(generate_numbers_to_sum(count=4))</code>: <strong>客户端发起 RPC 调用！</strong><ul>
<li><strong>客户端:</strong> <code>generate_numbers_to_sum(count=4)</code> 被调用，返回一个<strong>生成器对象</strong>。这个对象被传递给 <code>stub.SendClientStream</code>。</li>
<li><strong>客户端(后台):</strong> gRPC 库开始从这个生成器对象中获取数据 (next())。<ul>
<li>generate_numbers_to_sum 开始执行，print(“客户端流: 开始发送数字…”)。</li>
<li>第一次循环：print(f”客户端流: 发送数字 10”), <code>yield streaming_pb2.Number(value=10)</code>。</li>
</ul>
</li>
<li><strong>客户端(后台):</strong> <strong>将第一个 Number 消息发送给服务器</strong>。</li>
<li><strong>服务器:</strong> 某个后台线程接收到请求，识别是 <code>SendClientStream</code>。</li>
<li><strong>服务器:</strong> 调用 <code>StreamerServicer </code>实例的<code> SendClientStream</code> 方法。传入的 request_iterator 参数是一个特殊的迭代器，连接到客户端发来的数据流。</li>
<li><strong>服务器:</strong> <code>SendClientStream</code> 开始执行：<ul>
<li>print(“客户端流: 开始接收…”)</li>
<li><code>for number_message in request_iterator:</code>: 服务器<strong>阻塞</strong>在这里，等待客户端发送第一条消息。</li>
<li><strong>服务器:</strong> 收到客户端发来的第一个 Number (value&#x3D;10)。</li>
<li>print(f”客户端流: 收到数字 10”)。累加 total_sum。服务器的 for 循环继续等待下一条消息。</li>
</ul>
</li>
<li><strong>客户端(后台):</strong> gRPC 库再次从生成器获取数据 (next())。<ul>
<li>generate_numbers_to_sum 继续执行第二次循环，yield 第二个 Number (value&#x3D;20)。</li>
</ul>
</li>
<li><strong>客户端(后台):</strong> <strong>将第二个 Number 消息发送给服务器</strong>。</li>
<li><strong>服务器:</strong> 收到第二个 Number，打印，累加。继续等待。</li>
<li>… 这个过程重复，客户端生成一个，发送一个；服务器接收一个，处理一个 …</li>
<li><strong>客户端(后台):</strong> generate_numbers_to_sum 的 for 循环结束。</li>
<li>print(“客户端流: 发送完毕”)。生成器函数执行完毕。</li>
<li><strong>客户端(后台):</strong> gRPC 库检测到生成器结束，向服务器发送一个<strong>流结束</strong>的信号。</li>
<li><strong>服务器:</strong> request_iterator 检测到流结束，服务器的 for 循环终止。</li>
<li>print(f”客户端流: 接收完毕…”)</li>
<li>response &#x3D; streaming_pb2.SumResponse(total&#x3D;total_sum): 创建最终的响应消息。</li>
<li>print(f”客户端流: 返回总和…”)</li>
<li>return response: <strong>服务器将这个单个的 SumResponse 消息发送回客户端</strong>。</li>
<li><strong>客户端:</strong> stub.SendClientStream(…) 调用（之前可能在等待）接收到服务器返回的 SumResponse，并将其作为结果返回给 response_future 变量。</li>
</ul>
</li>
<li>final_response &#x3D; response_future: 将结果赋值。</li>
<li>print(f”客户端流: 收到服务器最终响应…”)。</li>
<li>(如果发生错误，会进入 except 块)</li>
<li><code>time.sleep(1)</code>: 客户端主线程暂停 1 秒。</li>
</ul>
</li>
<li><strong>— 执行测试 3：双向流式 RPC —</strong><ul>
<li>print(“\n— 3. …”)</li>
<li><code>response_iterator = stub.BidirectionalStream(generate_chat_messages())</code>: <strong>客户端发起 RPC 调用！</strong><ul>
<li><strong>客户端:</strong> <code>generate_chat_messages()</code> 被调用，返回一个<strong>生成器对象</strong>，传递给 <code>stub.BidirectionalStream</code>。</li>
<li><strong>客户端:</strong> <code>stub.BidirectionalStream</code> <strong>几乎立即返回</strong>一个用于接收服务器响应的<strong>迭代器</strong> (response_iterator)。</li>
<li><strong>客户端(后台):</strong> gRPC 库开始从 generate_chat_messages 生成器获取数据。<ul>
<li><code>generate_chat_messages</code> 开始执行，第一次循环，<code>print(&quot;双向流: 客户端发送 -&gt; &#39;你好！&#39;&quot;)</code>, <code>yield streaming_pb2.ChatMessage(message=&quot;你好！&quot;)</code>。</li>
</ul>
</li>
<li><strong>客户端(后台):</strong> <strong>将第一个 <code>ChatMessage (&quot;你好！&quot;)</code> 发送给服务器</strong>。</li>
<li><strong>服务器:</strong> 某个后台线程接收到请求，识别是 <code>BidirectionalStream</code>。</li>
<li><strong>服务器:</strong> 调用 <code>StreamerServicer</code> 实例的 <code>BidirectionalStream</code> 方法，传入 request_iterator。</li>
<li><strong>服务器:</strong> <code>BidirectionalStream</code> 开始执行：<ul>
<li>print(“双向流: 服务端启动…”)</li>
<li>for chat_message in request_iterator:: 服务器<strong>阻塞</strong>等待客户端的第一条消息。</li>
<li><strong>服务器:</strong> 收到 “你好！”。</li>
<li>print(f”双向流: 收到客户端消息 ‘你好！’”)。</li>
<li>response_message &#x3D; …: 准备响应 “服务器收到: ‘你好！’”。</li>
<li>response &#x3D; …</li>
<li>print(f”双向流: 发送响应 ‘{response_message}’”)</li>
<li>yield response: <strong>服务器发送第一个响应消息给客户端</strong>。</li>
<li><code>time.sleep(0.3)</code>。服务器的 for 循环继续等待客户端的下一条消息。</li>
</ul>
</li>
<li><strong>客户端:</strong> print(“双向流: 客户端启动，准备接收…”)</li>
<li>for server_response in response_iterator:: <strong>客户端开始迭代</strong>，阻塞等待服务器的第一条响应。</li>
<li><strong>客户端:</strong> 收到服务器的 “服务器收到: ‘你好！’”。</li>
<li><code>print(f&quot;双向流: 客户端收到 &lt;- &#39;&#123;server_response.message&#125;&#39;&quot;)</code>。客户端的 for 循环继续等待服务器的下一条响应。</li>
<li><strong>并发进行:</strong><ul>
<li><strong>客户端(后台):</strong> 从生成器获取下一条消息 “最近怎么样？”，发送给服务器。</li>
<li><strong>服务器:</strong> 收到 <code>&quot;最近怎么样？&quot;</code>，处理，yield 回复 <code>&quot;服务器收到: &#39;最近怎么样？&#39;&quot;</code>。</li>
<li><strong>客户端:</strong> 收到服务器的回复，打印。</li>
<li>… 这个发送-接收-处理-回复的过程由<code> gRPC</code> 库在后台调度并发进行 …</li>
</ul>
</li>
<li><strong>客户端(后台):</strong> generate_chat_messages 生成器执行完毕。客户端向服务器发送<strong>流结束</strong>信号。</li>
<li><strong>服务器:</strong> request_iterator 检测到流结束，服务器的 for 循环终止。</li>
<li>print(“双向流: 客户端消息流结束”)。服务器端的 <code>BidirectionalStream</code> 方法执行完毕。服务器自动关闭它的响应流。</li>
<li><strong>客户端:</strong> 由于服务器关闭了响应流，客户端的 <code>for server_response in response_iterator: </code>循环结束。</li>
<li>print(“双向流: 服务器消息流结束…”)。</li>
</ul>
</li>
<li>(如果发生错误，会进入 except 块)</li>
</ul>
</li>
<li><strong>结束 with 块:</strong> with 语句结束，<code>channel.close() </code>被自动调用，关闭与服务器的连接。</li>
<li>run() 函数执行完毕。</li>
</ul>
</li>
<li><strong>客户端退出:</strong> <code>client.py</code> 脚本执行完毕，退出。</li>
</ol>
<p><strong>阶段三：服务器停止 (可选)</strong></p>
<ul>
<li>如果此时你在运行 <code>server_grpc.py</code> 的终端按下 <code>Ctrl+C</code>：<ul>
<li>Python 解释器会抛出 <code>KeyboardInterrupt</code> 异常。</li>
<li><code>server.py </code>中 serve() 函数的 <code>except KeyboardInterrupt:</code> 块被触发。</li>
<li>print(“服务器停止…”)</li>
<li><code>server.stop(0)</code>: <strong>明确地命令服务器停止</strong>。参数 0 表示不等待当前正在处理的请求完成，立即开始关闭。服务器会停止接受新连接，并关闭现有连接和后台线程。</li>
<li><code>server.wait_for_termination()</code> 由于服务器已被停止，阻塞解除。</li>
<li>serve() 函数执行完毕。</li>
<li><code>server.py</code> 脚本执行完毕，退出。</li>
</ul>
</li>
</ul>
<p>这个流程详细描述了从启动到完成各种流式交互，再到最终关闭的整个过程。核心在于理解客户端发起调用、服务器接收并执行对应方法、以及双方如何通过迭代器&#x2F;生成器和 yield 来处理流式数据的发送与接收。</p>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>fastapi</tag>
        <tag>grpc</tag>
      </tags>
  </entry>
  <entry>
    <title>git常用命令</title>
    <url>/2025/01/23/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文梳理一些常用的git命令，以<strong>使用场景</strong>为切入点进行git指令介绍。</p>
<span id="more"></span>

<h2 id="一、本地仓库-远程仓库"><a href="#一、本地仓库-远程仓库" class="headerlink" title="一、本地仓库-&gt;远程仓库"></a>一、本地仓库-&gt;远程仓库</h2><h3 id="1-初始化本地仓库"><a href="#1-初始化本地仓库" class="headerlink" title="1.初始化本地仓库"></a>1.初始化本地仓库</h3><ul>
<li><p>创建一个项目文件夹，比如我创建了一个<code>agent_langgraph</code>文件夹</p>
</li>
<li><p>进入这个文件夹，命令行运行：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">git init</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="function">hint: <span class="title">Using</span> &#x27;<span class="title">master</span>&#x27; <span class="title">as</span> <span class="title">the</span> <span class="title">name</span> <span class="title">for</span> <span class="title">the</span> <span class="title">initial</span> <span class="title">branch</span>. <span class="title">This</span> <span class="title">default</span> <span class="title">branch</span> <span class="title">name</span></span></span><br><span class="line"><span class="function"><span class="title">hint</span>: <span class="title">is</span> <span class="title">subject</span> <span class="title">to</span> <span class="title">change</span>. <span class="title">To</span> <span class="title">configure</span> <span class="title">the</span> <span class="title">initial</span> <span class="title">branch</span> <span class="title">name</span> <span class="title">to</span> <span class="title">use</span> <span class="title">in</span> <span class="title">all</span></span></span><br><span class="line"><span class="function"><span class="title">hint</span>: <span class="title">of</span> <span class="title">your</span> <span class="title">new</span> <span class="title">repositories</span>, <span class="title">which</span> <span class="title">will</span> <span class="title">suppress</span> <span class="title">this</span> <span class="title">warning</span>, <span class="title">call</span>:</span></span><br><span class="line"><span class="function"><span class="title">hint</span>:</span></span><br><span class="line"><span class="function"><span class="title">hint</span>:   <span class="title">git</span> <span class="title">config</span> --<span class="title">global</span> <span class="title">init.defaultBranch</span> &lt;<span class="title">name</span>&gt;</span></span><br><span class="line"><span class="function"><span class="title">hint</span>:</span></span><br><span class="line"><span class="function"><span class="title">hint</span>: <span class="title">Names</span> <span class="title">commonly</span> <span class="title">chosen</span> <span class="title">instead</span> <span class="title">of</span> &#x27;<span class="title">master</span>&#x27; <span class="title">are</span> &#x27;<span class="title">main</span>&#x27;, &#x27;<span class="title">trunk</span>&#x27; <span class="title">and</span></span></span><br><span class="line"><span class="function"><span class="title">hint</span>: &#x27;<span class="title">development</span>&#x27;. <span class="title">The</span> <span class="title">just</span>-<span class="title">created</span> <span class="title">branch</span> <span class="title">can</span> <span class="title">be</span> <span class="title">renamed</span> <span class="title">via</span> <span class="title">this</span> <span class="title">command</span>:</span></span><br><span class="line"><span class="function"><span class="title">hint</span>:</span></span><br><span class="line"><span class="function"><span class="title">hint</span>:   <span class="title">git</span> <span class="title">branch</span> -<span class="title">m</span> &lt;<span class="title">name</span>&gt;</span></span><br><span class="line"><span class="function"><span class="title">Initialized</span> <span class="title">empty</span> <span class="title">Git</span> <span class="title">repository</span> <span class="title">in</span> <span class="title">E</span>:/<span class="title">chr_git</span>/<span class="title">agent_langgraph</span>/.<span class="title">git</span>/</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="2-创建文件并提交到本地仓库"><a href="#2-创建文件并提交到本地仓库" class="headerlink" title="2.创建文件并提交到本地仓库"></a>2.创建文件并提交到本地仓库</h3><p>先创建几个项目文件：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> # 基于langgraph的agent应用 &gt; README.<span class="built_in">md</span></span><br><span class="line"><span class="built_in">echo</span> &quot;<span class="built_in">print</span>(&#x27;Hello, LangGraph!&#x27;)&quot; &gt; main.py</span><br></pre></td></tr></table></figure>

<p>查看当前状态：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">git status</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">On branch master</span><br><span class="line"></span><br><span class="line">No commits yet</span><br><span class="line"></span><br><span class="line">Untracked files:</span><br><span class="line">  (use <span class="string">&quot;git add &lt;file&gt;...&quot;</span> to include <span class="keyword">in</span> what will be committed)</span><br><span class="line">        README.md</span><br><span class="line">        main.py</span><br><span class="line"></span><br><span class="line">nothing added to commit but untracked files present (use <span class="string">&quot;git add&quot;</span> to track)</span><br></pre></td></tr></table></figure>

<p>将这些文件加入Git的<code>暂存区</code>：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git add .</span><br></pre></td></tr></table></figure>

<p>再次查看状态：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git status</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">On branch master</span><br><span class="line"></span><br><span class="line">No commits yet</span><br><span class="line"></span><br><span class="line">Changes to be committed:</span><br><span class="line">  (use <span class="string">&quot;git rm --cached &lt;file&gt;...&quot;</span> to unstage)</span><br><span class="line">        new file:   README.md</span><br><span class="line">        new file:   main.py</span><br></pre></td></tr></table></figure>

<p>提交到Git仓库：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git commit -m <span class="string">&quot;Initial commit: add README and main.py&quot;</span></span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[master (root-commit) e1b1d5b] Initial commit: add README and main.py</span><br><span class="line"> 2 files changed, 2 insertions(+)</span><br><span class="line"> create mode 100644 README.md</span><br><span class="line"> create mode 100644 main.py</span><br></pre></td></tr></table></figure>

<p>注意，到这里只是在<strong>本地创建和管理</strong>这个Git仓库，并没有把项目上传到<code>Github</code>上。如果想让项目出现在你的<code>Github</code>账户里，还需要执行一些额外步骤，将本地仓库推送到Github。</p>
<h3 id="3-本地仓库-远程仓库"><a href="#3-本地仓库-远程仓库" class="headerlink" title="3. 本地仓库-&gt;远程仓库"></a>3. 本地仓库-&gt;远程仓库</h3><p>先在<code>Github</code>上创建一个远程仓库：</p>
<ul>
<li>登录你的<code>Github</code>账户，点击右上角的<code>+</code>按钮，选择<code>New repository</code></li>
<li>填写项目名称，如<code>agent_langgraph</code>，可在此界面添加项目描述(Description)，选择项目是公开可见(Public)还是仅你指定的人可见(Private)，选择初始化仓库时是否增加README文件，选择是否添加<code>.gitignore</code>模板，用于模板列表中选择不跟踪的文件，这里选择<code>Python</code>，最后还可以选择许可证(license)。、</li>
<li>点击<code>Create repository</code>以创建仓库</li>
</ul>
<p>现在就可以将本地仓库与Github远程仓库关联了，在你的本地项目目录下运行:</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">git remote add origin https://github.com/&lt;your_username&gt;/agent_langgraph.git</span><br><span class="line"></span><br><span class="line">如</span><br><span class="line"></span><br><span class="line">git remote add origin https://github.com/caihaoran-<span class="number">00</span>/agent_langgraph</span><br></pre></td></tr></table></figure>

<p>检查关联是否成功：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git remote -v</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">origin  https://github.com/caihaoran-<span class="number">00</span>/agent_langgraph (fetch)</span><br><span class="line">origin  https://github.com/caihaoran-<span class="number">00</span>/agent_langgraph (push)</span><br></pre></td></tr></table></figure>

<p>查看本地分支名称：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git branch</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">* master</span><br></pre></td></tr></table></figure>

<p>推送代码到远程仓库：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git push -u origin master</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="function">warning: <span class="title">git</span>-<span class="title">credential</span>-<span class="title">manager</span>-<span class="title">core</span> <span class="title">was</span> <span class="title">renamed</span> <span class="title">to</span> <span class="title">git</span>-<span class="title">credential</span>-<span class="title">manager</span></span></span><br><span class="line"><span class="function"><span class="title">warning</span>: <span class="title">see</span> <span class="title">https</span>://<span class="title">aka.ms</span>/<span class="title">gcm</span>/<span class="title">rename</span> <span class="title">for</span> <span class="title">more</span> <span class="title">information</span></span></span><br><span class="line"><span class="function"><span class="title">warning</span>: ----------------- <span class="title">SECURITY</span> <span class="title">WARNING</span> ----------------</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: | <span class="title">TLS</span> <span class="title">certificate</span> <span class="title">verification</span> <span class="title">has</span> <span class="title">been</span> <span class="title">disabled</span>! |</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: ---------------------------------------------------</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: <span class="title">HTTPS</span> <span class="title">connections</span> <span class="title">may</span> <span class="title">not</span> <span class="title">be</span> <span class="title">secure</span>. <span class="title">See</span> <span class="title">https</span>://<span class="title">aka.ms</span>/<span class="title">gcm</span>/<span class="title">tlsverify</span> <span class="title">for</span> <span class="title">more</span> <span class="title">information</span>.</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: <span class="title">git</span>-<span class="title">credential</span>-<span class="title">manager</span>-<span class="title">core</span> <span class="title">was</span> <span class="title">renamed</span> <span class="title">to</span> <span class="title">git</span>-<span class="title">credential</span>-<span class="title">manager</span></span></span><br><span class="line"><span class="function"><span class="title">warning</span>: <span class="title">see</span> <span class="title">https</span>://<span class="title">aka.ms</span>/<span class="title">gcm</span>/<span class="title">rename</span> <span class="title">for</span> <span class="title">more</span> <span class="title">information</span></span></span><br><span class="line"><span class="function"><span class="title">warning</span>: ----------------- <span class="title">SECURITY</span> <span class="title">WARNING</span> ----------------</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: | <span class="title">TLS</span> <span class="title">certificate</span> <span class="title">verification</span> <span class="title">has</span> <span class="title">been</span> <span class="title">disabled</span>! |</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: ---------------------------------------------------</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: <span class="title">HTTPS</span> <span class="title">connections</span> <span class="title">may</span> <span class="title">not</span> <span class="title">be</span> <span class="title">secure</span>. <span class="title">See</span> <span class="title">https</span>://<span class="title">aka.ms</span>/<span class="title">gcm</span>/<span class="title">tlsverify</span> <span class="title">for</span> <span class="title">more</span> <span class="title">information</span>.</span></span><br><span class="line"><span class="function"><span class="title">Enumerating</span> <span class="title">objects</span>: 4, <span class="title">done</span>.</span></span><br><span class="line"><span class="function"><span class="title">Counting</span> <span class="title">objects</span>: 100% (4/4), <span class="title">done</span>.</span></span><br><span class="line"><span class="function"><span class="title">Delta</span> <span class="title">compression</span> <span class="title">using</span> <span class="title">up</span> <span class="title">to</span> 16 <span class="title">threads</span></span></span><br><span class="line"><span class="function"><span class="title">Compressing</span> <span class="title">objects</span>: 100% (2/2), <span class="title">done</span>.</span></span><br><span class="line"><span class="function"><span class="title">Writing</span> <span class="title">objects</span>: 100% (4/4), 335 <span class="title">bytes</span> | 335.00 <span class="title">KiB</span>/<span class="title">s</span>, <span class="title">done</span>.</span></span><br><span class="line"><span class="function"><span class="title">Total</span> 4 (<span class="title">delta</span> 0), <span class="title">reused</span> 0 (<span class="title">delta</span> 0), <span class="title">pack</span>-<span class="title">reused</span> 0</span></span><br><span class="line"><span class="function"><span class="title">remote</span>:</span></span><br><span class="line"><span class="function"><span class="title">remote</span>: <span class="title">Create</span> <span class="title">a</span> <span class="title">pull</span> <span class="title">request</span> <span class="title">for</span> &#x27;<span class="title">master</span>&#x27; <span class="title">on</span> <span class="title">GitHub</span> <span class="title">by</span> <span class="title">visiting</span>:</span></span><br><span class="line"><span class="function"><span class="title">remote</span>:      <span class="title">https</span>://<span class="title">github.com</span>/<span class="title">caihaoran</span>-00/<span class="title">agent_langgraph</span>/<span class="title">pull</span>/<span class="title">new</span>/<span class="title">master</span></span></span><br><span class="line"><span class="function"><span class="title">remote</span>:</span></span><br><span class="line"><span class="function"><span class="title">To</span> <span class="title">https</span>://<span class="title">github.com</span>/<span class="title">caihaoran</span>-00/<span class="title">agent_langgraph</span></span></span><br><span class="line"><span class="function"> * [<span class="title">new</span> <span class="title">branch</span>]      <span class="title">master</span> -&gt; <span class="title">master</span></span></span><br><span class="line"><span class="function"><span class="title">branch</span> &#x27;<span class="title">master</span>&#x27; <span class="title">set</span> <span class="title">up</span> <span class="title">to</span> <span class="title">track</span> &#x27;<span class="title">origin</span>/<span class="title">master</span>&#x27;.</span></span><br></pre></td></tr></table></figure>

<p>好，推送成功了，打开我们的<code>git仓库</code>看看</p>
<img src="/2025/01/23/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/image-20250205113431936.png" class="" title="image-20250205113431936">

<p>咦，怎么没有呢？我们发现现在是两个分支了(2 Branches)，点击<code>main</code>切换到<code>master</code>分支，</p>
<img src="/2025/01/23/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/image-20250205113617249.png" class="" title="image-20250205113617249">

<p>哦，在这里啊，这是怎么回事呢，回到我们的第一个命令<code>git init</code>的输出，原来一开始就建议我们使用<code>main</code>而不是<code>master</code>作为默认分支了，首先运行：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">git config --global init.defaultBranch main</span><br></pre></td></tr></table></figure>

<p>让所有新仓库用<code>main</code>作为默认分支，然后重命名本地<code>master</code>分支为<code>main</code>：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">git branch -m master main</span><br></pre></td></tr></table></figure>

<p>将本地<code>main</code>和远程<code>main</code>关联：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">git push -u origin main</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="function">warning: <span class="title">git</span>-<span class="title">credential</span>-<span class="title">manager</span>-<span class="title">core</span> <span class="title">was</span> <span class="title">renamed</span> <span class="title">to</span> <span class="title">git</span>-<span class="title">credential</span>-<span class="title">manager</span></span></span><br><span class="line"><span class="function"><span class="title">warning</span>: <span class="title">see</span> <span class="title">https</span>://<span class="title">aka.ms</span>/<span class="title">gcm</span>/<span class="title">rename</span> <span class="title">for</span> <span class="title">more</span> <span class="title">information</span></span></span><br><span class="line"><span class="function"><span class="title">warning</span>: ----------------- <span class="title">SECURITY</span> <span class="title">WARNING</span> ----------------</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: | <span class="title">TLS</span> <span class="title">certificate</span> <span class="title">verification</span> <span class="title">has</span> <span class="title">been</span> <span class="title">disabled</span>! |</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: ---------------------------------------------------</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: <span class="title">HTTPS</span> <span class="title">connections</span> <span class="title">may</span> <span class="title">not</span> <span class="title">be</span> <span class="title">secure</span>. <span class="title">See</span> <span class="title">https</span>://<span class="title">aka.ms</span>/<span class="title">gcm</span>/<span class="title">tlsverify</span> <span class="title">for</span> <span class="title">more</span> <span class="title">information</span>.</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: <span class="title">git</span>-<span class="title">credential</span>-<span class="title">manager</span>-<span class="title">core</span> <span class="title">was</span> <span class="title">renamed</span> <span class="title">to</span> <span class="title">git</span>-<span class="title">credential</span>-<span class="title">manager</span></span></span><br><span class="line"><span class="function"><span class="title">warning</span>: <span class="title">see</span> <span class="title">https</span>://<span class="title">aka.ms</span>/<span class="title">gcm</span>/<span class="title">rename</span> <span class="title">for</span> <span class="title">more</span> <span class="title">information</span></span></span><br><span class="line"><span class="function"><span class="title">warning</span>: ----------------- <span class="title">SECURITY</span> <span class="title">WARNING</span> ----------------</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: | <span class="title">TLS</span> <span class="title">certificate</span> <span class="title">verification</span> <span class="title">has</span> <span class="title">been</span> <span class="title">disabled</span>! |</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: ---------------------------------------------------</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: <span class="title">HTTPS</span> <span class="title">connections</span> <span class="title">may</span> <span class="title">not</span> <span class="title">be</span> <span class="title">secure</span>. <span class="title">See</span> <span class="title">https</span>://<span class="title">aka.ms</span>/<span class="title">gcm</span>/<span class="title">tlsverify</span> <span class="title">for</span> <span class="title">more</span> <span class="title">information</span>.</span></span><br><span class="line"><span class="function"><span class="title">To</span> <span class="title">https</span>://<span class="title">github.com</span>/<span class="title">caihaoran</span>-00/<span class="title">agent_langgraph</span></span></span><br><span class="line"><span class="function"> ! [<span class="title">rejected</span>]        <span class="title">main</span> -&gt; <span class="title">main</span> (<span class="title">fetch</span> <span class="title">first</span>)</span></span><br><span class="line"><span class="function"><span class="title">error</span>: <span class="title">failed</span> <span class="title">to</span> <span class="title">push</span> <span class="title">some</span> <span class="title">refs</span> <span class="title">to</span> &#x27;<span class="title">https</span>://<span class="title">github.com</span>/<span class="title">caihaoran</span>-00/<span class="title">agent_langgraph</span>&#x27;</span></span><br><span class="line"><span class="function"><span class="title">hint</span>: <span class="title">Updates</span> <span class="title">were</span> <span class="title">rejected</span> <span class="title">because</span> <span class="title">the</span> <span class="title">remote</span> <span class="title">contains</span> <span class="title">work</span> <span class="title">that</span> <span class="title">you</span> <span class="title">do</span></span></span><br><span class="line"><span class="function"><span class="title">hint</span>: <span class="title">not</span> <span class="title">have</span> <span class="title">locally</span>. <span class="title">This</span> <span class="title">is</span> <span class="title">usually</span> <span class="title">caused</span> <span class="title">by</span> <span class="title">another</span> <span class="title">repository</span> <span class="title">pushing</span></span></span><br><span class="line"><span class="function"><span class="title">hint</span>: <span class="title">to</span> <span class="title">the</span> <span class="title">same</span> <span class="title">ref</span>. <span class="title">You</span> <span class="title">may</span> <span class="title">want</span> <span class="title">to</span> <span class="title">first</span> <span class="title">integrate</span> <span class="title">the</span> <span class="title">remote</span> <span class="title">changes</span></span></span><br><span class="line"><span class="function"><span class="title">hint</span>: (<span class="title">e.g</span>., &#x27;<span class="title">git</span> <span class="title">pull</span> ...&#x27;) <span class="title">before</span> <span class="title">pushing</span> <span class="title">again</span>.</span></span><br><span class="line"><span class="function"><span class="title">hint</span>: <span class="title">See</span> <span class="title">the</span> &#x27;<span class="title">Note</span> <span class="title">about</span> <span class="title">fast</span>-<span class="title">forwards</span>&#x27; <span class="title">in</span> &#x27;<span class="title">git</span> <span class="title">push</span> --<span class="title">help</span>&#x27; <span class="title">for</span> <span class="title">details</span>.</span></span><br></pre></td></tr></table></figure>

<p>这是因为创建远程<code>main</code>分支的时候添加了<code>.gitignore</code>文件，但本地<code>main</code>分支并没有同步远程的更新，所以<code>Git</code>拒绝了你的推送，执行</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">git pull --rebase origin main</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="function">remote: <span class="title">Enumerating</span> <span class="title">objects</span>: 3, <span class="title">done</span>.</span></span><br><span class="line"><span class="function"><span class="title">remote</span>: <span class="title">Counting</span> <span class="title">objects</span>: 100% (3/3), <span class="title">done</span>.</span></span><br><span class="line"><span class="function"><span class="title">remote</span>: <span class="title">Compressing</span> <span class="title">objects</span>: 100% (2/2), <span class="title">done</span>.</span></span><br><span class="line"><span class="function"><span class="title">remote</span>: <span class="title">Total</span> 3 (<span class="title">delta</span> 0), <span class="title">reused</span> 0 (<span class="title">delta</span> 0), <span class="title">pack</span>-<span class="title">reused</span> 0 (<span class="title">from</span> 0)</span></span><br><span class="line"><span class="function"><span class="title">Unpacking</span> <span class="title">objects</span>: 100% (3/3), 2.32 <span class="title">KiB</span> | 198.00 <span class="title">KiB</span>/<span class="title">s</span>, <span class="title">done</span>.</span></span><br><span class="line"><span class="function"><span class="title">From</span> <span class="title">https</span>://<span class="title">github.com</span>/<span class="title">caihaoran</span>-00/<span class="title">agent_langgraph</span></span></span><br><span class="line"><span class="function"> * <span class="title">branch</span>            <span class="title">main</span>       -&gt; <span class="title">FETCH_HEAD</span></span></span><br><span class="line"><span class="function"> * [<span class="title">new</span> <span class="title">branch</span>]      <span class="title">main</span>       -&gt; <span class="title">origin</span>/<span class="title">main</span></span></span><br><span class="line"><span class="function"><span class="title">Successfully</span> <span class="title">rebased</span> <span class="title">and</span> <span class="title">updated</span> <span class="title">refs</span>/<span class="title">heads</span>/<span class="title">main</span>.</span></span><br></pre></td></tr></table></figure>

<p>运行：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">git push -u origin main</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="function">warning: <span class="title">git</span>-<span class="title">credential</span>-<span class="title">manager</span>-<span class="title">core</span> <span class="title">was</span> <span class="title">renamed</span> <span class="title">to</span> <span class="title">git</span>-<span class="title">credential</span>-<span class="title">manager</span></span></span><br><span class="line"><span class="function"><span class="title">warning</span>: <span class="title">see</span> <span class="title">https</span>://<span class="title">aka.ms</span>/<span class="title">gcm</span>/<span class="title">rename</span> <span class="title">for</span> <span class="title">more</span> <span class="title">information</span></span></span><br><span class="line"><span class="function"><span class="title">warning</span>: ----------------- <span class="title">SECURITY</span> <span class="title">WARNING</span> ----------------</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: | <span class="title">TLS</span> <span class="title">certificate</span> <span class="title">verification</span> <span class="title">has</span> <span class="title">been</span> <span class="title">disabled</span>! |</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: ---------------------------------------------------</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: <span class="title">HTTPS</span> <span class="title">connections</span> <span class="title">may</span> <span class="title">not</span> <span class="title">be</span> <span class="title">secure</span>. <span class="title">See</span> <span class="title">https</span>://<span class="title">aka.ms</span>/<span class="title">gcm</span>/<span class="title">tlsverify</span> <span class="title">for</span> <span class="title">more</span> <span class="title">information</span>.</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: <span class="title">git</span>-<span class="title">credential</span>-<span class="title">manager</span>-<span class="title">core</span> <span class="title">was</span> <span class="title">renamed</span> <span class="title">to</span> <span class="title">git</span>-<span class="title">credential</span>-<span class="title">manager</span></span></span><br><span class="line"><span class="function"><span class="title">warning</span>: <span class="title">see</span> <span class="title">https</span>://<span class="title">aka.ms</span>/<span class="title">gcm</span>/<span class="title">rename</span> <span class="title">for</span> <span class="title">more</span> <span class="title">information</span></span></span><br><span class="line"><span class="function"><span class="title">warning</span>: ----------------- <span class="title">SECURITY</span> <span class="title">WARNING</span> ----------------</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: | <span class="title">TLS</span> <span class="title">certificate</span> <span class="title">verification</span> <span class="title">has</span> <span class="title">been</span> <span class="title">disabled</span>! |</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: ---------------------------------------------------</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: <span class="title">HTTPS</span> <span class="title">connections</span> <span class="title">may</span> <span class="title">not</span> <span class="title">be</span> <span class="title">secure</span>. <span class="title">See</span> <span class="title">https</span>://<span class="title">aka.ms</span>/<span class="title">gcm</span>/<span class="title">tlsverify</span> <span class="title">for</span> <span class="title">more</span> <span class="title">information</span>.</span></span><br><span class="line"><span class="function"><span class="title">Enumerating</span> <span class="title">objects</span>: 5, <span class="title">done</span>.</span></span><br><span class="line"><span class="function"><span class="title">Counting</span> <span class="title">objects</span>: 100% (5/5), <span class="title">done</span>.</span></span><br><span class="line"><span class="function"><span class="title">Delta</span> <span class="title">compression</span> <span class="title">using</span> <span class="title">up</span> <span class="title">to</span> 16 <span class="title">threads</span></span></span><br><span class="line"><span class="function"><span class="title">Compressing</span> <span class="title">objects</span>: 100% (2/2), <span class="title">done</span>.</span></span><br><span class="line"><span class="function"><span class="title">Writing</span> <span class="title">objects</span>: 100% (4/4), 405 <span class="title">bytes</span> | 405.00 <span class="title">KiB</span>/<span class="title">s</span>, <span class="title">done</span>.</span></span><br><span class="line"><span class="function"><span class="title">Total</span> 4 (<span class="title">delta</span> 0), <span class="title">reused</span> 0 (<span class="title">delta</span> 0), <span class="title">pack</span>-<span class="title">reused</span> 0</span></span><br><span class="line"><span class="function"><span class="title">To</span> <span class="title">https</span>://<span class="title">github.com</span>/<span class="title">caihaoran</span>-00/<span class="title">agent_langgraph</span></span></span><br><span class="line"><span class="function">   <span class="title">a8dd2f9</span>..<span class="title">d26a2dd</span>  <span class="title">main</span> -&gt; <span class="title">main</span></span></span><br><span class="line"><span class="function"><span class="title">branch</span> &#x27;<span class="title">main</span>&#x27; <span class="title">set</span> <span class="title">up</span> <span class="title">to</span> <span class="title">track</span> &#x27;<span class="title">origin</span>/<span class="title">main</span>&#x27;.</span></span><br></pre></td></tr></table></figure>

<p>OK!成功了，看下远程仓库也确实推送上去了，最后删除掉刚才的<code>master</code>分支：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">git push origin --delete master</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="function">warning: <span class="title">git</span>-<span class="title">credential</span>-<span class="title">manager</span>-<span class="title">core</span> <span class="title">was</span> <span class="title">renamed</span> <span class="title">to</span> <span class="title">git</span>-<span class="title">credential</span>-<span class="title">manager</span></span></span><br><span class="line"><span class="function"><span class="title">warning</span>: <span class="title">see</span> <span class="title">https</span>://<span class="title">aka.ms</span>/<span class="title">gcm</span>/<span class="title">rename</span> <span class="title">for</span> <span class="title">more</span> <span class="title">information</span></span></span><br><span class="line"><span class="function"><span class="title">warning</span>: ----------------- <span class="title">SECURITY</span> <span class="title">WARNING</span> ----------------</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: | <span class="title">TLS</span> <span class="title">certificate</span> <span class="title">verification</span> <span class="title">has</span> <span class="title">been</span> <span class="title">disabled</span>! |</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: ---------------------------------------------------</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: <span class="title">HTTPS</span> <span class="title">connections</span> <span class="title">may</span> <span class="title">not</span> <span class="title">be</span> <span class="title">secure</span>. <span class="title">See</span> <span class="title">https</span>://<span class="title">aka.ms</span>/<span class="title">gcm</span>/<span class="title">tlsverify</span> <span class="title">for</span> <span class="title">more</span> <span class="title">information</span>.</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: <span class="title">git</span>-<span class="title">credential</span>-<span class="title">manager</span>-<span class="title">core</span> <span class="title">was</span> <span class="title">renamed</span> <span class="title">to</span> <span class="title">git</span>-<span class="title">credential</span>-<span class="title">manager</span></span></span><br><span class="line"><span class="function"><span class="title">warning</span>: <span class="title">see</span> <span class="title">https</span>://<span class="title">aka.ms</span>/<span class="title">gcm</span>/<span class="title">rename</span> <span class="title">for</span> <span class="title">more</span> <span class="title">information</span></span></span><br><span class="line"><span class="function"><span class="title">warning</span>: ----------------- <span class="title">SECURITY</span> <span class="title">WARNING</span> ----------------</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: | <span class="title">TLS</span> <span class="title">certificate</span> <span class="title">verification</span> <span class="title">has</span> <span class="title">been</span> <span class="title">disabled</span>! |</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: ---------------------------------------------------</span></span><br><span class="line"><span class="function"><span class="title">warning</span>: <span class="title">HTTPS</span> <span class="title">connections</span> <span class="title">may</span> <span class="title">not</span> <span class="title">be</span> <span class="title">secure</span>. <span class="title">See</span> <span class="title">https</span>://<span class="title">aka.ms</span>/<span class="title">gcm</span>/<span class="title">tlsverify</span> <span class="title">for</span> <span class="title">more</span> <span class="title">information</span>.</span></span><br><span class="line"><span class="function"><span class="title">To</span> <span class="title">https</span>://<span class="title">github.com</span>/<span class="title">caihaoran</span>-00/<span class="title">agent_langgraph</span></span></span><br><span class="line"><span class="function"> - [<span class="title">deleted</span>]         <span class="title">master</span></span></span><br></pre></td></tr></table></figure>

<p>检查下远程仓库，确实删除掉了，这些<code>warning</code>怎么解决呢？</p>
<p>这理由两方面警告：</p>
<ul>
<li><p><code>git-credential-manager-core</code>被重命名为<code>git-credential-manager</code></p>
<p>升级<a href="https://git-scm.com/downloads/win">git</a>，然后<code>git --version</code>查看是否升级成功，再</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">git config --global credential.helper manager</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> # 基于langgraph的agent应用示例 &gt; README.<span class="built_in">md</span></span><br><span class="line">git add .</span><br><span class="line">git commit -m &quot;Modified README&quot;</span><br><span class="line">git push</span><br></pre></td></tr></table></figure>

<p>最终输出：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">Enumerating objects: <span class="number">5</span>, done.</span><br><span class="line">Counting objects: <span class="number">100</span>% (<span class="number">5</span>/<span class="number">5</span>), done.</span><br><span class="line">Delta compression using up to <span class="number">16</span> threads</span><br><span class="line">Compressing objects: <span class="number">100</span>% (<span class="number">2</span>/<span class="number">2</span>), done.</span><br><span class="line">Writing objects: <span class="number">100</span>% (<span class="number">3</span>/<span class="number">3</span>), <span class="number">348</span> bytes | <span class="number">348</span>.<span class="number">00</span> KiB/s, done.</span><br><span class="line">Total <span class="number">3</span> (delta <span class="number">0</span>), reused <span class="number">0</span> (delta <span class="number">0</span>), pack-reused <span class="number">0</span> (from <span class="number">0</span>)</span><br><span class="line">To https://github.com/caihaoran-<span class="number">00</span>/agent_langgraph</span><br><span class="line">   d26a2dd..ca9d0de  main -&gt; main</span><br></pre></td></tr></table></figure>

<p>没有警告了，完美。</p>
</li>
</ul>
<p>但是发现readme文件显示乱码了，通过任意编辑器打开readme文件，选择<code>UTF-8</code>格式保存，再：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">git add .</span><br><span class="line">git commit -m &quot;Modified README&quot;</span><br><span class="line">git push</span><br></pre></td></tr></table></figure>

<p>即可。</p>
<hr>
<h2 id="二、远程仓库-本地仓库（推荐）"><a href="#二、远程仓库-本地仓库（推荐）" class="headerlink" title="二、远程仓库-&gt;本地仓库（推荐）"></a>二、远程仓库-&gt;本地仓库（推荐）</h2><h3 id="1-创建远程仓库"><a href="#1-创建远程仓库" class="headerlink" title="1.创建远程仓库"></a>1.创建远程仓库</h3><p>第二个案例我们从新建远程仓库看起，与案例一大同小异，首先创建远程仓库，名称为<code>agent</code>。</p>
<h3 id="2-本地仓库文件创建"><a href="#2-本地仓库文件创建" class="headerlink" title="2. 本地仓库文件创建"></a>2. 本地仓库文件创建</h3><p>克隆这个仓库到本地：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/caihaoran-<span class="number">00</span>/agent.git</span><br></pre></td></tr></table></figure>

<p>然后进入这个文件夹，在本地新建几个文件：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> # 原生的agent应用 &gt; README.<span class="built_in">md</span></span><br><span class="line"><span class="built_in">echo</span> &quot;<span class="built_in">print</span>(&#x27;Hello, agent!&#x27;)&quot; &gt; main.py</span><br></pre></td></tr></table></figure>

<p>然后可以运行：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">git status</span><br></pre></td></tr></table></figure>

<p>查看下状态，输出：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">On branch main</span><br><span class="line">Your branch is up to <span class="built_in">date</span> with &#x27;origin/main&#x27;.</span><br><span class="line"></span><br><span class="line">Changes <span class="keyword">not</span> staged <span class="keyword">for</span> commit:</span><br><span class="line">  (use &quot;git add &lt;file&gt;...&quot; to update what will be committed)</span><br><span class="line">  (use &quot;git <span class="built_in">restore</span> &lt;file&gt;...&quot; to discard changes <span class="keyword">in</span> working directory)</span><br><span class="line"><span class="function">        modified:   <span class="title">README.md</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="title">Untracked</span> <span class="title">files</span>:</span></span><br><span class="line"><span class="function">  (<span class="title">use</span> &quot;<span class="title">git</span> <span class="title">add</span> &lt;<span class="title">file</span>&gt;...&quot; <span class="title">to</span> <span class="title">include</span> <span class="title">in</span> <span class="title">what</span> <span class="title">will</span> <span class="title">be</span> <span class="title">committed</span>)</span></span><br><span class="line"><span class="function">        <span class="title">main.py</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="title">no</span> <span class="title">changes</span> <span class="title">added</span> <span class="title">to</span> <span class="title">commit</span> (<span class="title">use</span> &quot;<span class="title">git</span> <span class="title">add</span>&quot; <span class="title">and</span>/<span class="title">or</span> &quot;<span class="title">git</span> <span class="title">commit</span> -<span class="title">a</span>&quot;)</span></span><br></pre></td></tr></table></figure>

<h3 id="3-本地仓库-远程仓库-1"><a href="#3-本地仓库-远程仓库-1" class="headerlink" title="3. 本地仓库-&gt;远程仓库"></a>3. 本地仓库-&gt;远程仓库</h3><p>运行：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">git add .</span><br><span class="line">git commit -m &quot;Initial commit: add README and main.py&quot;</span><br><span class="line">git push</span><br></pre></td></tr></table></figure>

<p>最终输出：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">Enumerating objects: <span class="number">6</span>, done.</span><br><span class="line">Counting objects: <span class="number">100</span>% (<span class="number">6</span>/<span class="number">6</span>), done.</span><br><span class="line">Delta compression using up to <span class="number">16</span> threads</span><br><span class="line">Compressing objects: <span class="number">100</span>% (<span class="number">2</span>/<span class="number">2</span>), done.</span><br><span class="line">Writing objects: <span class="number">100</span>% (<span class="number">4</span>/<span class="number">4</span>), <span class="number">355</span> bytes | <span class="number">355</span>.<span class="number">00</span> KiB/s, done.</span><br><span class="line">Total <span class="number">4</span> (delta <span class="number">0</span>), reused <span class="number">0</span> (delta <span class="number">0</span>), pack-reused <span class="number">0</span> (from <span class="number">0</span>)</span><br><span class="line">To https://github.com/caihaoran-<span class="number">00</span>/agent.git</span><br><span class="line">   <span class="number">43</span>b6c82..<span class="number">765</span>f15b  main -&gt; main</span><br></pre></td></tr></table></figure>

<p>好了，是不是要比案例一要简单一些呢。</p>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2025/01/13/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>gradio+cam搭建web页面体验</title>
    <url>/2025/04/11/gradio-cam%E6%90%AD%E5%BB%BAweb%E9%A1%B5%E9%9D%A2%E4%BD%93%E9%AA%8C/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前面使用<code>fastapi</code>搭建了<code>cam++</code>说话人辨识的微服务，现在要让测试人员测试下<code>cam++</code>的可用性和准确度方面，遂打算搭建个<code>gradio+cam++</code>的web页面，让测试人员直接使用web页面进行相关测试，本文主要提供思路及对应代码。</p>
<span id="more"></span>

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> gradio <span class="keyword">as</span> gr</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> modelscope.pipelines <span class="keyword">import</span> pipeline</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载模型</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    sv_pipeline = pipeline(</span><br><span class="line">        task=<span class="string">&#x27;speaker-verification&#x27;</span>,</span><br><span class="line">        model=<span class="string">&#x27;iic/speech_campplus_sv_zh_en_16k-common_advanced&#x27;</span>,</span><br><span class="line">        model_revision=<span class="string">&#x27;v1.0.0&#x27;</span></span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Speaker Verification pipeline loaded successfully.&quot;</span>)</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Error loading ModelScope pipeline: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="comment"># You might want to exit or disable functionality if the model fails to load</span></span><br><span class="line">    sv_pipeline = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process_audio</span>(<span class="params">audio_input</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Processes audio input from Gradio&#x27;s Audio component.</span></span><br><span class="line"><span class="string">    Input format from gr.Audio(type=&quot;numpy&quot;) is (sample_rate, numpy_array).</span></span><br><span class="line"><span class="string">    Converts audio to the format expected by the pipeline (float32, normalized).</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> audio_input <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    sample_rate, audio_array = audio_input</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;sample_rate=<span class="subst">&#123;sample_rate&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Ensure the audio is mono if it&#x27;s stereo (take the first channel)</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(audio_array.shape) &gt; <span class="number">1</span> <span class="keyword">and</span> audio_array.shape[<span class="number">1</span>] &gt; <span class="number">1</span>:</span><br><span class="line">        audio_array = audio_array[:, <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> audio_array.dtype == np.int16:</span><br><span class="line">        <span class="comment"># Normalize int16 audio</span></span><br><span class="line">        processed_audio = audio_array.astype(np.float32) / <span class="number">32768.0</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Processed int16 audio, shape: <span class="subst">&#123;processed_audio.shape&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">elif</span> audio_array.dtype == np.float32 <span class="keyword">or</span> audio_array.dtype == np.float64:</span><br><span class="line">        <span class="comment"># Assume float audio is already normalized [-1, 1]</span></span><br><span class="line">        processed_audio = audio_array.astype(np.float32)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Processed float audio, shape: <span class="subst">&#123;processed_audio.shape&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">elif</span> audio_array.dtype == np.int32:</span><br><span class="line">        <span class="comment"># 归一化 int32 音频 (-2147483648 to 2147483647)</span></span><br><span class="line">        <span class="comment"># 除以 2**31 (2147483648.0)</span></span><br><span class="line">        processed_audio = audio_array.astype(np.float32) / <span class="number">2147483648.0</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Processed int32 audio, shape: <span class="subst">&#123;processed_audio.shape&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># Handle other potential types or raise an error</span></span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">f&quot;Unsupported audio dtype: <span class="subst">&#123;audio_array.dtype&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Note: The pipeline should handle resampling to 16kHz if needed.</span></span><br><span class="line">    <span class="comment"># If you encounter issues, you might need to explicitly resample using libraries like librosa.</span></span><br><span class="line">    <span class="keyword">import</span> librosa</span><br><span class="line">    <span class="keyword">if</span> sample_rate != <span class="number">16000</span>:</span><br><span class="line">        processed_audio = librosa.resample(processed_audio, orig_sr=sample_rate, target_sr=<span class="number">16000</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Resampled audio to 16kHz, new shape: <span class="subst">&#123;processed_audio.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> processed_audio</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># --- Gradio Interface Functions ---</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">register_voice</span>(<span class="params">audio_input, current_state</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Function to handle voice registration.</span></span><br><span class="line"><span class="string">    Updates the Gradio state with the processed registered audio.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Register function called.&quot;</span>)</span><br><span class="line">    processed_audio = process_audio(audio_input)</span><br><span class="line">    <span class="keyword">if</span> processed_audio <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;No audio provided for registration.&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;错误：请提供用于注册的音频 (Error: Please provide audio for registration)&quot;</span>, current_state <span class="comment"># Return original state</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Registration audio processed successfully.&quot;</span>)</span><br><span class="line">    <span class="comment"># Update the state with the new registered audio</span></span><br><span class="line">    <span class="comment"># No need to save to file unless persistence across app restarts is needed</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;声纹注册成功！ (Voice registered successfully!)&quot;</span>, processed_audio</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">verify_voice</span>(<span class="params">registered_audio_state, audio_to_verify, verification_threshold</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Function to handle voice verification.</span></span><br><span class="line"><span class="string">    Compares new audio against the audio stored in the Gradio state.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Verify function called.&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> sv_pipeline <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">         <span class="keyword">return</span> <span class="string">&quot;错误：模型未加载 (Error: Model not loaded)&quot;</span>, <span class="literal">None</span> <span class="comment"># Return None for JSON</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> registered_audio_state <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;No registered voice found in state.&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;错误：请先注册声纹 (Error: Please register a voice first)&quot;</span>, <span class="literal">None</span> <span class="comment"># Return None for JSON</span></span><br><span class="line"></span><br><span class="line">    processed_verify_audio = process_audio(audio_to_verify)</span><br><span class="line">    <span class="keyword">if</span> processed_verify_audio <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;No audio provided for verification.&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;错误：请提供用于验证的音频 (Error: Please provide audio for verification)&quot;</span>, <span class="literal">None</span> <span class="comment"># Return None for JSON</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Comparing registered audio (shape: <span class="subst">&#123;registered_audio_state.shape&#125;</span>) with verification audio (shape: <span class="subst">&#123;processed_verify_audio.shape&#125;</span>)&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Using threshold: <span class="subst">&#123;verification_threshold&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># The pipeline expects a list of [voice_1, voice_2]</span></span><br><span class="line">        result = sv_pipeline(</span><br><span class="line">            [registered_audio_state, processed_verify_audio],</span><br><span class="line">            thr=verification_threshold</span><br><span class="line">        )</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Pipeline result: <span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="comment"># Return status message and the result dictionary for the JSON output</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;验证完成 (Verification complete)&quot;</span>, result</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Error during pipeline execution: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;验证时出错：<span class="subst">&#123;e&#125;</span> (Error during verification: <span class="subst">&#123;e&#125;</span>)&quot;</span>, <span class="literal">None</span> <span class="comment"># Return None for JSON</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --- Gradio UI Definition ---</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> gr.Blocks() <span class="keyword">as</span> demo:</span><br><span class="line">    gr.Markdown(</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        # Cam++ 说话人验证 Demo (Speaker Verification Demo)</span></span><br><span class="line"><span class="string">        1. 请先通过麦克风录制或上传一段音频 **注册** 声纹 ，点击注册声纹。\n</span></span><br><span class="line"><span class="string">        2. 然后，录制或上传另一段音频进行 **验证**, 点击验证声纹。\n</span></span><br><span class="line"><span class="string">        (First, **register** a voiceprint by recording via microphone or uploading an audio file.\n</span></span><br><span class="line"><span class="string">        Then, record or upload another audio file for **verification**.)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># State to hold the registered audio (as a processed numpy array)</span></span><br><span class="line">    registered_audio_state = gr.State(<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> gr.Row():</span><br><span class="line">        <span class="keyword">with</span> gr.Column(scale=<span class="number">1</span>):</span><br><span class="line">            gr.Markdown(<span class="string">&quot;## 1. 注册声纹 (Register Voiceprint)&quot;</span>)</span><br><span class="line">            audio_register = gr.Audio(</span><br><span class="line">                sources=[<span class="string">&quot;microphone&quot;</span>, <span class="string">&quot;upload&quot;</span>],</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;numpy&quot;</span>,  <span class="comment"># Get audio as (sample_rate, numpy_array)</span></span><br><span class="line">                label=<span class="string">&quot;录制或上传注册音频 (Record or Upload Registration Audio)&quot;</span>,</span><br><span class="line">                show_download_button=<span class="literal">True</span></span><br><span class="line">                <span class="comment"># waveform_options=gr.WaveformOptions(waveform_color=&quot;#0176dd&quot;, waveform_progress_color=&quot;#aa1111&quot;) # Optional styling</span></span><br><span class="line">            )</span><br><span class="line">            register_button = gr.Button(<span class="string">&quot;注册声纹 (Register Voiceprint)&quot;</span>)</span><br><span class="line">            register_status = gr.Textbox(label=<span class="string">&quot;注册状态 (Registration Status)&quot;</span>, interactive=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> gr.Column(scale=<span class="number">1</span>):</span><br><span class="line">            gr.Markdown(<span class="string">&quot;## 2. 验证声纹 (Verify Voiceprint)&quot;</span>)</span><br><span class="line">            audio_verify = gr.Audio(</span><br><span class="line">                sources=[<span class="string">&quot;microphone&quot;</span>, <span class="string">&quot;upload&quot;</span>],</span><br><span class="line">                <span class="built_in">type</span>=<span class="string">&quot;numpy&quot;</span>,  <span class="comment"># Get audio as (sample_rate, numpy_array)</span></span><br><span class="line">                label=<span class="string">&quot;录制或上传验证音频 (Record or Upload Verification Audio)&quot;</span>,</span><br><span class="line">                show_download_button=<span class="literal">True</span></span><br><span class="line">                <span class="comment"># waveform_options=gr.WaveformOptions(waveform_color=&quot;#0176dd&quot;, waveform_progress_color=&quot;#aa1111&quot;) # Optional styling</span></span><br><span class="line">            )</span><br><span class="line">            threshold_slider = gr.Slider(</span><br><span class="line">                minimum=<span class="number">0.0</span>, maximum=<span class="number">1.0</span>, step=<span class="number">0.01</span>, value=<span class="number">0.4</span>, <span class="comment"># Default threshold from your FastAPI code was 0.4, pipeline default might differ (check docs, 0.6?)</span></span><br><span class="line">                label=<span class="string">&quot;验证阈值 (Verification Threshold)&quot;</span></span><br><span class="line">            )</span><br><span class="line">            verify_button = gr.Button(<span class="string">&quot;验证声纹 (Verify Voiceprint)&quot;</span>)</span><br><span class="line">            verify_status = gr.Textbox(label=<span class="string">&quot;验证状态 (Verification Status)&quot;</span>, interactive=<span class="literal">False</span>)  <span class="comment"># For text feedback</span></span><br><span class="line">            verify_result_json = gr.JSON(label=<span class="string">&quot;验证结果详情 (Verification Result Details)&quot;</span>)   <span class="comment">#  To display the dict score/decision</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># --- Connect UI Components to Functions ---</span></span><br><span class="line">    register_button.click(</span><br><span class="line">        fn=register_voice,</span><br><span class="line">        inputs=[audio_register, registered_audio_state],  <span class="comment"># Pass audio input and current state</span></span><br><span class="line">        outputs=[register_status, registered_audio_state]  <span class="comment"># Update status text and the state itself</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    verify_button.click(</span><br><span class="line">        fn=verify_voice,</span><br><span class="line">        inputs=[registered_audio_state, audio_verify, threshold_slider],  <span class="comment">#  Pass registered audio state, new audio, and threshold</span></span><br><span class="line">        outputs=[verify_status, verify_result_json]  <span class="comment"># Update status text and the JSON output</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- Launch the Gradio App ---</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Launching Gradio interface...&quot;</span>)</span><br><span class="line">    <span class="comment"># share=True creates a public link (useful for sharing temporarily)</span></span><br><span class="line">    <span class="comment"># demo.launch(share=False)</span></span><br><span class="line">    <span class="comment"># To make it accessible on your network, use:</span></span><br><span class="line">    demo.launch(server_name=<span class="string">&quot;0.0.0.0&quot;</span>, server_port=<span class="number">7860</span>)</span><br></pre></td></tr></table></figure>

<p>思路：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">模型加载(pipeline)</span><br><span class="line">→ 音频预处理(process<span class="built_in">_</span>audio)</span><br><span class="line">→ 注册声纹(register<span class="built_in">_</span>voice)</span><br><span class="line">→ 验证声纹(verify<span class="built_in">_</span>voice)</span><br><span class="line">→ Gradio界面设计(with gr.Blocks() as demo:)</span><br><span class="line">→ 组件绑定(...<span class="built_in">_</span>button.click)</span><br><span class="line">→ 启动服务(demo.launch)</span><br></pre></td></tr></table></figure>

<p>值得注意的是<code>float32(IEEE)</code>格式的音频文件通过<code>gradio</code>框架传输到服务端时会被识别成<code>int32</code>格式，所以我的<code>process_audio</code>对<code>int32</code>的格式也做了兼容（没兼容前会报错），关于确认音频格式，我是这样做的：</p>
<ol>
<li><p>AU(<code>Adobe Audition</code>)中打开音频文件，点击另存为会看到音频原始格式（显示的<code>float32(IEEE)</code>)</p>
</li>
<li><p>通过<code>soundfile.info</code>来确认</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> soundfile <span class="keyword">as</span> sf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  <span class="comment"># 只是为了对比 numpy 的 dtype</span></span><br><span class="line">filepath = <span class="string">&#x27;int32.wav&#x27;</span>   <span class="comment"># 替换成你的文件路径</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="comment"># 方法一：使用 sf.info() 获取信息对象 (不加载数据)</span></span><br><span class="line">    info = sf.info(filepath)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;--- SoundFile Info ---&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;File: <span class="subst">&#123;filepath&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Sample Rate: <span class="subst">&#123;info.samplerate&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Channels: <span class="subst">&#123;info.channels&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Frames: <span class="subst">&#123;info.frames&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Duration: <span class="subst">&#123;info.duration:<span class="number">.2</span>f&#125;</span> seconds&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Format Code: <span class="subst">&#123;info.<span class="built_in">format</span>&#125;</span>&quot;</span>)  <span class="comment"># 例如 &#x27;WAV&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Subtype Code: <span class="subst">&#123;info.subtype&#125;</span>&quot;</span>)  <span class="comment"># 例如 &#x27;PCM_16&#x27;, &#x27;PCM_32&#x27;, &#x27;FLOAT&#x27;, &#x27;DOUBLE&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Endian: <span class="subst">&#123;info.endian&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Extra Info: <span class="subst">&#123;info.extra_info&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 解释 Subtype</span></span><br><span class="line">    subtype = info.subtype</span><br><span class="line">    bit_depth_str = <span class="string">&quot;Unknown&quot;</span></span><br><span class="line">    format_type = <span class="string">&quot;Unknown&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;PCM_16&#x27;</span> <span class="keyword">in</span> subtype:</span><br><span class="line">        bit_depth_str = <span class="string">&quot;16-bit&quot;</span></span><br><span class="line">        format_type = <span class="string">&quot;Integer (PCM)&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="string">&#x27;PCM_24&#x27;</span> <span class="keyword">in</span> subtype:</span><br><span class="line">        bit_depth_str = <span class="string">&quot;24-bit&quot;</span></span><br><span class="line">        format_type = <span class="string">&quot;Integer (PCM)&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="string">&#x27;PCM_32&#x27;</span> <span class="keyword">in</span> subtype:</span><br><span class="line">        bit_depth_str = <span class="string">&quot;32-bit&quot;</span></span><br><span class="line">        format_type = <span class="string">&quot;Integer (PCM)&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="string">&#x27;FLOAT&#x27;</span> <span class="keyword">in</span> subtype:</span><br><span class="line">        bit_depth_str = <span class="string">&quot;32-bit&quot;</span></span><br><span class="line">        format_type = <span class="string">&quot;Floating Point (IEEE Float)&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> <span class="string">&#x27;DOUBLE&#x27;</span> <span class="keyword">in</span> subtype:</span><br><span class="line">        bit_depth_str = <span class="string">&quot;64-bit&quot;</span></span><br><span class="line">        format_type = <span class="string">&quot;Floating Point (IEEE Double)&quot;</span></span><br><span class="line">    <span class="comment"># ...可以根据需要添加更多 subtypes (e.g., &#x27;PCM_U8&#x27;)</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Detected Format: <span class="subst">&#123;bit_depth_str&#125;</span> <span class="subst">&#123;format_type&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-&quot;</span> * <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 方法二：加载数据并检查 dtype (这会像你之前做的那样)</span></span><br><span class="line">    data, samplerate = sf.read(filepath, dtype=<span class="literal">None</span>)  <span class="comment"># dtype=None 读取原始类型</span></span><br><span class="line">    <span class="built_in">print</span>(data.shape)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;NumPy dtype after loading: <span class="subst">&#123;data.dtype&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Error reading file info: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">/home/chr/anaconda3/envs/funasr/bin/python /home/chr/桌面/fast<span class="built_in">_</span>api/test<span class="built_in">_</span>int32<span class="built_in">_</span>2.py </span><br><span class="line">--- SoundFile Info ---</span><br><span class="line">File: int32.wav</span><br><span class="line">Sample Rate: 48000</span><br><span class="line">Channels: 2</span><br><span class="line">Frames: 68815</span><br><span class="line">Duration: 1.43 seconds</span><br><span class="line">Format Code: WAV</span><br><span class="line">Subtype Code: FLOAT</span><br><span class="line">Endian: FILE</span><br><span class="line">Extra Info: File : int32.wav</span><br><span class="line">Length : 556286</span><br><span class="line">RIFF : 556278</span><br><span class="line">WAVE</span><br><span class="line">fmt  : 16</span><br><span class="line">  Format        : 0x3 =&gt; WAVE<span class="built_in">_</span>FORMAT<span class="built_in">_</span>IEEE<span class="built_in">_</span>FLOAT</span><br><span class="line">  Channels      : 2</span><br><span class="line">  Sample Rate   : 48000</span><br><span class="line">  Block Align   : 8</span><br><span class="line">  Bit Width     : 32</span><br><span class="line">  Bytes/sec     : 384000</span><br><span class="line">data : 550520</span><br><span class="line">LIST : 76</span><br><span class="line">  INFO</span><br><span class="line">    ICRD : 2025-04-21T10:48:15+08:00</span><br><span class="line">    ISFT : Adobe Audition 22.0 (Windows)</span><br><span class="line"><span class="built_in">_</span>PMX : 5630</span><br><span class="line">End</span><br><span class="line">**** All non-PCM format files should have a &#x27;fact&#x27; chunk.</span><br><span class="line"></span><br><span class="line">Detected Format: 32-bit Floating Point (IEEE Float)</span><br><span class="line">--------------------</span><br><span class="line">(68815, 2)</span><br><span class="line">NumPy dtype after loading: float64</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br></pre></td></tr></table></figure>

<p>两种方法区别：</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>作用</th>
<th>可靠性</th>
</tr>
</thead>
<tbody><tr>
<td><code>sf.info()</code></td>
<td>获取音频<strong>文件头描述</strong>，直接显示 subtype。</td>
<td>✅ 很准确，100%反映<strong>文件原始格式</strong>。</td>
</tr>
<tr>
<td><code>sf.read()</code></td>
<td>将音频<strong>加载成 numpy 数组</strong>，<code>dtype=None</code> 时自动转换。</td>
<td>⚠️ 不总是反映原始格式，受 <code>libsndfile</code> 策略影响。</td>
</tr>
</tbody></table>
</li>
</ol>
<p>可见，gradio框架貌似在也进行了数据格式的自动转化，将<code>float32(IEEE)</code>转化为了<code>int32</code>。</p>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>cam++</tag>
        <tag>gradio</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo主题配置及美化之Next</title>
    <url>/2025/01/14/hexo%E4%B8%BB%E9%A2%98%E9%85%8D%E7%BD%AE%E5%8F%8A%E7%BE%8E%E5%8C%96%E4%B9%8Bnext/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前面介绍了Hexo + Github Pages环境的搭建和简单的走了一遍总体发布流程，本文介绍：</p>
<ul>
<li>使用<a href="https://github.com/theme-next/hexo-theme-next">Next</a>主题进行页面美化</li>
<li>对站点配置文件（.&#x2F;_config.yml）和主题配置文件（.&#x2F;themes&#x2F;next&#x2F;_config.yml）的部分配置进行使用和介绍</li>
</ul>
<p>关于markdown文件的撰写，下次文章介绍。</p>
<hr>
<span id="more"></span>

<h2 id="1-安装Next主题"><a href="#1-安装Next主题" class="headerlink" title="1.安装Next主题"></a>1.安装Next主题</h2><ul>
<li><p>与上文的yilia主题一样，在<code>blog</code>目录下运行：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/theme-next/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure>
</li>
<li><p>打开<code>blog/_config.yml</code>文件，拉到倒数第二项的theme配置部分，修改如下：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="function">theme: <span class="title">next</span></span></span><br></pre></td></tr></table></figure>
</li>
<li><p>（可选）此时即可本地运行看下效果：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">hexo server</span><br></pre></td></tr></table></figure>
</li>
<li><p>打开<code>blog/themes/next/_config.yml</code>，搜索<code>scheme</code>，配置如下：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"># Schemes</span><br><span class="line">#scheme: Muse</span><br><span class="line">#scheme: Mist</span><br><span class="line">#scheme: Pisces</span><br><span class="line"><span class="function">scheme: <span class="title">Gemini</span></span></span><br></pre></td></tr></table></figure>
</li>
<li><p>本地看下效果：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">hexo server</span><br></pre></td></tr></table></figure></li>
</ul>
<hr>
<h2 id="2-页面美化"><a href="#2-页面美化" class="headerlink" title="2.页面美化"></a>2.页面美化</h2><h3 id="1-站点title"><a href="#1-站点title" class="headerlink" title="1.站点title"></a>1.站点title</h3><ul>
<li><p>打开<code>blog/_config.yml</code>文件，开头部分：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"># Site</span><br><span class="line"><span class="function">title: <span class="title">Chr</span>&#x27;<span class="title">s</span> <span class="title">Blog</span></span></span><br><span class="line"><span class="function"><span class="title">subtitle</span>: &#x27;<span class="title">Record</span> <span class="title">and</span> <span class="title">Share</span>&#x27;</span></span><br><span class="line"><span class="function"><span class="title">description</span>: &#x27;<span class="title">Welcome</span> <span class="title">to</span> <span class="title">my</span> <span class="title">little</span> <span class="title">world</span>&#x27;</span></span><br><span class="line"><span class="function"><span class="title">keywords</span>: <span class="title">Hexo</span>,<span class="title">langgraph</span>,<span class="title">ASR</span>,<span class="title">LLM</span>,<span class="title">TTS</span></span></span><br><span class="line"><span class="function"><span class="title">author</span>: <span class="title">Chr</span></span></span><br><span class="line"><span class="function"><span class="title">language</span>: <span class="title">zh</span>-<span class="title">CN</span></span></span><br><span class="line"><span class="function"><span class="title">timezone</span>: &#x27;<span class="title">Asia</span>/<span class="title">Shanghai</span>&#x27;</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="2-导航栏"><a href="#2-导航栏" class="headerlink" title="2.导航栏"></a>2.导航栏</h3><ul>
<li><p>打开<code>blog/themes/next/_config.yml</code>，搜索<code>menu</code>：	</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="function">menu:</span></span><br><span class="line"><span class="function">  <span class="title">home</span>: / || <span class="title">fa</span> <span class="title">fa</span>-<span class="title">home</span></span></span><br><span class="line"><span class="function">  <span class="title">about</span>: /<span class="title">about</span>/ || <span class="title">fa</span> <span class="title">fa</span>-<span class="title">user</span></span></span><br><span class="line"><span class="function">  <span class="title">tags</span>: /<span class="title">tags</span>/ || <span class="title">fa</span> <span class="title">fa</span>-<span class="title">tags</span></span></span><br><span class="line"><span class="function">  <span class="title">categories</span>: /<span class="title">categories</span>/ || <span class="title">fa</span> <span class="title">fa</span>-<span class="title">th</span></span></span><br><span class="line"><span class="function">  <span class="title">archives</span>: /<span class="title">archives</span>/ || <span class="title">fa</span> <span class="title">fa</span>-<span class="title">archive</span></span></span><br><span class="line"><span class="function">  #<span class="title">schedule</span>: /<span class="title">schedule</span>/ || <span class="title">fa</span> <span class="title">fa</span>-<span class="title">calendar</span></span></span><br><span class="line"><span class="function">  #<span class="title">sitemap</span>: /<span class="title">sitemap.xml</span> || <span class="title">fa</span> <span class="title">fa</span>-<span class="title">sitemap</span></span></span><br><span class="line"><span class="function">  #<span class="title">commonweal</span>: /404/ || <span class="title">fa</span> <span class="title">fa</span>-<span class="title">heartbeat</span></span></span><br></pre></td></tr></table></figure>
</li>
<li><p>此时导航栏显示了，但点进去会无法访问，运行：</p>
<figure class="highlight excel"><table><tr><td class="code"><pre><span class="line">hexo <span class="built_in">n</span> page <span class="string">&quot;about&quot;</span></span><br><span class="line">hexo <span class="built_in">n</span> page <span class="string">&quot;tags&quot;</span></span><br><span class="line">hexo <span class="built_in">n</span> page <span class="string">&quot;categories&quot;</span></span><br></pre></td></tr></table></figure>

<p>即会在<code>blog/source</code>文件加下新建<code>about</code>、<code>tags</code>、<code>categories</code>文件夹，每个文件夹下包含一个<code>index.md</code>文件。</p>
</li>
<li><p>此时依旧不行，需要打开各<code>index.md</code>，<code>分别</code>添加对应的<code>type</code>到头信息处，如：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line"><span class="function">title: <span class="title">categories</span></span></span><br><span class="line"><span class="function"><span class="title">date</span>: 2025-01-14 18:02:22</span></span><br><span class="line"><span class="function"><span class="title">type</span>: <span class="title">categories</span></span></span><br><span class="line"><span class="function">---</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="3-添加个人联系方式（社交链接）"><a href="#3-添加个人联系方式（社交链接）" class="headerlink" title="3.添加个人联系方式（社交链接）"></a>3.添加个人联系方式（社交链接）</h3><ul>
<li><p>打开<code>blog/themes/next/_config.yml</code>，搜索<code>social</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">social:</span><br><span class="line">  <span class="comment">#GitHub: https://github.com/yourname || fab fa-github</span></span><br><span class="line">  E-Mail: mailto:<span class="number">1299964565</span>@qq.com || fa fa-envelope</span><br><span class="line">  <span class="comment">#Weibo: https://weibo.com/yourname || fab fa-weibo</span></span><br><span class="line">  <span class="comment">#Twitter: https://twitter.com/yourname || fab fa-twitter</span></span><br><span class="line">  <span class="comment">#FB Page: https://www.facebook.com/yourname || fab fa-facebook</span></span><br><span class="line">  <span class="comment">#StackOverflow: https://stackoverflow.com/yourname || fab fa-stack-overflow</span></span><br><span class="line">  <span class="comment">#YouTube: https://youtube.com/yourname || fab fa-youtube</span></span><br><span class="line">  <span class="comment">#Instagram: https://instagram.com/yourname || fab fa-instagram</span></span><br><span class="line">  <span class="comment">#Skype: skype:yourname?call|chat || fab fa-skype</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="4-网页底部powered-By-Hexo"><a href="#4-网页底部powered-By-Hexo" class="headerlink" title="4.网页底部powered By Hexo"></a>4.网页底部powered By Hexo</h3><ul>
<li><p>打开<code>blog/themes/next/_config.yml</code>，搜索<code>powered</code>：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"># Powered by Hexo &amp; NexT</span><br><span class="line"><span class="function">  powered: <span class="title">false</span></span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="5-代码高亮"><a href="#5-代码高亮" class="headerlink" title="5.代码高亮"></a>5.代码高亮</h3><ul>
<li><p>打开<code>blog/_config.yml</code>文件，搜索<code>highlight</code>：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="function">highlight:</span></span><br><span class="line"><span class="function">  <span class="title">enable</span>: <span class="title">true</span></span></span><br><span class="line"><span class="function">  <span class="title">line_number</span>: <span class="title">true</span></span></span><br><span class="line"><span class="function">  <span class="title">auto_detect</span>: <span class="title">true</span></span></span><br><span class="line"><span class="function">  <span class="title">tab_replace</span>: &#x27;&#x27;</span></span><br><span class="line"><span class="function">  <span class="title">wrap</span>: <span class="title">true</span></span></span><br><span class="line"><span class="function">  <span class="title">hljs</span>: <span class="title">false</span></span></span><br><span class="line"><span class="function"><span class="title">prismjs</span>:</span></span><br><span class="line"><span class="function">  <span class="title">preprocess</span>: <span class="title">true</span></span></span><br><span class="line"><span class="function">  <span class="title">line_number</span>: <span class="title">true</span></span></span><br><span class="line"><span class="function">  <span class="title">tab_replace</span>: &#x27;&#x27;</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="6-代码段一键复制"><a href="#6-代码段一键复制" class="headerlink" title="6.代码段一键复制"></a>6.代码段一键复制</h3><ul>
<li><p>打开<code>blog/themes/next/_config.yml</code>，搜索<code>codeblock</code>：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="function">codeblock:</span></span><br><span class="line"><span class="function">  # <span class="title">Code</span> <span class="title">Highlight</span> <span class="title">theme</span></span></span><br><span class="line"><span class="function">  # <span class="title">All</span> <span class="title">available</span> <span class="title">themes</span>: <span class="title">https</span>://<span class="title">theme</span>-<span class="title">next.js.org</span>/<span class="title">highlight</span>/</span></span><br><span class="line"><span class="function">  <span class="title">theme</span>:</span></span><br><span class="line"><span class="function">    <span class="title">light</span>: <span class="title">github</span>-<span class="title">dark</span></span></span><br><span class="line"><span class="function">    <span class="title">dark</span>: <span class="title">github</span>-<span class="title">dark</span></span></span><br><span class="line"><span class="function">  <span class="title">prism</span>:</span></span><br><span class="line"><span class="function">    <span class="title">light</span>: <span class="title">prism</span></span></span><br><span class="line"><span class="function">    <span class="title">dark</span>: <span class="title">prism</span>-<span class="title">dark</span></span></span><br><span class="line"><span class="function">  # <span class="title">Add</span> <span class="title">copy</span> <span class="title">button</span> <span class="title">on</span> <span class="title">codeblock</span></span></span><br><span class="line"><span class="function">  <span class="title">copy_button</span>:</span></span><br><span class="line"><span class="function">    <span class="title">enable</span>: <span class="title">true</span></span></span><br><span class="line"><span class="function">    # <span class="title">Available</span> <span class="title">values</span>: <span class="title">default</span> | <span class="title">flat</span> | <span class="title">mac</span></span></span><br><span class="line"><span class="function">    <span class="title">style</span>: <span class="title">mac</span></span></span><br><span class="line"><span class="function">  # <span class="title">Fold</span> <span class="title">code</span> <span class="title">block</span></span></span><br><span class="line"><span class="function">  <span class="title">fold</span>:</span></span><br><span class="line"><span class="function">    <span class="title">enable</span>: <span class="title">false</span></span></span><br><span class="line"><span class="function">    <span class="title">height</span>: 500</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>可在<a href="https://theme-next.js.org/highlight/">这里</a>查看代码高亮主题，选择心仪主题。</p>
</blockquote>
</li>
</ul>
<h3 id="7-显示浏览进度"><a href="#7-显示浏览进度" class="headerlink" title="7.显示浏览进度"></a>7.显示浏览进度</h3><ul>
<li><p>打开<code>blog/themes/next/_config.yml</code>，搜索<code>back2top</code>：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="function">back2top:</span></span><br><span class="line"><span class="function">  <span class="title">enable</span>: <span class="title">true</span></span></span><br><span class="line"><span class="function">  # <span class="title">Back</span> <span class="title">to</span> <span class="title">top</span> <span class="title">in</span> <span class="title">sidebar</span>.</span></span><br><span class="line"><span class="function">  <span class="title">sidebar</span>: <span class="title">true</span></span></span><br><span class="line"><span class="function">  # <span class="title">Scroll</span> <span class="title">percent</span> <span class="title">label</span> <span class="title">in</span> <span class="title">b2t</span> <span class="title">button</span>.</span></span><br><span class="line"><span class="function">  <span class="title">scrollpercent</span>: <span class="title">true</span></span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="8-本地搜索"><a href="#8-本地搜索" class="headerlink" title="8.本地搜索"></a>8.本地搜索</h3><ul>
<li><p>安装<code>hexo-generator-searchdb</code>：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">npm install hexo-generator-searchdb --save</span><br></pre></td></tr></table></figure>
</li>
<li><p>打开<code>blog/_config.yml</code>文件，添加以下代码到末尾：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="function">search:</span></span><br><span class="line"><span class="function"><span class="title">path</span>: <span class="title">search.xml</span></span></span><br><span class="line"><span class="function"><span class="title">field</span>: <span class="title">post</span></span></span><br><span class="line"><span class="function"><span class="title">format</span>: <span class="title">html</span></span></span><br><span class="line"><span class="function"><span class="title">limit</span>: 10000</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>打开<code>blog/themes/next/_config.yml</code>，搜索<code>local_search</code>：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="function">local_search:</span></span><br><span class="line"><span class="function">  <span class="title">enable</span>: <span class="title">true</span></span></span><br><span class="line"><span class="function">  # <span class="title">Show</span> <span class="title">top</span> <span class="title">n</span> <span class="title">results</span> <span class="title">per</span> <span class="title">article</span>, <span class="title">show</span> <span class="title">all</span> <span class="title">results</span> <span class="title">by</span> <span class="title">setting</span> <span class="title">to</span> -1</span></span><br><span class="line"><span class="function">  <span class="title">top_n_per_article</span>: 1</span></span><br><span class="line"><span class="function">  # <span class="title">Unescape</span> <span class="title">html</span> <span class="title">strings</span> <span class="title">to</span> <span class="title">the</span> <span class="title">readable</span> <span class="title">one</span>.</span></span><br><span class="line"><span class="function">  <span class="title">unescape</span>: <span class="title">false</span></span></span><br><span class="line"><span class="function">  # <span class="title">Preload</span> <span class="title">the</span> <span class="title">search</span> <span class="title">data</span> <span class="title">when</span> <span class="title">the</span> <span class="title">page</span> <span class="title">loads</span>.</span></span><br><span class="line"><span class="function">  <span class="title">preload</span>: <span class="title">false</span></span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="9-文章字数、阅读时长和访客量、文章阅读量"><a href="#9-文章字数、阅读时长和访客量、文章阅读量" class="headerlink" title="9.文章字数、阅读时长和访客量、文章阅读量"></a>9.文章字数、阅读时长和访客量、文章阅读量</h3><ul>
<li><p>打开<code>blog/themes/next/_config.yml</code>，搜索<code>busuanzi_count</code>：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="function">busuanzi_count:</span></span><br><span class="line"><span class="function">  <span class="title">enable</span>: <span class="title">true</span></span></span><br><span class="line"><span class="function">  <span class="title">total_visitors</span>: <span class="title">true</span></span></span><br><span class="line"><span class="function">  <span class="title">total_visitors_icon</span>: <span class="title">fa</span> <span class="title">fa</span>-<span class="title">user</span></span></span><br><span class="line"><span class="function">  <span class="title">total_views</span>: <span class="title">true</span></span></span><br><span class="line"><span class="function">  <span class="title">total_views_icon</span>: <span class="title">fa</span> <span class="title">fa</span>-<span class="title">eye</span></span></span><br><span class="line"><span class="function">  <span class="title">post_views</span>: <span class="title">true</span></span></span><br><span class="line"><span class="function">  <span class="title">post_views_icon</span>: <span class="title">far</span> <span class="title">fa</span>-<span class="title">eye</span></span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：本地<code>hexo s</code>查看效果时网页底部的访客量和文章阅读量的统计会不正确（很大），但<code>hexo g</code>部署在<code>GitHub Pages</code>上就没问题了。</p>
</blockquote>
</li>
</ul>
<h3 id="10-阅读全文"><a href="#10-阅读全文" class="headerlink" title="10.阅读全文"></a>10.阅读全文</h3><ul>
<li>直接在md文件中添加<code>&lt;!--more--&gt;</code>即可控制摘要内容，即控制Read More（阅读全文）的位置，可添加前言对文章进行总结提炼，详情可点击阅读全文。</li>
</ul>
<h3 id="11-插入图片"><a href="#11-插入图片" class="headerlink" title="11.插入图片"></a>11.插入图片</h3><ul>
<li>插入图片上碰到了一个问题，在<code>typora</code>上图片是正常显示的，但无论是<code>hexo s</code>还是<code>hexo d</code>都无法显示，参考<a href="https://blog.csdn.net/lengcs/article/details/143816877">这个博客</a>解决了问题。</li>
</ul>
<h3 id="12-公式支持"><a href="#12-公式支持" class="headerlink" title="12.公式支持"></a>12.公式支持</h3><ul>
<li><p>打开<code>blog/themes/next/_config.yml</code>，搜索<code>math</code>，设置如下即可：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="function">math:</span></span><br><span class="line"><span class="function">  # <span class="title">Default</span> (<span class="title">false</span>) <span class="title">will</span> <span class="title">load</span> <span class="title">mathjax</span> / <span class="title">katex</span> <span class="title">script</span> <span class="title">on</span> <span class="title">demand</span>.</span></span><br><span class="line"><span class="function">  # <span class="title">That</span> <span class="title">is</span> <span class="title">it</span> <span class="title">only</span> <span class="title">render</span> <span class="title">those</span> <span class="title">page</span> <span class="title">which</span> <span class="title">has</span> `<span class="title">mathjax</span>: <span class="title">true</span>` <span class="title">in</span> <span class="title">front</span>-<span class="title">matter</span>.</span></span><br><span class="line"><span class="function">  # <span class="title">If</span> <span class="title">you</span> <span class="title">set</span> <span class="title">it</span> <span class="title">to</span> <span class="title">true</span>, <span class="title">it</span> <span class="title">will</span> <span class="title">load</span> <span class="title">mathjax</span> / <span class="title">katex</span> <span class="title">script</span> <span class="title">EVERY</span> <span class="title">PAGE</span>.</span></span><br><span class="line"><span class="function">  <span class="title">every_page</span>: <span class="title">false</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">  <span class="title">mathjax</span>:</span></span><br><span class="line"><span class="function">    <span class="title">enable</span>: <span class="title">true</span></span></span><br><span class="line"><span class="function">    # <span class="title">Available</span> <span class="title">values</span>: <span class="title">none</span> | <span class="title">ams</span> | <span class="title">all</span></span></span><br><span class="line"><span class="function">    <span class="title">tags</span>: <span class="title">none</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">  <span class="title">katex</span>:</span></span><br><span class="line"><span class="function">    <span class="title">enable</span>: <span class="title">false</span></span></span><br><span class="line"><span class="function">    # <span class="title">See</span>: <span class="title">https</span>://<span class="title">github.com</span>/<span class="title">KaTeX</span>/<span class="title">KaTeX</span>/<span class="title">tree</span>/<span class="title">master</span>/<span class="title">contrib</span>/<span class="title">copy</span>-<span class="title">tex</span></span></span><br><span class="line"><span class="function">    <span class="title">copy_tex</span>: <span class="title">false</span></span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="13-加粗"><a href="#13-加粗" class="headerlink" title="13 加粗"></a>13 加粗</h3><ul>
<li><p>在markdown文件中加粗使用<code>**A**</code>即可，但在网页上并没有显示加粗，我目前是用：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">&lt;b&gt;A&lt;/b&gt;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="14-TODO"><a href="#14-TODO" class="headerlink" title="14 TODO"></a>14 TODO</h3><hr>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><p><a href="https://blog.csdn.net/Bennnnnnn/article/details/128000842">https://blog.csdn.net/Bennnnnnn/article/details/128000842</a></p>
</li>
<li><p><a href="https://blog.csdn.net/mqdxiaoxiao/article/details/93644533">https://blog.csdn.net/mqdxiaoxiao/article/details/93644533</a></p>
</li>
<li><p><a href="https://blog.csdn.net/lengcs/article/details/143816877">https://blog.csdn.net/lengcs/article/details/143816877</a></p>
</li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title>ja方案调研</title>
    <url>/2025/03/17/ja%E6%96%B9%E6%A1%88%E8%B0%83%E7%A0%94/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近我们公司想与某上市公司合作的一个LLM应用的项目，本文记录下调研和思路历程，用作记录和分享。</p>
<span id="more"></span>

<hr>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在<strong>设备操作</strong>场景，一般情况下，操作员会按固定流程进行工具的操作，学员在刚接触工具使用时往往需要经历学习阶段，故需要<strong>有专业知识的指导员的指引和监督</strong>，随着deepseek的爆火，人们思考大语言模型在现实场景下的应用，那么这个场景怎么应用大语言模型来接替（或分担工作量）指导员的工作呢？</p>
<h2 id="任务拆解"><a href="#任务拆解" class="headerlink" title="任务拆解"></a>任务拆解</h2><p>想要分担指导员的工作量，主要需要：</p>
<ol>
<li>硬：大脑、眼睛、耳朵、嘴巴</li>
<li>软：专业知识</li>
</ol>
<p>其中：</p>
<ol>
<li>大脑+眼睛&#x3D;<strong>视觉大语言模型</strong></li>
<li>嘴巴负责教学（输出大脑给出的结果，即<strong>TTS</strong>模块）</li>
<li>耳朵负责听学员的问题（例如学员询问下一步该怎么作，即<strong>ASR</strong>模块）</li>
</ol>
<p>再细化，按实际<strong>使用场景</strong>来分类讨论具体实现方案：</p>
<p>**场景1：**文字问答（语音问答也属于此类，此类与视觉无关）</p>
<p>行业黑话（专有词汇）等专有知识的了解，</p>
<p>解决方案：RAG or 微调</p>
<p>建议：</p>
<p>专有知识的更新频率不高-&gt;微调；</p>
<p>专有知识的更新频率高-&gt;RAG；</p>
<p>另外，微调的成本要比RAG的高。</p>
<p>**场景2：**视觉问答</p>
<p>此场景指学员操作到某一步时，询问接下来该怎么操作，此处按学员的实际描述情况进行分类：</p>
<ol>
<li><p>学员描述：我已经完成了…，…, …,接下来应该做什么</p>
<p>这种情况可弱化为场景1的方式，无需视觉，将SOP（标准操作流程，Standard Operating Procedure）制作成RAG的向量数据库或直接将SOP作为prompt输入，或进行微调（将SOP置入大模型记忆）</p>
</li>
<li><p>学员描述：我接下来应该做什么？</p>
<p>这种情况仅从学员描述是得不到上文信息的（不知道已经做了什么，现在处于什么阶段），那么就需要摄像头来捕捉这些信息：</p>
<p>一种（思路）简单的解决方案：</p>
<p>**使用方式1：**摄像头用作录像功能，学员问问题（我接下来应该怎么做）时，将视频和问题传入视觉语言大模型(VLM, Qwen2.5 VL为例)，视觉语言大模型基于已有知识（需微调）和视频理解能力（模型自身结构设计和微调）做出回答。</p>
<p><strong>技术实现1（微调）：</strong></p>
<p>上述使用方式，仅需对VLM进行微调，需要视频数据：</p>
<ol>
<li>正确操作的视频</li>
<li>错误操作的视频</li>
</ol>
<p>使用上述两种视频进行标记，例（仅做说明）：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;video_id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;video_001&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;video_path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;path/to/video_001.mp4&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;frames&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span><span class="attr">&quot;frame_id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;frame_0001&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;image_path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;path/to/frame_0001.jpg&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span> <span class="string">&quot;厨师从冰箱中取出蔬菜。&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span><span class="attr">&quot;frame_id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;frame_0002&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;image_path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;path/to/frame_0002.jpg&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span> <span class="string">&quot;厨师在水槽前清洗蔬菜。&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span><span class="attr">&quot;frame_id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;frame_0003&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;image_path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;path/to/frame_0003.jpg&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span> <span class="string">&quot;厨师在砧板上切菜。&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span><span class="attr">&quot;frame_id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;frame_0004&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;image_path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;path/to/frame_0004.jpg&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span> <span class="string">&quot;厨师将切好的蔬菜放入锅中。&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span><span class="attr">&quot;frame_id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;frame_0005&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;image_path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;path/to/frame_0005.jpg&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span> <span class="string">&quot;厨师在炉灶上翻炒蔬菜。&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span><span class="attr">&quot;frame_id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;frame_0006&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;image_path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;path/to/frame_0006.jpg&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span> <span class="string">&quot;厨师将烹饪好的菜肴装盘。&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;qa_pairs&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;question&quot;</span><span class="punctuation">:</span> <span class="string">&quot;厨师从冰箱中取出了什么？&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;answer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;蔬菜&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;relevant_frames&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;frame_0001&quot;</span><span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;question&quot;</span><span class="punctuation">:</span> <span class="string">&quot;厨师在做什么准备工作？&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;answer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;清洗和切割蔬菜&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;relevant_frames&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;frame_0002&quot;</span><span class="punctuation">,</span> <span class="string">&quot;frame_0003&quot;</span><span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;question&quot;</span><span class="punctuation">:</span> <span class="string">&quot;蔬菜是如何烹饪的？&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;answer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;在锅中翻炒&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;relevant_frames&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;frame_0005&quot;</span><span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;question&quot;</span><span class="punctuation">:</span> <span class="string">&quot;最终的菜肴是如何处理的？&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;answer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;装盘&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;relevant_frames&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;frame_0006&quot;</span><span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>使用方式2（1的优化版本）：</strong></p>
<p>首先科普下从视频输入+文本问题-&gt;文本结果的总过程：</p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph LR</span><br><span class="line">    A[视频输入] --&gt; B[动态帧采样]</span><br><span class="line">    B --&gt; C[视频帧预处理]</span><br><span class="line">    C --&gt; D[视觉编码器ViT]</span><br><span class="line">    D --&gt; E[单帧特征提取]</span><br><span class="line">    E --&gt; F[时空联合建模]</span><br><span class="line">    F --&gt; G[时间位置编码mRoPE]</span><br><span class="line">    G --&gt; H[特征序列压缩]</span><br><span class="line">    H --&gt; I[跨模态注意力融合]</span><br><span class="line">    I --&gt; J[语言模型LLM]</span><br><span class="line">    J --&gt; K&#123;任务特定输出&#125;</span><br><span class="line">    K --&gt; L1[视觉问答VQA]</span><br><span class="line">    K --&gt; L2[操作步骤检测]</span><br><span class="line">    K --&gt; L3[异常报警]</span><br></pre></td></tr></table></figure>

<p><strong>流程说明：</strong></p>
<ol>
<li><strong>视频输入</strong>：摄像头实时画面或预录视频。</li>
<li><strong>动态帧采样</strong>：根据动作复杂度动态选择关键帧（<strong>如快速动作高采样率，静态场景低采样率</strong>）。</li>
<li><strong>（可选）视频帧预处理</strong>：数据增强（遮挡模拟、亮度调整）。</li>
<li><strong>视觉编码器</strong>：使用ViT或CLIP-ViT提取单帧特征。</li>
<li><strong>时空联合建模</strong>：通过时间注意力机制建模帧间关系。</li>
<li><strong>时间位置编码</strong>：使用mRoPE将时间戳编码为旋转矩阵，注入视觉特征。</li>
<li><strong>特征序列压缩</strong>：对长视频进行特征压缩（均值池化或可学习Token筛选）。</li>
<li><strong>跨模态注意力融合</strong>：视觉特征与语言特征（问题文本）通过交叉注意力交互。</li>
<li><strong>语言模型</strong>：生成任务相关输出（如VQA答案、操作步骤标签）。</li>
<li><strong>任务特定输出</strong>：根据任务类型设计输出头（如VQA、步骤检测、异常报警）。</li>
</ol>
<p>可以看到，在第八步跨模态注意力融合时才需要问题文本（即学员的问题），那么可以<strong>实时获取关键帧</strong>（动态帧采样策略），理论上会比方式1快一些（快多少需实测）</p>
<p>**场景3：**考试场景</p>
<p>此场景表示摄像头对学员操作过程录像，考试结束后（学员离场），VLM去逐帧分析视频（动态帧采样），判断操作过程有无错误。</p>
<p>方案：依旧是微调，方案同<strong>技术实现1</strong>。</p>
<h2 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h2><p>评估方法：构建测试数据集，人工测试各场景下的准确率。</p>
<h2 id="技术路线"><a href="#技术路线" class="headerlink" title="技术路线"></a>技术路线</h2><ol>
<li>数据准备</li>
<li>模型选择</li>
<li>模型微调</li>
<li>测试与优化</li>
<li>部署与运维</li>
</ol>
<h2 id="成本"><a href="#成本" class="headerlink" title="成本"></a>成本</h2><p><strong>人力：</strong></p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">场景1</th>
<th align="center">场景2</th>
<th align="center">场景3</th>
</tr>
</thead>
<tbody><tr>
<td align="center">需求确认与数据收集标准</td>
<td align="center">–</td>
<td align="center">20 工作日</td>
<td align="center">–</td>
</tr>
<tr>
<td align="center">数据制作（根据具体工作量）</td>
<td align="center">15工作日</td>
<td align="center">20工作日</td>
<td align="center">20工作日</td>
</tr>
<tr>
<td align="center">开发（微调）</td>
<td align="center">1个月</td>
<td align="center">30工作日</td>
<td align="center">30工作日</td>
</tr>
<tr>
<td align="center">测试与优化</td>
<td align="center">–</td>
<td align="center">30工作日</td>
<td align="center">–</td>
</tr>
</tbody></table>
<p>硬件成本：</p>
<table>
<thead>
<tr>
<th>微调</th>
<th>训练</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td></td>
</tr>
</tbody></table>
<h2 id="为什么选我们"><a href="#为什么选我们" class="headerlink" title="为什么选我们"></a>为什么选我们</h2><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文叙述了三个具体使用场景的基本方案，下一步将对微调数据集的具体策略进行设计，计划采用LoRA微调方式。</p>
]]></content>
      <categories>
        <category>theory</category>
      </categories>
      <tags>
        <tag>方案调研</tag>
      </tags>
  </entry>
  <entry>
    <title>langgraph介绍及demo</title>
    <url>/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在现代大模型应用开发中，构建能够处理复杂任务和多步骤推理的 Agent 是一个重要需求。<strong>LangGraph</strong> 是一个基于 LangChain 的框架，专门设计用于构建和编排复杂的 Agent 工作流。它通过图（Graph）结构定义任务流程，支持循环、分支、并行等复杂逻辑，是开发高效、灵活 Agent 应用的理想选择。</p>
<p>本文将介绍 LangGraph 的核心概念，并通过几个基础示例展示如何使用它构建 Agent 应用。</p>
<span id="more"></span>

<hr>
<h2 id="Langgraph"><a href="#Langgraph" class="headerlink" title="Langgraph"></a>Langgraph</h2><p>LangGraph 是一个基于图的框架，用于定义和运行复杂的 Agent 工作流。它的核心思想是将任务分解为多个节点（Node），并通过边（Edge）连接这些节点，形成一个有向图。每个节点可以执行特定的任务（如调用 API、生成文本、处理数据等），而边则定义了任务的执行顺序和条件分支。</p>
<h3 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h3><ol>
<li><strong>节点（Node）</strong>：任务的基本单元，每个节点执行特定的功能</li>
<li><strong>边（Edge）</strong>：连接节点的路径，定义任务的执行顺序</li>
<li><strong>图（Graph）</strong>：由节点和边组成的工作流</li>
<li><strong>条件分支（Conditional Edge）</strong>：根据条件决定下一步执行的节点</li>
<li><strong>循环（Cycle）</strong>：支持循环执行某些节点。</li>
</ol>
<hr>
<h2 id="LangGraph-的优势"><a href="#LangGraph-的优势" class="headerlink" title="LangGraph 的优势"></a>LangGraph 的优势</h2><ul>
<li><strong>灵活性</strong>：支持复杂的工作流设计，包括分支、循环和并行任务。</li>
<li><strong>模块化</strong>：将任务分解为多个节点，便于维护和扩展。</li>
<li><strong>高效性</strong>：通过图结构优化任务执行顺序，减少冗余计算。</li>
<li><strong>易用性</strong>：与 LangChain 无缝集成，提供丰富的工具和模块。</li>
</ul>
<hr>
<h2 id="示例1：构建基本聊天机器人"><a href="#示例1：构建基本聊天机器人" class="headerlink" title="示例1：构建基本聊天机器人"></a>示例1：构建基本聊天机器人</h2><figure class="highlight python"><figcaption><span>introduction_part1.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">https://langchain-ai.github.io/langgraph/tutorials/introduction/#part-1-build-a-basic-chatbot</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用局域网本地部署模型</span></span><br><span class="line"><span class="comment"># llm = ChatOpenAI(model_name=&quot;Qwen&quot;,</span></span><br><span class="line"><span class="comment">#                    openai_api_key=&#x27;Empty&#x27;,</span></span><br><span class="line"><span class="comment">#                    openai_api_base=&#x27;http://192.168.0.138:8000/v1&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置大模型参数</span></span><br><span class="line">LLM_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;sk-*******&quot;</span>,</span><br><span class="line">    <span class="string">&quot;base_url&quot;</span>: <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen2.5-7b-instruct&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化大模型</span></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=LLM_CONFIG[<span class="string">&quot;model&quot;</span>],</span><br><span class="line">    openai_api_key=LLM_CONFIG[<span class="string">&quot;api_key&quot;</span>],</span><br><span class="line">    openai_api_base=LLM_CONFIG[<span class="string">&quot;base_url&quot;</span>],</span><br><span class="line">    streaming=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [llm.invoke(state[<span class="string">&quot;messages&quot;</span>])]&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># The first argument is the unique node name</span></span><br><span class="line"><span class="comment"># The second argument is the function or object that will be called whenever</span></span><br><span class="line"><span class="comment"># the node is used.</span></span><br><span class="line">graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br><span class="line">graph_builder.set_entry_point(<span class="string">&quot;chatbot&quot;</span>)    <span class="comment"># graph_builder.add_edge(START, &quot;chatbot&quot;)</span></span><br><span class="line">graph_builder.set_finish_point(<span class="string">&quot;chatbot&quot;</span>)   <span class="comment"># graph_builder.add_edge(&quot;chatbot&quot;, END)</span></span><br><span class="line">graph = graph_builder.<span class="built_in">compile</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stream_graph_updates</span>(<span class="params">user_input: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="keyword">for</span> event <span class="keyword">in</span> graph.stream(&#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, user_input)]&#125;):</span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> event.values():</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Assistant:&quot;</span>, value[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].content)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        user_input = <span class="built_in">input</span>(<span class="string">&quot;User: &quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> user_input.lower() <span class="keyword">in</span> [<span class="string">&quot;quit&quot;</span>, <span class="string">&quot;exit&quot;</span>, <span class="string">&quot;q&quot;</span>]:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Goodbye!&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="comment"># fallback if input() is not available</span></span><br><span class="line">        user_input = <span class="string">&quot;What do you know about LangGraph?&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;User: &quot;</span> + user_input)</span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<p>主要流程：</p>
<ul>
<li>定义对话状态（State）</li>
<li>初始化Langgraph</li>
<li>配置LLM</li>
<li>定义聊天机器人（chatbot）</li>
<li>构建对话流，这里是最简单的线性结构</li>
<li>运行聊天循环</li>
</ul>
<img src="/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/image-20250211153745222.png" class="" title="image-20250211153745222">

<p><strong>代码拆解&amp;讲解：</strong></p>
<h3 id="TypedDict"><a href="#TypedDict" class="headerlink" title="TypedDict"></a>TypedDict</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br></pre></td></tr></table></figure>

<p>首先，<code>TypedDict</code> 是 Python 3.8+ 引入的一种<strong>类型提示工具</strong>，用于为字典定义结构化类型约束。<br>它本质上是<strong>一种“伪类”</strong>，但它的实例<strong>仍然是普通的 Python 字典</strong>，而不是类的实例。</p>
<p>是不是和<a href="https://caihaoran-00.github.io/2025/02/05/fastapi-request%E6%9E%84%E5%BB%BA%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BE%AE%E6%9C%8D%E5%8A%A1/#more">这里的</a><code>pydantic</code>的<code>BaseModel</code>模块（结构化类型约束方面）比较相似？：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"><span class="comment"># 定义请求数据模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">User</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    name: <span class="built_in">str</span></span><br><span class="line">    age: <span class="built_in">int</span></span><br><span class="line">    email: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span>  <span class="comment"># 可选字段</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># POST 接口，接收 JSON 请求体</span></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/users/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_user</span>(<span class="params">user: User</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;message&quot;</span>: <span class="string">&quot;用户已创建&quot;</span>, <span class="string">&quot;user&quot;</span>: user&#125;</span><br></pre></td></tr></table></figure>

<p>话说回来，为什么要使用<code>TypeDict</code>？</p>
<p>在Python中，字典是一种常见的数据结构：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">person = &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;Alice&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="number">25</span>&#125;</span><br></pre></td></tr></table></figure>

<p>有个问题：</p>
<ul>
<li>没有静态类型检查：<code>person[&quot;age&quot;]</code> 可能被意外赋值为 <code>str</code> 类型（如 <code>&quot;25&quot;</code>）。</li>
<li>没有固定结构：字典可以动态添加&#x2F;删除键，容易导致数据不一致。</li>
</ul>
<p>所以，<code>TypeDict</code>应运而生。</p>
<p><code>TypeDict</code>的基本用法</p>
<p>定义一个结构化的字典：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> TypedDict</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    name: <span class="built_in">str</span></span><br><span class="line">    age: <span class="built_in">int</span></span><br></pre></td></tr></table></figure>

<p>这个<code>Person</code><strong>看起来像类</strong>，但它<strong>不能被实例化</strong>（pyhton 3.8+版本不能实例化，Python3.9+就能实例化了，我使用的python 3.10+所以可以被实例化）：</p>
<figure class="highlight python"><figcaption><span>typeddict_t.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> TypedDict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    name: <span class="built_in">str</span></span><br><span class="line">    age: <span class="built_in">int</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">p = Person()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;p=<span class="subst">&#123;p&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;type(p)=<span class="subst">&#123;<span class="built_in">type</span>(p)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">p1 = &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;Alice&quot;</span>&#125;</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;type(p1)=<span class="subst">&#123;<span class="built_in">type</span>(p1)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">p2: Person = &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;Bob&quot;</span>&#125;</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;p2=<span class="subst">&#123;p2&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">p3: Person = &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;Alice&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="number">23</span>&#125;</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;p3=<span class="subst">&#123;p3&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">p4: Person = &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;Alice&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="string">&quot;23&quot;</span>&#125;</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;p4=<span class="subst">&#123;p4&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">p5: Person = &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;Alice&quot;</span>, <span class="string">&quot;age&quot;</span>: <span class="number">23</span>, <span class="string">&quot;height&quot;</span>: <span class="number">168</span>&#125;</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;p5=<span class="subst">&#123;p5&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<img src="/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/image-20250224115957563.png" class="" title="image-20250224115957563">

<img src="/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/image-20250224120037990.png" class="" title="image-20250224120037990">



<p><strong>注意注意注意：</strong></p>
<p>上面说的<strong>为字典定义结构化类型约束</strong>，并未体现出来啊，类型不匹配或者增加新的键值对不是也能运行吗？也没报错啊？好的，你越来越接近真相了，这里引入（科普）两个概念，</p>
<ul>
<li><p><strong>静态检查</strong>是在你运行代码之前（比如使用PyCharm的类型检查功能）进行的。这些工具会根据你写的类型提示（例如 TypedDict）来检查代码是否符合预期。如果发现类型不匹配，它们会给出警告或错误提示，但这并不会阻止代码运行。</p>
</li>
<li><p><strong>运行时</strong>则是在你点击“运行”之后，Python 真正执行你的代码。此时 Python 不会自动检查类型约束，所以即使类型不匹配（比如 p4 的 age 传了字符串），也不会报错。</p>
</li>
</ul>
<p>哦！明白了！原来TypedDict是作用在静态检查阶段的啊！就说为什么p2、p4和p5会出现阴影标注呢，而且鼠标放上去还会有提示，但实际上TypedDict并不影响运行时。</p>
<h3 id="Annotated"><a href="#Annotated" class="headerlink" title="Annotated"></a>Annotated</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br></pre></td></tr></table></figure>

<p>上文解释了TypedDict的作用，那么Annotated的作用是什么呢？</p>
<p><code>Annotated</code> 是 <code>typing</code> 模块中的一个工具，它的作用是：<br>💡 <strong>“给类型提示（Type Hint）添加额外的元数据（Metadata）。”</strong></p>
<p>简单来说，它可以在 <strong>类型上附加额外的信息</strong>，这些信息不会影响 Python 运行时的行为，但可以被工具（如 <code>mypy</code>、框架、库）用来做额外的检查或处理。</p>
<p>简单的Annotated例子：</p>
<figure class="highlight python"><figcaption><span>annotated_t.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel, Field</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 规定 age 只能在 0~120 之间</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Person</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    name: <span class="built_in">str</span></span><br><span class="line">    age: Annotated[<span class="built_in">int</span>, Field(ge=<span class="number">0</span>, le=<span class="number">120</span>)]  <span class="comment"># ge=greater or equal, le=less or equal</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">p = Person(name=<span class="string">&quot;Alice&quot;</span>, age=<span class="number">25</span>)  <span class="comment"># ✅ 正确</span></span><br><span class="line">p1 = Person(name=<span class="number">1</span>, age=<span class="number">25</span>)  <span class="comment"># ❌ 运行时报错</span></span><br><span class="line">p2 = Person(name=<span class="string">&quot;Bob&quot;</span>, age=<span class="number">150</span>)  <span class="comment"># ❌ 运行时报错</span></span><br></pre></td></tr></table></figure>

<p>哦，那看起来定义的这个State首先是个字典，然后键是”messages”，值对应的是个List，对这个messages附加的额外信息是add_messages，那么意思是他有自动累积历史对话的功能咯？验证一下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;[DEBUG] Incoming state[&#x27;messages&#x27;]: <span class="subst">&#123;state[<span class="string">&#x27;messages&#x27;</span>]&#125;</span>&quot;</span>)  <span class="comment"># 打印历史消息</span></span><br><span class="line">    response = llm.invoke(state[<span class="string">&quot;messages&quot;</span>])  <span class="comment"># 生成回复</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [response]&#125;  <span class="comment"># 仅返回当前的回复，不手动累积</span></span><br></pre></td></tr></table></figure>

<img src="/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/image-20250224151902529.png" class="" title="image-20250224151902529">

<p>可见，<strong>这里的add_messages并没有什么实际效果</strong>？</p>
<hr>
<h2 id="示例2：使用工具增强聊天机器人"><a href="#示例2：使用工具增强聊天机器人" class="headerlink" title="示例2：使用工具增强聊天机器人"></a>示例2：使用工具增强聊天机器人</h2><h3 id="自己构建方式"><a href="#自己构建方式" class="headerlink" title="自己构建方式"></a>自己构建方式</h3><ul>
<li><p>去<a href="https://tavily.com/">这里</a>申请下tavily的API_KEY</p>
</li>
<li><p>定义（调用）工具</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.tools.tavily_search <span class="keyword">import</span> TavilySearchResults</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;TAVILY_API_KEY&quot;</span>] = <span class="string">&quot;tvly-*****&quot;</span></span><br><span class="line">tool = TavilySearchResults(max_results=<span class="number">2</span>)</span><br><span class="line">tools = [tool]</span><br><span class="line">tool.invoke(<span class="string">&quot;What&#x27;s a &#x27;node&#x27; in LangGraph?&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">D:\Anaconda3\envs\langchain\python.exe E:\chr_git\langchain_t\langgraph\introduction_part2.py </span><br><span class="line">[&#123;<span class="string">&#x27;url&#x27;</span>: <span class="string">&#x27;https://medium.com/@kbdhunga/beginners-guide-to-langgraph-understanding-state-nodes-and-edges-part-1-897e6114fa48&#x27;</span>, <span class="string">&#x27;content&#x27;</span>: <span class="string">&quot;Beginner’s Guide to LangGraph: Understanding State, Nodes, and Edges — Part 1 | by Kamal Dhungana | Medium Beginner’s Guide to LangGraph: Understanding State, Nodes, and Edges — Part 1 LangGraph — State, Node and Edge Explained Mainly, we will focus on various components of LangGraph: State, Node, and Edges, and how to build a complete graph from these components. Once we understand these components, we will be able to build relatively complex LangGraph-based agents. Each node represents a specific function or operation that processes the current state. Nodes can perform computations, modify the state, or generate outputs based on the input they receive. Follow 1.2K Followers Data scientist with a passion for AI, Regularly blogging about LLM and OpenAI&#x27;s innovations,Sharing insights for AI community growth Follow&quot;</span>&#125;, &#123;<span class="string">&#x27;url&#x27;</span>: <span class="string">&#x27;https://blog.langchain.dev/langgraph/&#x27;</span>, <span class="string">&#x27;content&#x27;</span>: <span class="string">&#x27;TL;DR: LangGraph is module built on top of LangChain to better enable creation of cyclical graphs, often needed for agent runtimes. This state is updated by nodes in the graph, which return operations to attributes of this state (in the form of a key-value store). After adding nodes, you can then add edges to create the graph. An example of this may be in the basic agent runtime, where we always want the model to be called after we call a tool. graph.add_edge(&quot;tools&quot;, &quot;model&quot;) The state of this graph by default contains concepts that should be familiar to you if you\&#x27;ve used LangChain agents: input, chat_history, intermediate_steps (and agent_outcome to represent the most recent agent outcome)&#x27;</span>&#125;]</span><br><span class="line"></span><br><span class="line">进程已结束，退出代码为 <span class="number">0</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>结合示例1就得到了：</p>
</li>
</ul>
<figure class="highlight python"><figcaption><span>introduction_part2.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">https://langchain-ai.github.io/langgraph/tutorials/introduction/#requirements</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> langchain_community.tools.tavily_search <span class="keyword">import</span> TavilySearchResults</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;TAVILY_API_KEY&quot;</span>] = <span class="string">&quot;tvly-*****&quot;</span></span><br><span class="line"></span><br><span class="line">tool = TavilySearchResults(max_results=<span class="number">2</span>)</span><br><span class="line">tools = [tool]</span><br><span class="line"><span class="comment"># print(tool.invoke(&quot;What&#x27;s a &#x27;node&#x27; in LangGraph?&quot;))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph,START,END</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"><span class="comment"># llm = ChatOpenAI(model_name=&quot;Qwen&quot;,</span></span><br><span class="line"><span class="comment">#                    openai_api_key=&#x27;Empty&#x27;,</span></span><br><span class="line"><span class="comment">#                    openai_api_base=&#x27;http://192.168.0.138:8000/v1&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置大模型参数</span></span><br><span class="line">LLM_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;sk-***********&quot;</span>,</span><br><span class="line">    <span class="string">&quot;base_url&quot;</span>: <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen2.5-7b-instruct&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化大模型</span></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=LLM_CONFIG[<span class="string">&quot;model&quot;</span>],</span><br><span class="line">    openai_api_key=LLM_CONFIG[<span class="string">&quot;api_key&quot;</span>],</span><br><span class="line">    openai_api_base=LLM_CONFIG[<span class="string">&quot;base_url&quot;</span>],</span><br><span class="line">    streaming=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [llm_with_tools.invoke(state[<span class="string">&quot;messages&quot;</span>])]&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> ToolMessage</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BasicToolNode</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;A node that runs the tools requested in the last AIMessage.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, tools: <span class="built_in">list</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="variable language_">self</span>.tools_by_name = &#123;tool.name: tool <span class="keyword">for</span> tool <span class="keyword">in</span> tools&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, inputs: <span class="built_in">dict</span></span>):</span><br><span class="line">        <span class="keyword">if</span> messages := inputs.get(<span class="string">&quot;messages&quot;</span>, []):</span><br><span class="line">            message = messages[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;No message found in input&quot;</span>)</span><br><span class="line">        outputs = []</span><br><span class="line">        <span class="keyword">for</span> tool_call <span class="keyword">in</span> message.tool_calls:</span><br><span class="line">            tool_result = <span class="variable language_">self</span>.tools_by_name[tool_call[<span class="string">&quot;name&quot;</span>]].invoke(</span><br><span class="line">                tool_call[<span class="string">&quot;args&quot;</span>]</span><br><span class="line">            )</span><br><span class="line">            outputs.append(</span><br><span class="line">                ToolMessage(</span><br><span class="line">                    content=json.dumps(tool_result),</span><br><span class="line">                    name=tool_call[<span class="string">&quot;name&quot;</span>],</span><br><span class="line">                    tool_call_id=tool_call[<span class="string">&quot;id&quot;</span>],</span><br><span class="line">                )</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: outputs&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tool_node = BasicToolNode(tools=tools)</span><br><span class="line">graph_builder.add_node(<span class="string">&quot;tools&quot;</span>, tool_node)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Literal</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">route_tools</span>(<span class="params"></span></span><br><span class="line"><span class="params">    state: State,</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Use in the conditional_edge to route to the ToolNode if the last message</span></span><br><span class="line"><span class="string">    has tool calls. Otherwise, route to the end.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(state, <span class="built_in">list</span>):</span><br><span class="line">        ai_message = state[-<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">elif</span> messages := state.get(<span class="string">&quot;messages&quot;</span>, []):</span><br><span class="line">        ai_message = messages[-<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">f&quot;No messages found in input state to tool_edge: <span class="subst">&#123;state&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">hasattr</span>(ai_message, <span class="string">&quot;tool_calls&quot;</span>) <span class="keyword">and</span> <span class="built_in">len</span>(ai_message.tool_calls) &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;tools&quot;</span></span><br><span class="line">    <span class="keyword">return</span> END</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># The `tools_condition` function returns &quot;tools&quot; if the chatbot asks to use a tool, and &quot;END&quot; if</span></span><br><span class="line"><span class="comment"># it is fine directly responding. This conditional routing defines the main agent loop.</span></span><br><span class="line">graph_builder.add_conditional_edges(</span><br><span class="line">    <span class="string">&quot;chatbot&quot;</span>,</span><br><span class="line">    route_tools,</span><br><span class="line">    <span class="comment"># The following dictionary lets you tell the graph to interpret the condition&#x27;s outputs as a specific node</span></span><br><span class="line">    <span class="comment"># It defaults to the identity function, but if you</span></span><br><span class="line">    <span class="comment"># want to use a node named something else apart from &quot;tools&quot;,</span></span><br><span class="line">    <span class="comment"># You can update the value of the dictionary to something else</span></span><br><span class="line">    <span class="comment"># e.g., &quot;tools&quot;: &quot;my_tools&quot;</span></span><br><span class="line">    &#123;<span class="string">&quot;tools&quot;</span>: <span class="string">&quot;tools&quot;</span>, END: END&#125;,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># Any time a tool is called, we return to the chatbot to decide the next step</span></span><br><span class="line">graph_builder.add_edge(<span class="string">&quot;tools&quot;</span>, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph_builder.add_edge(START, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph = graph_builder.<span class="built_in">compile</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stream_graph_updates</span>(<span class="params">user_input: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="keyword">for</span> event <span class="keyword">in</span> graph.stream(&#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, user_input)]&#125;):</span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> event.values():</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Assistant:&quot;</span>, value[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].content)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        user_input = <span class="built_in">input</span>(<span class="string">&quot;User: &quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> user_input.lower() <span class="keyword">in</span> [<span class="string">&quot;quit&quot;</span>, <span class="string">&quot;exit&quot;</span>, <span class="string">&quot;q&quot;</span>]:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Goodbye!&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="comment"># fallback if input() is not available</span></span><br><span class="line">        user_input = <span class="string">&quot;What do you know about LangGraph?&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;User: &quot;</span> + user_input)</span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<img src="/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/image-20250225103010292.png" class="" title="image-20250225103010292">

<p>与示例1相比，有以下几个方面改动：</p>
<ul>
<li><p>定义（调用）了TavilySearchResults工具，并放在了tools列表中，最后通过bind_tools将tools列表与llm绑定，chatbot中的使用的是绑定tools后的llm，即llm_with_tools</p>
</li>
<li><p>新增了工具节点（node），通过BasicToolNode类来定义工具节点（tool_node），</p>
<ul>
<li><code>__init__</code>方法接受一个工具列表（每个工具对象都有name），然后把工具列表转换成字典，以工具的<code>name</code>作为键，这样就可以通过<code>name</code>直接查找工具，而不必遍历整个列表，提高查找速度。</li>
<li><code>__call__</code>方法使这个类的实例可以像函数一样调用</li>
<li><code>inputs: dict</code>：<strong>输入数据</strong>，其中应该包含 <code>&quot;messages&quot;</code>，记录了当前的对话历史。</li>
<li><code>inputs.get(&quot;messages&quot;, [])</code>：尝试获取 <code>&quot;messages&quot;</code>，如果不存在就返回空列表 <code>[]</code>。</li>
<li><code>message = messages[-1]</code>：获取最新的消息（通常是 AI 生成的回复）。最新的 AI 消息可能包含 <code>&quot;tool_calls&quot;</code>，这些是 AI 让工具执行的指令。如果 <code>&quot;messages&quot;</code> 为空，则抛出异常 <code>ValueError</code></li>
<li><code>message.tool_calls</code>：这个 AI 消息中的工具调用列表</li>
<li><code>for tool_call in message.tool_calls:</code>：<strong>遍历所有工具调用</strong></li>
<li><code>tool_call[&quot;name&quot;]</code>：从 <code>tool_call</code> 获取工具名称</li>
<li><code>self.tools_by_name[tool_call[&quot;name&quot;]]</code>：从 <code>self.tools_by_name</code> <strong>找到对应的工具</strong></li>
<li><code>.invoke(tool_call[&quot;args&quot;])</code>：<strong>调用工具</strong>，传入 <code>tool_call[&quot;args&quot;]</code> 作为参数，得到 <code>tool_result</code>（工具执行结果）</li>
<li><code>ToolMessage</code> 是 LangGraph 或 LangChain 中的工具调用响应格式，表示 <strong>工具的返回信息</strong>。</li>
<li><code>json.dumps(tool_result)</code>：将 <code>tool_result</code> 转换为 JSON 格式，方便传输</li>
<li><code>name=tool_call[&quot;name&quot;]</code>：工具的名称</li>
<li><code>tool_call_id=tool_call[&quot;id&quot;]</code>：工具调用的 ID（用于追踪）</li>
<li><code>outputs</code> 是<strong>所有工具执行结果的列表</strong></li>
<li>返回一个字典 <code>&#123;&quot;messages&quot;: outputs&#125;</code>，符合 <code>LangGraph</code> 处理节点的格式</li>
</ul>
</li>
<li><p>新增条件边（add_conditional_edges,  route_tools），根据AI生成的消息是否包含工具调用（tool calls）来决定下一个执行的节点。如果消息里有工具调用，就转到<code>tools</code>处理工具请求；否则，直接结束对话（<code>END</code>）</p>
<ul>
<li><p><code>route_tools</code>函数用在<code>graph_builder.add_conditional_edges</code>里，作用是决定对话流程的走向</p>
</li>
<li><p><code>state</code> 是 <code>TypedDict</code> 结构，包含一个 <code>&quot;messages&quot;</code> 键（通常是一个消息列表）</p>
</li>
<li><p>这个函数会<strong>检查最近的一条消息</strong>，看它是否包含 <code>&quot;tool_calls&quot;</code>，如果有，就返回 <code>&quot;tools&quot;</code>，否则返回 <code>&quot;END&quot;</code></p>
</li>
<li><p>检查 <code>state</code> 是否是<strong>列表</strong>：</p>
<ul>
<li><p>如果 <code>state</code> 是列表，就取最后一条消息（<code>state[-1]</code>）</p>
</li>
<li><p>这种情况可能出现在某些消息格式不同的情况，比如 <code>state</code> 直接是消息列表，而不是 <code>TypedDict</code> 结构</p>
</li>
<li><p><code>state.get(&quot;messages&quot;, [])</code> 尝试获取 <code>&quot;messages&quot;</code> 列表，默认返回 &#96;[]&#96;&#96;</p>
</li>
<li><p>&#96;&#96;:&#x3D;<code>（海象运算符）确保 </code>messages<code>变量赋值后能继续在</code>if&#96; 代码块中使用</p>
</li>
<li><p><code>messages[-1]</code> 取出最后一条消息</p>
</li>
<li><p>如果 <code>state</code> 既不是列表，也没有 <code>&quot;messages&quot;</code>，就报错，说明输入 <code>state</code> 结构不对</p>
</li>
</ul>
</li>
<li><p><code>hasattr(ai_message, &quot;tool_calls&quot;)</code> 检查 <code>ai_message</code> 是否有 <code>tool_calls</code> 属性</p>
</li>
<li><p><code>len(ai_message.tool_calls) &gt; 0</code> 确保 <code>tool_calls</code> 里确实有内容</p>
</li>
<li><p>如果 <code>tool_calls</code> <strong>存在且不为空</strong>，返回 <code>&quot;tools&quot;</code>，表示应该去工具节点处理工具请求</p>
</li>
<li><p>添加条件边（conditional edges），根据<code>route_tools</code>的返回值决定下一个节点</p>
</li>
<li><p><code>chatbot</code>是当前节点，表示从<code>chatbot</code>节点出发；<code>route_tools</code>是条件判断函数，会根据<code>state</code>判断下一个要走的路径；<code>&#123;&quot;tools&quot;: &quot;tools&quot;, END: END&#125;</code>定义了 <code>route_tools</code> 返回值和图节点的映射，如果 <code>route_tools</code> 返回 <code>&quot;tools&quot;</code>，那么<strong>跳转到 <code>&quot;tools&quot;</code> 节点</strong>，如果 <code>route_tools</code> 返回 <code>END</code>，那么<strong>跳转到 <code>END</code> 节点（结束对话）</strong></p>
</li>
</ul>
</li>
</ul>
<p><strong>总结：</strong></p>
<ul>
<li><p>首先LLM通过llm.bind_tools(tools)绑定一组工具tools，以告诉LLM可以调用哪些工具，同时定义每个工具的调用格式，让LLM生成符合格式的<code>tool_calls</code>请求</p>
</li>
<li><p>BasicToolNode负责执行工具</p>
</li>
<li><p>结合 <code>route_tools</code> 实现自动工具调用</p>
</li>
</ul>
<p>好的，这里的代码只是为了帮助理解<code>Langgraph</code>中的简单写法的基本原理，实际使用时这样使用：</p>
<figure class="highlight python"><figcaption><span>introduction_part2_simple.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">https://langchain-ai.github.io/langgraph/tutorials/introduction/#requirements</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> langchain_community.tools.tavily_search <span class="keyword">import</span> TavilySearchResults</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> ToolNode, tools_condition</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;TAVILY_API_KEY&quot;</span>] = <span class="string">&quot;tvly-***********&quot;</span></span><br><span class="line"></span><br><span class="line">tool = TavilySearchResults(max_results=<span class="number">2</span>)</span><br><span class="line">tools = [tool]</span><br><span class="line"><span class="comment"># print(tool.invoke(&quot;What&#x27;s a &#x27;node&#x27; in LangGraph?&quot;))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START, END</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"><span class="comment"># llm = ChatOpenAI(model_name=&quot;Qwen&quot;,</span></span><br><span class="line"><span class="comment">#                    openai_api_key=&#x27;Empty&#x27;,</span></span><br><span class="line"><span class="comment">#                    openai_api_base=&#x27;http://192.168.0.138:8000/v1&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置大模型参数</span></span><br><span class="line">LLM_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;sk-*********&quot;</span>,</span><br><span class="line">    <span class="string">&quot;base_url&quot;</span>: <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen2.5-7b-instruct&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化大模型</span></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=LLM_CONFIG[<span class="string">&quot;model&quot;</span>],</span><br><span class="line">    openai_api_key=LLM_CONFIG[<span class="string">&quot;api_key&quot;</span>],</span><br><span class="line">    openai_api_base=LLM_CONFIG[<span class="string">&quot;base_url&quot;</span>],</span><br><span class="line">    streaming=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    response = llm_with_tools.invoke(state[<span class="string">&quot;messages&quot;</span>])</span><br><span class="line">    <span class="comment"># print(&quot;Debug - chatbot response:&quot;, response)  # 调试信息</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [response]&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br><span class="line"></span><br><span class="line">tool_node = ToolNode(tools=[tool])</span><br><span class="line">graph_builder.add_node(<span class="string">&quot;tools&quot;</span>, tool_node)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_conditional_edges(</span><br><span class="line">    <span class="string">&quot;chatbot&quot;</span>,</span><br><span class="line">    tools_condition,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># Any time a tool is called, we return to the chatbot to decide the next step</span></span><br><span class="line">graph_builder.add_edge(<span class="string">&quot;tools&quot;</span>, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph_builder.add_edge(START, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph = graph_builder.<span class="built_in">compile</span>()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stream_graph_updates</span>(<span class="params">user_input: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="keyword">for</span> event <span class="keyword">in</span> graph.stream(&#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, user_input)]&#125;):</span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> event.values():</span><br><span class="line">            <span class="comment"># print(&quot;Debug - event value:&quot;, value)  # 调试信息</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Assistant:&quot;</span>, value[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].content)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        user_input = <span class="built_in">input</span>(<span class="string">&quot;User: &quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> user_input.lower() <span class="keyword">in</span> [<span class="string">&quot;quit&quot;</span>, <span class="string">&quot;exit&quot;</span>, <span class="string">&quot;q&quot;</span>]:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Goodbye!&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="comment"># fallback if input() is not available</span></span><br><span class="line">        user_input = <span class="string">&quot;What do you know about LangGraph?&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;User: &quot;</span> + user_input)</span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<p>与供理解版本相比：</p>
<ul>
<li>BasicToolNode-&gt;ToolNode</li>
<li>route_tools-&gt;tools_condition</li>
<li>也不再需要在add_conditional_edges中添加{“tools”: “tools”, END: END}</li>
</ul>
<img src="/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/image-20250225104331399.png" class="" title="image-20250225104331399">

<p>可看到目前确实是能调用网络搜索工具了，但是缺少：</p>
<ul>
<li>记忆功能</li>
<li>流式输出</li>
</ul>
<p>而且关于天气信息的网络搜索并不准确，星期几是正确的（后续关于天气查询和时间查询我会另开一个博客，<strong>对比原生实现和langgraph实现</strong>）</p>
<hr>
<h2 id="示例3：为聊天机器人添加内存（记忆）"><a href="#示例3：为聊天机器人添加内存（记忆）" class="headerlink" title="示例3：为聊天机器人添加内存（记忆）"></a>示例3：为聊天机器人添加内存（记忆）</h2><figure class="highlight python"><figcaption><span>introduction_part3.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">https://langchain-ai.github.io/langgraph/tutorials/introduction/#requirements</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> langchain_community.tools.tavily_search <span class="keyword">import</span> TavilySearchResults</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> ToolNode, tools_condition</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;TAVILY_API_KEY&quot;</span>] = <span class="string">&quot;tvly-************&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START, END</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"><span class="keyword">from</span> langgraph.checkpoint.memory <span class="keyword">import</span> MemorySaver</span><br><span class="line"></span><br><span class="line">memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line">tool = TavilySearchResults(max_results=<span class="number">2</span>)</span><br><span class="line">tools = [tool]</span><br><span class="line"></span><br><span class="line"><span class="comment"># llm = ChatOpenAI(model_name=&quot;Qwen&quot;,</span></span><br><span class="line"><span class="comment">#                    openai_api_key=&#x27;Empty&#x27;,</span></span><br><span class="line"><span class="comment">#                    openai_api_base=&#x27;http://192.168.0.138:8000/v1&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置大模型参数</span></span><br><span class="line">LLM_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;sk-**************&quot;</span>,</span><br><span class="line">    <span class="string">&quot;base_url&quot;</span>: <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen2.5-7b-instruct&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化大模型</span></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=LLM_CONFIG[<span class="string">&quot;model&quot;</span>],</span><br><span class="line">    openai_api_key=LLM_CONFIG[<span class="string">&quot;api_key&quot;</span>],</span><br><span class="line">    openai_api_base=LLM_CONFIG[<span class="string">&quot;base_url&quot;</span>],</span><br><span class="line">    streaming=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [llm_with_tools.invoke(state[<span class="string">&quot;messages&quot;</span>])]&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br><span class="line"></span><br><span class="line">tool_node = ToolNode(tools=[tool])</span><br><span class="line">graph_builder.add_node(<span class="string">&quot;tools&quot;</span>, tool_node)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_conditional_edges(</span><br><span class="line">    <span class="string">&quot;chatbot&quot;</span>,</span><br><span class="line">    tools_condition,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># Any time a tool is called, we return to the chatbot to decide the next step</span></span><br><span class="line">graph_builder.add_edge(<span class="string">&quot;tools&quot;</span>, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph_builder.add_edge(START, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph = graph_builder.<span class="built_in">compile</span>(checkpointer=memory)</span><br><span class="line"></span><br><span class="line">config = &#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: <span class="string">&quot;1&quot;</span>&#125;&#125;</span><br><span class="line">user_input = <span class="string">&quot;你好，我叫蔡&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The config is the **second positional argument** to stream() or invoke()!</span></span><br><span class="line">events = graph.stream(</span><br><span class="line">    &#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, user_input)]&#125;, config, stream_mode=<span class="string">&quot;values&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">for</span> event <span class="keyword">in</span> events:</span><br><span class="line">    event[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].pretty_print()</span><br><span class="line"></span><br><span class="line">user_input = <span class="string">&quot;我的名字是什么？&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The config is the **second positional argument** to stream() or invoke()!</span></span><br><span class="line">events = graph.stream(</span><br><span class="line">    &#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, user_input)]&#125;, config, stream_mode=<span class="string">&quot;values&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">for</span> event <span class="keyword">in</span> events:</span><br><span class="line">    event[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].pretty_print()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># The only difference is we change the `thread_id` here to &quot;2&quot; instead of &quot;1&quot;</span></span><br><span class="line">events = graph.stream(</span><br><span class="line">    &#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, user_input)]&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: <span class="string">&quot;2&quot;</span>&#125;&#125;,</span><br><span class="line">    stream_mode=<span class="string">&quot;values&quot;</span>,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">for</span> event <span class="keyword">in</span> events:</span><br><span class="line">    event[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].pretty_print()</span><br><span class="line"></span><br><span class="line">snapshot = graph.get_state(config)</span><br><span class="line"><span class="built_in">print</span>(snapshot)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(snapshot.<span class="built_in">next</span>)</span><br></pre></td></tr></table></figure>

<p>与示例2不同在于：</p>
<ul>
<li><p>创建一个<code>MemorySaver</code>检查点，<code>memory = MemorySaver()</code></p>
<blockquote>
<p>仅做示例，在生产应用程序中，您可能会将其更改为使用<code>SqliteSaver</code>或<code>PostgresSaver</code>并连接到您自己的数据库。</p>
</blockquote>
</li>
<li><p>使用提供的检查点编译图，<code>graph = graph_builder.compile(checkpointer=memory)</code></p>
</li>
<li><p>在<code>graph.stream</code>的第二个参数位置增加配置<code>config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</code></p>
</li>
</ul>
<p>注意事项：</p>
<ul>
<li>检查点针对各配置（thread_id）是分离的</li>
<li>注意体会下这个示例的graph.stream与上个示例的用法区别</li>
<li>可通过<code>snapshot = graph.get_state(config)</code>查看当前快照，其中包括当前状态值、相应的配置以及<code>next</code>要处理的节点。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">D:\Anaconda3\envs\langchain\python.exe E:\chr_git\langchain_t\langgraph\introduction_part3.py </span><br><span class="line">================================ Human Message =================================</span><br><span class="line"></span><br><span class="line">你好，我叫蔡</span><br><span class="line">================================== Ai Message ==================================</span><br><span class="line"></span><br><span class="line">你好，蔡！有什么问题或者需要帮助的吗？</span><br><span class="line">================================ Human Message =================================</span><br><span class="line"></span><br><span class="line">我的名字是什么？</span><br><span class="line">================================== Ai Message ==================================</span><br><span class="line"></span><br><span class="line">你的名字是蔡。如果你有任何其他问题或需要进一步的帮助，请告诉我！</span><br><span class="line">================================ Human Message =================================</span><br><span class="line"></span><br><span class="line">我的名字是什么？</span><br><span class="line">================================== Ai Message ==================================</span><br><span class="line"></span><br><span class="line">您没有在本次对话中提供您的名字。如果您希望我称呼您某个名字，或者想告诉我您的名字，请直接告诉我。</span><br><span class="line"></span><br><span class="line">StateSnapshot(values=&#123;<span class="string">&#x27;messages&#x27;</span>: [HumanMessage(content=<span class="string">&#x27;你好，我叫蔡&#x27;</span>, additional_kwargs=&#123;&#125;, response_metadata=&#123;&#125;, <span class="built_in">id</span>=<span class="string">&#x27;94cccb05-ee77-49d4-9183-563707c23b20&#x27;</span>), </span><br><span class="line">AIMessage(content=<span class="string">&#x27;你好，蔡！有什么问题或者需要帮助的吗？&#x27;</span>, additional_kwargs=&#123;&#125;, response_metadata=&#123;<span class="string">&#x27;finish_reason&#x27;</span>: <span class="string">&#x27;stop&#x27;</span>, <span class="string">&#x27;model_name&#x27;</span>: <span class="string">&#x27;qwen2.5-7b-instruct&#x27;</span>&#125;, <span class="built_in">id</span>=<span class="string">&#x27;run-ef5ba90c-dd2d-442b-9376-19e330d6aba8-0&#x27;</span>), </span><br><span class="line">                                   </span><br><span class="line">HumanMessage(content=<span class="string">&#x27;我的名字是什么？&#x27;</span>, additional_kwargs=&#123;&#125;, response_metadata=&#123;&#125;, <span class="built_in">id</span>=<span class="string">&#x27;fad15992-5dbf-46d6-9156-fd388dd32957&#x27;</span>), </span><br><span class="line">                                   </span><br><span class="line">AIMessage(content=<span class="string">&#x27;你的名字是蔡。如果你有任何其他问题或需要进一步的帮助，请告诉我！&#x27;</span>, additional_kwargs=&#123;&#125;, response_metadata=&#123;<span class="string">&#x27;finish_reason&#x27;</span>: <span class="string">&#x27;stop&#x27;</span>, <span class="string">&#x27;model_name&#x27;</span>: <span class="string">&#x27;qwen2.5-7b-instruct&#x27;</span>&#125;, <span class="built_in">id</span>=<span class="string">&#x27;run-11bf0ee6-2049-435c-81e7-da8ff47b95d8-0&#x27;</span>)]&#125;, <span class="built_in">next</span>=(), config=&#123;<span class="string">&#x27;configurable&#x27;</span>: &#123;<span class="string">&#x27;thread_id&#x27;</span>: <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;checkpoint_ns&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;checkpoint_id&#x27;</span>: <span class="string">&#x27;1eff3284-e246-66b1-8004-69625438a61d&#x27;</span>&#125;&#125;, metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;loop&#x27;</span>, <span class="string">&#x27;writes&#x27;</span>: &#123;<span class="string">&#x27;chatbot&#x27;</span>: &#123;<span class="string">&#x27;messages&#x27;</span>: [AIMessage(content=<span class="string">&#x27;你的名字是蔡。如果你有任何其他问题或需要进一步的帮助，请告诉我！&#x27;</span>, additional_kwargs=&#123;&#125;, response_metadata=&#123;<span class="string">&#x27;finish_reason&#x27;</span>: <span class="string">&#x27;stop&#x27;</span>, <span class="string">&#x27;model_name&#x27;</span>: <span class="string">&#x27;qwen2.5-7b-instruct&#x27;</span>&#125;, <span class="built_in">id</span>=<span class="string">&#x27;run-11bf0ee6-2049-435c-81e7-da8ff47b95d8-0&#x27;</span>)]&#125;&#125;, <span class="string">&#x27;thread_id&#x27;</span>: <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;step&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;parents&#x27;</span>: &#123;&#125;&#125;, created_at=<span class="string">&#x27;2025-02-25T03:26:30.701462+00:00&#x27;</span>, parent_config=&#123;<span class="string">&#x27;configurable&#x27;</span>: &#123;<span class="string">&#x27;thread_id&#x27;</span>: <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;checkpoint_ns&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;checkpoint_id&#x27;</span>: <span class="string">&#x27;1eff3284-db3b-656c-8003-08f03ddb0c2b&#x27;</span>&#125;&#125;, tasks=())</span><br><span class="line">()</span><br></pre></td></tr></table></figure>

<p>可见，现在已经为我们的聊天机器人添加内存（记忆）功能了，但现在还缺少流式输出功能。</p>
<hr>
<h2 id="示例4：流式输出"><a href="#示例4：流式输出" class="headerlink" title="示例4：流式输出"></a>示例4：流式输出</h2><p>先把示例3改成示例1 or 2 的写法（qwen2.5 7b试用完了，换个大模型）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.tools.tavily_search <span class="keyword">import</span> TavilySearchResults</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> ToolNode, tools_condition</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;TAVILY_API_KEY&quot;</span>] = <span class="string">&quot;tvly-*********************&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START, END</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"><span class="keyword">from</span> langgraph.checkpoint.memory <span class="keyword">import</span> MemorySaver</span><br><span class="line"></span><br><span class="line">memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line">tool = TavilySearchResults(max_results=<span class="number">2</span>)</span><br><span class="line">tools = [tool]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置大模型参数</span></span><br><span class="line">LLM_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;sk-****************&quot;</span>,</span><br><span class="line">    <span class="string">&quot;base_url&quot;</span>: <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen-max&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化大模型</span></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=LLM_CONFIG[<span class="string">&quot;model&quot;</span>],</span><br><span class="line">    openai_api_key=LLM_CONFIG[<span class="string">&quot;api_key&quot;</span>],</span><br><span class="line">    openai_api_base=LLM_CONFIG[<span class="string">&quot;base_url&quot;</span>],</span><br><span class="line">    streaming=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [llm_with_tools.invoke(state[<span class="string">&quot;messages&quot;</span>])]&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br><span class="line"></span><br><span class="line">tool_node = ToolNode(tools=[tool])</span><br><span class="line">graph_builder.add_node(<span class="string">&quot;tools&quot;</span>, tool_node)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_conditional_edges(</span><br><span class="line">    <span class="string">&quot;chatbot&quot;</span>,</span><br><span class="line">    tools_condition,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># Any time a tool is called, we return to the chatbot to decide the next step</span></span><br><span class="line">graph_builder.add_edge(<span class="string">&quot;tools&quot;</span>, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph_builder.add_edge(START, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph = graph_builder.<span class="built_in">compile</span>(checkpointer=memory)</span><br><span class="line"></span><br><span class="line">config = &#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: <span class="string">&quot;1&quot;</span>&#125;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stream_graph_updates</span>(<span class="params">user_input: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="keyword">for</span> event <span class="keyword">in</span> graph.stream(&#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, user_input)]&#125;, config, stream_mode=<span class="string">&quot;values&quot;</span>):</span><br><span class="line">        event[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].pretty_print()</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        user_input = <span class="built_in">input</span>(<span class="string">&quot;User: &quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> user_input.lower() <span class="keyword">in</span> [<span class="string">&quot;quit&quot;</span>, <span class="string">&quot;exit&quot;</span>, <span class="string">&quot;q&quot;</span>]:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Goodbye!&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="comment"># fallback if input() is not available</span></span><br><span class="line">        user_input = <span class="string">&quot;What do you know about LangGraph?&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;User: &quot;</span> + user_input)</span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">User: 你好</span><br><span class="line">================================ Human Message =================================</span><br><span class="line"></span><br><span class="line">你好</span><br><span class="line">================================== Ai Message ==================================</span><br><span class="line"></span><br><span class="line">你好！有什么可以帮助你的吗？</span><br><span class="line">User: 今天周几</span><br><span class="line">================================ Human Message =================================</span><br><span class="line"></span><br><span class="line">今天周几</span><br><span class="line">================================== Ai Message ==================================</span><br><span class="line"></span><br><span class="line">今天是周二。不过请注意，我基于的是标准时间，您可能需要根据您所在的时区进行调整。如果想要知道具体的日期信息，您可以查看设备上的日历或者问我<span class="string">&quot;今天具体是哪一天&quot;</span>。</span><br><span class="line">实际上，我没有直接访问实时日期和时间的功能。为了获取今天的准确星期几，请查看您的设备如手机、电脑右下角的时间显示，那里通常会显示当前的日期和星期。或者，如果您愿意告诉我您所在的时区，我可以尝试提供更具体的帮助。</span><br><span class="line">User: 今天中国星期几</span><br><span class="line">================================ Human Message =================================</span><br><span class="line"></span><br><span class="line">今天中国星期几</span><br><span class="line">================================== Ai Message ==================================</span><br><span class="line"></span><br><span class="line">要获取今天在中国是星期几的确切信息，我们可以通过查询当前的日期来确定。让我来帮您查找一下今天的具体日期。</span><br><span class="line">Tool Calls:</span><br><span class="line">  tavily_search_results_json (call_145884c25be845efbdb348)</span><br><span class="line"> Call ID: call_145884c25be845efbdb348</span><br><span class="line">  Args:</span><br><span class="line">    query: 今天的日期 中国</span><br><span class="line">================================= Tool Message =================================</span><br><span class="line">Name: tavily_search_results_json</span><br><span class="line"></span><br><span class="line">[&#123;<span class="string">&quot;url&quot;</span>: <span class="string">&quot;http://date.china6636.com/&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;中国今天几号? 答案: 2025年2月28日星期五. 中国現在是2025年2月28日星期五. 今天是2025年第59天. 今年还剩下306天. 本周是2025年的第9周。 2025二月日历. 星期一, 星期二&quot;</span>&#125;, &#123;<span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://time.is/zh_tw/China&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;中国 的現在時間是. 您的時間晚了20 小時, 1 分又40.1 秒. 對時準確度為±0.005 秒. 04:01:45. 2025年二月28日，星期五，第9週. Rare Disease Day. 太陽： ↑ 07:29 ↓ 18&quot;</span>&#125;]</span><br><span class="line">================================== Ai Message ==================================</span><br><span class="line"></span><br><span class="line">今天在中国是<span class="number">2025</span>年<span class="number">2</span>月<span class="number">28</span>日，星期五。如果您有任何基于这个信息的计划或需要进一步的帮助，请告诉我！</span><br><span class="line">User: </span><br></pre></td></tr></table></figure>

<p>✨好的，那么我想流式输出token，怎么办呢，同时也不想看到与AI回复不直接相关的文字，怎么办：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">https://langchain-ai.github.io/langgraph/tutorials/introduction/#requirements</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> langchain_community.tools.tavily_search <span class="keyword">import</span> TavilySearchResults</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> HumanMessage, AIMessageChunk</span><br><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> ToolNode, tools_condition</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;TAVILY_API_KEY&quot;</span>] = <span class="string">&quot;tvly-xxxxxxxxxxxxxxxxxx&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START, END</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"><span class="keyword">from</span> langgraph.checkpoint.memory <span class="keyword">import</span> MemorySaver</span><br><span class="line"></span><br><span class="line">memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line">tool = TavilySearchResults(max_results=<span class="number">2</span>)</span><br><span class="line">tools = [tool]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置大模型参数</span></span><br><span class="line">LLM_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;sk-xxxxxxxxxxxxxxxxxxx&quot;</span>,</span><br><span class="line">    <span class="string">&quot;base_url&quot;</span>: <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen-max&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化大模型</span></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=LLM_CONFIG[<span class="string">&quot;model&quot;</span>],</span><br><span class="line">    openai_api_key=LLM_CONFIG[<span class="string">&quot;api_key&quot;</span>],</span><br><span class="line">    openai_api_base=LLM_CONFIG[<span class="string">&quot;base_url&quot;</span>],</span><br><span class="line">    streaming=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [llm_with_tools.invoke(state[<span class="string">&quot;messages&quot;</span>])]&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br><span class="line"></span><br><span class="line">tool_node = ToolNode(tools=[tool])</span><br><span class="line">graph_builder.add_node(<span class="string">&quot;tools&quot;</span>, tool_node)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_conditional_edges(</span><br><span class="line">    <span class="string">&quot;chatbot&quot;</span>,</span><br><span class="line">    tools_condition,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># Any time a tool is called, we return to the chatbot to decide the next step</span></span><br><span class="line">graph_builder.add_edge(<span class="string">&quot;tools&quot;</span>, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph_builder.add_edge(START, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph = graph_builder.<span class="built_in">compile</span>(checkpointer=memory)</span><br><span class="line"></span><br><span class="line">config = &#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: <span class="string">&quot;1&quot;</span>&#125;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stream_graph_updates</span>(<span class="params">user_input: <span class="built_in">str</span></span>):</span><br><span class="line">    first = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">for</span> msg, metadata <span class="keyword">in</span> graph.stream(&#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, user_input)]&#125;, config, stream_mode=<span class="string">&quot;messages&quot;</span>):</span><br><span class="line">        <span class="comment"># 仅处理AI生成的消息快</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk) <span class="keyword">and</span> msg.content:</span><br><span class="line">            <span class="built_in">print</span>(msg.content, end=<span class="string">&quot;|&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk):</span><br><span class="line">            <span class="keyword">if</span> first:</span><br><span class="line">                gathered = msg</span><br><span class="line">                first = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                gathered = gathered + msg</span><br><span class="line"></span><br><span class="line">            <span class="comment"># if msg.tool_call_chunks:</span></span><br><span class="line">            <span class="comment">#     print(gathered.tool_calls)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        user_input = <span class="built_in">input</span>(<span class="string">&quot;User: &quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> user_input.lower() <span class="keyword">in</span> [<span class="string">&quot;quit&quot;</span>, <span class="string">&quot;exit&quot;</span>, <span class="string">&quot;q&quot;</span>]:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Goodbye!&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="comment"># fallback if input() is not available</span></span><br><span class="line">        user_input = <span class="string">&quot;What do you know about LangGraph?&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;User: &quot;</span> + user_input)</span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">User: 今天中国是几月几号</span><br><span class="line">根|据搜索结果，|目前中国的日期是|<span class="number">2025</span>|年<span class="number">2</span>月<span class="number">2</span>|<span class="number">8</span>日星期五|。</span><br><span class="line"></span><br><span class="line">- [时间|网站](https://|time.<span class="keyword">is</span>/zh|_tw/China)|上显示的具体时间为|：04:|01:<span class="number">4</span>|<span class="number">5</span>（北京时间）|。</span><br><span class="line">-| 而在中国<span class="number">66</span>|<span class="number">36</span>网上则是|直接给出日期：|<span class="number">2025</span>|年<span class="number">2</span>月<span class="number">2</span>|<span class="number">8</span>日星期五|。</span><br><span class="line"></span><br><span class="line">请注意，这些|信息可能因为时|区差异而有所不同|，上述时间是|基于北京时间。|</span><br><span class="line"></span><br><span class="line">User: 我叫蔡浩然</span><br><span class="line">很高兴|认识|你|，蔡浩然|！有什么问题或者|需要帮助的吗|？|</span><br><span class="line"></span><br><span class="line">User: 我叫什么名字</span><br><span class="line">您|叫|蔡|浩然。| </span><br></pre></td></tr></table></figure>

<p>✨我真厉害😁。</p>
<hr>
<h2 id="示例5：自定义工具"><a href="#示例5：自定义工具" class="headerlink" title="示例5：自定义工具"></a>示例5：自定义工具</h2><p>前面使用的工具为langchain提供的TavilySearchResults工具，那如果我想自己定义个工具呢？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> langchain_community.tools.tavily_search <span class="keyword">import</span> TavilySearchResults</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> HumanMessage, AIMessageChunk</span><br><span class="line"><span class="keyword">from</span> langchain_core.tools <span class="keyword">import</span> tool</span><br><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> ToolNode, tools_condition</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;TAVILY_API_KEY&quot;</span>] = <span class="string">&quot;tvly-xxxxxxxxxxxxxxxxx&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START, END</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"><span class="keyword">from</span> langgraph.checkpoint.memory <span class="keyword">import</span> MemorySaver</span><br><span class="line"></span><br><span class="line">memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@tool</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_current_time</span>(<span class="params">region: <span class="built_in">str</span> = <span class="literal">None</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Get the current time for a given region/timezone.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">    region (str): The region to query, e.g., &quot;Asia/Shanghai&quot;。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># 新API端点</span></span><br><span class="line">        <span class="keyword">if</span> region:</span><br><span class="line">            url = <span class="string">f&quot;https://timeapi.io/api/Time/current/zone?timeZone=<span class="subst">&#123;region&#125;</span>&quot;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> (<span class="string">&quot;Location information is not available, so bring it with you when asking for the time, e.g.,&quot;</span></span><br><span class="line">                    <span class="string">&quot; what time is it in San Francisco&quot;</span>)</span><br><span class="line"></span><br><span class="line">        response = requests.get(url, timeout=<span class="number">5</span>)</span><br><span class="line">        response.raise_for_status()</span><br><span class="line">        data = response.json()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 解析新API的响应格式</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;current time of <span class="subst">&#123;region&#125;</span>: <span class="subst">&#123;data[<span class="string">&#x27;hour&#x27;</span>]:02d&#125;</span>:<span class="subst">&#123;data[<span class="string">&#x27;minute&#x27;</span>]:02d&#125;</span>:<span class="subst">&#123;data[<span class="string">&#x27;seconds&#x27;</span>]:02d&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;API call error details：<span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Unable to get time information, please try again later&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试新API</span></span><br><span class="line"><span class="built_in">print</span>(get_current_time.invoke(&#123;<span class="string">&quot;region&quot;</span>: <span class="string">&quot;Asia/Shanghai&quot;</span>&#125;))  <span class="comment"># 应输出类似：Asia/Shanghai当前时间: 15:30:45</span></span><br><span class="line"><span class="built_in">print</span>(get_current_time.invoke(&#123;&#125;))</span><br><span class="line"></span><br><span class="line">tool = TavilySearchResults(max_results=<span class="number">2</span>)</span><br><span class="line">tools = [tool, get_current_time]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置大模型参数</span></span><br><span class="line">LLM_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;sk-xxxxxxxxxxxxxxx&quot;</span>,</span><br><span class="line">    <span class="string">&quot;base_url&quot;</span>: <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen-max&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化大模型</span></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=LLM_CONFIG[<span class="string">&quot;model&quot;</span>],</span><br><span class="line">    openai_api_key=LLM_CONFIG[<span class="string">&quot;api_key&quot;</span>],</span><br><span class="line">    openai_api_base=LLM_CONFIG[<span class="string">&quot;base_url&quot;</span>],</span><br><span class="line">    streaming=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [llm_with_tools.invoke(state[<span class="string">&quot;messages&quot;</span>])]&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br><span class="line"></span><br><span class="line">tool_node = ToolNode(tools=tools)</span><br><span class="line">graph_builder.add_node(<span class="string">&quot;tools&quot;</span>, tool_node)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_conditional_edges(</span><br><span class="line">    <span class="string">&quot;chatbot&quot;</span>,</span><br><span class="line">    tools_condition,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># Any time a tool is called, we return to the chatbot to decide the next step</span></span><br><span class="line">graph_builder.add_edge(<span class="string">&quot;tools&quot;</span>, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph_builder.add_edge(START, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph = graph_builder.<span class="built_in">compile</span>(checkpointer=memory)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">config = &#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: <span class="string">&quot;1&quot;</span>&#125;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stream_graph_updates</span>(<span class="params">user_input: <span class="built_in">str</span></span>):</span><br><span class="line">    first = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">for</span> msg, metadata <span class="keyword">in</span> graph.stream(&#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, user_input)]&#125;, config, stream_mode=<span class="string">&quot;messages&quot;</span>):</span><br><span class="line">        <span class="comment"># 仅处理AI生成的消息快</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk) <span class="keyword">and</span> msg.content:</span><br><span class="line">            <span class="built_in">print</span>(msg.content, end=<span class="string">&quot;|&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk):</span><br><span class="line">            <span class="keyword">if</span> first:</span><br><span class="line">                gathered = msg</span><br><span class="line">                first = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                gathered = gathered + msg</span><br><span class="line"></span><br><span class="line">            <span class="comment"># if msg.tool_call_chunks:</span></span><br><span class="line">            <span class="comment">#     print(gathered.tool_calls)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        user_input = <span class="built_in">input</span>(<span class="string">&quot;User: &quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> user_input.lower() <span class="keyword">in</span> [<span class="string">&quot;quit&quot;</span>, <span class="string">&quot;exit&quot;</span>, <span class="string">&quot;q&quot;</span>]:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Goodbye!&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="comment"># fallback if input() is not available</span></span><br><span class="line">        user_input = <span class="string">&quot;What do you know about LangGraph?&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;User: &quot;</span> + user_input)</span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">current time of Asia/Shanghai: <span class="number">14</span>:<span class="number">40</span>:<span class="number">36</span></span><br><span class="line">Location information <span class="keyword">is</span> <span class="keyword">not</span> available, so bring it <span class="keyword">with</span> you when asking <span class="keyword">for</span> the time, e.g., what time <span class="keyword">is</span> it <span class="keyword">in</span> San Francisco</span><br><span class="line">User: what time <span class="keyword">is</span> it <span class="keyword">in</span> San Francisco</span><br><span class="line">The| current| time <span class="keyword">in</span> San Francisco| <span class="keyword">is</span> <span class="number">22</span>|:<span class="number">41</span>:|<span class="number">03.</span>|</span><br><span class="line">User: what time <span class="keyword">is</span> it</span><br><span class="line">Could| you| please| specify the region <span class="keyword">or</span>| timezone you want to| know the time about|?|</span><br><span class="line">User: San Francisco</span><br><span class="line"></span><br><span class="line">The current time <span class="keyword">in</span>| San Francisco <span class="keyword">is</span>| <span class="number">22</span>:<span class="number">4</span>|<span class="number">2</span>:05|.|</span><br><span class="line">User: ok,my name <span class="keyword">is</span> caihaoran</span><br><span class="line">Nice| to meet you,| Caihaoran|! How can I| assist you further?|</span><br><span class="line">User: what<span class="string">&#x27;s my name</span></span><br><span class="line"><span class="string">Your| name| is| Caihaoran|. How can I| assist you further,| Caihaoran|?|</span></span><br></pre></td></tr></table></figure>

<p>重点注意其中的<code>get_current_time</code>函数，</p>
<ul>
<li><code>@tool</code> 用于标记函数，使其可以被 LangChain 作为工具调用</li>
<li>LLM 可以基于 <code>docstring</code>（文档字符串）理解工具的用途和参数</li>
<li><code>region</code> 表示时区，例如 <code>&quot;Asia/Shanghai&quot;</code>。<strong>默认值 <code>None</code></strong>：如果用户没有提供时区，则返回提示信息，要求用户提供具体的地点</li>
<li>通过 <code>https://timeapi.io/api/Time/current/zone?timeZone=&#123;region&#125;</code> 获取时间。使用 <code>requests.get(url, timeout=5)</code> 发送请求，并解析返回的 JSON 数据</li>
</ul>
<hr>
<h2 id="示例6：系统提示词"><a href="#示例6：系统提示词" class="headerlink" title="示例6：系统提示词"></a>示例6：系统提示词</h2><p>回到最原始的问题，Langgraph的系统提示词（Prompt）怎么添加？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">stream_graph_updates</span>(<span class="params">user_input: <span class="built_in">str</span></span>):</span><br><span class="line">    system_message = (<span class="string">&quot;You are a lively and lovely little assistant, whose name is Xiao CAI. You always answer questions in a humorous, funny, light-hearted way.&quot;</span>)</span><br><span class="line">    first = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">for</span> msg, metadata <span class="keyword">in</span> graph.stream(</span><br><span class="line">        &#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;system&quot;</span>, system_message), (<span class="string">&quot;user&quot;</span>, user_input)]&#125;, </span><br><span class="line">        config, </span><br><span class="line">        stream_mode=<span class="string">&quot;messages&quot;</span></span><br><span class="line">    ):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk) <span class="keyword">and</span> msg.content:</span><br><span class="line">            <span class="built_in">print</span>(msg.content, end=<span class="string">&quot;|&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk):</span><br><span class="line">            <span class="keyword">if</span> first:</span><br><span class="line">                gathered = msg</span><br><span class="line">                first = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                gathered = gathered + msg</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">User: Hi,What<span class="string">&#x27;s your name?</span></span><br><span class="line"><span class="string">Hey| there|!| I&#x27;</span>m Xiao CA|I, your lively| <span class="keyword">and</span> lovely little assistant| <span class="keyword">with</span> a dash of| humor. How can| I make your day| brighter? 😊|✨|</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="示例7：终极简化版"><a href="#示例7：终极简化版" class="headerlink" title="示例7：终极简化版"></a>示例7：终极简化版</h2><p>好的，现在看看代码成什么样子了：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> langchain_community.tools.tavily_search <span class="keyword">import</span> TavilySearchResults</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> HumanMessage, AIMessageChunk</span><br><span class="line"><span class="keyword">from</span> langchain_core.tools <span class="keyword">import</span> tool</span><br><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> ToolNode, tools_condition</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;TAVILY_API_KEY&quot;</span>] = <span class="string">&quot;tvly-xxxxxxxxxxxxxx&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START, END</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"><span class="keyword">from</span> langgraph.checkpoint.memory <span class="keyword">import</span> MemorySaver</span><br><span class="line"></span><br><span class="line">memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"><span class="meta">@tool</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_current_time</span>(<span class="params">region: <span class="built_in">str</span> = <span class="literal">None</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Get the current time for a given region/timezone.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">    region (str): The region to query, e.g., &quot;Asia/Shanghai&quot;。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># 新API端点</span></span><br><span class="line">        <span class="keyword">if</span> region:</span><br><span class="line">            url = <span class="string">f&quot;https://timeapi.io/api/Time/current/zone?timeZone=<span class="subst">&#123;region&#125;</span>&quot;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> (<span class="string">&quot;Location information is not available, so bring it with you when asking for the time, e.g.,&quot;</span></span><br><span class="line">                    <span class="string">&quot; what time is it in San Francisco&quot;</span>)</span><br><span class="line"></span><br><span class="line">        response = requests.get(url, timeout=<span class="number">5</span>)</span><br><span class="line">        response.raise_for_status()</span><br><span class="line">        data = response.json()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 解析新API的响应格式</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;current time of <span class="subst">&#123;region&#125;</span>: <span class="subst">&#123;data[<span class="string">&#x27;hour&#x27;</span>]:02d&#125;</span>:<span class="subst">&#123;data[<span class="string">&#x27;minute&#x27;</span>]:02d&#125;</span>:<span class="subst">&#123;data[<span class="string">&#x27;seconds&#x27;</span>]:02d&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;API call error details：<span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Unable to get time information, please try again later&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试新API</span></span><br><span class="line"><span class="built_in">print</span>(get_current_time.invoke(&#123;<span class="string">&quot;region&quot;</span>: <span class="string">&quot;Asia/Shanghai&quot;</span>&#125;))  <span class="comment"># 应输出类似：Asia/Shanghai当前时间: 15:30:45</span></span><br><span class="line"><span class="built_in">print</span>(get_current_time.invoke(&#123;&#125;))</span><br><span class="line"></span><br><span class="line">tool = TavilySearchResults(max_results=<span class="number">2</span>)</span><br><span class="line">tools = [tool, get_current_time]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置大模型参数</span></span><br><span class="line">LLM_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;sk-xxxxxxxxxxxxxxxxxxxxxxx&quot;</span>,</span><br><span class="line">    <span class="string">&quot;base_url&quot;</span>: <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen-max&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化大模型</span></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=LLM_CONFIG[<span class="string">&quot;model&quot;</span>],</span><br><span class="line">    openai_api_key=LLM_CONFIG[<span class="string">&quot;api_key&quot;</span>],</span><br><span class="line">    openai_api_base=LLM_CONFIG[<span class="string">&quot;base_url&quot;</span>],</span><br><span class="line">    streaming=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [llm_with_tools.invoke(state[<span class="string">&quot;messages&quot;</span>])]&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br><span class="line"></span><br><span class="line">tool_node = ToolNode(tools=tools)</span><br><span class="line">graph_builder.add_node(<span class="string">&quot;tools&quot;</span>, tool_node)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_conditional_edges(</span><br><span class="line">    <span class="string">&quot;chatbot&quot;</span>,</span><br><span class="line">    tools_condition,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># Any time a tool is called, we return to the chatbot to decide the next step</span></span><br><span class="line">graph_builder.add_edge(<span class="string">&quot;tools&quot;</span>, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph_builder.add_edge(START, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph = graph_builder.<span class="built_in">compile</span>(checkpointer=memory)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">config = &#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: <span class="string">&quot;1&quot;</span>&#125;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stream_graph_updates</span>(<span class="params">user_input: <span class="built_in">str</span></span>):</span><br><span class="line">    system_message = (<span class="string">&quot;You are a lively and lovely little assistant, whose name is Xiao CAI. You always answer questions in a humorous, funny, light-hearted way.&quot;</span>)</span><br><span class="line">    first = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">for</span> msg, metadata <span class="keyword">in</span> graph.stream(</span><br><span class="line">        &#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;system&quot;</span>, system_message), (<span class="string">&quot;user&quot;</span>, user_input)]&#125;, </span><br><span class="line">        config, </span><br><span class="line">        stream_mode=<span class="string">&quot;messages&quot;</span></span><br><span class="line">    ):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk) <span class="keyword">and</span> msg.content:</span><br><span class="line">            <span class="built_in">print</span>(msg.content, end=<span class="string">&quot;|&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk):</span><br><span class="line">            <span class="keyword">if</span> first:</span><br><span class="line">                gathered = msg</span><br><span class="line">                first = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                gathered = gathered + msg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        user_input = <span class="built_in">input</span>(<span class="string">&quot;User: &quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> user_input.lower() <span class="keyword">in</span> [<span class="string">&quot;quit&quot;</span>, <span class="string">&quot;exit&quot;</span>, <span class="string">&quot;q&quot;</span>]:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Goodbye!&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="comment"># fallback if input() is not available</span></span><br><span class="line">        user_input = <span class="string">&quot;What do you know about LangGraph?&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;User: &quot;</span> + user_input)</span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<p><a href="https://langchain-ai.github.io/langgraph/#example">参考链接4</a>，可将代码简化为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> langchain_community.tools.tavily_search <span class="keyword">import</span> TavilySearchResults</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> AIMessageChunk</span><br><span class="line"><span class="keyword">from</span> langchain_core.tools <span class="keyword">import</span> tool</span><br><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> create_react_agent</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;TAVILY_API_KEY&quot;</span>] = <span class="string">&quot;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&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> langgraph.checkpoint.memory <span class="keyword">import</span> MemorySaver</span><br><span class="line"></span><br><span class="line">memory = MemorySaver()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@tool</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_current_time</span>(<span class="params">region: <span class="built_in">str</span> = <span class="literal">None</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Get the current time for a given region/timezone.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters:</span></span><br><span class="line"><span class="string">    region (str): The region to query, e.g., &quot;Asia/Shanghai&quot;。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># 新API端点</span></span><br><span class="line">        <span class="keyword">if</span> region:</span><br><span class="line">            url = <span class="string">f&quot;https://timeapi.io/api/Time/current/zone?timeZone=<span class="subst">&#123;region&#125;</span>&quot;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> (<span class="string">&quot;Location information is not available, so bring it with you when asking for the time, e.g.,&quot;</span></span><br><span class="line">                    <span class="string">&quot; what time is it in San Francisco&quot;</span>)</span><br><span class="line"></span><br><span class="line">        response = requests.get(url, timeout=<span class="number">5</span>)</span><br><span class="line">        response.raise_for_status()</span><br><span class="line">        data = response.json()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 解析新API的响应格式</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;current time of <span class="subst">&#123;region&#125;</span>: <span class="subst">&#123;data[<span class="string">&#x27;hour&#x27;</span>]:02d&#125;</span>:<span class="subst">&#123;data[<span class="string">&#x27;minute&#x27;</span>]:02d&#125;</span>:<span class="subst">&#123;data[<span class="string">&#x27;seconds&#x27;</span>]:02d&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;API call error details：<span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Unable to get time information, please try again later&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tool = TavilySearchResults(max_results=<span class="number">2</span>)</span><br><span class="line">tools = [tool, get_current_time]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置大模型参数</span></span><br><span class="line">LLM_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;sk-9fa12110ca284e969fa5757a7b865f50&quot;</span>,</span><br><span class="line">    <span class="string">&quot;base_url&quot;</span>: <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen-max&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化大模型</span></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=LLM_CONFIG[<span class="string">&quot;model&quot;</span>],</span><br><span class="line">    openai_api_key=LLM_CONFIG[<span class="string">&quot;api_key&quot;</span>],</span><br><span class="line">    openai_api_base=LLM_CONFIG[<span class="string">&quot;base_url&quot;</span>],</span><br><span class="line">    streaming=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">config = &#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: <span class="string">&quot;1&quot;</span>&#125;&#125;</span><br><span class="line">graph = create_react_agent(llm, tools, checkpointer=memory)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stream_graph_updates</span>(<span class="params">user_input: <span class="built_in">str</span></span>):</span><br><span class="line">    first = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">for</span> msg, metadata <span class="keyword">in</span> graph.stream(&#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, user_input)]&#125;, config, stream_mode=<span class="string">&quot;messages&quot;</span>):</span><br><span class="line">        <span class="comment"># 仅处理AI生成的消息快</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk) <span class="keyword">and</span> msg.content:</span><br><span class="line">            <span class="built_in">print</span>(msg.content, end=<span class="string">&quot;|&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk):</span><br><span class="line">            <span class="keyword">if</span> first:</span><br><span class="line">                gathered = msg</span><br><span class="line">                first = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                gathered = gathered + msg</span><br><span class="line"></span><br><span class="line">            <span class="comment"># if msg.tool_call_chunks:</span></span><br><span class="line">            <span class="comment">#     print(gathered.tool_calls)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        user_input = <span class="built_in">input</span>(<span class="string">&quot;User: &quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> user_input.lower() <span class="keyword">in</span> [<span class="string">&quot;quit&quot;</span>, <span class="string">&quot;exit&quot;</span>, <span class="string">&quot;q&quot;</span>]:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Goodbye!&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="comment"># fallback if input() is not available</span></span><br><span class="line">        user_input = <span class="string">&quot;What do you know about LangGraph?&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;User: &quot;</span> + user_input)</span><br><span class="line">        stream_graph_updates(user_input)</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">User: what time <span class="keyword">is</span> it</span><br><span class="line">Could| you please specify the| region <span class="keyword">or</span> timezone you want to| know the time <span class="keyword">for</span>? For| example, <span class="string">&quot;Asia|/Shanghai&quot;</span> <span class="keyword">or</span>| <span class="string">&quot;Europe/London&quot;</span>. If| you are asking <span class="keyword">for</span>| your local time <span class="keyword">and</span>| yo<span class="string">u&#x27;re not sure about| your timezone, let| me know, and| I can help you| figure it out.|</span></span><br><span class="line"><span class="string">User: beijing</span></span><br><span class="line"><span class="string">The| current| time in Beijing,| which is in the| &quot;Asia/Shanghai|&quot; timezone, is| 17:|58:5|1.|</span></span><br><span class="line"><span class="string">User: ok,my name is Cai</span></span><br><span class="line"><span class="string">Nice| to meet you,| Cai! If| you have any other| questions or need further| assistance, feel free| to let me know. Whether| it&#x27;</span>s about time| zones, local information|, <span class="keyword">or</span> anything <span class="keyword">else</span>|, I<span class="string">&#x27;m here| to help.|</span></span><br><span class="line"><span class="string">User: what&#x27;</span>s my name?</span><br><span class="line">Your| name| <span class="keyword">is</span>| Cai. If| you need <span class="built_in">help</span> <span class="keyword">with</span>| anything <span class="keyword">else</span>, feel| free to ask!|</span><br></pre></td></tr></table></figure>

<p>OK，还差提示词（Prompt），<a href="https://langchain-ai.github.io/langgraph/how-tos/create-react-agent-system-prompt/?h=prompt">参考链接5</a>，得到：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">prompt = <span class="string">&quot;You are a lively and lovely little assistant, whose name is Xiao CAI.&quot;</span></span><br><span class="line"></span><br><span class="line">graph = create_react_agent(llm, tools, checkpointer=memory, prompt=prompt)</span><br></pre></td></tr></table></figure>

<p>注意，如果提示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">TypeError: create_react_agent() got an unexpected keyword argument <span class="string">&#x27;prompt&#x27;</span></span><br></pre></td></tr></table></figure>

<p>请升级<code>langgrph</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install --upgrade langgraph==<span class="number">0.2</span><span class="number">.76</span></span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">User: hi,what<span class="string">&#x27;s your name</span></span><br><span class="line"><span class="string">Hello|!| My| name is Xiao CA|I. I&#x27;</span>m| a lively <span class="keyword">and</span> lovely| little assistant. How| can I assist you| today? 😊| </span><br></pre></td></tr></table></figure>

<p>其实，我感觉完全可以参考<strong>示例6</strong>，试一下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">graph = create_react_agent(llm, tools, checkpointer=memory)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stream_graph_updates</span>(<span class="params">user_input: <span class="built_in">str</span></span>):</span><br><span class="line">    system_message = (<span class="string">&quot;You are a lively and lovely little assistant, whose name is Xiao CAI. You always answer questions in a humorous, funny, light-hearted way.&quot;</span>)</span><br><span class="line">    first = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">for</span> msg, metadata <span class="keyword">in</span> graph.stream(</span><br><span class="line">        &#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;system&quot;</span>, prompt), (<span class="string">&quot;user&quot;</span>, user_input)]&#125;, </span><br><span class="line">        config, </span><br><span class="line">        stream_mode=<span class="string">&quot;messages&quot;</span></span><br><span class="line">    ):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk) <span class="keyword">and</span> msg.content:</span><br><span class="line">            <span class="built_in">print</span>(msg.content, end=<span class="string">&quot;|&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk):</span><br><span class="line">            <span class="keyword">if</span> first:</span><br><span class="line">                gathered = msg</span><br><span class="line">                first = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                gathered = gathered + msg</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">User: what<span class="string">&#x27;s your name?</span></span><br><span class="line"><span class="string">My| name is Xiao CA|I. I&#x27;</span>m a| lively <span class="keyword">and</span> lovely little| assistant, happy to <span class="built_in">help</span> <span class="keyword">with</span>| your inquiries!| 😊|User: </span><br></pre></td></tr></table></figure>

<hr>
<h2 id="示例8：聊天历史管理"><a href="#示例8：聊天历史管理" class="headerlink" title="示例8：聊天历史管理"></a>示例8：聊天历史管理</h2><p>TODO…</p>
<hr>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h3 id="ReAct"><a href="#ReAct" class="headerlink" title="ReAct"></a>ReAct</h3><p>ReAct（Reasoning + Acting）是Agent的一种常见实现方式，现在主流的LLM Agent绝大多数都是基于ReAct。通过循环的推理（Reasoning）和行动（Acting）机制来执行任务。ReAct 的提出是为了解决传统语言模型只能生成文本的局限性，使其能够通过与外部环境的交互，完成更复杂的任务。</p>
<p> <strong>ReAct 的关键特点：</strong></p>
<ol>
<li>结合 <strong>思维链（CoT, Chain of Thought）</strong> 推理，提升决策能力。</li>
<li>让 Agent <strong>能动态调用工具（如 API、数据库、Python 代码）</strong>，避免局限于训练数据。</li>
<li>通过循环执行，适用于 <strong>多步骤任务（如搜索、计算、规划）</strong></li>
</ol>
<hr>
<h3 id="思维链（Chain-of-Thought-CoT）"><a href="#思维链（Chain-of-Thought-CoT）" class="headerlink" title="思维链（Chain of Thought, CoT）"></a>思维链（Chain of Thought, CoT）</h3><p><strong>思维链（Chain of Thought, CoT）</strong> 是一种用于增强大语言模型推理能力的技术。它的核心思想是让模型在生成最终答案之前，先生成一系列中间推理步骤，从而模拟人类的思考过程。通过这种方式，模型能够更好地解决复杂的逻辑推理、数学计算和多步骤问题。</p>
<p>思维链的<strong>优势</strong>：</p>
<ul>
<li>提高复杂任务的<strong>准确性</strong>，通过显式生成中间步骤，模型能够更好地处理需要多步推理的任务</li>
<li>增强<strong>可解释性</strong>，思维链展示了模型的推理过程，使结果更具可解释性</li>
<li>支持<strong>动态调整</strong>，如果中间步骤出错，可以更容易地定位和修正问题</li>
<li>适用于<strong>多种任务</strong>，包括数学计算、逻辑推理、常识推理、多步骤问题解决等</li>
</ul>
<p>思维链的实现方法：</p>
<ol>
<li><p>提示词工程（Prompt Engineering）</p>
<p>通过在输入提示中明确要求模型生成思维链，引导模型分步推理。</p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">小明有 <span class="number">5</span> 个苹果，他吃了 <span class="number">2</span> 个，又买了 <span class="number">3</span> 个，他现在有多少个苹果？</span><br><span class="line">请一步步思考并给出最终答案。</span><br></pre></td></tr></table></figure>
</li>
<li><p>Few-Shot</p>
<p>在输入提示中提供少量示例，展示如何生成思维链</p>
<p>示例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">问题：小明有 <span class="number">3</span> 个苹果，他吃了 <span class="number">1</span> 个，又买了 <span class="number">2</span> 个，他现在有多少个苹果？</span><br><span class="line">思考过程：</span><br><span class="line"><span class="number">1.</span> 小明一开始有 <span class="number">3</span> 个苹果。</span><br><span class="line"><span class="number">2.</span> 他吃了 <span class="number">1</span> 个，剩下 <span class="number">3</span> - <span class="number">1</span> = <span class="number">2</span> 个。</span><br><span class="line"><span class="number">3.</span> 他又买了 <span class="number">2</span> 个，现在有 <span class="number">2</span> + <span class="number">2</span> = <span class="number">4</span> 个。</span><br><span class="line"><span class="number">4.</span> 所以，小明现在有 <span class="number">4</span> 个苹果。</span><br><span class="line"></span><br><span class="line">问题：小明有 <span class="number">5</span> 个苹果，他吃了 <span class="number">2</span> 个，又买了 <span class="number">3</span> 个，他现在有多少个苹果？</span><br><span class="line">思考过程：</span><br></pre></td></tr></table></figure>
</li>
<li><p>微调模型</p>
<p>在特定任务上微调模型，使其学会生成思维链，这种方法需要大量的标注数据（包括问题和对应的思维链）</p>
</li>
</ol>
<h3 id="workflow"><a href="#workflow" class="headerlink" title="workflow"></a>workflow</h3><p>工作流是为了完成某个任务所需的一系列步骤的组织方式，让它们按照一定顺序执行。Dify是一个LLM工作流管理工具。</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://langchain-ai.github.io/langgraph/#langgraph-platform">https://langchain-ai.github.io/langgraph/#langgraph-platform</a></li>
<li><a href="https://langchain-ai.github.io/langgraph/tutorials/introduction/#requirements">https://langchain-ai.github.io/langgraph/tutorials/introduction/#requirements</a></li>
<li><a href="https://www.aidoczh.com/langgraph/how-tos/streaming-tokens/#llm_1%E2%9C%A8">https://www.aidoczh.com/langgraph/how-tos/streaming-tokens/#llm_1✨</a></li>
<li><a href="https://langchain-ai.github.io/langgraph/#example">https://langchain-ai.github.io/langgraph/#example</a></li>
<li><a href="https://langchain-ai.github.io/langgraph/how-tos/create-react-agent-system-prompt/?h=prompt">https://langchain-ai.github.io/langgraph/how-tos/create-react-agent-system-prompt/?h=prompt</a></li>
<li><a href="https://langchain-ai.github.io/langgraph/reference/prebuilt/">https://langchain-ai.github.io/langgraph/reference/prebuilt/</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>llm</tag>
        <tag>langgraph</tag>
        <tag>langchain</tag>
        <tag>agent</tag>
        <tag>react</tag>
        <tag>cot</tag>
      </tags>
  </entry>
  <entry>
    <title>llama.cpp安装与简单使用（convert-hf-to-gguf.py)</title>
    <url>/2025/04/08/llama-cpp%E5%AE%89%E8%A3%85%E4%B8%8E%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8%EF%BC%88convert-hf-to-gguf-py/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在<a href="https://caihaoran-00.github.io/2025/03/25/%E5%A6%82%E4%BD%95%E5%B0%86%E4%BD%A0%E7%9A%84DeepSeek-R1%E5%BE%AE%E8%B0%83%E6%88%90%E6%9F%90%E4%B8%AA%E9%A2%86%E5%9F%9F%E7%9A%84%E4%B8%93%E5%AE%B6%EF%BC%88%E5%AE%9E%E6%88%98%E7%AF%87%EF%BC%89/#%E5%89%8D%E8%A8%80">如何将你的DeepSeek-R1微调成某个领域的专家（实战篇）</a>和<a href="https://caihaoran-00.github.io/2025/03/27/ollama%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%EF%BC%88ubuntu%EF%BC%89/#more">ollama安装与使用（ubuntu）</a>中，我们通过</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将模型保存为 8 位量化格式（Q8_0）</span></span><br><span class="line"><span class="comment"># 这种格式文件小且运行快，适合部署到资源受限的设备</span></span><br><span class="line"><span class="keyword">if</span> <span class="literal">True</span>: model.save_pretrained_gguf(<span class="string">&quot;model&quot;</span>, tokenizer,)</span><br></pre></td></tr></table></figure>

<p>将模型转化为gguf格式模型供ollama调用，但ollama调用出错了，从hf上下载大佬的gguf模型用ollama调用没问题，所以我们怀疑是unsloth（或hf？）在调用llama.cpp时出了一些问题（可能是版本不兼容？），However，问题出在llama.cpp上，那不用unsloth调用llama.cpp，而是我们直接调用llama.cpp将hf文件转化为gguf格式不就行了，那么本文就尝试通过<code>convert-hf-to-gguf.py</code>将hf格式模型转化为gguf格式模型，看ollama能不能正常调用。</p>
<span id="more"></span>

<hr>
<h2 id="Llama-cpp安装与使用"><a href="#Llama-cpp安装与使用" class="headerlink" title="Llama.cpp安装与使用"></a>Llama.cpp安装与使用</h2><p>依次运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/ggml-org/llama.cpp.git</span><br><span class="line"><span class="built_in">cd</span> llama.cpp</span><br><span class="line"></span><br><span class="line">cmake -B build  <span class="comment"># cpu方式构建</span></span><br><span class="line">cmake --build build --config Release -j 8  </span><br><span class="line"></span><br><span class="line">conda create -n llama_cpp python=3.10</span><br><span class="line">conda activate llama_cpp</span><br><span class="line">pip install -r requirements.txt</span><br><span class="line"></span><br><span class="line">python convert_hf_to_gguf.py ../model_vllm --outfile ../model_llamacpp/model.gguf --outtype q8_0</span><br></pre></td></tr></table></figure>

<p>这里先给出最后一条命令的模版：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python convert_hf_to_gguf.py &lt;模型路径或HF模型ID&gt; --outfile &lt;输出文件名.gguf&gt; --outtype q8_0 --outtype &lt;输出类型&gt;</span><br></pre></td></tr></table></figure>

<img src="/2025/04/08/llama-cpp%E5%AE%89%E8%A3%85%E4%B8%8E%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8%EF%BC%88convert-hf-to-gguf-py/5b14fc68e71e7b6ae99e789a4dde5b7b.png" class="" title="5b14fc68e71e7b6ae99e789a4dde5b7b">

<p>……</p>
<img src="/2025/04/08/llama-cpp%E5%AE%89%E8%A3%85%E4%B8%8E%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8%EF%BC%88convert-hf-to-gguf-py/325b17a69fa4f37a20bac33a94f8969f.png" class="" title="325b17a69fa4f37a20bac33a94f8969f">

<hr>
<h2 id="Ollama运行"><a href="#Ollama运行" class="headerlink" title="Ollama运行"></a>Ollama运行</h2><p>进入<code>model_llamacpp</code>目录，<code>touch Modelfile</code>创建<code>Modelfile</code>文件，其中填入内容：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">FROM model.gguf</span><br></pre></td></tr></table></figure>

<p>运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ollama create fortest -f Modelfile</span><br><span class="line">ollama run fortest</span><br></pre></td></tr></table></figure>

<img src="/2025/04/08/llama-cpp%E5%AE%89%E8%A3%85%E4%B8%8E%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8%EF%BC%88convert-hf-to-gguf-py/125f0d49d9969d62ca36b3e0ff5addf1.png" class="" title="125f0d49d9969d62ca36b3e0ff5addf1">

<p>好好好，虽然能运行，但是在胡言乱语，好的，暂时放弃了转化为<code>gguf</code>的方式了，下次有精力再看吧。</p>
<hr>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://github.com/ggml-org/llama.cpp/blob/master/docs/build.md">https://github.com/ggml-org/llama.cpp/blob/master/docs/build.md</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>llama.cpp</tag>
        <tag>ollama</tag>
        <tag>huggingface</tag>
      </tags>
  </entry>
  <entry>
    <title>ollama安装与使用（ubuntu）</title>
    <url>/2025/03/27/ollama%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%EF%BC%88ubuntu%EF%BC%89/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>久仰<code>ollama</code>的大名，但之前并没有去玩过，借着在大佬的时频中又一次看到<code>ollama</code>的身影，我想是时候玩玩了，本文记录了我的安装和实际过程。</p>
<span id="more"></span>

<hr>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -fsSL https://ollama.com/install.sh | sh</span><br></pre></td></tr></table></figure>

<img src="/2025/03/27/ollama%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%EF%BC%88ubuntu%EF%BC%89/fd3f58a640deb7086b6d21bec9b9c25.png" class="" title="fd3f58a640deb7086b6d21bec9b9c25">

<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><h3 id="快速开始"><a href="#快速开始" class="headerlink" title="快速开始"></a>快速开始</h3><p>安装好之后，运行下面命令下载deepseek-r1:8b模型，即为Deepseek蒸馏的Llama 8B模型，体验：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ollama run deepseek-r1:8b</span><br></pre></td></tr></table></figure>

<img src="/2025/03/27/ollama%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%EF%BC%88ubuntu%EF%BC%89/db9205bafe23c8452c9bf1920a798a5.png" class="" title="db9205bafe23c8452c9bf1920a798a5">

<hr>
<h3 id="加载本地gguf文件"><a href="#加载本地gguf文件" class="headerlink" title="加载本地gguf文件"></a>加载本地gguf文件</h3><p>以下图为例：</p>
<img src="/2025/03/27/ollama%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%EF%BC%88ubuntu%EF%BC%89/image-20250327143924386.png" class="" title="image-20250327143924386">

<p>运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">touch</span> Modelfile</span><br></pre></td></tr></table></figure>

<p>在<code>Modelfile</code>里面写上：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">FROM ./unsloth.Q8<span class="built_in">_</span>0.gguf</span><br></pre></td></tr></table></figure>

<p>并保存，运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ollama create fortel -f Modelfile	<span class="comment"># 创建ollama本地文件</span></span><br><span class="line">ollama run fortel  <span class="comment"># 运行模型</span></span><br></pre></td></tr></table></figure>

<p>但是呢，报错了😂：</p>
<img src="/2025/03/27/ollama%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%EF%BC%88ubuntu%EF%BC%89/938442560d1c3ee2617021c978758aa.png" class="" title="938442560d1c3ee2617021c978758aa">

<img src="/2025/03/27/ollama%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%EF%BC%88ubuntu%EF%BC%89/4363ef2b7f4e5e3d70b7a1430f0d159.png" class="" title="4363ef2b7f4e5e3d70b7a1430f0d159">

<p>咱也不知道哪错了，<code>ollama rm fortel</code>后再重新走一遍流程也不行，算了，先另辟蹊径，运行下面命令从<code>huggingface</code>仓库进行模型下载并运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ollama run hf.co/caihaoran/fortunetelling</span><br></pre></td></tr></table></figure>

<img src="/2025/03/27/ollama%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%EF%BC%88ubuntu%EF%BC%89/963bd76207d288e938aa9a05b22b087.png" class="" title="963bd76207d288e938aa9a05b22b087">

<p>还是不行，奇了怪了…，从大佬的仓库下载试试：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ollama run hf.co/Conard/fortunetelling</span><br></pre></td></tr></table></figure>

<img src="/2025/03/27/ollama%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%EF%BC%88ubuntu%EF%BC%89/2c840e68536871c83904df91e0bdd38.png" class="" title="2c840e68536871c83904df91e0bdd38">

<img src="/2025/03/27/ollama%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8%EF%BC%88ubuntu%EF%BC%89/56998b355526d8a75d1584c43760d6b.png" class="" title="56998b355526d8a75d1584c43760d6b">

<p>哇哦，居然可以，emmmm，难道是我的模型转成<code>gguf</code>的过程中出了问题？</p>
<p>在colab中训练并上传到Huggingface的gguf模型文件也不能在ollama中运行(累了.gif)，先这样吧…</p>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>ollama</tag>
      </tags>
  </entry>
  <entry>
    <title>silero_vad onnx方式使用示例</title>
    <url>/2025/02/07/silerovadonnx%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>语音活动检测（VAD, Voice Activity Detection）是语音处理中的重要技术，它用于检测音频流中是否存在语音信号。VAD 在语音识别、语音通信、语音增强等应用中起到了关键作用。例如，在语音助手、语音转写、降噪等任务中，VAD 可以帮助系统忽略无声片段，提高处理效率。</p>
<p><strong>Silero VAD</strong> 是一个轻量级、性能优异的 VAD 模型，它基于深度学习，可高效检测实时音频中的语音活动。本文将介绍如何使用 <strong>Silero VAD</strong> 进行实时语音检测，并给出一个简单的实现示例。</p>
<span id="more"></span>

<h2 id="示例代码"><a href="#示例代码" class="headerlink" title="示例代码"></a>示例代码</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">torch.set_num_threads(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">import</span> pyaudio</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载 Silero VAD 模型</span></span><br><span class="line">model, utils = torch.hub.load(repo_or_dir=<span class="string">&#x27;snakers4/silero-vad&#x27;</span>,</span><br><span class="line">                              model=<span class="string">&#x27;silero_vad&#x27;</span>,</span><br><span class="line">                              trust_repo=<span class="literal">True</span>,</span><br><span class="line">                              onnx=<span class="literal">True</span>,</span><br><span class="line">                              <span class="comment"># force_reload=True</span></span><br><span class="line">                              )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 录音参数</span></span><br><span class="line">FORMAT = pyaudio.paFloat32</span><br><span class="line">CHANNELS = <span class="number">1</span></span><br><span class="line">SAMPLE_RATE = <span class="number">16000</span></span><br><span class="line">num_samples = <span class="number">512</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 PyAudio</span></span><br><span class="line">audio = pyaudio.PyAudio()</span><br><span class="line">stream = audio.<span class="built_in">open</span>(<span class="built_in">format</span>=FORMAT,</span><br><span class="line">                    channels=CHANNELS,</span><br><span class="line">                    rate=SAMPLE_RATE,</span><br><span class="line">                    <span class="built_in">input</span>=<span class="literal">True</span>,</span><br><span class="line">                    frames_per_buffer=num_samples)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 采集和vad处理</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">start_recording_and_vad</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Recording...\n&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        data = stream.read(num_samples)</span><br><span class="line">        audio_chunk = np.frombuffer(data, dtype=np.float32)</span><br><span class="line">        speech_prob = model(torch.from_numpy(audio_chunk.copy()), SAMPLE_RATE).item()</span><br><span class="line">        <span class="keyword">if</span> speech_prob &gt; <span class="number">0.5</span>:</span><br><span class="line">            <span class="built_in">print</span>(speech_prob, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    start_recording_and_vad()</span><br></pre></td></tr></table></figure>

<p>也可以把录音放在单独线程里：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">torch.set_num_threads(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">import</span> pyaudio</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">from</span> queue <span class="keyword">import</span> Queue</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载 Silero VAD 模型</span></span><br><span class="line">model, utils = torch.hub.load(repo_or_dir=<span class="string">&#x27;snakers4/silero-vad&#x27;</span>,</span><br><span class="line">                              model=<span class="string">&#x27;silero_vad&#x27;</span>,</span><br><span class="line">                              trust_repo=<span class="literal">True</span>,</span><br><span class="line">                              onnx=<span class="literal">True</span>,</span><br><span class="line">                              <span class="comment"># force_reload=True</span></span><br><span class="line">                              )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 录音参数</span></span><br><span class="line">FORMAT = pyaudio.paFloat32</span><br><span class="line">CHANNELS = <span class="number">1</span></span><br><span class="line">SAMPLE_RATE = <span class="number">16000</span></span><br><span class="line">num_samples = <span class="number">512</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 PyAudio</span></span><br><span class="line">audio = pyaudio.PyAudio()</span><br><span class="line">stream = audio.<span class="built_in">open</span>(<span class="built_in">format</span>=FORMAT,</span><br><span class="line">                    channels=CHANNELS,</span><br><span class="line">                    rate=SAMPLE_RATE,</span><br><span class="line">                    <span class="built_in">input</span>=<span class="literal">True</span>,</span><br><span class="line">                    frames_per_buffer=num_samples)</span><br><span class="line"></span><br><span class="line">audio_queue = Queue()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 录音线程</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">start_recording</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Recording...\n&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        data = stream.read(num_samples)</span><br><span class="line">        audio_chunk = np.frombuffer(data, dtype=np.float32)</span><br><span class="line">        audio_queue.put(audio_chunk)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">vad_process</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Starting VAD...\n&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        audio_chunk = audio_queue.get()</span><br><span class="line">        speech_prob = model(torch.from_numpy(audio_chunk.copy()), SAMPLE_RATE).item()</span><br><span class="line">        <span class="keyword">if</span> speech_prob &gt; <span class="number">0.5</span>:</span><br><span class="line">            <span class="built_in">print</span>(speech_prob, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    threading.Thread(target=start_recording, daemon=<span class="literal">True</span>).start()</span><br><span class="line">    vad_process()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<img src="/2025/02/07/silerovadonnx%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/image-20250207172346401.png" class="" title="image-20250207172346401">

<h3 id="代码解析"><a href="#代码解析" class="headerlink" title="代码解析"></a>代码解析</h3><p>该示例展示了如何使用 <strong>Silero VAD</strong> 进行实时语音检测，主要包括以下步骤：</p>
<ol>
<li><strong>加载 Silero VAD 模型</strong><ul>
<li>使用 <code>torch.hub.load</code> 下载并加载模型。</li>
<li>设置 <code>onnx=True</code> 以使用 ONNX 版本的模型，提高推理速度。</li>
</ul>
</li>
<li><strong>初始化音频流</strong><ul>
<li>采用 <code>pyaudio</code> 进行音频采集，设置 <strong>采样率 16kHz</strong>，每次读取 <strong>512 个样本</strong>。</li>
<li>使用 <code>Queue</code> 作为音频缓冲队列，实现<strong>生产者-消费者模型</strong>。</li>
</ul>
</li>
<li><strong>录音线程</strong> (<code>start_recording</code>)<ul>
<li>从麦克风采集音频数据并存入 <code>Queue</code>，实现<strong>非阻塞录音</strong>。</li>
</ul>
</li>
<li><strong>VAD 处理线程</strong> (<code>vad_process</code>)<ul>
<li>从 <code>Queue</code> 获取音频块，输入 <strong>Silero VAD 模型</strong> 进行预测。</li>
<li><code>speech_prob &gt; 0.5</code> 表示当前帧检测到语音，并打印语音置信度。</li>
</ul>
</li>
<li><strong>多线程运行</strong><ul>
<li>录音和 VAD 处理分别运行在<strong>不同的线程</strong>，保证实时性。</li>
</ul>
</li>
</ol>
<h3 id="一些小细节"><a href="#一些小细节" class="headerlink" title="一些小细节"></a>一些小细节</h3><ul>
<li><strong>Silero VAD</strong>输入的数据是<code>float</code>型，每次处理<code>512</code>个样本点（<code>16000kHz</code>采样率下）</li>
<li>注释掉<code>force_reload</code>以保证每次运行代码时不会从新下载模型文件（虽然不大）</li>
<li><code>audio_chunk</code>是只读数据，所以需要<code>audio_chunk.copy()</code>复制一份进行操作，不然会有警告，另外也可以使用<code>torch.tensor(audio_chunk)</code></li>
<li>关于依赖项可查看参考链接。</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本示例展示了 <strong>Silero VAD</strong> 在 <strong>实时语音检测</strong> 中的基本用法。通过 <strong>PyAudio 录音 + Silero VAD 语音检测</strong>，可以实现实时 VAD 应用，如：</p>
<ul>
<li>语音助手唤醒</li>
<li>语音聊天的端点检测</li>
<li>噪音环境中的语音活动检测</li>
</ul>
<p>如果需要进一步优化，可以考虑：</p>
<ul>
<li><strong>结合 WebSocket 或 HTTP 服务，实现远程语音检测</strong></li>
<li><strong>使用 GPU 加速，提升推理速度</strong></li>
</ul>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://github.com/snakers4/silero-vad/wiki/Examples-and-Dependencies#examples">https://github.com/snakers4/silero-vad/wiki/Examples-and-Dependencies#examples</a></li>
<li><a href="https://github.com/snakers4/silero-vad">https://github.com/snakers4/silero-vad</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>silero vad</tag>
        <tag>VAD</tag>
      </tags>
  </entry>
  <entry>
    <title>Win10 hexo+GitHub Pages 0成本托管博客</title>
    <url>/2025/01/13/win10Hex+githubpages0%E6%88%90%E6%9C%AC%E6%89%98%E7%AE%A1%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<h2 id="1-环境准备"><a href="#1-环境准备" class="headerlink" title="1.环境准备"></a>1.环境准备</h2><h3 id="1-安装Node-js和npm"><a href="#1-安装Node-js和npm" class="headerlink" title="1.安装Node.js和npm"></a>1.安装Node.js和npm</h3><ul>
<li><p>下载并安装<a href="https://nodejs.org/zh-cn">Node.js</a>（自带npm工具）</p>
</li>
<li><p>安装完成后，验证是否成功：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">node -v</span><br><span class="line">npm -v</span><br></pre></td></tr></table></figure></li>
</ul>
<span id="more"></span>

<h3 id="2-安装Git"><a href="#2-安装Git" class="headerlink" title="2.安装Git"></a>2.安装Git</h3><ul>
<li><p>下载并安装Git</p>
</li>
<li><p>验证安装是否成功：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">git --version</span><br></pre></td></tr></table></figure></li>
</ul>
<hr>
<h2 id="2-初始化Hexo博客"><a href="#2-初始化Hexo博客" class="headerlink" title="2.初始化Hexo博客"></a>2.初始化Hexo博客</h2><h3 id="1-安装Hexo"><a href="#1-安装Hexo" class="headerlink" title="1.安装Hexo"></a>1.安装Hexo</h3><p>终端运行：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure>

<p>安装Hexo，验证安装是否成功：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">hexo -v</span><br></pre></td></tr></table></figure>

<h3 id="2-创建Hexo项目"><a href="#2-创建Hexo项目" class="headerlink" title="2.创建Hexo项目"></a>2.创建Hexo项目</h3><p>在你想存放博客的目录下运行：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">hexo init blog</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> blog</span><br><span class="line"></span><br><span class="line">npm instal</span><br></pre></td></tr></table></figure>

<blockquote>
<p>blog是你的博客文件夹的名称，随意命名。</p>
</blockquote>
<h3 id="3-启动本地预览"><a href="#3-启动本地预览" class="headerlink" title="3.启动本地预览"></a>3.启动本地预览</h3><p>在blog目录下运行：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">hexo s</span><br></pre></td></tr></table></figure>

<p>or</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">hexo server</span><br></pre></td></tr></table></figure>

<p>打开浏览器，访问<code>http://localhost:4000</code>，即可看到默认的博客页面。</p>
<hr>
<h2 id="3-配置GitHub-Pages"><a href="#3-配置GitHub-Pages" class="headerlink" title="3.配置GitHub Pages"></a>3.配置GitHub Pages</h2><h3 id="1-创建GitHub仓库"><a href="#1-创建GitHub仓库" class="headerlink" title="1.创建GitHub仓库"></a>1.创建GitHub仓库</h3><ul>
<li>登录你的GitHub，创建一个新仓库，命名为username.github.io(username替换为你的GitHub用户名)</li>
<li>这个仓库名是固定格式，GitHub Pages会自动识别并托管网页。</li>
</ul>
<h3 id="2-安装Hexo部署插件"><a href="#2-安装Hexo部署插件" class="headerlink" title="2.安装Hexo部署插件"></a>2.安装Hexo部署插件</h3><p>在blog目录下运行：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure>

<h3 id="3-修改Hexo配置"><a href="#3-修改Hexo配置" class="headerlink" title="3.修改Hexo配置"></a>3.修改Hexo配置</h3><p>打开blog&#x2F;_config.yml文件，拉到最后的deploy配置部分，修改如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="attr">repo:</span> <span class="string">https://github.com/username/username.github.io.git</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">main</span></span><br></pre></td></tr></table></figure>

<ul>
<li>repo填写你刚才创建的GitHub仓库地址</li>
<li>如果你的仓库主分支是master，将branch改为master。</li>
</ul>
<h3 id="4-首次部署"><a href="#4-首次部署" class="headerlink" title="4.首次部署"></a>4.首次部署</h3><p>运行以下命令，将博客部署到GitHub Pages:</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo generate</span><br><span class="line">hexo deploy</span><br></pre></td></tr></table></figure>

<p>即可打开<code>https://username.github.io</code>查看你的博客。</p>
<hr>
<h2 id="4-自定义主题"><a href="#4-自定义主题" class="headerlink" title="4.自定义主题"></a>4.自定义主题</h2><h3 id="1-选择主题"><a href="#1-选择主题" class="headerlink" title="1.选择主题"></a>1.选择主题</h3><ul>
<li><p>以<a href="https://github.com/litten/hexo-theme-yilia">hexo-theme-yilia</a>为例，在blog文件夹下运行：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/litten/hexo-theme-yilia.git themes/yilia</span><br></pre></td></tr></table></figure>
</li>
<li><p>打开blog&#x2F;_config.yml文件，拉到倒数第二项的theme配置部分，修改如下：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="function">theme: <span class="title">yilia</span></span></span><br></pre></td></tr></table></figure>
</li>
<li><p>（可选）本地预览，运行</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo generate</span><br><span class="line">hexo server</span><br></pre></td></tr></table></figure>
</li>
<li><p>部署到GitHub Pages:</p>
<ul>
<li><p>如果运行了本地预览，仅需Ctrl + C 结束掉本地预览，再运行：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">hexo deploy</span><br></pre></td></tr></table></figure>
</li>
<li><p>若未运行本地预览，需运行：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo generate</span><br><span class="line">hexo deploy</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="5-写博客和更新"><a href="#5-写博客和更新" class="headerlink" title="5.写博客和更新"></a>5.写博客和更新</h2><h3 id="1-新建文章"><a href="#1-新建文章" class="headerlink" title="1.新建文章"></a>1.新建文章</h3><p>在blog目录下运行：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">hexo new &quot;你的文章标题&quot;</span><br></pre></td></tr></table></figure>

<p>这会在<code>source/_posts</code> 文件夹下生成一个 <code>你的文章标题.md</code> 文件，你可以用任何文本编辑器编辑。</p>
<h3 id="2-本地预览"><a href="#2-本地预览" class="headerlink" title="2.本地预览"></a>2.本地预览</h3><p>运行以下命令本地查看效果：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">hexo server</span><br></pre></td></tr></table></figure>

<h3 id="3-发布更新到GitHub-Pages"><a href="#3-发布更新到GitHub-Pages" class="headerlink" title="3.发布更新到GitHub Pages"></a>3.发布更新到GitHub Pages</h3><p>每次修改或新增内容后运行：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo generate</span><br><span class="line">hexo deploy</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu与windows间双向传输文件</title>
    <url>/2025/05/30/ubuntu%E4%B8%8Ewindows%E9%97%B4%E5%8F%8C%E5%90%91%E4%BC%A0%E8%BE%93%E6%96%87%E4%BB%B6/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>由于我有两台工作机，一台windows系统，一台ubuntu系统，目前写博客时总是会有这个场景：在ubuntu上操作，但是在windows上写博客，就需要从ubuntu上截图发给windows，目前是通过微信传输助手来传输图片的，但发现截图清晰度就降低了，遂了解了下ubuntu与windows间怎么双向传输文件，重点是是创建共享文件夹，不复杂，本文将一起实操下。</p>
<span id="more"></span>

<hr>
<h2 id="可能的方式"><a href="#可能的方式" class="headerlink" title="可能的方式"></a>可能的方式</h2><p>我的应用场景是局域网下，有两种常用的方式：</p>
<h4 id="✅-方法1：Windows共享文件夹-Ubuntu挂载"><a href="#✅-方法1：Windows共享文件夹-Ubuntu挂载" class="headerlink" title="✅ 方法1：Windows共享文件夹 + Ubuntu挂载"></a>✅ 方法1：Windows共享文件夹 + Ubuntu挂载</h4><ol>
<li><p>在 <strong>Windows 上设置共享文件夹</strong>：</p>
<ul>
<li>右键点击文件夹 → 属性 → “共享” → “高级共享” → 勾选“共享此文件夹”。</li>
<li>设置共享权限（确保你账户有读写权限）。</li>
</ul>
</li>
<li><p>在 <strong>Ubuntu 上访问共享文件夹</strong>：</p>
<ul>
<li><p>安装 CIFS 支持（一次性操作）：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt update</span><br><span class="line"><span class="built_in">sudo</span> apt install cifs-utils</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建挂载点并挂载：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> <span class="built_in">mkdir</span> /mnt/winshare</span><br><span class="line"><span class="built_in">sudo</span> mount -t cifs //192.168.x.x/共享文件夹名 /mnt/winshare -o username=你的Windows用户名,password=密码,uid=1000,gid=1000,dir_mode=0777,file_mode=0777</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<h4 id="✅-方法2：Ubuntu开启Samba共享-Windows访问"><a href="#✅-方法2：Ubuntu开启Samba共享-Windows访问" class="headerlink" title="✅ 方法2：Ubuntu开启Samba共享 + Windows访问"></a>✅ 方法2：Ubuntu开启Samba共享 + Windows访问</h4><ol>
<li><p>在 Ubuntu 上安装 Samba：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt update</span><br><span class="line"><span class="built_in">sudo</span> apt install samba</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置共享文件夹：</p>
<ul>
<li><p>编辑配置文件：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> nano /etc/samba/smb.conf</span><br></pre></td></tr></table></figure>
</li>
<li><p>添加如下内容：</p>
<figure class="highlight abnf"><table><tr><td class="code"><pre><span class="line">pgsql复制编辑[Shared]</span><br><span class="line"><span class="attribute">path</span> <span class="operator">=</span> /home/你的用户名/共享文件夹</span><br><span class="line">read only <span class="operator">=</span> no</span><br><span class="line"><span class="attribute">browsable</span> <span class="operator">=</span> yes</span><br></pre></td></tr></table></figure>
</li>
<li><p>重启 Samba 服务：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> systemctl restart smbd</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>在 Windows 文件资源管理器中输入：</p>
<figure class="highlight armasm"><table><tr><td class="code"><pre><span class="line">\\Ubuntu的<span class="built_in">IP</span>地址\Shared</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="实操"><a href="#实操" class="headerlink" title="实操"></a>实操</h2><p>这里<strong>我选择方式1</strong>，创建一个文件夹，我这里创建了个<code>AAshare</code>，右键属性，看到：</p>
<img src="/2025/05/30/ubuntu%E4%B8%8Ewindows%E9%97%B4%E5%8F%8C%E5%90%91%E4%BC%A0%E8%BE%93%E6%96%87%E4%BB%B6/image-20250530115030146.png" class="" title="image-20250530115030146">

<p>点击<code>共享</code>，</p>
<img src="/2025/05/30/ubuntu%E4%B8%8Ewindows%E9%97%B4%E5%8F%8C%E5%90%91%E4%BC%A0%E8%BE%93%E6%96%87%E4%BB%B6/image-20250530115118437.png" class="" title="image-20250530115118437">

<p>点击高级共享后点击<code>共享此文件夹</code>，再点击<code>权限</code>，将权限给上，最后点击<code>确定</code>：</p>
<img src="/2025/05/30/ubuntu%E4%B8%8Ewindows%E9%97%B4%E5%8F%8C%E5%90%91%E4%BC%A0%E8%BE%93%E6%96%87%E4%BB%B6/image-20250530141956554.png" class="" title="image-20250530141956554">

<img src="/2025/05/30/ubuntu%E4%B8%8Ewindows%E9%97%B4%E5%8F%8C%E5%90%91%E4%BC%A0%E8%BE%93%E6%96%87%E4%BB%B6/image-20250530142035131.png" class="" title="image-20250530142035131">

<p>好了，然后去ubuntu主机上操作，</p>
<ul>
<li><p>安装 CIFS 支持（一次性操作）：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt update</span><br><span class="line"><span class="built_in">sudo</span> apt install cifs-utils</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建挂载点并挂载：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> <span class="built_in">mkdir</span> winshare</span><br><span class="line"><span class="built_in">sudo</span> mount -t cifs //192.168.0.60/AAshare ./winshare -o username=chr,password=1299964565,uid=1000,gid=1000,dir_mode=0777,file_mode=0777</span><br><span class="line"></span><br><span class="line"><span class="built_in">touch</span> ./winshare/test.txt</span><br></pre></td></tr></table></figure>

<p>没问题，然后再复制个图片到这个文件夹下，回到windows那个共享文件夹(AAshare)</p>
<img src="/2025/05/30/ubuntu%E4%B8%8Ewindows%E9%97%B4%E5%8F%8C%E5%90%91%E4%BC%A0%E8%BE%93%E6%96%87%E4%BB%B6/image-20250530142509499.png" class="" title="image-20250530142509499">

<p>好了，搞定！</p>
</li>
</ul>
<p>**注意注意注意，**这时候这是暂时&#x2F;一次性的挂载，如果ubuntu主机关机&#x2F;重启了，需重新挂载，那怎么永久挂载呢：</p>
<ol>
<li><p>在<code>/etc/fstab</code>文件末尾加上：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">//192.168.0.60/AAshare /home/chr/图片/winshare cifs username=chr,password=1299964565,uid=1000,gid=1000,dir<span class="built_in">_</span>mode=0777,file<span class="built_in">_</span>mode=0777,x-systemd.automount,<span class="built_in">_</span>netdev,nofail 0 0</span><br></pre></td></tr></table></figure>
</li>
<li><p>运行<code>sudo mount -a</code>没报错即为成功</p>
</li>
</ol>
<p>现在就不用担心ubuntu关机&#x2F;重启后挂载失效了。</p>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>文件共享</tag>
      </tags>
  </entry>
  <entry>
    <title>大模型应用开发之agent介绍</title>
    <url>/2025/02/10/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E4%B9%8Bagent%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<h2 id="什么是Agent"><a href="#什么是Agent" class="headerlink" title="什么是Agent"></a>什么是Agent</h2><p>Agent（智能体，代理），是指一种能够模拟人类思考和行为来自动执行程序，以解决复杂问题的程序或系统。在大模型应用开发中，Agent是指能够感知环境、做出决策并执行动作的智能实体。通常基于大模型构建，具备自然语言处理、推理、规划等能力。Agent的核心目标是通过与环境的交互完成特定任务或解决复杂问题。OpenAI将AI Agent定义为“以大语言模型为大脑驱动的系统，具备<strong>自主理解</strong>、<strong>感受</strong>、<strong>规划</strong>、<strong>记忆</strong>和<strong>使用工具</strong>的能力，能够自动化执行完成复杂任务的系统。”</p>
<p>Agent与LLM的区别：可以把LLM理解为人的大脑，LLM思考方案，agent最终使用工具完成特定任务。</p>
<span id="more"></span>

<hr>
<h2 id="Agent架构图"><a href="#Agent架构图" class="headerlink" title="Agent架构图"></a>Agent架构图</h2><img src="/2025/02/10/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E4%B9%8Bagent%E4%BB%8B%E7%BB%8D/image-20250210102002343.png" class="" title="image-20250210102002343">

<ul>
<li>感知：Agent通过输入（如文本、图像、声音等）感知环境。</li>
</ul>
<img src="/2025/02/10/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E4%B9%8Bagent%E4%BB%8B%E7%BB%8D/image-20250210102630576.png" class="" title="image-20250210102630576">

<p>大模型Agent技术架构主要包括规划（Planning）、记忆（Memory）、工具（Tools）和行动（Action)）四个关键部分</p>
<ul>
<li><strong>规划（Planning）</strong>：规划是大模型Agent的思维模式，负责将任务拆解为更小、更可管理的子任务，并评估工具的执行能力。通过大模型提示工程，如ReAct、CoT推理模式，可赋予Agent类似于人类的思维方式，精确拆解复杂任务，分布执行。基于感知到的信息，Agent利用大模型的推理能力做出规划决策</li>
<li><strong>记忆（Memory）</strong>：记忆即信息存储与回忆。Agent模拟人类，设有短期记忆和长期记忆。短期记忆存储会话上下文，助力多轮对话；长期记忆存储用户特征、业务数据，实现向量数据库的速存速查</li>
<li><strong>工具（Tools）</strong>：工具是Agent感知环境、执行决策的重要手段。通过配备多样工具并赋权，如API调用业务信息、插件扩展大模型能力等，Agent可以更加灵活地应对复杂任务</li>
<li><strong>行动（Action）</strong>：行动是Agent将规划与记忆转化为实际输出的过程。Agent依托规划与记忆，执行具体行动，包括与外部互动或工具调用，实现输入至输出的转化。</li>
</ul>
<p><strong>一个典型的Agent系统架构包括以下模块</strong>：</p>
<ol>
<li><strong>输入模块</strong>：接收用户输入或环境信息（如文本、语音、图像等）</li>
<li><strong>理解模块</strong>：利用大模型对输入进行理解和分析（如意图识别、实体提取）</li>
<li><strong>推理模块</strong>：基于理解结果进行推理和决策（如生成回复、规划任务）</li>
<li><strong>执行模块</strong>：执行决策结果（如调用API、生成文本、控制设备）</li>
<li><strong>记忆模块</strong>：存储历史交互信息，支持上下文理解和长期记忆</li>
<li><strong>学习模块</strong>：通过反馈优化Agent的行为（如强化学习、在线学习）</li>
</ol>
<h3 id="一个具体的问题"><a href="#一个具体的问题" class="headerlink" title="一个具体的问题"></a>一个具体的问题</h3><p>Q:长沙今天白天和晚上温差是多少？</p>
<p>针对上述问题，你会怎么解决？</p>
<ul>
<li>查询今天天气情况，获取白天温度和晚上温度-&gt;天气查询工具</li>
<li>白天温度-晚上温度-&gt;计算器工具</li>
</ul>
<h2 id="如何开发AI-Agent"><a href="#如何开发AI-Agent" class="headerlink" title="如何开发AI Agent"></a>如何开发AI Agent</h2><p>分为三大类：</p>
<ol>
<li><p>基于<code>python</code></p>
<ul>
<li>结合<code>langchain</code>等大模型应用开发框架</li>
<li>不使用大模型应用开发框架</li>
</ul>
</li>
<li><p>基于<code>Dify</code>、<code>Coze</code>、<code>AutoGen</code>等<code>Agent</code>开发管理平台，通过拖拉拽的方式快速生成一个<code>Agent</code></p>
</li>
<li><p>基于<code>MCP</code>框架</p>
</li>
</ol>
<p>下面我将用这三种方法分别实现上述的一个具体的问题：</p>
<h3 id="基于langgraph"><a href="#基于langgraph" class="headerlink" title="基于langgraph"></a>基于langgraph</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://www.bilibili.com/video/BV1dxm6YPEDB/?spm_id_from=333.337.search-card.all.click&vd_source=075a061948e76c87e2ee8754e264056e">https://www.bilibili.com/video/BV1dxm6YPEDB/?spm_id_from=333.337.search-card.all.click&amp;vd_source=075a061948e76c87e2ee8754e264056e</a></li>
<li><a href="https://www.cnblogs.com/edisonchou/p/-/quick-start-on-ai-agent-by-sk">https://www.cnblogs.com/edisonchou/p/-/quick-start-on-ai-agent-by-sk</a></li>
<li></li>
</ol>
]]></content>
      <categories>
        <category>theory</category>
      </categories>
      <tags>
        <tag>llm</tag>
        <tag>agent</tag>
      </tags>
  </entry>
  <entry>
    <title>从零训练大模型系列之ChatLM-mini-Chinese</title>
    <url>/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前面看了Qwen2.5 VL的技术报告，但感觉还是没有个具象的认识，遂打算从零训练个大模型，一般认为1B及以上参数量才是大模型，由于我只有一张4090，而且仅是为了对全流程有一个具象的认识，遂选择ChatLM-mini-Chinese模型，该模型仅有0.2 B参数量，本文记录我的实操过程，尽量记录详细并给出自己的思考。</p>
<p><strong>项目地址：<a href="https://github.com/charent/ChatLM-mini-Chinese">https://github.com/charent/ChatLM-mini-Chinese</a></strong></p>
<span id="more"></span>

<hr>
<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>运行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">git clone --depth <span class="number">1</span> https://github.com/charent/ChatLM-mini-Chinese.git</span><br><span class="line"></span><br><span class="line">cd ChatLM-mini-Chinese</span><br><span class="line"></span><br><span class="line">conda create -n chatlm_mini_chinese -y python=<span class="number">3.10</span></span><br><span class="line"></span><br><span class="line">conda activate chatlm_mini_chinese</span><br><span class="line"></span><br><span class="line">pip install -r ./requirements.txt</span><br><span class="line"></span><br><span class="line">(可选，查看torch是否支持cuda, 我的输出是<span class="number">2.11</span>+cu121就是支持cuda)：</span><br><span class="line">python -c <span class="string">&quot;import torch;print(torch.__version__)&quot;</span></span><br></pre></td></tr></table></figure>

<h2 id="Tokenizer训练"><a href="#Tokenizer训练" class="headerlink" title="Tokenizer训练"></a>Tokenizer训练</h2><h3 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h3><p><a href="https://dumps.wikimedia.org/zhwiki/latest/zhwiki-latest-pages-articles-multistream.xml.bz2">点击这里</a>下载维基百科中文语料（3.2G），下载完成后，回到桌面（去你管理程序库的地方）打开个终端，运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/attardi/wikiextractor</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> wikiextractor</span><br></pre></td></tr></table></figure>

<p>将下载的维基百科数据<code>zhwiki-latest-pages-articles-multistream.xml.bz2</code>放在该文件夹下，运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python -m wikiextractor.WikiExtractor -b 1000M -o zhwik zhwiki-latest-pages-articles-multistream.xml.bz2 </span><br></pre></td></tr></table></figure>

<p>耗时：14:28~15:18</p>
<p>或者：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">python -m wikiextractor.WikiExtractor -b 1000M -o zhwik1 zhwiki-latest-pages-articles-multistream.xml.bz2 --no-templates</span><br></pre></td></tr></table></figure>

<p>耗时：15:20~15:26</p>
<p><strong>不同点：</strong></p>
<p>不加<code>--no-templates</code></p>
<p>&lt;doc id&#x3D;”13” url&#x3D;”<a href="https://zh.wikipedia.org/wiki?curid=13">https://zh.wikipedia.org/wiki?curid=13</a>“ title&#x3D;”数学”&gt;<br>数学</p>
<p>&amp;lt;templatestyles src&#x3D;”Ambox&#x2F;style.css” &#x2F;&amp;gt;<br>&amp;lt;templatestyles src&#x3D;”Ambox&#x2F;style.css” &#x2F;&amp;gt;<br>数学是研究數量、结构…</p>
<p>参考书目.<br>&amp;lt;templatestyles src&#x3D;”Template:ReflistH&#x2F;styles.css” &#x2F;&amp;gt;</p>
<p>&lt;&#x2F;doc&gt;</p>
<p>加<code>--no-templates</code></p>
<p>&lt;doc id&#x3D;”13” url&#x3D;”<a href="https://zh.wikipedia.org/wiki?curid=13">https://zh.wikipedia.org/wiki?curid=13</a>“ title&#x3D;”数学”&gt;<br>数学</p>
<p>数学是研究數量、结构…</p>
<p>&lt;&#x2F;doc&gt;</p>
<p>进入到你的提取好的wiki文件的文件夹，这些文件<code>wiki_00、wiki_01、wiki_02</code>内容是繁体的，要先转化为繁体，使用opencc，终端运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt install opencc</span><br><span class="line"></span><br><span class="line">opencc -i wiki_00 -o wiki0.txt -c t2s.json</span><br></pre></td></tr></table></figure>

<p>等待片刻完成后，将<code>wiki0.txt</code>复制到<code>ChatLM-mini-Chinese/data</code>文件夹下，打开<code>train_tokenizer.py</code>，将151行改成：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cropus_file = PROJECT_ROOT + <span class="string">&#x27;/data/wiki0.txt&#x27;</span></span><br></pre></td></tr></table></figure>

<p>这是我未运行训练命令时的内存占用：</p>
<p>![2a06d299a89475b93bed10e77a714db](..&#x2F;..&#x2F;..&#x2F;..&#x2F;WeChat Files&#x2F;wxid_noknx8x7zbmf22&#x2F;FileStorage&#x2F;Temp&#x2F;2a06d299a89475b93bed10e77a714db.png)</p>
<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>好的，在你的conda环境下开炮试下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">python train_tokenizer.py</span><br></pre></td></tr></table></figure>

<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/fa7def4c95ae9b52114c9913be5af16.png" class="" title="fa7def4c95ae9b52114c9913be5af16">

<p>不行，运行不起来，把能关的都关上，只留三个终端（此时显存占用3.2G左右）：</p>
<ul>
<li>显存<code>watch -n 1 gpustat</code></li>
<li>内存<code>htop</code></li>
<li>运行训练代码<code>python train_tokenizer.py</code></li>
</ul>
<p>好的，运行起来了，但是也卡住了😅，口头描述一下吧：</p>
<ul>
<li>显存占用未增加</li>
<li>内存占用30 G</li>
<li>运行五分钟后还是被强制停止了</li>
</ul>
<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/33f81f22284ae303577bc3f96d8f8ce.png" class="" title="33f81f22284ae303577bc3f96d8f8ce">

<p>再想想办法，把Swp缓冲区释放了试试（但是发现虽然Swp清零了，但是这部分转移到Mem了）：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> swapoff -a</span><br><span class="line"><span class="built_in">sudo</span> swapon -a</span><br></pre></td></tr></table></figure>

<p>开炮！好的，Mem从<code>5.20G</code>一直升高，升高到<code>28G</code>的样子升高<code>Swp</code>，<code>Swp</code>升满后，<code>Mem</code>升高至30.4G，就又卡住了(16:42)，等一会吧，(17:07)又被嘎了，耗时25分钟，没法了，得改下代码咯（不！就不改！），我要扩充Swp的容量：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">free -m  <span class="comment"># 查看当前系统的swap大小</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">sudo</span> swapoff -a <span class="comment"># 关闭swap</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">dd</span> <span class="keyword">if</span>=/dev/zero of=/swapfile bs=1G count=32  <span class="comment"># 创建新的swap文件，bs*count=swap大小，这里直接设置32G</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">chmod</span> 600 /swapfile <span class="comment"># 设置权限</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">sudo</span> mkswap /swapfile  <span class="comment"># 设置swap</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">sudo</span> swapon /swapfile  <span class="comment"># 启用swap</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;/swapfile none swap sw 0 0&quot;</span> | <span class="built_in">sudo</span> <span class="built_in">tee</span> -a /etc/fstab  <span class="comment"># 使Swap文件永久生效（重启试了，确实有效）</span></span><br></pre></td></tr></table></figure>

<p>然后，再：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">python train_tokenizer.py</span><br></pre></td></tr></table></figure>

<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/9f1e7ddf11ec364329f95d8a4946541.png" class="" title="9f1e7ddf11ec364329f95d8a4946541">

<h3 id="简单测试"><a href="#简单测试" class="headerlink" title="简单测试"></a>简单测试</h3><p>成了！并且也很快，反正不要半小时，简单的体验下这是个什么：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer</span><br><span class="line"></span><br><span class="line"><span class="comment"># 你的 tokenizer 存放路径</span></span><br><span class="line">tokenizer_path = <span class="string">&quot;/home/chr/桌面/ChatLM-mini-Chinese/model_save/hf_tokenizer&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载 tokenizer</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.直接加载测试Tokenizer</span></span><br><span class="line"><span class="comment"># 测试分词效果</span></span><br><span class="line">text = <span class="string">&quot;你好，欢迎使用 Tokenizer！&quot;</span></span><br><span class="line">tokens = tokenizer.tokenize(text)</span><br><span class="line">ids = tokenizer.convert_tokens_to_ids(tokens)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;原始文本:&quot;</span>, text)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;分词结果:&quot;</span>, tokens)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Token ID:&quot;</span>, ids)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.使用tokenizer.encoder()和tokenizer.decoder()</span></span><br><span class="line">encoded = tokenizer.encode(text)</span><br><span class="line">decoded = tokenizer.decode(encoded)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;编码结果:&quot;</span>, encoded)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;解码结果:&quot;</span>, decoded)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.批量测试不同类型文本</span></span><br><span class="line">test_cases = [</span><br><span class="line">    <span class="string">&quot;你好，我叫小明。&quot;</span>,</span><br><span class="line">    <span class="string">&quot;AI 发展迅猛。&quot;</span>,</span><br><span class="line">    <span class="string">&quot;今天的天气怎么样？&quot;</span>,</span><br><span class="line">    <span class="string">&quot;ChatGPT 是一个大型语言模型。&quot;</span>,</span><br><span class="line">    <span class="string">&quot;BERT, GPT-3 和 LLaMA 是 NLP 领域的重要模型。&quot;</span>,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> text <span class="keyword">in</span> test_cases:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;原始文本: <span class="subst">&#123;text&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;分词结果: <span class="subst">&#123;tokenizer.tokenize(text)&#125;</span>\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.统计词表大小</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;词表大小:&quot;</span>, tokenizer.vocab_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.统计不同文本的平均Token长度</span></span><br><span class="line">texts = [<span class="string">&quot;今天天气很好，我们去公园玩吧！&quot;</span>,</span><br><span class="line">         <span class="string">&quot;Transformer 是一种基于自注意力机制的神经网络模型。&quot;</span>,</span><br><span class="line">         <span class="string">&quot;BERT 和 GPT 是 NLP 领域的重要突破。&quot;</span>,</span><br><span class="line">         <span class="string">&quot;自然语言处理（NLP）是人工智能的一个分支。&quot;</span>,</span><br><span class="line">         <span class="string">&quot;这是一条很短的句子。&quot;</span>]</span><br><span class="line"></span><br><span class="line">lengths = [<span class="built_in">len</span>(tokenizer.tokenize(text)) <span class="keyword">for</span> text <span class="keyword">in</span> texts]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;平均 Token 长度:&quot;</span>, <span class="built_in">sum</span>(lengths) / <span class="built_in">len</span>(lengths))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;单个文本 Token 数:&quot;</span>, lengths)</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">/home/<span class="built_in">chr</span>/anaconda3/envs/chatlm_mini_chinese/<span class="built_in">bin</span>/python /home/<span class="built_in">chr</span>/桌面/ChatLM-mini-Chinese/val_tokenizer.py </span><br><span class="line">原始文本: 你好，欢迎使用 Tokenizer！</span><br><span class="line">分词结果: [<span class="string">&#x27;▁你&#x27;</span>, <span class="string">&#x27;好&#x27;</span>, <span class="string">&#x27;▁,&#x27;</span>, <span class="string">&#x27;▁&#x27;</span>, <span class="string">&#x27;欢迎&#x27;</span>, <span class="string">&#x27;使用&#x27;</span>, <span class="string">&#x27;▁T&#x27;</span>, <span class="string">&#x27;ok&#x27;</span>, <span class="string">&#x27;en&#x27;</span>, <span class="string">&#x27;iz&#x27;</span>, <span class="string">&#x27;er&#x27;</span>, <span class="string">&#x27;▁!&#x27;</span>]</span><br><span class="line">Token ID: [<span class="number">21418</span>, <span class="number">6386</span>, <span class="number">19161</span>, <span class="number">2986</span>, <span class="number">20848</span>, <span class="number">19253</span>, <span class="number">19318</span>, <span class="number">21700</span>, <span class="number">19311</span>, <span class="number">24092</span>, <span class="number">19248</span>, <span class="number">19703</span>]</span><br><span class="line">编码结果: [<span class="number">21418</span>, <span class="number">6386</span>, <span class="number">19161</span>, <span class="number">2986</span>, <span class="number">20848</span>, <span class="number">19253</span>, <span class="number">19318</span>, <span class="number">21700</span>, <span class="number">19311</span>, <span class="number">24092</span>, <span class="number">19248</span>, <span class="number">19703</span>]</span><br><span class="line">解码结果: 你好, 欢迎使用 Tokenizer!</span><br><span class="line">原始文本: 你好，我叫小明。</span><br><span class="line">分词结果: [<span class="string">&#x27;▁你&#x27;</span>, <span class="string">&#x27;好&#x27;</span>, <span class="string">&#x27;▁,&#x27;</span>, <span class="string">&#x27;▁我&#x27;</span>, <span class="string">&#x27;叫&#x27;</span>, <span class="string">&#x27;小&#x27;</span>, <span class="string">&#x27;明&#x27;</span>, <span class="string">&#x27;▁。&#x27;</span>]</span><br><span class="line"></span><br><span class="line">原始文本: AI 发展迅猛。</span><br><span class="line">分词结果: [<span class="string">&#x27;▁A&#x27;</span>, <span class="string">&#x27;I&#x27;</span>, <span class="string">&#x27;▁发展&#x27;</span>, <span class="string">&#x27;迅&#x27;</span>, <span class="string">&#x27;猛&#x27;</span>, <span class="string">&#x27;▁。&#x27;</span>]</span><br><span class="line"></span><br><span class="line">原始文本: 今天的天气怎么样？</span><br><span class="line">分词结果: [<span class="string">&#x27;▁今天&#x27;</span>, <span class="string">&#x27;的天&#x27;</span>, <span class="string">&#x27;气&#x27;</span>, <span class="string">&#x27;怎么&#x27;</span>, <span class="string">&#x27;样&#x27;</span>, <span class="string">&#x27;▁?&#x27;</span>]</span><br><span class="line"></span><br><span class="line">原始文本: ChatGPT 是一个大型语言模型。</span><br><span class="line">分词结果: [<span class="string">&#x27;▁Ch&#x27;</span>, <span class="string">&#x27;at&#x27;</span>, <span class="string">&#x27;GP&#x27;</span>, <span class="string">&#x27;T&#x27;</span>, <span class="string">&#x27;▁是一个&#x27;</span>, <span class="string">&#x27;大型&#x27;</span>, <span class="string">&#x27;语言&#x27;</span>, <span class="string">&#x27;模型&#x27;</span>, <span class="string">&#x27;▁。&#x27;</span>]</span><br><span class="line"></span><br><span class="line">原始文本: BERT, GPT-<span class="number">3</span> 和 LLaMA 是 NLP 领域的重要模型。</span><br><span class="line">分词结果: [<span class="string">&#x27;▁B&#x27;</span>, <span class="string">&#x27;ER&#x27;</span>, <span class="string">&#x27;T&#x27;</span>, <span class="string">&#x27;▁,&#x27;</span>, <span class="string">&#x27;▁G&#x27;</span>, <span class="string">&#x27;P&#x27;</span>, <span class="string">&#x27;T&#x27;</span>, <span class="string">&#x27;▁-&#x27;</span>, <span class="string">&#x27;▁3&#x27;</span>, <span class="string">&#x27;▁和&#x27;</span>, <span class="string">&#x27;▁L&#x27;</span>, <span class="string">&#x27;L&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;MA&#x27;</span>, <span class="string">&#x27;▁是&#x27;</span>, <span class="string">&#x27;▁N&#x27;</span>, <span class="string">&#x27;L&#x27;</span>, <span class="string">&#x27;P&#x27;</span>, <span class="string">&#x27;▁&#x27;</span>, <span class="string">&#x27;领域&#x27;</span>, <span class="string">&#x27;的重要&#x27;</span>, <span class="string">&#x27;模型&#x27;</span>, <span class="string">&#x27;▁。&#x27;</span>]</span><br><span class="line"></span><br><span class="line">词表大小: <span class="number">40960</span></span><br><span class="line">平均 Token 长度: <span class="number">11.8</span></span><br><span class="line">单个文本 Token 数: [<span class="number">10</span>, <span class="number">13</span>, <span class="number">16</span>, <span class="number">14</span>, <span class="number">6</span>]</span><br><span class="line"></span><br><span class="line">Process finished <span class="keyword">with</span> exit code <span class="number">0</span></span><br></pre></td></tr></table></figure>

<h2 id="预训练"><a href="#预训练" class="headerlink" title="预训练"></a>预训练</h2><h3 id="预训练数据集下载"><a href="#预训练数据集下载" class="headerlink" title="预训练数据集下载"></a>预训练数据集下载</h3><ol>
<li><p><a href="https://drive.google.com/open?id=1u2yW_XohbYL2YAK6Bzc5XrngHstQTf0v">社区问答json版(webtext2019zh) 大规模高质量数据集</a></p>
<p>将下载完成的<code>webtext2019zh.zip</code>放到<code>data/raw_data</code>下（没有就创建），并运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">unzip webtext2019zh.zip</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意，解压得到三个文件<code>web_text_zh_testa.json</code>（我没写错）、<code>web_text_zh_train.json</code>和<code>web_text_zh_valid.json</code>，需要把<code>web_text_zh_testa.json</code>改为<code>web_text_zh_test.json</code>。</p>
</blockquote>
</li>
<li><p><a href="https://www.kaggle.com/datasets/terrychanorg/baike-qa2019?resource=download&amp;select=baike_qa_train.json">baike_qa2019百科问答类</a></p>
<p>操作与1类似，不再赘述</p>
</li>
<li><p>中国医药领域问答数据集</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 进入data/raw_data目录</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/Toyhom/Chinese-medical-dialogue-data.git</span><br></pre></td></tr></table></figure>

<blockquote>
<p>克隆完成后，将文件夹名称改为chinese_medical_dialogue_datasets</p>
</blockquote>
</li>
<li><p>知乎问答数据</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 也是在data/raw_data目录</span></span><br><span class="line">git <span class="built_in">clone</span> https://huggingface.co/datasets/wangrui6/Zhihu-KOL</span><br></pre></td></tr></table></figure>

<blockquote>
<p>克隆完成后，将文件夹名称改为zhihu-kol。</p>
</blockquote>
</li>
</ol>
<h3 id="清洗数据"><a href="#清洗数据" class="headerlink" title="清洗数据"></a>清洗数据</h3><p>清洗数据的脚本位于<code>utils/raw_data_process.py</code>，在运行之前先略微配置下代码，将<code>process_web_text</code>下面的代码全注释掉：</p>
<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/02936efbc49baa2164c16c2041a6482.png" class="" title="02936efbc49baa2164c16c2041a6482">

<p>conda环境下运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python raw_data_process.py</span><br></pre></td></tr></table></figure>

<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/581aa414b4e49cd72090ca0f8047842.png" class="" title="581aa414b4e49cd72090ca0f8047842">

<p>而且<code>logs/raw_data_process.log</code>中也会有调试信息：</p>
<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/56990b8a32e9c9d383bd24529cbb991.png" class="" title="56990b8a32e9c9d383bd24529cbb991">

<p>好的，继续，注释掉<code>process_web_text</code>，打开<code>process_bake_qa</code>，<code>process_chinese_medical_datasets</code>，<code>process_zhihu_kol_dataset</code>：</p>
<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/5adfc70a140c401c06ac7fa4f7aa95f.png" class="" title="5adfc70a140c401c06ac7fa4f7aa95f">

<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/79528face960a3e59d52c9934c5caf3.png" class="" title="79528face960a3e59d52c9934c5caf3">

<p>还差一些步骤（先把原来步骤注释掉），如图：</p>
<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/018ade7a8ad04e38063ce00ac67844a.png" class="" title="018ade7a8ad04e38063ce00ac67844a">

<p>然后继续：<code>python raw_data_process.py</code>，经过漫长的等待：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(chatlm_mini_chinese) chr@chr:~/桌面/ChatLM-mini-Chinese/utils$ python raw_data_process.py </span><br><span class="line">process file: /home/chr/桌面/ChatLM-mini-Chinese/data/my_data/my_web_text_zh.parquet</span><br><span class="line">Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:58</span><br><span class="line">process file: /home/chr/桌面/ChatLM-mini-Chinese/data/my_data/my_baike_qa.parquet</span><br><span class="line">Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:32</span><br><span class="line">process file: /home/chr/桌面/ChatLM-mini-Chinese/data/my_data/zhihu_kol.parquet</span><br><span class="line">Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:34</span><br><span class="line">process file: /home/chr/桌面/ChatLM-mini-Chinese/data/my_data/my_chinese_medical_dialogue.parquet</span><br><span class="line">Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:15</span><br><span class="line">[2025-03-21 16:08:24.638] [INFO]: merge into file: /home/chr/桌面/ChatLM-mini-Chinese/data/my_dataset.parquet, 全部数据共5718789行，清洗后剩余5718644行</span><br><span class="line">Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 2:34:53</span><br><span class="line">Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:02:30</span><br><span class="line">[2025-03-21 18:45:51.019] [INFO]: merge into file: /home/chr/桌面/ChatLM-mini-Chinese/data/my_dataset_no_dulpticates.parquet, 全部数据共5718644行，文档去重后剩余5519322行</span><br><span class="line">start shuffle...</span><br><span class="line">Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:02:34</span><br><span class="line">[2025-03-21 18:50:53.355] [INFO]: [[<span class="string">&#x27;file_name&#x27;</span>, <span class="string">&#x27;count&#x27;</span>], [<span class="string">&#x27;my_dataset.parquet&#x27;</span>, 5718644], [<span class="string">&#x27;汇总&#x27;</span>, 5718644]]</span><br><span class="line">┏━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┓</span><br><span class="line">┃ file_name          ┃ count┃</span><br><span class="line">┡━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━┩</span><br><span class="line">│ my_dataset.parquet │ 5718644 │</span><br><span class="line">├────────────────────┼─────────┤</span><br><span class="line">│ 汇总               │ 5718644 │</span><br><span class="line">└────────────────────┴─────────┘</span><br><span class="line">Working... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:08</span><br></pre></td></tr></table></figure>

<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/96ec2e98b0f075e87284581846a2a11.png" class="" title="96ec2e98b0f075e87284581846a2a11">

<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/ff07f320532d665cb0891e865eb005a.png" class="" title="ff07f320532d665cb0891e865eb005a">

<p>但是呢，进度在这里不动了，而且图已经画出来了（画图是最后一步），</p>
<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/aa9445b8e38fdec2f0f2167921cb7f3.png" class="" title="aa9445b8e38fdec2f0f2167921cb7f3">

<p>而且内存占用也没释放，点回车也没用😅，怎么办怎么办，不管了，应该是运行完了，直接ctrl+c给关掉。</p>
<h3 id="预训练（单机单卡）"><a href="#预训练（单机单卡）" class="headerlink" title="预训练（单机单卡）"></a>预训练（单机单卡）</h3><p>好的，开炮！</p>
<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/758a746fde78ede686731711c97f781.png" class="" title="758a746fde78ede686731711c97f781">

<p>哦，说在<code>model_save</code>文件夹下找不到训练好的<code>Tokenizer</code>，前面明明是保存到<code>model_save/hf_tokenizer</code>下了，在<code>model_save</code>下哪能找到，打开<code>config.py</code>，箭头位置改一下：</p>
<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/image-20250321202529850.png" class="" title="image-20250321202529850">

<p>开炮！</p>
<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/b47fb1d38c4863fbb8fbf699b330640.png" class="" title="b47fb1d38c4863fbb8fbf699b330640">

<p>显存、内存占用：</p>
<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/6a6bcabed9b7bb65acae8b98a741880.png" class="" title="6a6bcabed9b7bb65acae8b98a741880">

<p>好的，等待着吧，现在是25-3-21（20:28），好的，运行完了：</p>
<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/06e8c7567031d208f2dda383b1eb9f0.png" class="" title="06e8c7567031d208f2dda383b1eb9f0">

<p>看样子用了2 days + 10h，看loss也确实是降低的，去除警告后的完整信息：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(chatlm_mini_chinese) chr@chr:~/桌面/ChatLM-mini-Chinese$ accelerate launch ./train.py train</span><br><span class="line">The following values were not passed to `accelerate launch` and had defaults used instead:</span><br><span class="line">	`--num_processes` was <span class="built_in">set</span> to a value of `1`</span><br><span class="line">	`--num_machines` was <span class="built_in">set</span> to a value of `1`</span><br><span class="line">	`--mixed_precision` was <span class="built_in">set</span> to a value of `<span class="string">&#x27;no&#x27;</span>`</span><br><span class="line">	`--dynamo_backend` was <span class="built_in">set</span> to a value of `<span class="string">&#x27;no&#x27;</span>`</span><br><span class="line">To avoid this warning pass <span class="keyword">in</span> values <span class="keyword">for</span> each of the problematic parameters or run `accelerate config`.</span><br><span class="line">[2025-03-21 20:19:54.158] [INFO]: cpu memory available: 24.39 GB, disk space available: 668.51 GB, keep dataset <span class="keyword">in</span> memory: False.</span><br><span class="line">[2025-03-21 20:19:54.158] [INFO]: operation: train, keep training: False, loading datasets ...</span><br><span class="line">[2025-03-21 20:20:04.510] [INFO]: using device: cuda </span><br><span class="line">[2025-03-21 20:20:05.680] [INFO]: train dataset size: 5203576, steps per epoch:325223; validation dataset size: 13994, steps per validation: 874; datalodater num_workers: 0.</span><br><span class="line"></span><br><span class="line">epoch <span class="built_in">log</span>: epoch:0, avg_loss:4.247095609019069, cur_bleu4:0.0486591236416422, best_bleu4:0.0486591236416422, best_epoch:0</span><br><span class="line"></span><br><span class="line">epoch <span class="built_in">log</span>: epoch:1, avg_loss:3.805832653275791, cur_bleu4:0.06714899049061171, best_bleu4:0.06714899049061171, best_epoch:1</span><br><span class="line"></span><br><span class="line">epoch <span class="built_in">log</span>: epoch:2, avg_loss:3.713093634462342, cur_bleu4:0.03836117001107061, best_bleu4:0.06714899049061171, best_epoch:1</span><br><span class="line"></span><br><span class="line">epoch <span class="built_in">log</span>: epoch:3, avg_loss:3.658557256075041, cur_bleu4:0.024710511352158505, best_bleu4:0.06714899049061171, best_epoch:1</span><br><span class="line"></span><br><span class="line">epoch <span class="built_in">log</span>: epoch:4, avg_loss:3.6181896459202454, cur_bleu4:0.08591752119996698, best_bleu4:0.08591752119996698, best_epoch:4</span><br><span class="line"></span><br><span class="line">epoch <span class="built_in">log</span>: epoch:5, avg_loss:3.5855124745777927, cur_bleu4:0.04782050916056753, best_bleu4:0.08591752119996698, best_epoch:4</span><br><span class="line"></span><br><span class="line">epoch <span class="built_in">log</span>: epoch:6, avg_loss:3.5662105754453, cur_bleu4:0.09046048314026331, best_bleu4:0.09046048314026331, best_epoch:6</span><br><span class="line"></span><br><span class="line">epoch <span class="built_in">log</span>: epoch:7, avg_loss:3.5456458627353107, cur_bleu4:0.040374996576144455, best_bleu4:0.09046048314026331, best_epoch:6</span><br><span class="line">epoch:     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━━━  88% -:--:-- 2 days, 10:03:54 epoch: 7/8, avg_loss: 3.566211, best_epoch: 6, best_bleu: 0.09046048314026331</span><br><span class="line">steps:     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 6:24:13          step: 325223/325223, loss: 3.221098   </span><br></pre></td></tr></table></figure>

<p>好的，教程的下一步是SFT微调，但是我想这一步先试试效果。</p>
<hr>
<h3 id="试验一下"><a href="#试验一下" class="headerlink" title="试验一下"></a>试验一下</h3><p>打开model_save文件夹，你会看到：</p>
<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/c0fe0ead2ee03428a0c2b49943b68a4.png" class="" title="c0fe0ead2ee03428a0c2b49943b68a4">

<ul>
<li><p>将<code>hf_tokenizer</code>文件夹下的<code>special_tokens_map.json</code>、<code>tokenizer.json</code>和<code>tokenizer_config.json</code>复制到<code>model_save目录下</code></p>
</li>
<li><p>将<code>train_latest_state</code>文件夹下的<code>model.safetensors</code>复制到<code>model_save</code>目录下</p>
</li>
<li><p>运行下面命令下载一些配置文件和模型文件（用前辈的配置文件）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">git clone --depth <span class="number">1</span> https://www.modelscope.cn/charent/ChatLM-mini-Chinese.git</span><br></pre></td></tr></table></figure>
</li>
<li><p>将上面克隆得到的文件夹中的<code>config.json</code>复制到<code>model_save</code>目录下，并将该文件的最后一行的<code>vocab_size</code>改40961</p>
</li>
</ul>
<p>这时候文件夹下是这样的：</p>
<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/2f7c0d35b027b359fecfd6f7a185996.png" class="" title="2f7c0d35b027b359fecfd6f7a185996">

<p>运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python cli_demo.py</span><br></pre></td></tr></table></figure>

<p>我的简单测试结果：</p>
<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/4d0a28c8a61a6cf72a8bd04e7e8c45a.png" class="" title="4d0a28c8a61a6cf72a8bd04e7e8c45a">

<p>好的，这时候是胡言乱语的（我也不确认<code>config.json</code>能不能那样改，但不改运行不起来，先这样吧，继续往下走）。</p>
<hr>
<h2 id="SFT微调"><a href="#SFT微调" class="headerlink" title="SFT微调"></a>SFT微调</h2><h3 id="下载数据集"><a href="#下载数据集" class="headerlink" title="下载数据集"></a>下载数据集</h3><p>去<code>data/raw_data</code>文件夹下创建<code>bell_open_source</code>文件夹，然后运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://huggingface.co/datasets/BelleGroup/generated_chat_0.4M</span><br><span class="line"></span><br><span class="line">git <span class="built_in">clone</span> https://huggingface.co/datasets/BelleGroup/train_0.5M_CN</span><br><span class="line"></span><br><span class="line">git <span class="built_in">clone</span> https://huggingface.co/datasets/BelleGroup/train_2M_CN</span><br></pre></td></tr></table></figure>

<p>克隆完成后，将各文件夹下的<code>json</code>文件复制到<code>bell_open_source</code>文件夹下</p>
<h3 id="清洗数据-1"><a href="#清洗数据-1" class="headerlink" title="清洗数据"></a>清洗数据</h3><p>回到清洗数据的脚本：<code>utils/raw_data_process.py</code>，&#96;if _<em>name</em>_ &#x3D;&#x3D; ‘_<em>main</em>_’下面的部分除了开头部分和</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">process_belle_knowledge_enhanced_dataset_for_finetune(max_len=<span class="number">320</span>, group_cnt=<span class="number">50000</span>)</span><br></pre></td></tr></table></figure>

<p>外，均注释掉，再按下图所示位置改一下：</p>
<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/image-20250325101716479.png" class="" title="image-20250325101716479">

<p>运行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">python raw_data_process.py</span><br></pre></td></tr></table></figure>

<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/2d9dd25e5279a6444be89dd6ae9db4e.png" class="" title="2d9dd25e5279a6444be89dd6ae9db4e">

<p>再将&#96;if _<em>name</em>_ &#x3D;&#x3D; ‘_<em>main</em>_’下面的部分除了开头部分和</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">parquet_to_json()</span><br></pre></td></tr></table></figure>

<p>外均注释掉（生成sft.json数据供sft微调），运行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">python raw_data_process.py</span><br></pre></td></tr></table></figure>

<p>好的，现在sft数据有了，运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> ..</span><br><span class="line"></span><br><span class="line">pip install tensorboard</span><br><span class="line"></span><br><span class="line">python sft_train.py</span><br></pre></td></tr></table></figure>

<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/42e7638999c83740bea73557c23c9f2.png" class="" title="42e7638999c83740bea73557c23c9f2">

<p>好的，开始SFT了（11:00），完事了，用时7h+44 min：</p>
<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/af3b357acf806a9fd91bf83ee450432.png" class="" title="af3b357acf806a9fd91bf83ee450432">

<h3 id="试验一下-1"><a href="#试验一下-1" class="headerlink" title="试验一下"></a>试验一下</h3><p>按下图修改一下，使用sft得到的模型进行推理：</p>
<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/image-20250326110851718.png" class="" title="image-20250326110851718">

<p>运行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">python cli_demo.py</span><br></pre></td></tr></table></figure>

<p>说的有点像人话了，但重复概率很高：</p>
<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/c3a38a8e6ce3e077de06a9411d56881.png" class="" title="c3a38a8e6ce3e077de06a9411d56881">

<p>打开<code>model/chat_model.py</code>，将重复词惩罚打开，并设置为1.2：</p>
<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/image-20250325193813523.png" class="" title="image-20250325193813523">

<p><strong>再次试验：</strong></p>
<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/6323398b3316d8f21637256586767e8.png" class="" title="6323398b3316d8f21637256586767e8">

<p>好的，复读机现象没了，<code>1+1</code>也能算对了（神奇），但是关于李白是谁，回答的更离谱了。</p>
<hr>
<h2 id="RLHF-DPO"><a href="#RLHF-DPO" class="headerlink" title="RLHF -&gt; DPO"></a>RLHF -&gt; DPO</h2><p>OKOK，快完事了，前辈用RLHF（强化学习人类反馈优化方法，Reinforcement Learning from Human Feedback）的DPO（直接偏好优化，Direct Preference Optimization）微调，说是比较节省显存，无需训练奖励模型，取得正向回答（chosen）和负向回答（rejected）即可开始微调。微调的<code>chosen</code>文本来自原数据集<a href="https://huggingface.co/datasets/c-s-ale/alpaca-gpt4-data-zh">alpaca-gpt4-data-zh</a>，拒绝文本<code>rejected</code>来自SFT微调1个epoch后的模型输出，另外两个数据集：<a href="https://huggingface.co/datasets/Skepsun/huozi_rlhf_data_json">huozi_rlhf_data_json</a>和<a href="https://huggingface.co/datasets/beyond/rlhf-reward-single-round-trans_chinese">rlhf-reward-single-round-trans_chinese</a>，合并后共8万条dpo数据，dpo数据集处理过程在<code>utils/dpo_data_process.py</code>。</p>
<h3 id="数据集下载及制作"><a href="#数据集下载及制作" class="headerlink" title="数据集下载及制作"></a>数据集下载及制作</h3><p>在<code>data/raw_data</code>文件夹下打开终端，依次运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://huggingface.co/datasets/llm-wizard/alpaca-gpt4-data-zh</span><br><span class="line"></span><br><span class="line">git <span class="built_in">clone</span> https://huggingface.co/datasets/Skepsun/huozi_rlhf_data_json</span><br><span class="line"></span><br><span class="line">git <span class="built_in">clone</span> https://huggingface.co/datasets/beyond/rlhf-reward-single-round-trans_chinese</span><br></pre></td></tr></table></figure>

<p>然后，将</p>
<ul>
<li><p>alpaca_gpt4_data_zh&#x2F;alpaca_gpt4_data_zh.json</p>
</li>
<li><p>huozi_rlhf_data_json&#x2F;huozi_rlhf_data.json</p>
</li>
<li><p>rlhf-reward-single-round-trans_chinese&#x2F;data&#x2F;train-00000-of-00001-789dc5dece0f1fc1.parquet和</p>
<p>test-00000-of-00001-8ecd46436fadcf7f.parquet</p>
</li>
</ul>
<p>复制到raw_data文件夹下，打开<code>utils/dpo_data_process.py</code>，将主程序入口下方的函数注释去掉，然后运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python dpo_data_process.py</span><br></pre></td></tr></table></figure>

<p>由于STF微调的试验一下章节已经指定了推理路径使用sft的checkpoint-120000，所以rejected使用的也是这个检查点。</p>
<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/4c827d26cc2f531350a0c46f16fe5ea.png" class="" title="4c827d26cc2f531350a0c46f16fe5ea">

<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/d42712e2f723e6b3d9fd87ede8e40ef.png" class="" title="d42712e2f723e6b3d9fd87ede8e40ef">

<hr>
<h3 id="DPO训练"><a href="#DPO训练" class="headerlink" title="DPO训练"></a>DPO训练</h3><p>数据集制作完毕后，先更改下DPO加载模型的路径，设置成sft的checkpoint-120000检查点加载：</p>
<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/image-20250326142917174.png" class="" title="image-20250326142917174">

<p>运行：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install wandb</span><br><span class="line"></span><br><span class="line">cd ..</span><br><span class="line"></span><br><span class="line">python dpo_train.py</span><br></pre></td></tr></table></figure>

<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/276b78ff698e642d99babdbf9ad95e1.png" class="" title="276b78ff698e642d99babdbf9ad95e1">

<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/99b30048901aa654d190e49846588d6.png" class="" title="99b30048901aa654d190e49846588d6">

<h3 id="试验一下-2"><a href="#试验一下-2" class="headerlink" title="试验一下"></a>试验一下</h3><p>更改路径：</p>
<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/image-20250326152851163.png" class="" title="image-20250326152851163">

<p>运行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">python cli_demo.py</span><br></pre></td></tr></table></figure>

<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/04733e147854cb62395463940ce8326.png" class="" title="04733e147854cb62395463940ce8326">

<img src="/2025/03/20/%E4%BB%8E%E9%9B%B6%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%B3%BB%E7%BB%9F%E4%B9%8BChatLM-mini-Chinese/11142dca3a425570c53ff7d93c52ba2.png" class="" title="11142dca3a425570c53ff7d93c52ba2">

<p>好的吧，依旧是玩具。</p>
<p>最后还有下游任务的微调-三元组信息抽取任务，有空时候再弄吧。</p>
<hr>
<h2 id="下游任务微调-三元组信息抽取"><a href="#下游任务微调-三元组信息抽取" class="headerlink" title="下游任务微调-三元组信息抽取"></a>下游任务微调-三元组信息抽取</h2><p>TODO…</p>
<hr>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h3 id="token-type"><a href="#token-type" class="headerlink" title="token_type"></a>token_type</h3><p><code>token_type=&#39;char&#39;</code>（字符级）和 <code>token_type=&#39;byte&#39;</code>（字节级）的主要区别在于 <strong>分词粒度、可扩展性和适用场景</strong>，下面详细分析它们的优缺点：</p>
<p><strong>1. <code>char</code>（字符级 BPE）</strong></p>
<p><strong>📌 原理</strong>：</p>
<ul>
<li>按照<strong>字符</strong>（Character）单位进行分词，不会拆分字符。</li>
<li>例如 <code>&quot;中国&quot;</code> 会作为两个独立字符 <code>&quot;中&quot;</code> 和 <code>&quot;国&quot;</code>。</li>
</ul>
<p><strong>✅ 优势</strong></p>
<ol>
<li><strong>更直观易理解</strong><ul>
<li>训练出来的 Tokenizer 结果更接近人类的直觉，比如 <code>&quot;你好&quot;</code> 会分成 <code>&quot;你&quot;</code> 和 <code>&quot;好&quot;</code>，而不会拆分成更小的部分。</li>
</ul>
</li>
<li><strong>适用于汉语、日语等非空格分隔语言</strong><ul>
<li>适用于中文、日文等 <strong>没有空格分词的语言</strong>，可以保留完整字符，提高可读性。</li>
</ul>
</li>
<li><strong>更少的 OOV（Out of Vocabulary，未登录词）</strong><ul>
<li>只要训练语料足够大，基本不会有 OOV，因为所有常见字符都会出现在词表里。</li>
</ul>
</li>
<li><strong>适用于字符粒度的 NLP 任务</strong><ul>
<li>适用于 <strong>拼写错误检测、文本纠错、光学字符识别（OCR）</strong>，因为能处理每个字符。</li>
</ul>
</li>
</ol>
<p><strong>❌ 缺点</strong></p>
<ol>
<li><strong>词表较大</strong><ul>
<li>每个字符都是一个 Token，导致 Token 总数较多（尤其是 Unicode 语言）。</li>
</ul>
</li>
<li><strong>序列长度较长</strong><ul>
<li>例如 <code>[&#39;你&#39;, &#39;好&#39;, &#39;世&#39;, &#39;界&#39;]</code> 这样拆分时，<strong>一个单词可能会被拆成多个字符</strong>，导致序列变长，增加 Transformer 计算量。</li>
</ul>
</li>
</ol>
<p><strong>2. <code>byte</code>（字节级 BPE）</strong></p>
<p><strong>📌 原理</strong>：</p>
<ul>
<li>按照<strong>字节</strong>（Byte）进行分词，而不是按照字符。</li>
<li>例如 <code>&quot;你好&quot;</code> 在 UTF-8 编码下会被拆分成多个字节 <code>\xe4\xbd\xa0</code> 和 <code>\xe5\xa5\xbd</code>。</li>
</ul>
<p><strong>✅ 优势</strong></p>
<ol>
<li><strong>通用性更强</strong><ul>
<li>能够处理 <strong>任何语言、特殊符号、表情符号</strong>，甚至可以用于 <strong>代码（编程语言）</strong>。</li>
</ul>
</li>
<li><strong>词表更小</strong><ul>
<li>只需学习 <strong>256 个字节（Byte-Level）</strong>，就能覆盖所有 Unicode 字符，不会有 OOV。</li>
</ul>
</li>
<li><strong>数据压缩效果好</strong><ul>
<li>由于 BPE 在字节级别运作，它可以动态学习子词，从而压缩文本（减少 Token 数量）。</li>
</ul>
</li>
<li><strong>适用于多语言场景</strong><ul>
<li>比如 GPT-2 选择 Byte-level BPE 就是为了支持<strong>多种语言</strong>。</li>
</ul>
</li>
</ol>
<p><strong>❌ 缺点</strong></p>
<ol>
<li><strong>可读性差</strong><ul>
<li><code>byte</code> 级别的分词不可读，例如 <code>&quot;你好&quot;</code> 可能变成 <code>[&#39;\xe4\xbd\xa0&#39;, &#39;\xe5\xa5\xbd&#39;]</code>，对于人类来说完全看不懂。</li>
</ul>
</li>
<li><strong>分词不自然</strong><ul>
<li>例如 <code>&quot;apple&quot;</code> 可能变成 <code>[&quot;ap&quot;, &quot;ple&quot;]</code>，会拆分奇怪的部分。</li>
</ul>
</li>
<li><strong>中文、日文、韩文（CJK 语言）分词效果不如 <code>char</code></strong><ul>
<li>由于 <code>byte</code> 级别是基于 <strong>Unicode 字节流</strong>，<strong>对于 CJK 语言会拆得很碎</strong>，导致上下文丢失。</li>
</ul>
</li>
</ol>
<p><strong>3. <code>char</code> vs <code>byte</code> 选择建议</strong></p>
<table>
<thead>
<tr>
<th>选择场景</th>
<th><code>char</code>（字符级 BPE）</th>
<th><code>byte</code>（字节级 BPE）</th>
</tr>
</thead>
<tbody><tr>
<td><strong>适用语言</strong></td>
<td>中文、日文、韩文（CJK）</td>
<td>多语言（特别是含代码、符号）</td>
</tr>
<tr>
<td><strong>可读性</strong></td>
<td>好，人能直接理解</td>
<td>差，分词结果不可读</td>
</tr>
<tr>
<td><strong>OOV（未登录词）</strong></td>
<td>低，基本不会有</td>
<td>永远没有 OOV</td>
</tr>
<tr>
<td><strong>模型适配</strong></td>
<td>更适合 NLP 任务</td>
<td>适合 GPT-2、编程语言</td>
</tr>
<tr>
<td><strong>词表大小</strong></td>
<td>较大</td>
<td>非常小（256 tokens）</td>
</tr>
<tr>
<td><strong>序列长度</strong></td>
<td>较长</td>
<td>较短（更适合 Transformer）</td>
</tr>
<tr>
<td><strong>特殊字符处理</strong></td>
<td>需要额外处理符号</td>
<td>直接支持任何符号</td>
</tr>
</tbody></table>
<p><strong>👉 推荐选择</strong></p>
<ul>
<li><strong>中文 NLP（ASR、翻译、摘要） → <code>char</code></strong></li>
<li><strong>多语言 NLP（GPT-2, LLaMA） → <code>byte</code></strong></li>
<li><strong>代码&#x2F;表情符号&#x2F;特殊符号 NLP → <code>byte</code></strong></li>
<li><strong>光学字符识别（OCR） → <code>char</code></strong></li>
<li><strong>数据量小，担心 OOV → <code>byte</code></strong></li>
</ul>
<p><strong>4. 总结</strong></p>
<table>
<thead>
<tr>
<th><code>char</code>（字符级 BPE）</th>
<th><code>byte</code>（字节级 BPE）</th>
</tr>
</thead>
<tbody><tr>
<td>✅ 适合 <strong>中文、日语等非空格分隔语言</strong></td>
<td>✅ 适合 <strong>多语言（GPT-2&#x2F;LLaMA）</strong></td>
</tr>
<tr>
<td>✅ <strong>可读性高</strong>，易理解</td>
<td>❌ <strong>不可读</strong>，难以分析</td>
</tr>
<tr>
<td>❌ <strong>词表较大</strong>，占内存</td>
<td>✅ <strong>词表小</strong>，节省显存</td>
</tr>
<tr>
<td>❌ <strong>序列长度长</strong>，增加计算量</td>
<td>✅ <strong>序列短</strong>，更适合 Transformer</td>
</tr>
<tr>
<td>✅ 适合 <strong>OCR、文本生成</strong></td>
<td>✅ 适合 <strong>代码&#x2F;NLP&#x2F;通用 AI</strong></td>
</tr>
</tbody></table>
<p><strong>最终建议</strong>：</p>
<ul>
<li><strong>处理单一语言（如中文 NLP）</strong> → <strong><code>char</code> 更合适</strong></li>
<li><strong>多语言处理（如 GPT-2）</strong> → <strong><code>byte</code> 更合适</strong></li>
<li><strong>如果不确定，默认 <code>char</code> 即可</strong> 🚀</li>
</ul>
<hr>
<h3 id="dpo日志"><a href="#dpo日志" class="headerlink" title="dpo日志"></a>dpo日志</h3><p>以下面这条为例：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;loss&#x27;</span>: 0.1506, <span class="string">&#x27;learning_rate&#x27;</span>: 2.705977382875606e-07, <span class="string">&#x27;rewards/chosen&#x27;</span>: -0.2540930509567261, <span class="string">&#x27;rewards/rejected&#x27;</span>: -9.427597999572754, <span class="string">&#x27;rewards/accuracies&#x27;</span>: 0.949999988079071, <span class="string">&#x27;rewards/margins&#x27;</span>: 9.173505783081055, <span class="string">&#x27;logps/rejected&#x27;</span>: -284.3307189941406, <span class="string">&#x27;logps/chosen&#x27;</span>: -367.8659362792969, <span class="string">&#x27;logits/rejected&#x27;</span>: -5.64560079574585, <span class="string">&#x27;logits/chosen&#x27;</span>: -5.654943466186523, <span class="string">&#x27;epoch&#x27;</span>: 3.9&#125;</span><br></pre></td></tr></table></figure>

<p>每个字段分段是什么意思呢？</p>
<p><strong>📌 关键指标解读</strong></p>
<table>
<thead>
<tr>
<th>指标</th>
<th>含义</th>
<th>你的数值</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><strong><code>loss</code></strong></td>
<td>训练损失</td>
<td><code>0.1506</code></td>
<td>下降了，说明模型在收敛</td>
</tr>
<tr>
<td><strong><code>learning_rate</code></strong></td>
<td>当前学习率</td>
<td><code>2.7e-07</code></td>
<td>可能处于衰减阶段</td>
</tr>
<tr>
<td><strong><code>rewards/chosen</code></strong></td>
<td>选中样本的奖励分数</td>
<td><code>-0.2541</code></td>
<td>负数，可能是因为 reward 标准化</td>
</tr>
<tr>
<td><strong><code>rewards/rejected</code></strong></td>
<td>被拒绝样本的奖励</td>
<td><code>-9.4276</code></td>
<td>远低于 <code>rewards/chosen</code>，符合预期</td>
</tr>
<tr>
<td><strong><code>rewards/accuracies</code></strong></td>
<td>训练准确率</td>
<td><code>0.9500</code></td>
<td>非常高，模型基本学会正确选择</td>
</tr>
<tr>
<td><strong><code>rewards/margins</code></strong></td>
<td>选中与拒绝样本的奖励差距</td>
<td><code>9.1735</code></td>
<td>说明模型能很好地区分好坏回答</td>
</tr>
<tr>
<td><strong><code>logps/rejected</code></strong></td>
<td>拒绝样本的 log 概率</td>
<td><code>-284.33</code></td>
<td>数值大，表示模型更倾向于拒绝</td>
</tr>
<tr>
<td><strong><code>logps/chosen</code></strong></td>
<td>选中样本的 log 概率</td>
<td><code>-367.87</code></td>
<td>数值更大，表示模型信心较低</td>
</tr>
<tr>
<td><strong><code>logits/rejected</code></strong></td>
<td>拒绝样本的原始 logit 分值</td>
<td><code>-5.65</code></td>
<td>和 chosen 相差不大</td>
</tr>
<tr>
<td><strong><code>logits/chosen</code></strong></td>
<td>选中样本的原始 logit 分值</td>
<td><code>-5.65</code></td>
<td>选中样本略好</td>
</tr>
<tr>
<td><strong>epoch</strong></td>
<td>当前轮数</td>
<td>3.9</td>
<td>即将完成（以4为目标）</td>
</tr>
</tbody></table>
<blockquote>
<p>信心（置信度）低表明虽然能选对，但犹豫不决，泛化（鲁棒）性不好。</p>
</blockquote>
<p><strong>📌 训练状态分析</strong></p>
<p>✅ <strong>损失（loss）已经降低</strong>，说明模型正在有效收敛。<br> ✅ <strong>准确率（rewards&#x2F;accuracies）很高</strong>：说明模型能正确区分大部分样本。<br> ✅ <strong>奖励分数对比</strong>：</p>
<ul>
<li><code>rewards/chosen</code> (<code>-0.2541</code>) 明显高于 <code>rewards/rejected</code> (<code>9.4276</code>)，说明模型在学习正确偏好。</li>
<li><code>rewards/margins = 9.1735</code>，说明模型能拉开好坏样本的差距。<br> ✅ 学习率下降：可能已经进入 <strong>学习率衰减（decay）</strong> 阶段，预计训练即将结束。</li>
</ul>
<p><strong>📌 需要关注的点</strong></p>
<p>🔹 <strong>Logit 差距较小</strong>（<code>logits/chosen ≈ logits/rejected</code>）</p>
<ul>
<li>说明模型对选中样本和拒绝样本的区分度还可以进一步优化。</li>
<li>可以检查 <code>DPOTrainer</code> 里的 <code>beta</code> 参数，看看是否需要调整。<br> 🔹 <strong>学习率已降到较低水平</strong></li>
<li>如果 loss 继续下降，可以考虑 <strong>提前停止训练（early stopping）</strong>，防止过拟合。</li>
<li>如果 loss 不再下降，可以 <strong>增加训练轮数</strong> 或 <strong>调整学习率调度策略</strong>（如 <code>cosine</code> 代替 <code>linear</code>）。</li>
</ul>
<p><strong>📌 总结</strong></p>
<p>📉 <strong>训练进度良好</strong>，模型在收敛，<code>loss</code> 降低，准确率高（<code>0.9500%</code>），reward 差距明显。<br> 🛠 <strong>可以考虑</strong> 观察 logit 变化，调整 <code>beta</code> 或学习率调度策略，确保最终模型的泛化能力。<br> 🚀 <strong>如果 loss 继续降低</strong>，可以 <strong>提前结束训练，保存最佳模型！</strong></p>
<hr>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://blog.csdn.net/gmaaa123/article/details/140319691">https://blog.csdn.net/gmaaa123/article/details/140319691</a></li>
<li><a href="https://github.com/charent/ChatLM-mini-Chinese">https://github.com/charent/ChatLM-mini-Chinese</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>SFT</tag>
        <tag>ChatLM-mini-Chinese</tag>
        <tag>Pre-train</tag>
        <tag>DPO</tag>
      </tags>
  </entry>
  <entry>
    <title>查重系统：公司服务器上部署查重系统简单demo</title>
    <url>/2025/06/11/%E6%9F%A5%E9%87%8D%E7%B3%BB%E7%BB%9F%EF%BC%9A%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E9%83%A8%E7%BD%B2%E6%9F%A5%E9%87%8D%E7%B3%BB%E7%BB%9F%E7%AE%80%E5%8D%95demo/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>周一（2025-6-9）向客户展示了查重demo（其实也算不上demo，算是做了下可行性分析吧），但是是以代码的输出结果进行展示的（之前也一直是这么展示的），但这次的客户似乎完全不想看这些东西，只想看直观的<code>UI</code>页面的，上级让弄个带<code>UI</code>页面的进行展示，这篇博客记录一下。</p>
<span id="more"></span>

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>使用<code>streamlit</code>做前端页面，<code>pdfplumber</code>作为<code>pdf</code>解析器，关于文本查重的思路可见<a href="https://caihaoran-00.github.io/2025/06/09/%E6%96%87%E6%9C%AC%E6%9F%A5%E9%87%8D%E7%B3%BB%E7%BB%9F%E7%A4%BA%E4%BE%8B/">这里</a>，<strong>代码：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> streamlit <span class="keyword">as</span> st</span><br><span class="line"><span class="keyword">import</span> pdfplumber</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="keyword">from</span> simhash <span class="keyword">import</span> Simhash</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> cosine_similarity</span><br><span class="line"><span class="keyword">from</span> sentence_transformers <span class="keyword">import</span> SentenceTransformer, util</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 BERT 模型</span></span><br><span class="line">bert_model = SentenceTransformer(<span class="string">&#x27;paraphrase-MiniLM-L6-v2&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># -------------------- 文本处理函数 --------------------</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">split_sentences</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="keyword">return</span> [s.strip() <span class="keyword">for</span> s <span class="keyword">in</span> re.split(<span class="string">r&#x27;[。！？\n]&#x27;</span>, text) <span class="keyword">if</span> s.strip()]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27; &#x27;</span>.join(jieba.cut(text.strip().replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>).replace(<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;&#x27;</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_pdf_text</span>(<span class="params">file</span>):</span><br><span class="line">    <span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(file) <span class="keyword">as</span> pdf:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;\n&#x27;</span>.join(page.extract_text() <span class="keyword">or</span> <span class="string">&#x27;&#x27;</span> <span class="keyword">for</span> page <span class="keyword">in</span> pdf.pages)</span><br><span class="line"></span><br><span class="line"><span class="comment"># -------------------- 相似度函数 --------------------</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">simhash_similarity</span>(<span class="params">s1, s2</span>):</span><br><span class="line">    h1 = Simhash(preprocess(s1))</span><br><span class="line">    h2 = Simhash(preprocess(s2))</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> - h1.distance(h2) / <span class="number">64</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tfidf_similarity</span>(<span class="params">s1, s2</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> s1.strip() <span class="keyword">or</span> <span class="keyword">not</span> s2.strip():</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.0</span>  <span class="comment"># 空字符串相似度为0</span></span><br><span class="line">    vectorizer = TfidfVectorizer()</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        tfidf = vectorizer.fit_transform([s1, s2])</span><br><span class="line">        <span class="keyword">return</span> cosine_similarity(tfidf[<span class="number">0</span>:<span class="number">1</span>], tfidf[<span class="number">1</span>:<span class="number">2</span>])[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">except</span> ValueError:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.0</span>  <span class="comment"># 如果文本内容导致词表为空，也返回相似度0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bert_similarity</span>(<span class="params">s1, s2</span>):</span><br><span class="line">    emb1 = bert_model.encode(s1, convert_to_tensor=<span class="literal">True</span>)</span><br><span class="line">    emb2 = bert_model.encode(s2, convert_to_tensor=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> util.cos_sim(emb1, emb2).item()</span><br><span class="line"></span><br><span class="line"><span class="comment"># -------------------- 查重主函数 --------------------</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compare_docs</span>(<span class="params">name1, text1, name2, text2</span>):</span><br><span class="line">    results = []</span><br><span class="line">    sents1 = split_sentences(text1)</span><br><span class="line">    sents2 = split_sentences(text2)</span><br><span class="line">    matched_sentences = <span class="built_in">set</span>()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, q <span class="keyword">in</span> <span class="built_in">enumerate</span>(sents1):</span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> sents2:</span><br><span class="line">            sim1 = simhash_similarity(q, s)</span><br><span class="line">            <span class="keyword">if</span> sim1 &lt; <span class="number">0.8</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            q_p, s_p = preprocess(q), preprocess(s)</span><br><span class="line">            sim2 = tfidf_similarity(q_p, s_p)</span><br><span class="line">            sim3 = bert_similarity(q, s)</span><br><span class="line">            <span class="keyword">if</span> sim2 &gt; <span class="number">0.6</span> <span class="keyword">or</span> sim3 &gt; <span class="number">0.8</span>:</span><br><span class="line">                matched_sentences.add(i)</span><br><span class="line">                results.append(&#123;</span><br><span class="line">                    <span class="string">&quot;query&quot;</span>: q,</span><br><span class="line">                    <span class="string">&quot;match&quot;</span>: s</span><br><span class="line">                &#125;)</span><br><span class="line">                <span class="keyword">break</span>  <span class="comment"># 一段查到一次就够了</span></span><br><span class="line"></span><br><span class="line">    repeat_rate = <span class="built_in">len</span>(matched_sentences) / <span class="built_in">len</span>(sents1) <span class="keyword">if</span> sents1 <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> results, repeat_rate</span><br><span class="line"></span><br><span class="line"><span class="comment"># -------------------- 页面展示 --------------------</span></span><br><span class="line">st.set_page_config(page_title=<span class="string">&quot;PDF 查重系统&quot;</span>, layout=<span class="string">&quot;wide&quot;</span>)</span><br><span class="line">st.title(<span class="string">&quot;📄 多 PDF 文件查重系统&quot;</span>)</span><br><span class="line"></span><br><span class="line">uploaded_files = st.file_uploader(<span class="string">&quot;请上传多个 PDF 文件（至少两个）&quot;</span>, <span class="built_in">type</span>=[<span class="string">&quot;pdf&quot;</span>], accept_multiple_files=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> uploaded_files <span class="keyword">and</span> <span class="built_in">len</span>(uploaded_files) &gt;= <span class="number">2</span>:</span><br><span class="line">    st.success(<span class="string">f&quot;已上传 <span class="subst">&#123;<span class="built_in">len</span>(uploaded_files)&#125;</span> 个文件，正在处理...&quot;</span>)</span><br><span class="line"></span><br><span class="line">    docs = &#123;f.name: read_pdf_text(f) <span class="keyword">for</span> f <span class="keyword">in</span> uploaded_files&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (name1, text1), (name2, text2) <span class="keyword">in</span> itertools.combinations(docs.items(), <span class="number">2</span>):</span><br><span class="line">        st.markdown(<span class="string">f&quot;---&quot;</span>)</span><br><span class="line">        <span class="keyword">with</span> st.expander(<span class="string">f&quot;📊 对比结果：<span class="subst">&#123;name1&#125;</span> ⟷ <span class="subst">&#123;name2&#125;</span>&quot;</span>, expanded=<span class="literal">True</span>):</span><br><span class="line">            matches, repeat_rate = compare_docs(name1, text1, name2, text2)</span><br><span class="line">            st.markdown(<span class="string">f&quot;**🔁 重复率：<span class="subst">&#123;repeat_rate * <span class="number">100</span>:<span class="number">.1</span>f&#125;</span>%**&quot;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> matches:</span><br><span class="line">                <span class="keyword">for</span> i, item <span class="keyword">in</span> <span class="built_in">enumerate</span>(matches, <span class="number">1</span>):</span><br><span class="line">                    st.markdown(<span class="string">f&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">                    &lt;div style=&#x27;background-color:#f9f9f9; padding:10px; margin-bottom:10px; border-left: 4px solid #4CAF50;&#x27;&gt;</span></span><br><span class="line"><span class="string">                    &lt;b&gt;📌 文档1段落:&lt;/b&gt; <span class="subst">&#123;item[<span class="string">&#x27;query&#x27;</span>]&#125;</span>&lt;br&gt;</span></span><br><span class="line"><span class="string">                    &lt;b&gt;📌 文档2段落:&lt;/b&gt; <span class="subst">&#123;item[<span class="string">&#x27;match&#x27;</span>]&#125;</span></span></span><br><span class="line"><span class="string">                    &lt;/div&gt;</span></span><br><span class="line"><span class="string">                    &quot;&quot;&quot;</span>, unsafe_allow_html=<span class="literal">True</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                st.info(<span class="string">&quot;✅ 未检测到重复内容。&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    st.warning(<span class="string">&quot;请至少上传两个 PDF 文件以进行查重。&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>界面：</strong></p>
<img src="/2025/06/11/%E6%9F%A5%E9%87%8D%E7%B3%BB%E7%BB%9F%EF%BC%9A%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E9%83%A8%E7%BD%B2%E6%9F%A5%E9%87%8D%E7%B3%BB%E7%BB%9F%E7%AE%80%E5%8D%95demo/image-20250611110353559.png" class="" title="image-20250611110353559">

<p><strong>上传文件后会自动查重，效果如下：</strong></p>
<img src="/2025/06/11/%E6%9F%A5%E9%87%8D%E7%B3%BB%E7%BB%9F%EF%BC%9A%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E9%83%A8%E7%BD%B2%E6%9F%A5%E9%87%8D%E7%B3%BB%E7%BB%9F%E7%AE%80%E5%8D%95demo/image-20250611110604966.png" class="" title="image-20250611110604966">

<p>这里展示的<code>18.3%</code>的重复率，计算方式是：橙色文档与红色文档重合的字数除以橙色文档的总字数。</p>
<h3 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conda create -n chachong python=<span class="number">3.10</span></span><br><span class="line">conda activate chachong</span><br><span class="line"></span><br><span class="line">pip install streamlit pdfplumber jieba simhash scikit-learn sentence-transformers</span><br><span class="line"></span><br><span class="line">export HF_ENDPOINT=https://hf-mirror.com</span><br></pre></td></tr></table></figure>

<h3 id="创建启动脚本"><a href="#创建启动脚本" class="headerlink" title="创建启动脚本"></a>创建启动脚本</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">touch</span> run_pdf_check.sh</span><br><span class="line"></span><br><span class="line">nano run_pdf_check.sh</span><br></pre></td></tr></table></figure>

<p><strong>把下面的内容复制进去：</strong></p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 自动化启动 Streamlit 项目</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;启动 pdf_check_web.py ...&quot;</span></span><br><span class="line"><span class="built_in">nohup</span> streamlit run pdf_check_web.py --server.address 0.0.0.0 --server.port 8501 &gt; streamlit.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>

<p><strong>赋予执行权限：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">chmod</span> +x run_pdf_check.sh</span><br></pre></td></tr></table></figure>

<p><strong>运行脚本：</strong></p>
<p>注意注意，第一次启动时，<code>stream</code>会邀请用户填写<code>email</code>或者空格填过，但<code>nohup</code>是非交互式的，如果使用<code>nohup</code>启动就会卡住，第一次启动时应该手动运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">streamlit run pdf_check_web.py --server.address 0.0.0.0 --server.port 8501</span><br></pre></td></tr></table></figure>

<p>然后填写<code>email</code>或者空格跳过，后续再启动时就可以直接：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./run_pdf_check.sh</span><br></pre></td></tr></table></figure>

<p>服务就在后台启动了，想查看代码日志输出，可运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">tail</span> -f streamlit.log</span><br></pre></td></tr></table></figure>

<h3 id="存在的问题"><a href="#存在的问题" class="headerlink" title="存在的问题"></a>存在的问题</h3><p>上面代码只是个简单的展示demo，存在很多能想到和想不到的问题，目前最大的问题是：</p>
<ul>
<li><code>pdf</code>解析问题，现在用的是最简单的<code>extract_text</code>，对表格的兼容不好，且是一行一行读取，会割断语句</li>
</ul>
<p>下面会着重先解决这个问题。</p>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>streamlit</tag>
        <tag>查重</tag>
      </tags>
  </entry>
  <entry>
    <title>文本查重系统示例</title>
    <url>/2025/06/09/%E6%96%87%E6%9C%AC%E6%9F%A5%E9%87%8D%E7%B3%BB%E7%BB%9F%E7%A4%BA%E4%BE%8B/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><ul>
<li><p>背景：投标文件查重系统</p>
</li>
<li><p>目的：展示+记录</p>
</li>
<li><p>思路：文本预处理（分词）+<code>simhash</code>粗筛（第一层）+计算<code>TF-IDF</code>（第二层） 和 <code>BERT</code> 相似度（第三层），满足一定条件则判定可疑</p>
</li>
<li><p>后续优化方向</p>
<ul>
<li><p>明确使用场景✅</p>
</li>
<li><p>具体满足什么条件认定为可疑文本</p>
</li>
<li><p>可以文本达到什么程度认定可疑文件</p>
</li>
<li><p>是在什么文件的什么位置出现的可疑文本✅</p>
</li>
<li><p>…</p>
</li>
</ul>
</li>
</ul>
<span id="more"></span>

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>直接上代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 投标文件查重：分层查重系统（SimHash + TF-IDF + BERT） 支持 DOCX</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> simhash <span class="keyword">import</span> Simhash</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> cosine_similarity</span><br><span class="line"><span class="keyword">from</span> sentence_transformers <span class="keyword">import</span> SentenceTransformer, util</span><br><span class="line"><span class="keyword">from</span> docx <span class="keyword">import</span> Document</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 BERT 模型</span></span><br><span class="line">bert_model = SentenceTransformer(<span class="string">&#x27;paraphrase-MiniLM-L6-v2&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># -------------------- 文本预处理 --------------------</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">split_sentences</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;中文分句&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> re.split(<span class="string">r&#x27;[。！？\n]&#x27;</span>, text)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;去空格+分词+重组&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27; &#x27;</span>.join(jieba.cut(text.strip().replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>).replace(<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;&#x27;</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_docx</span>(<span class="params">path</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;读取 docx 文本内容&quot;&quot;&quot;</span></span><br><span class="line">    doc = Document(path)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;\n&#x27;</span>.join([p.text <span class="keyword">for</span> p <span class="keyword">in</span> doc.paragraphs])</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_documents</span>(<span class="params">path_pattern</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;加载历史文档库（支持 .docx）&quot;&quot;&quot;</span></span><br><span class="line">    documents = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> path <span class="keyword">in</span> glob.glob(path_pattern):</span><br><span class="line">        <span class="keyword">if</span> path.endswith(<span class="string">&#x27;.docx&#x27;</span>):</span><br><span class="line">            text = read_docx(path)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(path, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                text = f.read()</span><br><span class="line">        documents[os.path.basename(path)] = text</span><br><span class="line">    <span class="keyword">return</span> documents</span><br><span class="line"></span><br><span class="line"><span class="comment"># -------------------- 相似度计算函数 --------------------</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">simhash_similarity</span>(<span class="params">s1, s2</span>):</span><br><span class="line">    h1 = Simhash(preprocess(s1))</span><br><span class="line">    h2 = Simhash(preprocess(s2))</span><br><span class="line">    max_bits = <span class="number">64</span></span><br><span class="line">    distance = h1.distance(h2)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> - distance / max_bits</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tfidf_similarity</span>(<span class="params">s1, s2</span>):</span><br><span class="line">    vectorizer = TfidfVectorizer()</span><br><span class="line">    tfidf = vectorizer.fit_transform([s1, s2])</span><br><span class="line">    <span class="keyword">return</span> cosine_similarity(tfidf[<span class="number">0</span>:<span class="number">1</span>], tfidf[<span class="number">1</span>:<span class="number">2</span>])[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bert_similarity</span>(<span class="params">s1, s2</span>):</span><br><span class="line">    emb1 = bert_model.encode(s1, convert_to_tensor=<span class="literal">True</span>)</span><br><span class="line">    emb2 = bert_model.encode(s2, convert_to_tensor=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> util.cos_sim(emb1, emb2).item()</span><br><span class="line"></span><br><span class="line"><span class="comment"># -------------------- 主查重函数 --------------------</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_similarity</span>(<span class="params">query_path, library_pattern</span>):</span><br><span class="line">    <span class="comment"># 读取 query 文档</span></span><br><span class="line">    <span class="keyword">if</span> query_path.endswith(<span class="string">&#x27;.docx&#x27;</span>):</span><br><span class="line">        query_doc = read_docx(query_path)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        query_doc = <span class="built_in">open</span>(query_path, encoding=<span class="string">&#x27;utf-8&#x27;</span>).read()</span><br><span class="line"></span><br><span class="line">    query_sentences = [s <span class="keyword">for</span> s <span class="keyword">in</span> split_sentences(query_doc) <span class="keyword">if</span> s.strip()]</span><br><span class="line"></span><br><span class="line">    library = load_documents(library_pattern)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> lib_name, lib_content <span class="keyword">in</span> library.items():</span><br><span class="line">        lib_sentences = [s <span class="keyword">for</span> s <span class="keyword">in</span> split_sentences(lib_content) <span class="keyword">if</span> s.strip()]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;\n📄 对比文档：<span class="subst">&#123;lib_name&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> q <span class="keyword">in</span> query_sentences:</span><br><span class="line">            <span class="keyword">for</span> s <span class="keyword">in</span> lib_sentences:</span><br><span class="line">                sim1 = simhash_similarity(q, s)</span><br><span class="line">                <span class="keyword">if</span> sim1 &lt; <span class="number">0.8</span>:</span><br><span class="line">                    <span class="keyword">continue</span>  <span class="comment"># 第一层过滤</span></span><br><span class="line"></span><br><span class="line">                q_p, s_p = preprocess(q), preprocess(s)</span><br><span class="line">                sim2 = tfidf_similarity(q_p, s_p)</span><br><span class="line">                sim3 = bert_similarity(q, s)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> sim2 &gt; <span class="number">0.6</span> <span class="keyword">or</span> sim3 &gt; <span class="number">0.8</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&quot;\n【可能重复】&quot;</span>)</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&quot;▶ 查询段落:&quot;</span>, q)</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&quot;◆ 库中段落:&quot;</span>, s)</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;SimHash: <span class="subst">&#123;sim1:<span class="number">.2</span>f&#125;</span>, TF-IDF: <span class="subst">&#123;sim2:<span class="number">.2</span>f&#125;</span>, BERT: <span class="subst">&#123;sim3:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># -------------------- 运行入口 --------------------</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 查询文件路径（docx 格式）</span></span><br><span class="line">    query_file = <span class="string">&#x27;技术文档.docx&#x27;</span>  <span class="comment"># 替换成你的待查文件路径</span></span><br><span class="line">    <span class="comment"># 文档库路径匹配（仅查找 docx 文件）</span></span><br><span class="line">    library_files = <span class="string">&#x27;./library/*.docx&#x27;</span>  <span class="comment"># 文库目录</span></span><br><span class="line">    check_similarity(query_file, library_files)</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">📄 对比文档：技术文档（橙色）.docx</span><br><span class="line">Building prefix dict from the default dictionary ...</span><br><span class="line">Dumping model to file cache /tmp/jieba.cache</span><br><span class="line">Loading model cost 0.256 seconds.</span><br><span class="line">Prefix dict has been built successfully.</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 1、支持建立四级的通讯录架构，上一级别的部门管理员可对下一级别的部门进行管理</span><br><span class="line">◆ 库中段落: 1、支持建立四级的通讯录架构，上一级别的部门管理员可对下一级别的部门进行管理</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 2、部门管理员可添加成员、新建子部门、将成员移出部门</span><br><span class="line">◆ 库中段落: 2、部门管理员可添加成员、新建子部门、将成员移出部门</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 3、通讯录支持全部展开或部分展开显示</span><br><span class="line">◆ 库中段落: 3、通讯录支持全部展开或部分展开显示</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 会议名称：默认为“#昵称#的即时会议”，不限制输入字符类型，但不超过256个字符；</span><br><span class="line">◆ 库中段落: 会议名称：默认为“#昵称#的即时会议”，不限制输入字符类型，但不超过256个字符；</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 开始时间：默认为当下操作时间</span><br><span class="line">◆ 库中段落: 开始时间：默认为当下操作时间</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 会议时长：默认为30分钟</span><br><span class="line">◆ 库中段落: 会议时长：默认为30分钟</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 入会密码：默认为关闭</span><br><span class="line">◆ 库中段落: 入会密码：默认为关闭</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 仅限受邀人加入：默认为关闭</span><br><span class="line">◆ 库中段落: 仅限受邀人加入：默认为关闭</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 1、支持会议中成员，复制会议的邀请信息，将会议信息分享给会议外的成员</span><br><span class="line">◆ 库中段落: 1、支持会议中成员，复制会议的邀请信息，将会议信息分享给会议外的成员</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 2、会中支持添加会议外成员至会议参会人员中，同时呼叫会议外成员加入会议</span><br><span class="line">◆ 库中段落: 2、会中支持添加会议外成员至会议参会人员中，同时呼叫会议外成员加入会议</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 1、参会人角色支持3种：主持人、联席主持人、普通会议人，会议创建者默认是主持人；</span><br><span class="line">◆ 库中段落: 1、成员角色支持3种：主持人、联席主持人、普通会议人，会议创建者默认是主持人；</span><br><span class="line">SimHash: 0.86, TF-IDF: 0.91, BERT: 0.98</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 2、主持人/联席主持人可管控普通成员的音视频权限，普通成员音视频被禁用时，需举手审批，管理员通过后才能打开</span><br><span class="line">◆ 库中段落: 2、主持人/联席主持人可管控普通成员的音视频权限，普通成员音视频被禁用时，需举手审批，管理员通过后才能打开</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 3、主持人/联席主持人的功能按钮与普通会议人的功能按钮不同，可参考下图所示</span><br><span class="line">◆ 库中段落: 3、主持人/联席主持人的功能按钮与普通会议人的功能按钮不同</span><br><span class="line">SimHash: 0.95, TF-IDF: 0.85, BERT: 0.99</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 1、会议中所有成员可发送文字消息进行聊天，支持设置公开聊天或私密聊天</span><br><span class="line">◆ 库中段落: 1、会议中所有成员可发送文字消息进行聊天，支持设置公开聊天或私密聊天</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 2、管理员可以管控普通成员的聊天权限</span><br><span class="line">◆ 库中段落: 2、主持人可以管控普通成员的聊天权限</span><br><span class="line">SimHash: 0.81, TF-IDF: 0.75, BERT: 0.87</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 1、支持用户在会前/会后上传会议相关资料</span><br><span class="line">◆ 库中段落: 1、支持用户在会前/会后上传会议相关资料</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 2、用户可在会议记录中进行下载与检索</span><br><span class="line">◆ 库中段落: 2、用户可在会议记录中进行下载与检索</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 3年（不含开发期）</span><br><span class="line">◆ 库中段落: 3年（不含开发期）</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 提供7x24小时的技术支持，确保客户在任何时间都能得到帮助</span><br><span class="line">◆ 库中段落: 提供7x24小时的技术支持，确保客户在任何时间都能得到帮助</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 在线远程支持，通过远程桌面等方式快速解决问题</span><br><span class="line">◆ 库中段落: 在线远程支持，通过远程桌面等方式快速解决问题</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 定期技术培训，帮助客户更好地使用和维护系统</span><br><span class="line">◆ 库中段落: 定期技术培训，帮助客户更好地使用和维护系统</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 定期系统检查和维护，预防问题的发生</span><br><span class="line">◆ 库中段落: 定期系统检查和维护，预防问题的发生</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 系统更新和升级服务，确保客户的系统始终处于最新状态</span><br><span class="line">◆ 库中段落: 系统更新和升级服务，确保客户的系统始终处于最新状态</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 快速响应机制，确保在规定时间内响应客户的问题</span><br><span class="line">◆ 库中段落: 快速响应机制，确保在规定时间内响应客户的问题</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 故障诊断和修复服务，提供专业的故障诊断和修复方案</span><br><span class="line">◆ 库中段落: 故障诊断和修复服务，提供专业的故障诊断和修复方案</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 故障报告和分析，帮助客户了解故障原因并提供预防措施</span><br><span class="line">◆ 库中段落: 故障报告和分析，帮助客户了解故障原因并提供预防措施</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">📄 对比文档：技术文档（红色）.docx</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 技术文件</span><br><span class="line">◆ 库中段落: 技术文件</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 会议名称：默认为“#昵称#的即时会议”，不限制输入字符类型，但不超过256个字符；</span><br><span class="line">◆ 库中段落: 会议名称：默认为“#昵称#的即时会议”，不限制输入字符类型，但不超过256个字符；</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 开始时间：默认为当下操作时间</span><br><span class="line">◆ 库中段落: 开始时间：默认为当下操作时间</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 会议时长：默认为30分钟</span><br><span class="line">◆ 库中段落: 会议时长：默认为30分钟</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 入会密码：默认为关闭</span><br><span class="line">◆ 库中段落: 入会密码：默认为关闭</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 仅限受邀人加入：默认为关闭</span><br><span class="line">◆ 库中段落: 仅限受邀人加入：默认为关闭</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 支持公有云、私有云、混合云三种部署方式</span><br><span class="line">◆ 库中段落: 支持公有云、私有云、混合云部署</span><br><span class="line">SimHash: 0.81, TF-IDF: 0.75, BERT: 0.97</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 3年（不含开发期）</span><br><span class="line">◆ 库中段落: 3年（不含开发期）</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 5.2.2 技术支持</span><br><span class="line">◆ 库中段落: 4.2.2 技术支持</span><br><span class="line">SimHash: 0.83, TF-IDF: 1.00, BERT: 0.93</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 提供7x24小时的技术支持，确保客户在任何时间都能得到帮助</span><br><span class="line">◆ 库中段落: 提供7x24小时的技术支持，确保客户在任何时间都能得到帮助</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 在线远程支持，通过远程桌面等方式快速解决问题</span><br><span class="line">◆ 库中段落: 在线远程支持，通过远程桌面等方式快速解决问题</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 定期技术培训，帮助客户更好地使用和维护系统</span><br><span class="line">◆ 库中段落: 定期技术培训，帮助客户更好地使用和维护系统</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 定期系统检查和维护，预防问题的发生</span><br><span class="line">◆ 库中段落: 定期系统检查和维护，预防问题的发生</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 系统更新和升级服务，确保客户的系统始终处于最新状态</span><br><span class="line">◆ 库中段落: 系统更新和升级服务，确保客户的系统始终处于最新状态</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 5.2.4 故障处理</span><br><span class="line">◆ 库中段落: 4.2.4 故障处理</span><br><span class="line">SimHash: 0.86, TF-IDF: 1.00, BERT: 0.95</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 快速响应机制，确保在规定时间内响应客户的问题</span><br><span class="line">◆ 库中段落: 快速响应机制，确保在规定时间内响应客户的问题</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 故障诊断和修复服务，提供专业的故障诊断和修复方案</span><br><span class="line">◆ 库中段落: 故障诊断和修复服务，提供专业的故障诊断和修复方案</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br><span class="line"></span><br><span class="line">【可能重复】</span><br><span class="line">▶ 查询段落: 故障报告和分析，帮助客户了解故障原因并提供预防措施</span><br><span class="line">◆ 库中段落: 故障报告和分析，帮助客户了解故障原因并提供预防措施</span><br><span class="line">SimHash: 1.00, TF-IDF: 1.00, BERT: 1.00</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>查重</tag>
        <tag>simhash</tag>
        <tag>TF-IDF</tag>
        <tag>BERT</tag>
      </tags>
  </entry>
  <entry>
    <title>大模型应用开发之agent介绍前篇：工具调用</title>
    <url>/2025/06/17/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E4%B9%8Bagent%E4%BB%8B%E7%BB%8D%E5%89%8D%E7%AF%87%EF%BC%9A%E5%B7%A5%E5%85%B7%E8%B0%83%E7%94%A8/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在写<a href="https://caihaoran-00.github.io/2025/02/10/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E4%B9%8Bagent%E4%BB%8B%E7%BB%8D/">大模型应用开发之agent介绍</a>时突然意识到还没好好介绍下工具&#x2F;函数调用（function calling），遂补上这篇博客介绍工具调用，同一功能将使用三种方式给出，本文目标是从最基础的讲解起，从入门到进阶，注意本文出现的工具仅用于讲解和体会工具调用，<strong>工具的定义不保证正确性和通用性</strong>：</p>
<ul>
<li>纯<code>python</code>(<code>requests</code>库)</li>
<li><code>OpenAI库</code></li>
<li><code>langgraph</code>库</li>
</ul>
<p>Let’s go！</p>
<span id="more"></span>

<hr>
<h2 id="不调用工具"><a href="#不调用工具" class="headerlink" title="不调用工具"></a>不调用工具</h2><p>万丈高楼平地起，首先给出最基本最基本（不调用工具）的示例：</p>
<h3 id="纯Python（requests）"><a href="#纯Python（requests）" class="headerlink" title="纯Python（requests）"></a>纯Python（<code>requests</code>）</h3><p><strong>非流式：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换成你的实际 API Key</span></span><br><span class="line">api_key = <span class="string">&quot;sk-xxxxxxxxxxxxxxxxxxxxxxxx&quot;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;Authorization&quot;</span>: <span class="string">f&quot;Bearer <span class="subst">&#123;api_key&#125;</span>&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;application/json&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen3-8b&quot;</span>,  <span class="comment"># 或 &quot;qwen3-8b&quot; 等</span></span><br><span class="line">    <span class="string">&quot;messages&quot;</span>: [</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;You are a helpful assistant.&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;你是谁？&quot;</span>&#125;</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">&quot;enable_thinking&quot;</span>: <span class="literal">False</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions&quot;</span></span><br><span class="line"></span><br><span class="line">response = requests.post(url, headers=headers, json=data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印结果</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    result = response.json()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;AI回复：&quot;</span>, result[<span class="string">&quot;choices&quot;</span>][<span class="number">0</span>][<span class="string">&quot;message&quot;</span>][<span class="string">&quot;content&quot;</span>])</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;请求失败或解析出错：&quot;</span>, e)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;返回原始内容：&quot;</span>, response.text)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>note: <code>&quot;enable_thinking&quot;: False</code>需写在<code>data</code>字段中。response是<code>requests.Response</code>对象，<code>result = response.json()</code>用于将Json解析成Python字典，最后通过<code>result[&quot;choices&quot;][0][&quot;message&quot;][&quot;content&quot;]</code>拿出<code>LLM</code>的回复。</p>
</blockquote>
<p><strong>流式：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置参数</span></span><br><span class="line">DASHSCOPE_API_KEY = <span class="string">&quot;sk-xxxxxxxxxxxxxxx&quot;</span>  <span class="comment"># 替换为你的API Key</span></span><br><span class="line">MODEL_NAME = <span class="string">&quot;qwen3-8b&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 请求头</span></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">&quot;Authorization&quot;</span>: <span class="string">f&quot;Bearer <span class="subst">&#123;DASHSCOPE_API_KEY&#125;</span>&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;application/json&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 请求数据</span></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: MODEL_NAME,</span><br><span class="line">    <span class="string">&quot;messages&quot;</span>: [</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;You are a helpful assistant.&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;你是谁？&quot;</span>&#125;</span><br><span class="line">    ],</span><br><span class="line">    <span class="string">&quot;stream&quot;</span>: <span class="literal">True</span>,  <span class="comment"># 关键：启用流式输出</span></span><br><span class="line">    <span class="string">&quot;enable_thinking&quot;</span>: <span class="literal">False</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 流式请求</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = requests.post(</span><br><span class="line">        <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions&quot;</span>,</span><br><span class="line">        headers=headers,</span><br><span class="line">        json=data,</span><br><span class="line">        stream=<span class="literal">True</span>  <span class="comment"># 关键：保持连接开放</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;AI回复（实时流式输出）: &quot;</span>, end=<span class="string">&quot;&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> response.iter_lines():</span><br><span class="line">            <span class="keyword">if</span> line:</span><br><span class="line">                decoded_line = line.decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">                <span class="keyword">if</span> decoded_line.startswith(<span class="string">&quot;data:&quot;</span>):</span><br><span class="line">                    event_data = decoded_line[<span class="number">5</span>:].strip()</span><br><span class="line">                    <span class="keyword">if</span> event_data != <span class="string">&quot;[DONE]&quot;</span>:</span><br><span class="line">                        <span class="keyword">try</span>:</span><br><span class="line">                            chunk = json.loads(event_data)</span><br><span class="line">                            content = chunk[<span class="string">&quot;choices&quot;</span>][<span class="number">0</span>][<span class="string">&quot;delta&quot;</span>].get(<span class="string">&quot;content&quot;</span>, <span class="string">&quot;&quot;</span>)</span><br><span class="line">                            <span class="built_in">print</span>(content, end=<span class="string">&quot;&quot;</span>, flush=<span class="literal">True</span>)  <span class="comment"># 逐字实时输出</span></span><br><span class="line">                        <span class="keyword">except</span> json.JSONDecodeError:</span><br><span class="line">                            <span class="keyword">continue</span></span><br><span class="line">        <span class="built_in">print</span>()  <span class="comment"># 输出换行</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;请求失败，状态码: <span class="subst">&#123;response.status_code&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;错误详情:&quot;</span>, response.text)</span><br><span class="line"></span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;请求异常:&quot;</span>, <span class="built_in">str</span>(e))</span><br></pre></td></tr></table></figure>

<blockquote>
<p> 注意非流式与流式获取模型回复的位置不一样，流式的为：<code>chunk[&quot;choices&quot;][0][&quot;delta&quot;][&quot;content&quot;]</code>。</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">chunk[&quot;choices&quot;][0][&quot;delta&quot;].get(&quot;content&quot;, &quot;&quot;)</span><br><span class="line"></span><br><span class="line">相当于：</span><br><span class="line"></span><br><span class="line">if &quot;content&quot; in chunk[&quot;choices&quot;][0][&quot;delta&quot;]:</span><br><span class="line">    content = chunk[&quot;choices&quot;][0][&quot;delta&quot;][&quot;content&quot;]</span><br><span class="line">else:</span><br><span class="line">    content = &quot;&quot;</span><br></pre></td></tr></table></figure></blockquote>
<hr>
<p>相信有小友也看到过<code>openai.ChatCompletion.create()</code>这个方法，但有时候看到的又是<code>client.chat.completions.create()</code>方法，那么这两种方法有什么区别和联系呢？</p>
<table>
<thead>
<tr>
<th>对比项</th>
<th><code>openai.ChatCompletion.create()</code></th>
<th><code>client.chat.completions.create()</code></th>
</tr>
</thead>
<tbody><tr>
<td>模型支持</td>
<td>只能调用 OpenAI 的模型（gpt-4, gpt-3.5）</td>
<td>可以调用任何兼容 OpenAI API 格式的模型（如通义 Qwen、Mistral、Moonshot、DeepSeek）</td>
</tr>
<tr>
<td><code>base_url</code> 设置方式</td>
<td>不支持设置 <code>base_url</code>，只能发给 <code>api.openai.com</code></td>
<td>可以显式设置 <code>base_url</code> 指向其他服务</td>
</tr>
<tr>
<td>可扩展性</td>
<td>低</td>
<td>高（可以用来调用 OpenRouter、AnyScale、DashScope 等）</td>
</tr>
<tr>
<td>推荐用途</td>
<td>调用 OpenAI 官方服务</td>
<td>调用任何支持 OpenAI API 格式的第三方模型（如阿里通义 Qwen）</td>
</tr>
</tbody></table>
<p><strong>那么我们显然选择<code>client.chat.completions.create()</code>，我要用Qwen的模型，GOGOGO！</strong></p>
<h3 id="OpenAI"><a href="#OpenAI" class="headerlink" title="OpenAI"></a><code>OpenAI</code></h3><p><strong>非流式</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">client = OpenAI(</span><br><span class="line">    <span class="comment"># 若没有配置环境变量，请用百炼API Key将下行替换为：api_key=&quot;sk-xxx&quot;,</span></span><br><span class="line">    api_key=<span class="string">&quot;sk-xxxxxxxxxxxxxxxxxxxxxxx&quot;</span>,</span><br><span class="line">    base_url=<span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">completion = client.chat.completions.create(</span><br><span class="line">    <span class="comment"># 模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models</span></span><br><span class="line">    model=<span class="string">&quot;qwen3-8b&quot;</span>,</span><br><span class="line">    messages=[</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;You are a helpful assistant.&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;你是谁？&quot;</span>&#125;,</span><br><span class="line">    ],</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Qwen3模型通过enable_thinking参数控制思考过程（开源版默认True，商业版默认False）</span></span><br><span class="line">    <span class="comment"># 使用Qwen3开源版模型时，若未启用流式输出，请将下行取消注释，否则会报错</span></span><br><span class="line">    extra_body=&#123;<span class="string">&quot;enable_thinking&quot;</span>: <span class="literal">False</span>&#125;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(completion.choices[<span class="number">0</span>].message.content)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>流式：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line">client = OpenAI(</span><br><span class="line">    api_key=<span class="string">&quot;sk-xxxxxxxxxxxxxxxxxxxxxxxxxx&quot;</span>,</span><br><span class="line">    base_url=<span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用流式输出</span></span><br><span class="line">stream = client.chat.completions.create(</span><br><span class="line">    model=<span class="string">&quot;qwen3-8b&quot;</span>,</span><br><span class="line">    messages=[</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;You are a helpful assistant.&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;你是谁？&quot;</span>&#125;,</span><br><span class="line">    ],</span><br><span class="line">    stream=<span class="literal">True</span>,  <span class="comment"># 开启流式输出</span></span><br><span class="line">    extra_body=&#123;<span class="string">&quot;enable_thinking&quot;</span>: <span class="literal">False</span>&#125;,  <span class="comment"># 注意必须启用该参数，否则流式不支持</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 边生成边输出</span></span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> stream:</span><br><span class="line">    content = chunk.choices[<span class="number">0</span>].delta.content</span><br><span class="line">    <span class="keyword">if</span> content:</span><br><span class="line">        <span class="built_in">print</span>(content, end=<span class="string">&quot;|&quot;</span>, flush=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>与<code>requests</code>库的类似，只是这里的<code>completion</code>或者<code>chunk</code>是对象，所以使用点语法。</p>
</blockquote>
<hr>
<h3 id="Langgraph"><a href="#Langgraph" class="headerlink" title="Langgraph"></a><code>Langgraph</code></h3><p><strong>非流式：</strong></p>
<blockquote>
<p>使用<code>ChatOpenAI</code>怎么添加<code>&quot;enable_thinking&quot;: False</code>都不对，最后通过参考链接1和2得知需使用<code>ChatTongyi</code>。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义状态类型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建图</span></span><br><span class="line">graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Qwen3 配置（DashScope）</span></span><br><span class="line">LLM_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxx&quot;</span>,</span><br><span class="line">    <span class="string">&quot;base_url&quot;</span>: <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen3-8b&quot;</span>,  <span class="comment"># 可换为 qwen3-14b 等</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_community.chat_models.tongyi <span class="keyword">import</span> ChatTongyi</span><br><span class="line"></span><br><span class="line">llm = ChatTongyi(</span><br><span class="line">    <span class="comment"># 您可按需更换为其它深度思考模型</span></span><br><span class="line">    model=LLM_CONFIG[<span class="string">&#x27;model&#x27;</span>],</span><br><span class="line">    api_key=LLM_CONFIG[<span class="string">&#x27;api_key&#x27;</span>],</span><br><span class="line">    <span class="comment"># enable_thinking 参数的设置对 QwQ 与 DeepSeek-R1 无效。</span></span><br><span class="line">    model_kwargs=&#123;</span><br><span class="line">        <span class="string">&quot;enable_thinking&quot;</span>: <span class="literal">False</span></span><br><span class="line">    &#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 节点逻辑</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [</span><br><span class="line">        llm.invoke(state[<span class="string">&quot;messages&quot;</span>])]&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br><span class="line">graph_builder.set_entry_point(<span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph_builder.set_finish_point(<span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph = graph_builder.<span class="built_in">compile</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行固定问题</span></span><br><span class="line">result = graph.invoke(&#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, <span class="string">&quot;你是谁？&quot;</span>)]&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Assistant:&quot;</span>, result[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].content)</span><br></pre></td></tr></table></figure>

<p><strong>流式：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"><span class="keyword">from</span> langchain_community.chat_models.tongyi <span class="keyword">import</span> ChatTongyi</span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> AIMessage</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 状态定义</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 图构建</span></span><br><span class="line">graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Qwen3 配置</span></span><br><span class="line">LLM_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;sk-xxxxxxxxxxxxxxxxxxxxxxx&quot;</span>,</span><br><span class="line">    <span class="string">&quot;base_url&quot;</span>: <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen3-8b&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 ChatTongyi，开启 streaming</span></span><br><span class="line">llm = ChatTongyi(</span><br><span class="line">    model=LLM_CONFIG[<span class="string">&quot;model&quot;</span>],</span><br><span class="line">    api_key=LLM_CONFIG[<span class="string">&quot;api_key&quot;</span>],</span><br><span class="line">    streaming=<span class="literal">True</span>,</span><br><span class="line">    model_kwargs=&#123;<span class="string">&quot;enable_thinking&quot;</span>: <span class="literal">False</span>&#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 节点：处理对话，返回完整 AIMessage</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    chunks = llm.stream(state[<span class="string">&quot;messages&quot;</span>])</span><br><span class="line">    content = <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> chunk <span class="keyword">in</span> chunks:</span><br><span class="line">        <span class="keyword">if</span> chunk.content:</span><br><span class="line">            <span class="built_in">print</span>(chunk.content, end=<span class="string">&quot;&quot;</span>, flush=<span class="literal">True</span>)  <span class="comment"># 实时打印流式输出</span></span><br><span class="line">            content += chunk.content</span><br><span class="line">    <span class="built_in">print</span>()  <span class="comment"># 换行</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [AIMessage(content=content)]&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建图</span></span><br><span class="line">graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br><span class="line">graph_builder.set_entry_point(<span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph_builder.set_finish_point(<span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph = graph_builder.<span class="built_in">compile</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行</span></span><br><span class="line">result = graph.invoke(&#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, <span class="string">&quot;你是谁？&quot;</span>)]&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;最终输出:&quot;</span>, result[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].content)</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="调用工具"><a href="#调用工具" class="headerlink" title="调用工具"></a>调用工具</h2><h3 id="示例1：计算器"><a href="#示例1：计算器" class="headerlink" title="示例1：计算器"></a>示例1：计算器</h3><p><strong>纯python：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">API_KEY = <span class="string">&quot;sk-xxxxxxxxxxxxxxxxxxxxxxxx&quot;</span></span><br><span class="line">API_URL = <span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions&quot;</span></span><br><span class="line">HEADERS = &#123;</span><br><span class="line">    <span class="string">&quot;Authorization&quot;</span>: <span class="string">f&quot;Bearer <span class="subst">&#123;API_KEY&#125;</span>&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;application/json&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注册函数定义，告诉模型有哪些工具可以调用</span></span><br><span class="line">functions = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;name&quot;</span>: <span class="string">&quot;calculator&quot;</span>,</span><br><span class="line">        <span class="string">&quot;description&quot;</span>: <span class="string">&quot;简单计算器，计算加减乘除表达式&quot;</span>,</span><br><span class="line">        <span class="string">&quot;parameters&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;type&quot;</span>: <span class="string">&quot;object&quot;</span>,</span><br><span class="line">            <span class="string">&quot;properties&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;expression&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;description&quot;</span>: <span class="string">&quot;算术表达式，比如 1+1 或 2*3&quot;</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;required&quot;</span>: [<span class="string">&quot;expression&quot;</span>]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculator</span>(<span class="params">expression: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="comment"># 安全计算</span></span><br><span class="line">    allowed = <span class="string">&quot;0123456789+-*/. ()&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">any</span>(c <span class="keyword">not</span> <span class="keyword">in</span> allowed <span class="keyword">for</span> c <span class="keyword">in</span> expression):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;表达式包含非法字符。&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">str</span>(<span class="built_in">eval</span>(expression))</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;计算错误：<span class="subst">&#123;e&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">send_message</span>(<span class="params">messages, functions=<span class="literal">None</span>, function_call=<span class="literal">None</span>, stream=<span class="literal">False</span></span>):</span><br><span class="line">    payload = &#123;</span><br><span class="line">        <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen3-8b&quot;</span>,</span><br><span class="line">        <span class="string">&quot;messages&quot;</span>: messages,</span><br><span class="line">        <span class="string">&quot;enable_thinking&quot;</span>: <span class="literal">False</span>,</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> functions:</span><br><span class="line">        payload[<span class="string">&quot;functions&quot;</span>] = functions</span><br><span class="line">    <span class="keyword">if</span> function_call:</span><br><span class="line">        payload[<span class="string">&quot;function_call&quot;</span>] = function_call</span><br><span class="line">    <span class="keyword">if</span> stream:</span><br><span class="line">        payload[<span class="string">&quot;stream&quot;</span>] = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    response = requests.post(API_URL, headers=HEADERS, json=payload, stream=stream)</span><br><span class="line">    response.raise_for_status()</span><br><span class="line">    <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chat_loop</span>():</span><br><span class="line">    messages = [&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;你是一个乐于助人的助手。&quot;</span>&#125;]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        user_input = <span class="built_in">input</span>(<span class="string">&quot;用户: &quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> user_input.lower() <span class="keyword">in</span> [<span class="string">&quot;quit&quot;</span>, <span class="string">&quot;exit&quot;</span>, <span class="string">&quot;q&quot;</span>]:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;再见！&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: user_input&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 第一次调用，告诉模型有哪些函数可调用</span></span><br><span class="line">        resp = send_message(messages, functions=functions, stream=<span class="literal">False</span>)</span><br><span class="line">        resp_json = resp.json()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 检查是否有函数调用指令</span></span><br><span class="line">        message = resp_json[<span class="string">&quot;choices&quot;</span>][<span class="number">0</span>][<span class="string">&quot;message&quot;</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&quot;function_call&quot;</span> <span class="keyword">in</span> message:</span><br><span class="line">            <span class="comment"># 模型请求调用函数</span></span><br><span class="line">            func_call = message[<span class="string">&quot;function_call&quot;</span>]</span><br><span class="line">            func_name = func_call[<span class="string">&quot;name&quot;</span>]</span><br><span class="line">            func_args = json.loads(func_call[<span class="string">&quot;arguments&quot;</span>])</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;\n[模型请求调用函数]: <span class="subst">&#123;func_name&#125;</span>，参数: <span class="subst">&#123;func_args&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 执行函数</span></span><br><span class="line">            <span class="keyword">if</span> func_name == <span class="string">&quot;calculator&quot;</span>:</span><br><span class="line">                result = calculator(func_args.get(<span class="string">&quot;expression&quot;</span>, <span class="string">&quot;&quot;</span>))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                result = <span class="string">f&quot;未知函数: <span class="subst">&#123;func_name&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;[函数执行结果]: <span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 把函数结果作为 assistant 的 function 角色消息添加</span></span><br><span class="line">            messages.append(message)  <span class="comment"># 模型请求调用函数消息</span></span><br><span class="line">            messages.append(&#123;</span><br><span class="line">                <span class="string">&quot;role&quot;</span>: <span class="string">&quot;function&quot;</span>,</span><br><span class="line">                <span class="string">&quot;name&quot;</span>: func_name,</span><br><span class="line">                <span class="string">&quot;content&quot;</span>: result</span><br><span class="line">            &#125;)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 再次调用模型，传入函数结果，让模型继续回答</span></span><br><span class="line">            resp2 = send_message(messages, stream=<span class="literal">True</span>)</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> resp2.iter_lines():</span><br><span class="line">                <span class="keyword">if</span> line:</span><br><span class="line">                    <span class="keyword">try</span>:</span><br><span class="line">                        data = json.loads(line.decode())</span><br><span class="line">                        chunk = data.get(<span class="string">&quot;choices&quot;</span>, [&#123;&#125;])[<span class="number">0</span>].get(<span class="string">&quot;delta&quot;</span>, &#123;&#125;).get(<span class="string">&quot;content&quot;</span>, <span class="string">&quot;&quot;</span>)</span><br><span class="line">                        <span class="keyword">if</span> chunk:</span><br><span class="line">                            <span class="built_in">print</span>(chunk, end=<span class="string">&quot;&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">                    <span class="keyword">except</span>:</span><br><span class="line">                        <span class="keyword">continue</span></span><br><span class="line">            <span class="built_in">print</span>()</span><br><span class="line">            messages.append(&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;[工具调用完毕，继续对话]&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 直接输出模型回复</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;助手: &quot;</span>, end=<span class="string">&quot;&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">            <span class="comment"># 流式打印</span></span><br><span class="line">            <span class="comment"># 这里因为第一次调用是非流式，简单打印content</span></span><br><span class="line">            <span class="built_in">print</span>(message.get(<span class="string">&quot;content&quot;</span>, <span class="string">&quot;&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    chat_loop()</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">用户: 你能帮我算一下 1234 * 5678 吗？</span><br><span class="line"></span><br><span class="line">[模型请求调用函数]: calculator，参数: &#123;&#x27;expression&#x27;: &#x27;1234 * 5678&#x27;&#125;</span><br><span class="line">[函数执行结果]: 7006652</span><br></pre></td></tr></table></figure>



<hr>
<p><strong><code>OpenAI</code>：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化客户端（适配 Qwen 的 OpenAI 兼容模式）</span></span><br><span class="line">client = OpenAI(</span><br><span class="line">    api_key=<span class="string">&quot;sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&quot;</span>,</span><br><span class="line">    base_url=<span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义工具函数（Function Calling 格式）</span></span><br><span class="line">tools = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;function&quot;</span>,</span><br><span class="line">        <span class="string">&quot;function&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;calculator&quot;</span>,</span><br><span class="line">            <span class="string">&quot;description&quot;</span>: <span class="string">&quot;进行基础数学运算，比如加减乘除&quot;</span>,</span><br><span class="line">            <span class="string">&quot;parameters&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;type&quot;</span>: <span class="string">&quot;object&quot;</span>,</span><br><span class="line">                <span class="string">&quot;properties&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;expression&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;description&quot;</span>: <span class="string">&quot;要计算的表达式，例如 &#x27;3 * (2 + 5)&#x27;&quot;</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="string">&quot;required&quot;</span>: [<span class="string">&quot;expression&quot;</span>]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 首次请求：让模型判断是否要调用函数</span></span><br><span class="line">response = client.chat.completions.create(</span><br><span class="line">    model=<span class="string">&quot;qwen3-8b&quot;</span>,</span><br><span class="line">    messages=[</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;你是一个会调用计算器函数的助手&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;你能帮我算一下 1234 * 5678 吗？&quot;</span>&#125;,</span><br><span class="line">    ],</span><br><span class="line">    tools=tools,</span><br><span class="line">    tool_choice=<span class="string">&quot;auto&quot;</span>,  <span class="comment"># 自动判断是否调用工具</span></span><br><span class="line">    extra_body=&#123;<span class="string">&quot;enable_thinking&quot;</span>: <span class="literal">False</span>&#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果模型选择了调用工具</span></span><br><span class="line">choice = response.choices[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">if</span> choice.finish_reason == <span class="string">&quot;tool_calls&quot;</span>:</span><br><span class="line">    tool_call = choice.message.tool_calls[<span class="number">0</span>]</span><br><span class="line">    func_name = tool_call.function.name</span><br><span class="line">    arguments = json.loads(tool_call.function.arguments)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 实际执行函数调用</span></span><br><span class="line">    <span class="keyword">if</span> func_name == <span class="string">&quot;calculator&quot;</span>:</span><br><span class="line">        expression = arguments[<span class="string">&quot;expression&quot;</span>]</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            result = <span class="built_in">str</span>(<span class="built_in">eval</span>(expression))</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            result = <span class="string">f&quot;计算出错：<span class="subst">&#123;e&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 回传结果给模型继续对话</span></span><br><span class="line">        follow_up = client.chat.completions.create(</span><br><span class="line">            model=<span class="string">&quot;qwen3-8b&quot;</span>,</span><br><span class="line">            messages=[</span><br><span class="line">                &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;你是一个会调用计算器函数的助手&quot;</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;你能帮我算一下 1234 * 5678 吗？&quot;</span>&#125;,</span><br><span class="line">                choice.message,</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="string">&quot;role&quot;</span>: <span class="string">&quot;tool&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;tool_call_id&quot;</span>: tool_call.<span class="built_in">id</span>,</span><br><span class="line">                    <span class="string">&quot;name&quot;</span>: func_name,</span><br><span class="line">                    <span class="string">&quot;content&quot;</span>: result</span><br><span class="line">                &#125;</span><br><span class="line">            ],</span><br><span class="line">            stream=<span class="literal">True</span>,  <span class="comment"># 开启流式输出</span></span><br><span class="line">            extra_body=&#123;<span class="string">&quot;enable_thinking&quot;</span>: <span class="literal">False</span>&#125;</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 流式打印最终回答</span></span><br><span class="line">        <span class="keyword">for</span> chunk <span class="keyword">in</span> follow_up:</span><br><span class="line">            delta = chunk.choices[<span class="number">0</span>].delta</span><br><span class="line">            <span class="keyword">if</span> delta <span class="keyword">and</span> delta.content:</span><br><span class="line">                <span class="built_in">print</span>(delta.content, end=<span class="string">&quot;&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 没调用工具，直接输出回答</span></span><br><span class="line">    <span class="built_in">print</span>(choice.message.content)</span><br></pre></td></tr></table></figure>

<p>注意第二个<code>messages</code>的内容（<code>OpenAI</code>的<code>Function Calling</code>规范）：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">messages=[</span><br><span class="line">    <span class="params">#</span> 1. 系统消息（设定助手角色）</span><br><span class="line">    &#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;你是一个会调用计算器函数的助手&quot;&#125;,</span><br><span class="line"></span><br><span class="line">    <span class="params">#</span> 2. 用户初始问题</span><br><span class="line">    &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;你能帮我算一下 1234 * 5678 吗？&quot;&#125;,</span><br><span class="line"></span><br><span class="line">    <span class="params">#</span> 3. 模型第一次的回复（包含工具调用请求）</span><br><span class="line">    choice.message,</span><br><span class="line"></span><br><span class="line">    <span class="params">#</span> 4. 工具执行结果的反馈</span><br><span class="line">    &#123;</span><br><span class="line">        &quot;role&quot;: &quot;tool&quot;,</span><br><span class="line">        &quot;tool<span class="built_in">_</span>call<span class="built_in">_</span>id&quot;: tool<span class="built_in">_</span>call.id,  <span class="params">#</span> 关联工具调用的ID</span><br><span class="line">        &quot;name&quot;: func<span class="built_in">_</span>name,            <span class="params">#</span> 工具名称（如 &quot;calculator&quot;）</span><br><span class="line">        &quot;content&quot;: result             <span class="params">#</span> 工具执行结果（如 &quot;7006652&quot;）</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p><strong><code>choice.message</code>的内容如下：</strong></p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">ChatCompletionMessage(</span><br><span class="line">	content=&#x27;&#x27;,</span><br><span class="line">    refusal=None,</span><br><span class="line">    role=&#x27;assistant&#x27;,</span><br><span class="line">    audio=None,</span><br><span class="line">    function<span class="built_in">_</span>call=None,</span><br><span class="line">    tool<span class="built_in">_</span>calls=[</span><br><span class="line">    	ChatCompletionMessageToolCall(id=&#x27;call<span class="built_in">_</span>d9655f57796f44928ced84&#x27;,</span><br><span class="line">    	function=Function(arguments=&#x27;&#123;&quot;expression&quot;: &quot;1234 * 5678&quot;&#125;&#x27;, name=&#x27;calculator&#x27;),</span><br><span class="line">        type=&#x27;function&#x27;,</span><br><span class="line">        index=0)</span><br><span class="line">        ],</span><br><span class="line">    reasoning<span class="built_in">_</span>content=&#x27;&#x27;)</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">1234 乘以 5678 等于 **7006652**。</span><br></pre></td></tr></table></figure>

<hr>
<p><strong>Langgraph:</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"><span class="keyword">from</span> langgraph.checkpoint.memory <span class="keyword">import</span> MemorySaver</span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> AIMessageChunk</span><br><span class="line"><span class="keyword">from</span> langchain_core.tools <span class="keyword">import</span> tool</span><br><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> ToolNode, tools_condition</span><br><span class="line"><span class="keyword">from</span> langchain_community.chat_models.tongyi <span class="keyword">import</span> ChatTongyi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 1. 状态结构定义 ----</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">memory = MemorySaver()</span><br><span class="line">graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 2. 注册计算器工具，并打印调用信息 ----</span></span><br><span class="line"><span class="meta">@tool</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculator</span>(<span class="params">expression: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;计算器：输入数学表达式（如 &#x27;2+3*4&#x27;），返回结果&quot;&quot;&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;[Tool] calculator 被调用，参数 expression = <span class="subst">&#123;expression&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        result = <span class="built_in">eval</span>(expression, &#123;<span class="string">&quot;__builtins__&quot;</span>: &#123;&#125;&#125;)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">str</span>(result)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;表达式有误：<span class="subst">&#123;e&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tools = [calculator]</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 3. 初始化 ChatTongyi 模型 ----</span></span><br><span class="line">LLM_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;sk-xxxxxxxxxxxxxxxxxxxxx&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen3-8b&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">llm = ChatTongyi(</span><br><span class="line">    model=LLM_CONFIG[<span class="string">&quot;model&quot;</span>],</span><br><span class="line">    api_key=LLM_CONFIG[<span class="string">&quot;api_key&quot;</span>],</span><br><span class="line">    streaming=<span class="literal">True</span>,</span><br><span class="line">    model_kwargs=&#123;<span class="string">&quot;enable_thinking&quot;</span>: <span class="literal">False</span>&#125;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 4. 节点逻辑 ----</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;[ChatBot] 正在生成回复...&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [llm_with_tools.invoke(state[<span class="string">&quot;messages&quot;</span>])]&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 工具节点</span></span><br><span class="line">tool_node = ToolNode(tools=tools)</span><br><span class="line">graph_builder.add_node(<span class="string">&quot;tools&quot;</span>, tool_node)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置入口和出口</span></span><br><span class="line">graph_builder.set_entry_point(<span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph_builder.set_finish_point(<span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加条件跳转：是否调用工具</span></span><br><span class="line">graph_builder.add_conditional_edges(<span class="string">&quot;chatbot&quot;</span>, tools_condition)</span><br><span class="line">graph_builder.add_edge(<span class="string">&quot;tools&quot;</span>, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译图</span></span><br><span class="line">graph = graph_builder.<span class="built_in">compile</span>(checkpointer=memory)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 5. 流式输出 ----</span></span><br><span class="line">config = &#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: <span class="string">&quot;session-1&quot;</span>&#125;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stream_graph_updates</span>(<span class="params">user_input: <span class="built_in">str</span></span>):</span><br><span class="line">    first = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">for</span> msg, _ <span class="keyword">in</span> graph.stream(&#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, user_input)]&#125;, config, stream_mode=<span class="string">&quot;messages&quot;</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk) <span class="keyword">and</span> msg.content:</span><br><span class="line">            <span class="keyword">if</span> first:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;Assistant: &quot;</span>, end=<span class="string">&quot;&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">                first = <span class="literal">False</span></span><br><span class="line">            <span class="built_in">print</span>(msg.content, end=<span class="string">&quot;&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 6. 主循环 ----</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;欢迎使用 AI 计算助手，可输入数学表达式或其他问题。\n输入 exit 退出。\n&quot;</span>)</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        user_input = <span class="built_in">input</span>(<span class="string">&quot;User: &quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> user_input.lower() <span class="keyword">in</span> [<span class="string">&quot;exit&quot;</span>, <span class="string">&quot;quit&quot;</span>, <span class="string">&quot;q&quot;</span>]:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Goodbye!&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        stream_graph_updates(user_input)</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">User: 你能帮我算一下 1234 * 5678 吗？</span><br><span class="line">[ChatBot] 正在生成回复...</span><br><span class="line">[Tool] calculator 被调用，参数 expression = 1234 * 5678</span><br><span class="line">[ChatBot] 正在生成回复...</span><br><span class="line">Assistant: 1234 乘以 5678 的结果是 7006652。</span><br></pre></td></tr></table></figure>

<p>现在实现了简易的计算器调用示例，那么如果是串行调用两个工具呢？</p>
<hr>
<h3 id="示例2：统计计算结果的位数"><a href="#示例2：统计计算结果的位数" class="headerlink" title="示例2：统计计算结果的位数"></a>示例2：统计计算结果的位数</h3><p><strong><code>OpenAI</code></strong></p>
<p>目的：串行实现计算器工具+统计位数工具</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">client = OpenAI(</span><br><span class="line">    api_key=<span class="string">&quot;sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&quot;</span>,</span><br><span class="line">    base_url=<span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义两个工具</span></span><br><span class="line">tools = [</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;function&quot;</span>,</span><br><span class="line">        <span class="string">&quot;function&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;calculator&quot;</span>,</span><br><span class="line">            <span class="string">&quot;description&quot;</span>: <span class="string">&quot;进行基础数学运算，比如加减乘除&quot;</span>,</span><br><span class="line">            <span class="string">&quot;parameters&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;type&quot;</span>: <span class="string">&quot;object&quot;</span>,</span><br><span class="line">                <span class="string">&quot;properties&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;expression&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;description&quot;</span>: <span class="string">&quot;要计算的表达式，例如 &#x27;3 * (2 + 5)&#x27;&quot;</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="string">&quot;required&quot;</span>: [<span class="string">&quot;expression&quot;</span>]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;function&quot;</span>,</span><br><span class="line">        <span class="string">&quot;function&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;count_digits&quot;</span>,</span><br><span class="line">            <span class="string">&quot;description&quot;</span>: <span class="string">&quot;计算一个整数有几位数字&quot;</span>,</span><br><span class="line">            <span class="string">&quot;parameters&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;type&quot;</span>: <span class="string">&quot;object&quot;</span>,</span><br><span class="line">                <span class="string">&quot;properties&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;number&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;integer&quot;</span>,</span><br><span class="line">                        <span class="string">&quot;description&quot;</span>: <span class="string">&quot;要统计位数的整数&quot;</span></span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;,</span><br><span class="line">                <span class="string">&quot;required&quot;</span>: [<span class="string">&quot;number&quot;</span>]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用户输入的问题</span></span><br><span class="line">init_messages = [</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;你是一个能调用工具解决复杂问题的助手&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;1234 * 5678的结果有几位？&quot;</span>&#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一次请求：让模型判断是否调用工具</span></span><br><span class="line">response = client.chat.completions.create(</span><br><span class="line">    model=<span class="string">&quot;qwen3-8b&quot;</span>,</span><br><span class="line">    messages=init_messages,</span><br><span class="line">    tools=tools,</span><br><span class="line">    tool_choice=<span class="string">&quot;auto&quot;</span>,</span><br><span class="line">    extra_body=&#123;<span class="string">&quot;enable_thinking&quot;</span>: <span class="literal">False</span>&#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">choice1 = response.choices[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型选择调用 calculator 工具</span></span><br><span class="line">tool_call_1 = choice1.message.tool_calls[<span class="number">0</span>]</span><br><span class="line">arguments_1 = json.loads(tool_call_1.function.arguments)</span><br><span class="line">expression = arguments_1[<span class="string">&quot;expression&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行 calculator 函数</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    calc_result = <span class="built_in">eval</span>(expression)</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    calc_result = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟第二次工具调用（使用 messages 再次构造工具调用请求）</span></span><br><span class="line">followup_response = client.chat.completions.create(</span><br><span class="line">    model=<span class="string">&quot;qwen3-8b&quot;</span>,</span><br><span class="line">    messages=init_messages + [</span><br><span class="line">        choice1.message,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;role&quot;</span>: <span class="string">&quot;tool&quot;</span>,</span><br><span class="line">            <span class="string">&quot;tool_call_id&quot;</span>: tool_call_1.<span class="built_in">id</span>,</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;calculator&quot;</span>,</span><br><span class="line">            <span class="string">&quot;content&quot;</span>: <span class="built_in">str</span>(calc_result)</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    tools=tools,</span><br><span class="line">    tool_choice=<span class="string">&quot;auto&quot;</span>,</span><br><span class="line">    extra_body=&#123;<span class="string">&quot;enable_thinking&quot;</span>: <span class="literal">False</span>&#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">choice2 = followup_response.choices[<span class="number">0</span>]</span><br><span class="line">tool_call_real_2 = choice2.message.tool_calls[<span class="number">0</span>]</span><br><span class="line">arguments_2 = json.loads(tool_call_real_2.function.arguments)</span><br><span class="line">number = arguments_2[<span class="string">&quot;number&quot;</span>]</span><br><span class="line">digit_count = <span class="built_in">len</span>(<span class="built_in">str</span>(number))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最终：把两个工具调用结果传回模型，生成自然语言回答</span></span><br><span class="line">final_response = client.chat.completions.create(</span><br><span class="line">    model=<span class="string">&quot;qwen3-8b&quot;</span>,</span><br><span class="line">    messages=init_messages + [</span><br><span class="line">        choice1.message,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;role&quot;</span>: <span class="string">&quot;tool&quot;</span>,</span><br><span class="line">            <span class="string">&quot;tool_call_id&quot;</span>: tool_call_1.<span class="built_in">id</span>,</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;calculator&quot;</span>,</span><br><span class="line">            <span class="string">&quot;content&quot;</span>: <span class="built_in">str</span>(calc_result)</span><br><span class="line">        &#125;,</span><br><span class="line">        choice2.message,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;role&quot;</span>: <span class="string">&quot;tool&quot;</span>,</span><br><span class="line">            <span class="string">&quot;tool_call_id&quot;</span>: tool_call_real_2.<span class="built_in">id</span>,</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: <span class="string">&quot;count_digits&quot;</span>,</span><br><span class="line">            <span class="string">&quot;content&quot;</span>: <span class="built_in">str</span>(digit_count)</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    stream=<span class="literal">True</span>,</span><br><span class="line">    extra_body=&#123;<span class="string">&quot;enable_thinking&quot;</span>: <span class="literal">False</span>&#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 流式输出最终回答</span></span><br><span class="line"><span class="keyword">for</span> chunk <span class="keyword">in</span> final_response:</span><br><span class="line">    delta = chunk.choices[<span class="number">0</span>].delta</span><br><span class="line">    <span class="keyword">if</span> delta <span class="keyword">and</span> delta.content:</span><br><span class="line">        <span class="built_in">print</span>(delta.content, end=<span class="string">&quot;&quot;</span>, flush=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p><strong>输出结果：</strong></p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">1234 乘以 5678 的结果是 **7006652**，这个数共有 **7 位**。</span><br></pre></td></tr></table></figure>

<p><strong><code>Langgraph</code>的示例见示例3</strong></p>
<p>现在实现了两个工具的串行调用来完成一个问题的回答，但现实使用中，我们并不知道工具调用的次数和顺序，那该怎么办呢？</p>
<hr>
<h3 id="示例3：现代Agent框架"><a href="#示例3：现代Agent框架" class="headerlink" title="示例3：现代Agent框架"></a>示例3：现代Agent框架</h3><p><strong><code>OpenAI</code></strong></p>
<p><strong>将仿照<code>langchain/langgraph</code>原理改写示例2，提高其扩展性</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">TOOL_CALL_PREFIX = <span class="string">&quot;🔧 [工具调用]&quot;</span></span><br><span class="line"></span><br><span class="line">client = OpenAI(</span><br><span class="line">    api_key=<span class="string">&quot;sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&quot;</span>,</span><br><span class="line">    base_url=<span class="string">&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 定义工具基类（抽象）</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Tool</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name, description, parameters, func</span>):</span><br><span class="line">        <span class="variable language_">self</span>.name = name</span><br><span class="line">        <span class="variable language_">self</span>.description = description</span><br><span class="line">        <span class="variable language_">self</span>.parameters = parameters</span><br><span class="line">        <span class="variable language_">self</span>.func = func</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self, args</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;统一调用接口&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="variable language_">self</span>.func(args)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">f&quot;执行出错：<span class="subst">&#123;e&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 具体工具函数实现</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculator_func</span>(<span class="params">args</span>):</span><br><span class="line">    expr = args.get(<span class="string">&quot;expression&quot;</span>)</span><br><span class="line">    <span class="comment"># eval不安全，实际项目用安全库替代</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">str</span>(<span class="built_in">eval</span>(expr))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">count_digits_func</span>(<span class="params">args</span>):</span><br><span class="line">    number = args.get(<span class="string">&quot;number&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">str</span>(<span class="built_in">len</span>(<span class="built_in">str</span>(number)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 创建工具实例</span></span><br><span class="line">tools = [</span><br><span class="line">    Tool(</span><br><span class="line">        name=<span class="string">&quot;calculator&quot;</span>,</span><br><span class="line">        description=<span class="string">&quot;进行基础数学运算，比如加减乘除&quot;</span>,</span><br><span class="line">        parameters=&#123;</span><br><span class="line">            <span class="string">&quot;type&quot;</span>: <span class="string">&quot;object&quot;</span>,</span><br><span class="line">            <span class="string">&quot;properties&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;expression&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;description&quot;</span>: <span class="string">&quot;要计算的表达式&quot;</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;required&quot;</span>: [<span class="string">&quot;expression&quot;</span>]</span><br><span class="line">        &#125;,</span><br><span class="line">        func=calculator_func</span><br><span class="line">    ),</span><br><span class="line">    Tool(</span><br><span class="line">        name=<span class="string">&quot;count_digits&quot;</span>,</span><br><span class="line">        description=<span class="string">&quot;计算一个整数有几位数字&quot;</span>,</span><br><span class="line">        parameters=&#123;</span><br><span class="line">            <span class="string">&quot;type&quot;</span>: <span class="string">&quot;object&quot;</span>,</span><br><span class="line">            <span class="string">&quot;properties&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;number&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;integer&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;description&quot;</span>: <span class="string">&quot;要统计位数的整数&quot;</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="string">&quot;required&quot;</span>: [<span class="string">&quot;number&quot;</span>]</span><br><span class="line">        &#125;,</span><br><span class="line">        func=count_digits_func</span><br><span class="line">    )</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 工具名称到工具对象的映射</span></span><br><span class="line">tool_map = &#123;tool.name: tool <span class="keyword">for</span> tool <span class="keyword">in</span> tools&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 生成OpenAI API需要的tools参数格式</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_tools_for_api</span>():</span><br><span class="line">    <span class="keyword">return</span> [&#123;</span><br><span class="line">        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;function&quot;</span>,</span><br><span class="line">        <span class="string">&quot;function&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: tool.name,</span><br><span class="line">            <span class="string">&quot;description&quot;</span>: tool.description,</span><br><span class="line">            <span class="string">&quot;parameters&quot;</span>: tool.parameters</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">for</span> tool <span class="keyword">in</span> tools]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. 主流程</span></span><br><span class="line">messages = [</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;你是一个能调用工具的助手&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;1234 * 5678的结果是几位数&quot;</span>&#125;</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    response = client.chat.completions.create(</span><br><span class="line">        model=<span class="string">&quot;qwen3-8b&quot;</span>,</span><br><span class="line">        messages=messages,</span><br><span class="line">        tools=get_tools_for_api(),</span><br><span class="line">        tool_choice=<span class="string">&quot;auto&quot;</span>,</span><br><span class="line">        extra_body=&#123;<span class="string">&quot;enable_thinking&quot;</span>: <span class="literal">False</span>&#125;</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    choice = response.choices[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> choice.finish_reason != <span class="string">&quot;tool_calls&quot;</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n🤖 最终回答：&quot;</span>, choice.message.content)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> tool_call <span class="keyword">in</span> choice.message.tool_calls:</span><br><span class="line">        func_name = tool_call.function.name</span><br><span class="line">        args = json.loads(tool_call.function.arguments)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;\n<span class="subst">&#123;TOOL_CALL_PREFIX&#125;</span> 调用函数: <span class="subst">&#123;func_name&#125;</span>，参数: <span class="subst">&#123;args&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> func_name <span class="keyword">in</span> tool_map:</span><br><span class="line">            result = tool_map[func_name].run(args)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;TOOL_CALL_PREFIX&#125;</span> 返回结果: <span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            result = <span class="string">&quot;未知函数&quot;</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;TOOL_CALL_PREFIX&#125;</span> ⚠️ 未识别的函数: <span class="subst">&#123;func_name&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        messages.append(choice.message)</span><br><span class="line">        messages.append(&#123;</span><br><span class="line">            <span class="string">&quot;role&quot;</span>: <span class="string">&quot;tool&quot;</span>,</span><br><span class="line">            <span class="string">&quot;tool_call_id&quot;</span>: tool_call.<span class="built_in">id</span>,</span><br><span class="line">            <span class="string">&quot;name&quot;</span>: func_name,</span><br><span class="line">            <span class="string">&quot;content&quot;</span>: result</span><br><span class="line">        &#125;)</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">🔧 [工具调用] 调用函数: calculator，参数: &#123;&#x27;expression&#x27;: &#x27;1234 * 5678&#x27;&#125;</span><br><span class="line">🔧 [工具调用] 返回结果: 7006652</span><br><span class="line"></span><br><span class="line">🔧 [工具调用] 调用函数: count<span class="built_in">_</span>digits，参数: &#123;&#x27;number&#x27;: 7006652&#125;</span><br><span class="line">🔧 [工具调用] 返回结果: 7</span><br><span class="line"></span><br><span class="line">🤖 最终回答： 1234 乘以 5678 的结果是 7006652，它是一个 7 位数。</span><br></pre></td></tr></table></figure>

<hr>
<p><strong>Langgraph：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"><span class="keyword">from</span> langgraph.checkpoint.memory <span class="keyword">import</span> MemorySaver</span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> AIMessageChunk</span><br><span class="line"><span class="keyword">from</span> langchain_core.tools <span class="keyword">import</span> tool</span><br><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> ToolNode, tools_condition</span><br><span class="line"><span class="keyword">from</span> langchain_community.chat_models.tongyi <span class="keyword">import</span> ChatTongyi</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 1. 状态结构定义 ----</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line">memory = MemorySaver()</span><br><span class="line">graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 2. 工具定义 ----</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@tool</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calculator</span>(<span class="params">expression: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;计算器：输入数学表达式（如 &#x27;2+3*4&#x27;），返回结果&quot;&quot;&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;[Tool] calculator 被调用，参数 expression = <span class="subst">&#123;expression&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        result = <span class="built_in">eval</span>(expression, &#123;<span class="string">&quot;__builtins__&quot;</span>: &#123;&#125;&#125;)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">str</span>(result)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;表达式有误：<span class="subst">&#123;e&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@tool</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">count_digits</span>(<span class="params">number: <span class="built_in">float</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    价格位数统计：输入一个数字，返回其位数。</span></span><br><span class="line"><span class="string">    示例：输入 123.45 → 返回 6（含小数点和数字）</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;[Tool] count_digits 被调用，参数 number = <span class="subst">&#123;number&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        digit_count = <span class="built_in">len</span>(<span class="built_in">str</span>(number))</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;数字 <span class="subst">&#123;number&#125;</span> 的总位数是 <span class="subst">&#123;digit_count&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;无法统计位数：<span class="subst">&#123;e&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line">tools = [calculator, count_digits]</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 3. 初始化 ChatTongyi 模型 ----</span></span><br><span class="line">LLM_CONFIG = &#123;</span><br><span class="line">    <span class="string">&quot;api_key&quot;</span>: <span class="string">&quot;sk-xxxxxxxxxxxxxxxxxxxxxxx&quot;</span>,</span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen3-8b&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">llm = ChatTongyi(</span><br><span class="line">    model=LLM_CONFIG[<span class="string">&quot;model&quot;</span>],</span><br><span class="line">    api_key=LLM_CONFIG[<span class="string">&quot;api_key&quot;</span>],</span><br><span class="line">    streaming=<span class="literal">True</span>,</span><br><span class="line">    model_kwargs=&#123;<span class="string">&quot;enable_thinking&quot;</span>: <span class="literal">False</span>&#125;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 4. 节点逻辑 ----</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;[ChatBot] 正在生成回复...&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [llm_with_tools.invoke(state[<span class="string">&quot;messages&quot;</span>])]&#125;</span><br><span class="line"></span><br><span class="line">graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 工具节点</span></span><br><span class="line">tool_node = ToolNode(tools=tools)</span><br><span class="line">graph_builder.add_node(<span class="string">&quot;tools&quot;</span>, tool_node)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置入口和出口</span></span><br><span class="line">graph_builder.set_entry_point(<span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph_builder.set_finish_point(<span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加条件跳转：是否调用工具</span></span><br><span class="line">graph_builder.add_conditional_edges(<span class="string">&quot;chatbot&quot;</span>, tools_condition)</span><br><span class="line">graph_builder.add_edge(<span class="string">&quot;tools&quot;</span>, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译图</span></span><br><span class="line">graph = graph_builder.<span class="built_in">compile</span>(checkpointer=memory)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 5. 流式输出 ----</span></span><br><span class="line">config = &#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: <span class="string">&quot;session-1&quot;</span>&#125;&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stream_graph_updates</span>(<span class="params">user_input: <span class="built_in">str</span></span>):</span><br><span class="line">    first = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">for</span> msg, _ <span class="keyword">in</span> graph.stream(&#123;<span class="string">&quot;messages&quot;</span>: [(<span class="string">&quot;user&quot;</span>, user_input)]&#125;, config, stream_mode=<span class="string">&quot;messages&quot;</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, AIMessageChunk) <span class="keyword">and</span> msg.content:</span><br><span class="line">            <span class="keyword">if</span> first:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;Assistant: &quot;</span>, end=<span class="string">&quot;&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">                first = <span class="literal">False</span></span><br><span class="line">            <span class="built_in">print</span>(msg.content, end=<span class="string">&quot;&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 6. 主循环 ----</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;欢迎使用 AI 工具助手，支持计算和价格位数统计。\n输入 exit 退出。\n&quot;</span>)</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        user_input = <span class="built_in">input</span>(<span class="string">&quot;User: &quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> user_input.lower() <span class="keyword">in</span> [<span class="string">&quot;exit&quot;</span>, <span class="string">&quot;quit&quot;</span>, <span class="string">&quot;q&quot;</span>]:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Goodbye!&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        stream_graph_updates(user_input)</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">[ChatBot] 正在生成回复...</span><br><span class="line">[Tool] calculator 被调用，参数 expression = 1234 * 5678</span><br><span class="line">[ChatBot] 正在生成回复...</span><br><span class="line">[Tool] count<span class="built_in">_</span>digits 被调用，参数 number = 7006652.0</span><br><span class="line">[ChatBot] 正在生成回复...</span><br><span class="line">Assistant: 1234 乘以 5678 的结果是 7006652，这个结果共有 9 位数字。</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文对比了三种实现工具&#x2F;函数调用的方式，在日常使用时更多的是使用<code>OpenAI</code>或者<code>langchain/langgraph</code>库，而<code>requests</code>库更适合用于原理学习，由于<code>requests</code>库方式与<code>OpenAI</code>库使用时异曲同工，故只给出示例1的计算器调用。另外，提前预告下，接下来会出<code>MCP</code>的使用示例。</p>
<hr>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><p><a href="https://python.langchain.com/docs/integrations/chat/tongyi/#construct-args-manually">https://python.langchain.com/docs/integrations/chat/tongyi/#construct-args-manually</a></p>
</li>
<li><p><a href="https://blog.csdn.net/qq_45055172/article/details/146091768">https://blog.csdn.net/qq_45055172/article/details/146091768</a></p>
</li>
<li><p><a href="https://caihaoran-00.github.io/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/?highlight=langgraph#%E7%A4%BA%E4%BE%8B5%EF%BC%9A%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B7%A5%E5%85%B7">https://caihaoran-00.github.io/2025/02/10/langgraph%E4%BB%8B%E7%BB%8D%E5%8F%8Ademo/?highlight=langgraph#%E7%A4%BA%E4%BE%8B5%EF%BC%9A%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B7%A5%E5%85%B7</a></p>
</li>
<li><p><a href="https://caihaoran-00.github.io/2025/02/25/Langgraph%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA%E7%AF%87/?highlight=langgraph#%E2%9C%A8%E9%99%84%E5%BD%95%EF%BC%9A%E6%B5%81%E5%BC%8F%E4%BC%A0%E8%BE%93LLM-tokens%E6%89%A9%E5%B1%95">https://caihaoran-00.github.io/2025/02/25/Langgraph%E6%B5%81%E5%BC%8F%E8%BE%93%E5%87%BA%E7%AF%87/?highlight=langgraph#%E2%9C%A8%E9%99%84%E5%BD%95%EF%BC%9A%E6%B5%81%E5%BC%8F%E4%BC%A0%E8%BE%93LLM-tokens%E6%89%A9%E5%B1%95</a></p>
</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>端侧实时交互数字人调研</title>
    <url>/2025/03/05/%E7%AB%AF%E4%BE%A7%E5%AE%9E%E6%97%B6%E4%BA%A4%E4%BA%92%E6%95%B0%E5%AD%97%E4%BA%BA%E8%B0%83%E7%A0%94/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前面做了些AI智能聊天机器人的工作，那能不能和数字人结合起来呢，给聊天机器人赋予形象，本文即为端侧（安卓端）可运行的数字人调研记录。</p>
<span id="more"></span>

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2>]]></content>
      <categories>
        <category>theory</category>
      </categories>
      <tags>
        <tag>数字人</tag>
      </tags>
  </entry>
  <entry>
    <title>自定义唤醒词(KWS):调研与目前想法</title>
    <url>/2025/06/13/%E8%87%AA%E5%AE%9A%E4%B9%89%E5%94%A4%E9%86%92%E8%AF%8D-KWS-%E8%B0%83%E7%A0%94%E4%B8%8E%E7%9B%AE%E5%89%8D%E6%83%B3%E6%B3%95/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>第一版玩具决定先不量产了，第二版再量产，增加了一些新需求，比如自定义唤醒词，如果在高性能<code>SoC</code>上，比如<code>Amlogic A113X</code>(<code>CPU:4× Cortex-A53(64位)</code>, 小米智能音箱的芯片)，是可以运行<a href="https://github.com/k2-fsa/sherpa-onnx">sherpa-onnx</a>的，有佬已经实现了，可以参考<a href="https://github.com/idootop/open-xiaoai-kws">这里</a>，支持自定义唤醒词的模型本质上都是精简的语音识别模型。但是呢，对于<code>ESP32-s3</code>这种低功耗<code>MCU</code>来说，是运行不了这些端侧的模型的，之前使用的是<a href="https://caihaoran-00.github.io/2025/04/03/KWS%E4%B9%8BmicroWakeWord%E5%AE%89%E8%A3%85%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95/">microWakeWord</a>，但一个模型对应一个唤醒词，是实现不了一个模型兼顾多个唤醒词的。那么，还有什么办法呢？</p>
<span id="more"></span>

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><blockquote>
<p>还是先提一下，这里说的自定义唤醒词指的是不从新训练模型的基础上，能实现更改唤醒词。</p>
</blockquote>
<p>先捋一下按顺序调研的整体思路：</p>
<ul>
<li>调研有没有可以直接运行在<code>ESP32-s3</code>上的，支持自定义唤醒词的开源模型&#x2F;框架</li>
<li>乐鑫官方有没有提供自定义唤醒词或其他解决方案</li>
<li>自己搭建网络训练并部署方案</li>
</ul>
<hr>
<p>对于第一点，<code>esp32-s3</code>上能运行的自定义唤醒词的开源模型&#x2F;框架，正如前言中提到的，即使对于小型&#x2F;精简的语音识别模型，也不是能运行在<code>esp32-s3</code>这种低功耗的<code>MCU</code>上的。</p>
<p>第二点，乐鑫官方是没有提供自定义唤醒词方案的，但是支持定制唤醒词（当然是收费的），参考<a href="https://docs.espressif.com/projects/esp-sr/zh_CN/latest/esp32s3/wake_word_engine/ESP_Wake_Words_Customization.html">这里</a>，<a href="https://github.com/espressif/esp-sr/issues/88">esp-sr</a>官方也提供了免费的唤醒词定制，但是提唤醒词的用户太多，扩容之前一个月大概是完成两个唤醒词，扩容后我看还是一个月大概两个唤醒词？免费的要什么自行车🤨</p>
<p>第二点否决掉了，因为技术完全掌握在别人手里，不自主可控。</p>
<p>其实刚听到自定义唤醒词方案，第一个想到的是通过端侧<code>ASR</code>实现，还是回到自定义唤醒词的本质：小型&#x2F;精简的语音识别模型。那么肯定可以通过端侧部署一个更大的<code>ASR</code>模型能实现自定义唤醒词的功能，但是这个方案有个弊端，那就是必须联网（连接<code>ASR</code>的服务器）才能使用唤醒词功能，于我们的产品设计相悖，遂也排除。</p>
<p>那么现在只有最后一种方案了：自己搭建网络训练并部署。但是这本质上是实现伪自定义唤醒词，并不能实时的添加唤醒词。需要实现一个自动化的流程：</p>
<img src="/2025/06/13/%E8%87%AA%E5%AE%9A%E4%B9%89%E5%94%A4%E9%86%92%E8%AF%8D-KWS-%E8%B0%83%E7%A0%94%E4%B8%8E%E7%9B%AE%E5%89%8D%E6%83%B3%E6%B3%95/image-20250616121833930.png" class="" title="image-20250616121833930">

<p>这个流程是：</p>
<ul>
<li>用户提交唤醒词（APP端），服务端接收（HTTP接口）</li>
<li>使用 TTS 合成语音样本（+数据增强）</li>
<li>训练自定义唤醒词模型（如 KWS 小模型）</li>
<li>在标准音频集上评估性能（Recall &#x2F; FAR）</li>
<li>若通过 → 下发模型（via HTTP 或 OTA）给用户设备；若未通过 → 重试（重新生成样本、微调参数）</li>
</ul>
<blockquote>
<p>召回率（Recall）：在所有真实说出了唤醒词的情况下，模型正，确唤醒的比例。或者叫RAR，right alarm rate，正确报警率。</p>
<p>FAR（误唤醒率 &#x2F; False Alarm Rate）：在没有唤醒词出现的音频中，系统错误唤醒的频率，以“次&#x2F;小时”为单位。</p>
</blockquote>
<hr>
<h3 id="用户提交环节（HTTP）"><a href="#用户提交环节（HTTP）" class="headerlink" title="用户提交环节（HTTP）"></a>用户提交环节（HTTP）</h3><p>暂不管。</p>
<hr>
<h3 id="✅TTS-合成训练数据"><a href="#✅TTS-合成训练数据" class="headerlink" title="✅TTS 合成训练数据"></a>✅TTS 合成训练数据</h3><ul>
<li>选择开源<code>TTS</code>系统如chat-tts，</li>
<li>同一唤醒词建议合成多种说话人、语速、语调，并进行以下增强：<ul>
<li>加背景噪声（环境模拟）</li>
<li>语速变化（±15%）</li>
<li>音高变化（Pitch Shift），模拟不同说话人的发声特征</li>
<li>混响或压缩模拟（设备特征），模拟用户设备环境和麦克风录音特性</li>
</ul>
</li>
</ul>
<p>该步骤我认为最关键的在于</p>
<hr>
<h3 id="训练阶段"><a href="#训练阶段" class="headerlink" title="训练阶段"></a>训练阶段</h3><p>暂不变：<a href="https://caihaoran-00.github.io/2025/04/03/KWS%E4%B9%8BmicroWakeWord%E5%AE%89%E8%A3%85%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95/">microWakeWord</a></p>
<hr>
<h3 id="✅测试与评估指标"><a href="#✅测试与评估指标" class="headerlink" title="✅测试与评估指标"></a>✅测试与评估指标</h3><ul>
<li><strong>Recall &#x2F; RAR（正确唤醒率）</strong>：<ul>
<li><code># 正确唤醒次数 / 所有唤醒词播放次数</code></li>
</ul>
</li>
<li><strong>FAR（误唤醒率）</strong>：<ul>
<li>可按「每小时触发次数」或「每小时每类噪音中的误触发次数」计算</li>
<li>建议构建 <strong>多类噪音测试集</strong>（如厨房、音乐、车内、安静环境）</li>
</ul>
</li>
</ul>
<p>📌 阈值建议：</p>
<table>
<thead>
<tr>
<th>指标</th>
<th>推荐阈值</th>
</tr>
</thead>
<tbody><tr>
<td>Recall (RAR)</td>
<td>≥ 90%</td>
</tr>
<tr>
<td>FAR</td>
<td>≤ 0.2 次&#x2F;小时</td>
</tr>
</tbody></table>
<hr>
<h3 id="模型下发"><a href="#模型下发" class="headerlink" title="模型下发"></a>模型下发</h3><p>暂不管。</p>
<hr>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://github.com/k2-fsa/sherpa-onnx">https://github.com/k2-fsa/sherpa-onnx</a></li>
<li><a href="https://github.com/idootop/open-xiaoai-kws">https://github.com/idootop/open-xiaoai-kws</a></li>
<li><a href="https://caihaoran-00.github.io/2025/04/03/KWS%E4%B9%8BmicroWakeWord%E5%AE%89%E8%A3%85%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95/">https://caihaoran-00.github.io/2025/04/03/KWS%E4%B9%8BmicroWakeWord%E5%AE%89%E8%A3%85%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%B5%8B%E8%AF%95/</a></li>
<li><a href="https://docs.espressif.com/projects/esp-sr/zh_CN/latest/esp32s3/wake_word_engine/ESP_Wake_Words_Customization.html">https://docs.espressif.com/projects/esp-sr/zh_CN/latest/esp32s3/wake_word_engine/ESP_Wake_Words_Customization.html</a></li>
<li><a href="https://github.com/espressif/esp-sr/issues/88">https://github.com/espressif/esp-sr/issues/88</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>kws</tag>
      </tags>
  </entry>
  <entry>
    <title>玩具第二版:新需求调研</title>
    <url>/2025/06/16/%E7%8E%A9%E5%85%B7%E7%AC%AC%E4%BA%8C%E7%89%88-%E6%96%B0%E9%9C%80%E6%B1%82%E8%B0%83%E7%A0%94/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>今早周例会明确提出了四个新需求：</p>
<ul>
<li>自定场景</li>
<li>内容库</li>
<li>对话报告</li>
<li>自定义唤醒词</li>
</ul>
<p>本文调研下前三个需求，自定义唤醒词方案见<a href="https://caihaoran-00.github.io/2025/06/13/%E8%87%AA%E5%AE%9A%E4%B9%89%E5%94%A4%E9%86%92%E8%AF%8D-KWS-%E8%B0%83%E7%A0%94%E4%B8%8E%E7%9B%AE%E5%89%8D%E6%83%B3%E6%B3%95/">这里</a>。</p>
<span id="more"></span>

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>首先展开介绍下各名词&#x2F;需求指代（原名不重要），再对各需求方案调研。</p>
<h3 id="1-自定场景"><a href="#1-自定场景" class="headerlink" title="1. 自定场景"></a>1. 自定场景</h3><h4 id="含义"><a href="#含义" class="headerlink" title="含义"></a>含义</h4><p>该需求指的是让玩具在恰当时机主动对话，具象例子：</p>
<ul>
<li>在6.1儿童节那天，唤醒玩具后，玩具在第一句主动进行节日祝福</li>
<li>家长在玩具<code>APP</code>上设置5.20号是孩子生日，让玩具祝福孩子（暂定时机也在唤醒玩具后的第一句）</li>
</ul>
<h4 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h4><p>云端更新+<code>LLM</code>生成祝福语+<code>TTS</code>播报</p>
<ul>
<li>云端更新：业务逻辑通过<code>GET</code>请求查询服务端日历&#x2F;节假日信息</li>
<li><code>LLM</code>生成祝福语：通过提示词让<code>LLM</code>生成祝福语</li>
<li>调用<code>TTS</code>进行语音播报</li>
<li>自定义节日接口</li>
</ul>
<p><strong>云端更新方式1：自建</strong></p>
<p><strong>服务端：</strong></p>
<figure class="highlight python"><figcaption><span>jieri_server.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Optional</span></span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FestivalResponse</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    is_festival: <span class="built_in">bool</span></span><br><span class="line">    festival_name: <span class="type">Optional</span>[<span class="built_in">str</span>] = <span class="literal">None</span></span><br><span class="line">    date: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 节日数据库</span></span><br><span class="line">festivals = &#123;</span><br><span class="line">    <span class="string">&quot;2025-01-01&quot;</span>: <span class="string">&quot;元旦&quot;</span>,</span><br><span class="line">    <span class="string">&quot;2025-01-28&quot;</span>: <span class="string">&quot;除夕&quot;</span>,</span><br><span class="line">    <span class="string">&quot;2025-01-29&quot;</span>: <span class="string">&quot;春节&quot;</span>,</span><br><span class="line">    <span class="string">&quot;2025-02-12&quot;</span>: <span class="string">&quot;元宵节&quot;</span>,</span><br><span class="line">    <span class="string">&quot;2025-03-08&quot;</span>: <span class="string">&quot;妇女节&quot;</span>,</span><br><span class="line">    <span class="string">&quot;2025-05-01&quot;</span>: <span class="string">&quot;劳动节&quot;</span>,</span><br><span class="line">    <span class="string">&quot;2025-10-01&quot;</span>: <span class="string">&quot;国庆节&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/api/check_festival&quot;</span>, response_model=FestivalResponse</span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">check_festival</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;检查今天是否是节日&quot;&quot;&quot;</span></span><br><span class="line">    today = datetime.now().strftime(<span class="string">&quot;%Y-%m-%d&quot;</span>)</span><br><span class="line">    festival_name = festivals.get(today)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;is_festival&quot;</span>: festival_name <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>,</span><br><span class="line">        <span class="string">&quot;festival_name&quot;</span>: festival_name,</span><br><span class="line">        <span class="string">&quot;date&quot;</span>: today</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/api/check_date/&#123;date&#125;&quot;</span>, response_model=FestivalResponse</span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">check_specific_date</span>(<span class="params">date: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;检查指定日期是否是节日&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        datetime.strptime(date, <span class="string">&quot;%Y-%m-%d&quot;</span>)  <span class="comment"># 验证日期格式</span></span><br><span class="line">        festival_name = festivals.get(date)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">&quot;is_festival&quot;</span>: festival_name <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>,</span><br><span class="line">            <span class="string">&quot;festival_name&quot;</span>: festival_name,</span><br><span class="line">            <span class="string">&quot;date&quot;</span>: date</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">except</span> ValueError:</span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">&quot;is_festival&quot;</span>: <span class="literal">False</span>,</span><br><span class="line">            <span class="string">&quot;festival_name&quot;</span>: <span class="literal">None</span>,</span><br><span class="line">            <span class="string">&quot;date&quot;</span>: date,</span><br><span class="line">            <span class="string">&quot;error&quot;</span>: <span class="string">&quot;Invalid date format, please use YYYY-MM-DD&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">import</span> uvicorn</span><br><span class="line"></span><br><span class="line">    uvicorn.run(app, host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="number">8000</span>)</span><br></pre></td></tr></table></figure>

<p><strong>客户端：</strong></p>
<figure class="highlight python"><figcaption><span>jieri_client.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 服务端地址（如果是本地运行就不用改）</span></span><br><span class="line">API_URL = <span class="string">&quot;http://127.0.0.1:8000/api/check_festival&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送请求</span></span><br><span class="line">response = requests.get(API_URL)</span><br><span class="line">result = response.json()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示结果</span></span><br><span class="line"><span class="keyword">if</span> result[<span class="string">&quot;is_festival&quot;</span>]:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;🎉 今天是 <span class="subst">&#123;result[<span class="string">&#x27;festival_name&#x27;</span>]&#125;</span>！&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;📅 今天不是节日&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">date = <span class="string">&quot;2025-10-01&quot;</span>  <span class="comment"># 想查询的日期</span></span><br><span class="line">response = requests.get(<span class="string">f&quot;http://127.0.0.1:8000/api/check_date/<span class="subst">&#123;date&#125;</span>&quot;</span>)</span><br><span class="line">data = response.json()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;date&#125;</span> 是节日吗？<span class="subst">&#123;<span class="string">&#x27;是&#x27;</span> <span class="keyword">if</span> data[<span class="string">&#x27;is_festival&#x27;</span>] <span class="keyword">else</span> <span class="string">&#x27;不是&#x27;</span>&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> data[<span class="string">&quot;is_festival&quot;</span>]:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;节日名称：<span class="subst">&#123;data[<span class="string">&#x27;festival_name&#x27;</span>]&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">📅 今天不是节日</span><br><span class="line"><span class="number">2025</span>-<span class="number">10</span>-01 是节日吗？是</span><br><span class="line">节日名称：国庆节</span><br></pre></td></tr></table></figure>



<p><strong>云端更新方式2：调用API</strong></p>
<p><strong>服务端：</strong></p>
<figure class="highlight python"><figcaption><span>jieri_server_api.pu</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, Query</span><br><span class="line"><span class="keyword">from</span> fastapi.responses <span class="keyword">import</span> JSONResponse</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line">API_KEY = <span class="string">&#x27;XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX&#x27;</span></span><br><span class="line">CALENDARIFIC_URL = <span class="string">&#x27;https://calendarific.com/api/v2/holidays&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/is_holiday&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">is_holiday</span>(<span class="params"></span></span><br><span class="line"><span class="params">    date: <span class="built_in">str</span> = Query(<span class="params">default=<span class="literal">None</span>, description=<span class="string">&quot;格式为 YYYY-MM-DD&quot;</span></span>),</span></span><br><span class="line"><span class="params">    country: <span class="built_in">str</span> = <span class="string">&quot;CN&quot;</span>,</span></span><br><span class="line"><span class="params">    language: <span class="built_in">str</span> = <span class="string">&quot;zh&quot;</span></span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    <span class="comment"># 如果没有传 date，默认为今天</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> date:</span><br><span class="line">        date = datetime.today().strftime(<span class="string">&#x27;%Y-%m-%d&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    year = <span class="built_in">int</span>(date[:<span class="number">4</span>])  <span class="comment"># 从日期中提取年份用于 API 查询</span></span><br><span class="line"></span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">&#x27;api_key&#x27;</span>: API_KEY,</span><br><span class="line">        <span class="string">&#x27;country&#x27;</span>: country,</span><br><span class="line">        <span class="string">&#x27;year&#x27;</span>: year,</span><br><span class="line">        <span class="string">&#x27;language&#x27;</span>: language</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = requests.get(CALENDARIFIC_URL, params=params)</span><br><span class="line">        data = response.json()</span><br><span class="line">        holidays = data.get(<span class="string">&quot;response&quot;</span>, &#123;&#125;).get(<span class="string">&quot;holidays&quot;</span>, [])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> h <span class="keyword">in</span> holidays:</span><br><span class="line">            <span class="keyword">if</span> h[<span class="string">&quot;date&quot;</span>][<span class="string">&quot;iso&quot;</span>] == date:</span><br><span class="line">                <span class="keyword">return</span> &#123;</span><br><span class="line">                    <span class="string">&quot;is_holiday&quot;</span>: <span class="literal">True</span>,</span><br><span class="line">                    <span class="string">&quot;name&quot;</span>: h[<span class="string">&quot;name&quot;</span>],</span><br><span class="line">                    <span class="string">&quot;description&quot;</span>: h.get(<span class="string">&quot;description&quot;</span>, <span class="string">&quot;&quot;</span>),</span><br><span class="line">                    <span class="string">&quot;type&quot;</span>: h.get(<span class="string">&quot;type&quot;</span>, [])</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&quot;is_holiday&quot;</span>: <span class="literal">False</span>, <span class="string">&quot;date&quot;</span>: date&#125;</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">return</span> JSONResponse(status_code=<span class="number">500</span>, content=&#123;<span class="string">&quot;error&quot;</span>: <span class="built_in">str</span>(e)&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">import</span> uvicorn</span><br><span class="line">    uvicorn.run(app, host=<span class="string">&quot;127.0.0.1&quot;</span>, port=<span class="number">8000</span>)</span><br></pre></td></tr></table></figure>

<p><strong>客户端：</strong></p>
<figure class="highlight python"><figcaption><span>jieri_client_api.py</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置服务地址</span></span><br><span class="line">SERVICE_URL = <span class="string">&#x27;http://127.0.0.1:8000/is_holiday&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例：检查今天是否节日</span></span><br><span class="line">response = requests.get(SERVICE_URL)</span><br><span class="line"><span class="built_in">print</span>(response.json())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例：检查指定日期是否节日</span></span><br><span class="line">params = &#123;<span class="string">&#x27;date&#x27;</span>: <span class="string">&#x27;2025-06-01&#x27;</span>&#125;  <span class="comment"># 六一儿童节</span></span><br><span class="line">response = requests.get(SERVICE_URL, params=params)</span><br><span class="line"><span class="built_in">print</span>(response.json())</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">&#123;&#x27;is<span class="built_in">_</span>holiday&#x27;: False, &#x27;date&#x27;: &#x27;2025-06-17&#x27;&#125;</span><br><span class="line">&#123;&#x27;is<span class="built_in">_</span>holiday&#x27;: True, &#x27;name&#x27;: &quot;Children&#x27;s Day&quot;, &#x27;description&#x27;: &quot;Children&#x27;s Day is a other observance in China&quot;, &#x27;type&#x27;: [&#x27;Observance&#x27;]&#125;</span><br></pre></td></tr></table></figure>


<p>现在实现了节日查询的功能，接着实现用LLM生成祝福语，我们以API查询节日为例：</p>
<p><strong>服务端：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, Query</span><br><span class="line"><span class="keyword">from</span> fastapi.responses <span class="keyword">import</span> StreamingResponse, JSONResponse</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> AsyncGenerator</span><br><span class="line"><span class="keyword">import</span> httpx</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置信息</span></span><br><span class="line">API_KEY = <span class="string">&#x27;xxxxxxxxxxxxxxxxxxxxxxxx&#x27;</span>  <span class="comment"># Calendarific API Key</span></span><br><span class="line">DEEPSEEK_API_KEY = <span class="string">&quot;xxxxxxxxxxxxxxxxxxxxxxxx&quot;</span>   <span class="comment"># 替换为实际Key</span></span><br><span class="line">CALENDARIFIC_URL = <span class="string">&#x27;https://calendarific.com/api/v2/holidays&#x27;</span></span><br><span class="line">DEEPSEEK_API_URL = <span class="string">&quot;https://api.deepseek.com/v1/chat/completions&quot;</span>  <span class="comment"># DeepSeek API地址</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">deepseek_stream</span>(<span class="params">prompt: <span class="built_in">str</span></span>) -&gt; AsyncGenerator[<span class="built_in">str</span>, <span class="literal">None</span>]:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;调用DeepSeek-v3生成流式响应&quot;&quot;&quot;</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&quot;Authorization&quot;</span>: <span class="string">f&quot;Bearer <span class="subst">&#123;DEEPSEEK_API_KEY&#125;</span>&quot;</span>,</span><br><span class="line">        <span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;application/json&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">    payload = &#123;</span><br><span class="line">        <span class="string">&quot;model&quot;</span>: <span class="string">&quot;deepseek-chat&quot;</span>,</span><br><span class="line">        <span class="string">&quot;messages&quot;</span>: [&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: prompt&#125;],</span><br><span class="line">        <span class="string">&quot;stream&quot;</span>: <span class="literal">True</span>,</span><br><span class="line">        <span class="string">&quot;temperature&quot;</span>: <span class="number">0.7</span>,</span><br><span class="line">        <span class="string">&quot;max_tokens&quot;</span>: <span class="number">100</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> httpx.AsyncClient() <span class="keyword">as</span> client:</span><br><span class="line">        <span class="keyword">async</span> <span class="keyword">with</span> client.stream(<span class="string">&quot;POST&quot;</span>, DEEPSEEK_API_URL, headers=headers, json=payload) <span class="keyword">as</span> response:</span><br><span class="line">            <span class="keyword">async</span> <span class="keyword">for</span> chunk <span class="keyword">in</span> response.aiter_lines():</span><br><span class="line">                <span class="keyword">if</span> chunk.startswith(<span class="string">&quot;data:&quot;</span>):</span><br><span class="line">                    <span class="keyword">try</span>:</span><br><span class="line">                        data = json.loads(chunk[<span class="number">5</span>:])</span><br><span class="line">                        <span class="keyword">if</span> content := data.get(<span class="string">&quot;choices&quot;</span>, [&#123;&#125;])[<span class="number">0</span>].get(<span class="string">&quot;delta&quot;</span>, &#123;&#125;).get(<span class="string">&quot;content&quot;</span>, <span class="string">&quot;&quot;</span>):</span><br><span class="line">                            <span class="keyword">yield</span> content</span><br><span class="line">                    <span class="keyword">except</span> json.JSONDecodeError:</span><br><span class="line">                        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/is_holiday&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">is_holiday</span>(<span class="params"></span></span><br><span class="line"><span class="params">    date: <span class="built_in">str</span> = Query(<span class="params">default=<span class="literal">None</span>, description=<span class="string">&quot;格式: YYYY-MM-DD&quot;</span></span>),</span></span><br><span class="line"><span class="params">    country: <span class="built_in">str</span> = <span class="string">&quot;CN&quot;</span>,</span></span><br><span class="line"><span class="params">    with_wish: <span class="built_in">bool</span> = <span class="literal">False</span></span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    <span class="comment"># 默认今天</span></span><br><span class="line">    date = date <span class="keyword">or</span> datetime.today().strftime(<span class="string">&#x27;%Y-%m-%d&#x27;</span>)</span><br><span class="line">    year = date[:<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取节日数据</span></span><br><span class="line">    params = &#123;<span class="string">&#x27;api_key&#x27;</span>: API_KEY, <span class="string">&#x27;country&#x27;</span>: country, <span class="string">&#x27;year&#x27;</span>: year&#125;</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        resp = requests.get(CALENDARIFIC_URL, params=params)</span><br><span class="line">        holidays = resp.json().get(<span class="string">&quot;response&quot;</span>, &#123;&#125;).get(<span class="string">&quot;holidays&quot;</span>, [])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 查找匹配的节日</span></span><br><span class="line">        holiday = <span class="built_in">next</span>((h <span class="keyword">for</span> h <span class="keyword">in</span> holidays <span class="keyword">if</span> h[<span class="string">&quot;date&quot;</span>][<span class="string">&quot;iso&quot;</span>] == date), <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 不需要祝福语时直接返回</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> with_wish:</span><br><span class="line">            <span class="keyword">return</span> &#123;</span><br><span class="line">                <span class="string">&quot;is_holiday&quot;</span>: <span class="built_in">bool</span>(holiday),</span><br><span class="line">                <span class="string">&quot;date&quot;</span>: date,</span><br><span class="line">                <span class="string">&quot;name&quot;</span>: holiday[<span class="string">&quot;name&quot;</span>] <span class="keyword">if</span> holiday <span class="keyword">else</span> <span class="literal">None</span>,</span><br><span class="line">                <span class="string">&quot;type&quot;</span>: holiday.get(<span class="string">&quot;type&quot;</span>, []) <span class="keyword">if</span> holiday <span class="keyword">else</span> []</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 生成流式祝福语</span></span><br><span class="line">        <span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">generate_stream</span>():</span><br><span class="line">            <span class="keyword">if</span> holiday:</span><br><span class="line">                prompt = <span class="string">f&quot;&quot;&quot;你是一个可爱的玩具，今天是<span class="subst">&#123;holiday[<span class="string">&#x27;name&#x27;</span>]&#125;</span>，请用儿童语言（限100字）给小朋友送上祝福，要求：</span></span><br><span class="line"><span class="string">                - 不要有emoji表情</span></span><br><span class="line"><span class="string">                - 包含节日元素</span></span><br><span class="line"><span class="string">                &quot;&quot;&quot;</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                prompt = <span class="string">f&quot;&quot;&quot;你是一个温暖的玩具，今天不是节日（日期：<span class="subst">&#123;date&#125;</span>），请用儿童语言（限80字）给小朋友发送日常鼓励，要求：</span></span><br><span class="line"><span class="string">                - 不要有emoji表情</span></span><br><span class="line"><span class="string">                - 包含对日常生活的赞美&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">async</span> <span class="keyword">for</span> chunk <span class="keyword">in</span> deepseek_stream(prompt):</span><br><span class="line">                <span class="keyword">yield</span> chunk</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> StreamingResponse(generate_stream(), media_type=<span class="string">&quot;text/event-stream&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">return</span> JSONResponse(status_code=<span class="number">500</span>, content=&#123;<span class="string">&quot;error&quot;</span>: <span class="built_in">str</span>(e)&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">import</span> uvicorn</span><br><span class="line">    uvicorn.run(app, host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="number">8000</span>)</span><br></pre></td></tr></table></figure>

<p><strong>客户端：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">HolidayClient</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, base_url=<span class="string">&quot;http://127.0.0.1:8000&quot;</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.base_url = base_url</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">check_holiday</span>(<span class="params">self, date=<span class="literal">None</span>, country=<span class="string">&quot;CN&quot;</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;查询节日信息（非流式）&quot;&quot;&quot;</span></span><br><span class="line">        params = &#123;<span class="string">&quot;country&quot;</span>: country&#125;</span><br><span class="line">        <span class="keyword">if</span> date:</span><br><span class="line">            params[<span class="string">&quot;date&quot;</span>] = date</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            response = requests.get(<span class="string">f&quot;<span class="subst">&#123;self.base_url&#125;</span>/is_holiday&quot;</span>, params=params)</span><br><span class="line">            <span class="keyword">return</span> response.json()</span><br><span class="line">        <span class="keyword">except</span> requests.exceptions.RequestException <span class="keyword">as</span> e:</span><br><span class="line">            <span class="keyword">return</span> &#123;<span class="string">&quot;error&quot;</span>: <span class="built_in">str</span>(e)&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_wish</span>(<span class="params">self, date=<span class="literal">None</span>, country=<span class="string">&quot;CN&quot;</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;获取流式祝福语&quot;&quot;&quot;</span></span><br><span class="line">        params = &#123;</span><br><span class="line">            <span class="string">&quot;country&quot;</span>: country,</span><br><span class="line">            <span class="string">&quot;with_wish&quot;</span>: <span class="literal">True</span>,</span><br><span class="line">            <span class="string">&quot;date&quot;</span>: date <span class="keyword">or</span> datetime.now().strftime(<span class="string">&quot;%Y-%m-%d&quot;</span>)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            response = requests.get(</span><br><span class="line">                <span class="string">f&quot;<span class="subst">&#123;self.base_url&#125;</span>/is_holiday&quot;</span>,</span><br><span class="line">                params=params,</span><br><span class="line">                stream=<span class="literal">True</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;🧸 玩具说：&quot;</span>, end=<span class="string">&quot;&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">                <span class="keyword">for</span> chunk <span class="keyword">in</span> response.iter_content(chunk_size=<span class="literal">None</span>):</span><br><span class="line">                    <span class="built_in">print</span>(chunk.decode(<span class="string">&#x27;utf-8&#x27;</span>), end=<span class="string">&#x27;&#x27;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;⚠️ 请求失败: <span class="subst">&#123;response.text&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;❌ 发生错误: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用示例</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    client = HolidayClient()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 示例1：查询今日节日状态</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=== 节日查询 ===&quot;</span>)</span><br><span class="line">    result = client.check_holiday()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;日期: <span class="subst">&#123;result.get(<span class="string">&#x27;date&#x27;</span>)&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;是否节日: <span class="subst">&#123;<span class="string">&#x27;是&#x27;</span> <span class="keyword">if</span> result.get(<span class="string">&#x27;is_holiday&#x27;</span>) <span class="keyword">else</span> <span class="string">&#x27;否&#x27;</span>&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> result.get(<span class="string">&#x27;is_holiday&#x27;</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;节日名称: <span class="subst">&#123;result.get(<span class="string">&#x27;name&#x27;</span>)&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;节日类型: <span class="subst">&#123;<span class="string">&#x27;, &#x27;</span>.join(result.get(<span class="string">&#x27;type&#x27;</span>, []))&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 示例2：获取祝福语（自动判断节日）</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n=== 获取祝福语 ===&quot;</span>)</span><br><span class="line">    <span class="comment"># client.get_wish()  # 默认今天</span></span><br><span class="line">    client.get_wish(date=<span class="string">&quot;2025-06-01&quot;</span>)  <span class="comment"># 测试儿童节</span></span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">client.get<span class="built_in">_</span>wish()</span><br><span class="line"></span><br><span class="line">=== 节日查询 ===</span><br><span class="line">日期: 2025-06-17</span><br><span class="line">是否节日: 否</span><br><span class="line"></span><br><span class="line">=== 获取祝福语 ===</span><br><span class="line">🧸 玩具说：亲爱的小朋友，今天阳光暖暖的，像你笑起来的样子！你认真刷牙、和小伙伴分享玩具的样子真棒。记得吗？昨天你帮妈妈摆碗筷时像个小超人！每天都有闪闪发光的时刻，你真是世界上最会创造快乐的小星星呀～</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">client.get<span class="built_in">_</span>wish(date=&quot;2025-06-01&quot;)</span><br><span class="line">=== 节日查询 ===</span><br><span class="line">日期: 2025-06-17</span><br><span class="line">是否节日: 否</span><br><span class="line"></span><br><span class="line">=== 获取祝福语 ===</span><br><span class="line">🧸 玩具说：亲爱的小宝贝，儿童节快乐呀！今天是你最最开心的日子，像彩虹糖一样甜滋滋！快去和好朋友一起玩吧，可以吹泡泡、跳皮筋，或者分享一块小熊饼干。记得要咯咯笑，像小云朵一样飘呀飘。爸爸妈妈和老师都爱你，愿你每天都有童话般的奇妙冒险！加油，小小超人！</span><br></pre></td></tr></table></figure>



<p><strong>现在实现了传统节日等的查询与问候语生成，那像生日这种自定义的节日怎么做呢？</strong></p>
<p><strong>服务端：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, Query, Body, HTTPException</span><br><span class="line"><span class="keyword">from</span> fastapi.responses <span class="keyword">import</span> StreamingResponse</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime, timedelta</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> AsyncGenerator, <span class="type">Dict</span>, <span class="type">List</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> httpx</span><br><span class="line"><span class="keyword">import</span> uuid</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置信息</span></span><br><span class="line">CALENDARIFIC_API_KEY = <span class="string">&#x27;xxxxxxxxxxxxxxxxxxxxxxxx&#x27;</span></span><br><span class="line">DEEPSEEK_API_KEY = <span class="string">&quot;xxxxxxxxxxxxxxxxxxxxxxx&quot;</span></span><br><span class="line">CALENDARIFIC_URL = <span class="string">&#x27;https://calendarific.com/api/v2/holidays&#x27;</span></span><br><span class="line">DEEPSEEK_API_URL = <span class="string">&quot;https://api.deepseek.com/v1/chat/completions&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 内存存储自定义节日（生产环境建议用数据库）</span></span><br><span class="line">custom_holidays: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Dict</span>] = &#123;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CustomHoliday</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    date: <span class="built_in">str</span>  <span class="comment"># 格式: &quot;MM-DD&quot;</span></span><br><span class="line">    name: <span class="built_in">str</span>  <span class="comment"># 节日名称</span></span><br><span class="line">    description: <span class="built_in">str</span> = <span class="string">&quot;&quot;</span>  <span class="comment"># 节日描述</span></span><br><span class="line">    is_recurring: <span class="built_in">bool</span> = <span class="literal">True</span>  <span class="comment"># 是否每年重复</span></span><br><span class="line">    user_id: <span class="built_in">str</span> = <span class="string">&quot;default&quot;</span>  <span class="comment"># 用户标识</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># DeepSeek流式生成</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">deepseek_stream</span>(<span class="params">prompt: <span class="built_in">str</span></span>) -&gt; AsyncGenerator[<span class="built_in">str</span>, <span class="literal">None</span>]:</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&quot;Authorization&quot;</span>: <span class="string">f&quot;Bearer <span class="subst">&#123;DEEPSEEK_API_KEY&#125;</span>&quot;</span>,</span><br><span class="line">        <span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;application/json&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">    payload = &#123;</span><br><span class="line">        <span class="string">&quot;model&quot;</span>: <span class="string">&quot;deepseek-chat&quot;</span>,</span><br><span class="line">        <span class="string">&quot;messages&quot;</span>: [&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: prompt&#125;],</span><br><span class="line">        <span class="string">&quot;stream&quot;</span>: <span class="literal">True</span>,</span><br><span class="line">        <span class="string">&quot;temperature&quot;</span>: <span class="number">0.7</span>,</span><br><span class="line">        <span class="string">&quot;max_tokens&quot;</span>: <span class="number">150</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> httpx.AsyncClient() <span class="keyword">as</span> client:</span><br><span class="line">        <span class="keyword">async</span> <span class="keyword">with</span> client.stream(<span class="string">&quot;POST&quot;</span>, DEEPSEEK_API_URL, headers=headers, json=payload) <span class="keyword">as</span> response:</span><br><span class="line">            <span class="keyword">async</span> <span class="keyword">for</span> chunk <span class="keyword">in</span> response.aiter_lines():</span><br><span class="line">                <span class="keyword">if</span> chunk.startswith(<span class="string">&quot;data:&quot;</span>):</span><br><span class="line">                    <span class="keyword">try</span>:</span><br><span class="line">                        data = json.loads(chunk[<span class="number">5</span>:])</span><br><span class="line">                        <span class="keyword">if</span> content := data.get(<span class="string">&quot;choices&quot;</span>, [&#123;&#125;])[<span class="number">0</span>].get(<span class="string">&quot;delta&quot;</span>, &#123;&#125;).get(<span class="string">&quot;content&quot;</span>, <span class="string">&quot;&quot;</span>):</span><br><span class="line">                            <span class="keyword">yield</span> content</span><br><span class="line">                    <span class="keyword">except</span> json.JSONDecodeError:</span><br><span class="line">                        <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查法定节假日</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">check_official_holiday</span>(<span class="params">date: <span class="built_in">str</span>, country: <span class="built_in">str</span></span>) -&gt; <span class="type">Dict</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        year = date[:<span class="number">4</span>]</span><br><span class="line">        params = &#123;</span><br><span class="line">            <span class="string">&#x27;api_key&#x27;</span>: CALENDARIFIC_API_KEY,</span><br><span class="line">            <span class="string">&#x27;country&#x27;</span>: country,</span><br><span class="line">            <span class="string">&#x27;year&#x27;</span>: year</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">async</span> <span class="keyword">with</span> httpx.AsyncClient() <span class="keyword">as</span> client:</span><br><span class="line">            resp = <span class="keyword">await</span> client.get(CALENDARIFIC_URL, params=params)</span><br><span class="line">            data = resp.json()</span><br><span class="line">            <span class="comment"># 本地过滤目标日期</span></span><br><span class="line">            holidays = [</span><br><span class="line">                h <span class="keyword">for</span> h <span class="keyword">in</span> data.get(<span class="string">&quot;response&quot;</span>, &#123;&#125;).get(<span class="string">&quot;holidays&quot;</span>, [])</span><br><span class="line">                <span class="keyword">if</span> h[<span class="string">&quot;date&quot;</span>][<span class="string">&quot;iso&quot;</span>] == date  <span class="comment"># 精确匹配日期</span></span><br><span class="line">            ]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> holidays:</span><br><span class="line">                <span class="keyword">return</span> &#123;</span><br><span class="line">                    <span class="string">&quot;is_holiday&quot;</span>: <span class="literal">True</span>,</span><br><span class="line">                    <span class="string">&quot;name&quot;</span>: holidays[<span class="number">0</span>][<span class="string">&quot;name&quot;</span>],</span><br><span class="line">                    <span class="string">&quot;type&quot;</span>: holidays[<span class="number">0</span>].get(<span class="string">&quot;type&quot;</span>, [])</span><br><span class="line">                &#125;</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&quot;is_holiday&quot;</span>: <span class="literal">False</span>&#125;</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">raise</span> HTTPException(status_code=<span class="number">500</span>, detail=<span class="string">f&quot;节假日查询失败: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查自定义节日</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_custom_holiday</span>(<span class="params">date: <span class="built_in">str</span>, user_id: <span class="built_in">str</span> = <span class="string">&quot;default&quot;</span></span>) -&gt; <span class="type">Dict</span>:</span><br><span class="line">    month_day = date[<span class="number">5</span>:]  <span class="comment"># 提取&quot;MM-DD&quot;</span></span><br><span class="line">    <span class="keyword">for</span> hid, h <span class="keyword">in</span> custom_holidays.items():</span><br><span class="line">        <span class="keyword">if</span> h[<span class="string">&quot;user_id&quot;</span>] == user_id <span class="keyword">and</span> h[<span class="string">&quot;date&quot;</span>] == month_day <span class="keyword">and</span> h[<span class="string">&quot;is_recurring&quot;</span>]:</span><br><span class="line">            <span class="keyword">return</span> &#123;</span><br><span class="line">                <span class="string">&quot;is_custom&quot;</span>: <span class="literal">True</span>,</span><br><span class="line">                <span class="string">&quot;name&quot;</span>: h[<span class="string">&quot;name&quot;</span>],</span><br><span class="line">                <span class="string">&quot;description&quot;</span>: h[<span class="string">&quot;description&quot;</span>]</span><br><span class="line">            &#125;</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;is_custom&quot;</span>: <span class="literal">False</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># API端点</span></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/custom_holidays&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">add_custom_holiday</span>(<span class="params">holiday: CustomHoliday</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;添加自定义节日&quot;&quot;&quot;</span></span><br><span class="line">    holiday_id = <span class="built_in">str</span>(uuid.uuid4())</span><br><span class="line">    custom_holidays[holiday_id] = holiday.<span class="built_in">dict</span>()</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;id&quot;</span>: holiday_id, <span class="string">&quot;message&quot;</span>: <span class="string">&quot;添加成功&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/custom_holidays&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">list_custom_holidays</span>(<span class="params">user_id: <span class="built_in">str</span> = <span class="string">&quot;default&quot;</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;列出用户的自定义节日&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        uid: data <span class="keyword">for</span> uid, data <span class="keyword">in</span> custom_holidays.items()</span><br><span class="line">        <span class="keyword">if</span> data[<span class="string">&quot;user_id&quot;</span>] == user_id</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/holiday&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">check_holiday</span>(<span class="params"></span></span><br><span class="line"><span class="params">        date: <span class="built_in">str</span> = Query(<span class="params">default=<span class="literal">None</span>, description=<span class="string">&quot;格式: YYYY-MM-DD&quot;</span></span>),</span></span><br><span class="line"><span class="params">        country: <span class="built_in">str</span> = <span class="string">&quot;CN&quot;</span>,</span></span><br><span class="line"><span class="params">        user_id: <span class="built_in">str</span> = <span class="string">&quot;default&quot;</span>,</span></span><br><span class="line"><span class="params">        with_wish: <span class="built_in">bool</span> = <span class="literal">False</span></span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;查询节日并生成祝福语&quot;&quot;&quot;</span></span><br><span class="line">    date = date <span class="keyword">or</span> datetime.now().strftime(<span class="string">&#x27;%Y-%m-%d&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1. 检查节日</span></span><br><span class="line">    official = <span class="keyword">await</span> check_official_holiday(date, country)</span><br><span class="line">    custom = check_custom_holiday(date, user_id)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. 不需要祝福语时直接返回</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> with_wish:</span><br><span class="line">        <span class="keyword">return</span> &#123;**official, **custom, <span class="string">&quot;date&quot;</span>: date&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. 生成流式祝福语</span></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">generate_stream</span>():</span><br><span class="line">        <span class="keyword">if</span> official[<span class="string">&quot;is_holiday&quot;</span>]:</span><br><span class="line">            prompt = <span class="string">f&quot;&quot;&quot;你是一个可爱的玩具，今天是<span class="subst">&#123;official[<span class="string">&#x27;name&#x27;</span>]&#125;</span>，请用儿童语言（限100字）给小朋友送上祝福，要求：</span></span><br><span class="line"><span class="string">            - 以&quot;亲爱的小朋友&quot;开头</span></span><br><span class="line"><span class="string">            - 包含节日元素</span></span><br><span class="line"><span class="string">            - 以纯文本给出，不要emoji表情等&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">elif</span> custom[<span class="string">&quot;is_custom&quot;</span>]:</span><br><span class="line">            prompt = <span class="string">f&quot;&quot;&quot;今天是<span class="subst">&#123;custom[<span class="string">&#x27;name&#x27;</span>]&#125;</span>（<span class="subst">&#123;custom.get(<span class="string">&#x27;description&#x27;</span>, <span class="string">&#x27;&#x27;</span>)&#125;</span>），请以玩具口吻：</span></span><br><span class="line"><span class="string">            - 用&quot;小朋友&quot;称呼</span></span><br><span class="line"><span class="string">            - 结合<span class="subst">&#123;custom[<span class="string">&#x27;name&#x27;</span>]&#125;</span>特点</span></span><br><span class="line"><span class="string">            - 包含1个互动建议</span></span><br><span class="line"><span class="string">            - 以纯文本给出，不要emoji表情等&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            prompt = <span class="string">&quot;&quot;&quot;你是一个温暖的玩具，请用儿童语言（限80字）发送日常鼓励：</span></span><br><span class="line"><span class="string">            - 以&quot;你好呀&quot;开头</span></span><br><span class="line"><span class="string">            - 包含对日常生活的赞美</span></span><br><span class="line"><span class="string">            - 以纯文本给出，不要emoji表情等&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">async</span> <span class="keyword">for</span> chunk <span class="keyword">in</span> deepseek_stream(prompt):</span><br><span class="line">            <span class="keyword">yield</span> chunk</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> StreamingResponse(generate_stream(), media_type=<span class="string">&quot;text/event-stream&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">import</span> uvicorn</span><br><span class="line"></span><br><span class="line">    uvicorn.run(app, host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="number">8000</span>)</span><br></pre></td></tr></table></figure>

<p><strong>客户端：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">HolidayClient</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, base_url=<span class="string">&quot;http://localhost:8000&quot;</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.base_url = base_url</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_custom_holiday</span>(<span class="params"></span></span><br><span class="line"><span class="params">            self,</span></span><br><span class="line"><span class="params">            name: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">            date: <span class="built_in">str</span>,  <span class="comment"># MM-DD格式</span></span></span><br><span class="line"><span class="params">            description: <span class="built_in">str</span> = <span class="string">&quot;&quot;</span>,</span></span><br><span class="line"><span class="params">            is_recurring: <span class="built_in">bool</span> = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">            user_id: <span class="built_in">str</span> = <span class="string">&quot;default&quot;</span></span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;添加自定义节日&quot;&quot;&quot;</span></span><br><span class="line">        resp = requests.post(</span><br><span class="line">            <span class="string">f&quot;<span class="subst">&#123;self.base_url&#125;</span>/custom_holidays&quot;</span>,</span><br><span class="line">            json=&#123;</span><br><span class="line">                <span class="string">&quot;date&quot;</span>: date,</span><br><span class="line">                <span class="string">&quot;name&quot;</span>: name,</span><br><span class="line">                <span class="string">&quot;description&quot;</span>: description,</span><br><span class="line">                <span class="string">&quot;is_recurring&quot;</span>: is_recurring,</span><br><span class="line">                <span class="string">&quot;user_id&quot;</span>: user_id</span><br><span class="line">            &#125;</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> resp.json()[<span class="string">&quot;id&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">check_holiday</span>(<span class="params"></span></span><br><span class="line"><span class="params">            self,</span></span><br><span class="line"><span class="params">            date: <span class="built_in">str</span> = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">            country: <span class="built_in">str</span> = <span class="string">&quot;CN&quot;</span>,</span></span><br><span class="line"><span class="params">            user_id: <span class="built_in">str</span> = <span class="string">&quot;default&quot;</span></span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="built_in">dict</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;查询节日信息&quot;&quot;&quot;</span></span><br><span class="line">        params = &#123;<span class="string">&quot;country&quot;</span>: country, <span class="string">&quot;user_id&quot;</span>: user_id&#125;</span><br><span class="line">        <span class="keyword">if</span> date:</span><br><span class="line">            params[<span class="string">&quot;date&quot;</span>] = date</span><br><span class="line">        resp = requests.get(<span class="string">f&quot;<span class="subst">&#123;self.base_url&#125;</span>/holiday&quot;</span>, params=params)</span><br><span class="line">        <span class="keyword">return</span> resp.json()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_wish</span>(<span class="params"></span></span><br><span class="line"><span class="params">            self,</span></span><br><span class="line"><span class="params">            date: <span class="built_in">str</span> = <span class="literal">None</span>,</span></span><br><span class="line"><span class="params">            country: <span class="built_in">str</span> = <span class="string">&quot;CN&quot;</span>,</span></span><br><span class="line"><span class="params">            user_id: <span class="built_in">str</span> = <span class="string">&quot;default&quot;</span></span></span><br><span class="line"><span class="params">    </span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;获取流式祝福语&quot;&quot;&quot;</span></span><br><span class="line">        params = &#123;</span><br><span class="line">            <span class="string">&quot;country&quot;</span>: country,</span><br><span class="line">            <span class="string">&quot;user_id&quot;</span>: user_id,</span><br><span class="line">            <span class="string">&quot;with_wish&quot;</span>: <span class="literal">True</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> date:</span><br><span class="line">            params[<span class="string">&quot;date&quot;</span>] = date</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">with</span> requests.get(</span><br><span class="line">                    <span class="string">f&quot;<span class="subst">&#123;self.base_url&#125;</span>/holiday&quot;</span>,</span><br><span class="line">                    params=params,</span><br><span class="line">                    stream=<span class="literal">True</span></span><br><span class="line">            ) <span class="keyword">as</span> response:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;🧸 玩具说：&quot;</span>, end=<span class="string">&quot;&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">                <span class="keyword">for</span> chunk <span class="keyword">in</span> response.iter_content(chunk_size=<span class="literal">None</span>):</span><br><span class="line">                    <span class="built_in">print</span>(chunk.decode(<span class="string">&#x27;utf-8&#x27;</span>), end=<span class="string">&#x27;&#x27;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;❌ 错误: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用示例</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    client = HolidayClient()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1. 添加生日（每年8月15日）</span></span><br><span class="line">    birthday_id = client.add_custom_holiday(</span><br><span class="line">        name=<span class="string">&quot;小明的生日&quot;</span>,</span><br><span class="line">        date=<span class="string">&quot;08-15&quot;</span>,</span><br><span class="line">        description=<span class="string">&quot;小朋友最喜欢的日子！&quot;</span></span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;添加生日成功，ID: <span class="subst">&#123;birthday_id&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. 查询今天是否是节日</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n=== 节日查询 ===&quot;</span>)</span><br><span class="line">    result = client.check_holiday()</span><br><span class="line">    <span class="built_in">print</span>(json.dumps(result, indent=<span class="number">2</span>, ensure_ascii=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. 查询今天是否是节日</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n=== 节日查询 ===&quot;</span>)</span><br><span class="line">    result = client.check_holiday(<span class="string">&quot;2025-06-01&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(json.dumps(result, indent=<span class="number">2</span>, ensure_ascii=<span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4. 获取生日祝福（测试日期设为8月15日）</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n=== 生日祝福 ===&quot;</span>)</span><br><span class="line">    client.get_wish(date=<span class="string">&quot;2024-08-15&quot;</span>)  <span class="comment"># 替换为真实日期测试</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5. 获取日常问候（非节日）</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n=== 日常问候 ===&quot;</span>)</span><br><span class="line">    client.get_wish(date=<span class="string">&quot;2024-03-15&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 6. 获取节日问候</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n=== 节日问候 ===&quot;</span>)</span><br><span class="line">    client.get_wish(date=<span class="string">&quot;2025-06-01&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">=== 节日查询 ===</span><br><span class="line">&#123;</span><br><span class="line">  &quot;is<span class="built_in">_</span>holiday&quot;: false,</span><br><span class="line">  &quot;is<span class="built_in">_</span>custom&quot;: false,</span><br><span class="line">  &quot;date&quot;: &quot;2025-06-17&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">=== 节日查询 ===</span><br><span class="line">&#123;</span><br><span class="line">  &quot;is<span class="built_in">_</span>holiday&quot;: true,</span><br><span class="line">  &quot;name&quot;: &quot;Children&#x27;s Day&quot;,</span><br><span class="line">  &quot;type&quot;: [</span><br><span class="line">    &quot;Observance&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;is<span class="built_in">_</span>custom&quot;: false,</span><br><span class="line">  &quot;date&quot;: &quot;2025-06-01&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">=== 生日祝福 ===</span><br><span class="line">🧸 玩具说：&quot;小朋友小朋友，听我说！今天可是你最特别的生日大派对呀！我是你枕头底下会发光的小汽车，早就偷偷看到妈妈在厨房藏了星星形状的蛋糕啦~要不要和我玩个生日寻宝游戏？数到十的时候，第一个找到窗帘后面彩色气球的小朋友，能获得本车神特技表演——原地转圈圈发光三连击！(引擎嗡嗡准备中)&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">=== 日常问候 ===</span><br><span class="line">🧸 玩具说：你好呀！今天太阳公公又出来玩啦，小鸟在唱歌，小花在跳舞，世界多美好呀！你是最棒的小星星，每天都会发光发亮，要开开心心过好今天哦～</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">=== 节日问候 ===</span><br><span class="line">🧸 玩具说：亲爱的小朋友，儿童节快乐呀！今天是小星星跳舞的日子，是糖果云飘过的日子！愿你的小书包装满彩虹，小脚丫踩出棉花糖小路~记得和气球说悄悄话，让风筝把笑声撒满蓝天。吃蛋糕时要像小熊一样开心，做梦时要遇见会讲故事的月亮船哦！永远爱你的玩具朋友~</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注：自定义日期不需包含年，仅月份和日期即可。</p>
</blockquote>
<hr>
<h3 id="2-对话报告"><a href="#2-对话报告" class="headerlink" title="2. 对话报告"></a>2. 对话报告</h3><h4 id="含义-1"><a href="#含义-1" class="headerlink" title="含义"></a>含义</h4><p>该需求指的是每日通过查看并总结孩子与玩具的对话内容，生成一份对话内容，关注<strong>情绪变化</strong>与<strong>关键事件</strong>供家长查看。</p>
<h4 id="方案-1"><a href="#方案-1" class="headerlink" title="方案"></a>方案</h4><p>通过系统提示词（system prompt)让<code>LLM</code>分析当天的对话内容，生成对话报告。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置DeepSeek API（替换为你的API密钥）</span></span><br><span class="line">DEEPSEEK_API_KEY = <span class="string">&quot;xxxxxxxxxxxxxxxxxxxxxxxxxx&quot;</span></span><br><span class="line">DEEPSEEK_API_URL = <span class="string">&quot;https://api.deepseek.com/v1/chat/completions&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">analyze_child_conversation</span>(<span class="params">dialogue_text</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    使用DeepSeek分析儿童对话并生成每日情绪报告</span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">        dialogue_text: 当天所有对话文本（字符串）</span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">        纯文本分析结果（字符串）</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 预处理对话文本（移除重复换行/空格）</span></span><br><span class="line">    cleaned_text = re.sub(<span class="string">r&#x27;\s+&#x27;</span>, <span class="string">&#x27; &#x27;</span>, dialogue_text.strip())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构建prompt</span></span><br><span class="line">    system_prompt = <span class="string">&quot;&quot;&quot;你是一位幼儿园老师，需要给家长发送孩子当日情绪简报：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    输出要求：</span></span><br><span class="line"><span class="string">    1. 第一句总结主要情绪</span></span><br><span class="line"><span class="string">    2. 第二句用孩子原话描述1-2个关键事件</span></span><br><span class="line"><span class="string">    3. 总字数不超过200字</span></span><br><span class="line"><span class="string">    4. 要求用语正式且简洁，以纯文本形式给出</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        headers = &#123;</span><br><span class="line">            <span class="string">&quot;Authorization&quot;</span>: <span class="string">f&quot;Bearer <span class="subst">&#123;DEEPSEEK_API_KEY&#125;</span>&quot;</span>,</span><br><span class="line">            <span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;application/json&quot;</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        payload = &#123;</span><br><span class="line">            <span class="string">&quot;model&quot;</span>: <span class="string">&quot;deepseek-chat&quot;</span>,  <span class="comment"># 根据实际模型名称调整</span></span><br><span class="line">            <span class="string">&quot;messages&quot;</span>: [</span><br><span class="line">                &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: system_prompt&#125;,</span><br><span class="line">                &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: cleaned_text&#125;</span><br><span class="line">            ],</span><br><span class="line">            <span class="string">&quot;temperature&quot;</span>: <span class="number">0.3</span>,</span><br><span class="line">            <span class="string">&quot;max_tokens&quot;</span>: <span class="number">100</span></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        response = requests.post(DEEPSEEK_API_URL, headers=headers, json=payload)</span><br><span class="line">        response.raise_for_status()  <span class="comment"># 检查HTTP错误</span></span><br><span class="line"></span><br><span class="line">        result = response.json()</span><br><span class="line">        <span class="keyword">return</span> result[<span class="string">&#x27;choices&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;message&#x27;</span>][<span class="string">&#x27;content&#x27;</span>].strip()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;生成报告时出错：<span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例使用</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 模拟当天的对话记录</span></span><br><span class="line">    sample_dialogue = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    [09:00] 孩子：机器人你醒了吗？太阳公公都晒屁股啦！</span></span><br><span class="line"><span class="string">[09:00] 玩具：早上好呀！我早就醒啦，正在做电子操呢~你今天想玩什么？</span></span><br><span class="line"><span class="string">[09:01] 孩子：嗯...我想玩恐龙打架！但是妈妈说要先吃早饭...</span></span><br><span class="line"><span class="string">[09:02] 玩具：哇！暴龙最喜欢吃煎蛋了，你今天的早餐有煎蛋吗？</span></span><br><span class="line"><span class="string">[09:03] 孩子：有！但是...但是蛋黄流出来了，我弄到手手了</span></span><br><span class="line"><span class="string">[09:04] 玩具：没关系呀，用小毛巾擦擦就干净了。要听恐龙怎么清理爪子吗？</span></span><br><span class="line"><span class="string">[09:05] 孩子：要！...啊妈妈叫我再喝半杯牛奶...</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[10:30] 孩子：我回来啦！妈妈准我玩十分钟！</span></span><br><span class="line"><span class="string">[10:31] 玩具：太好啦！我们让剑龙和霸王龙比赛跑步好不好？</span></span><br><span class="line"><span class="string">[10:32] 孩子：霸王龙会赢！因为...因为它的腿腿长！但是剑龙有刺刺！</span></span><br><span class="line"><span class="string">[10:33] 玩具：你说得对！3-2-1...哎呀剑龙被石头绊倒了！</span></span><br><span class="line"><span class="string">[10:34] 孩子：哈哈哈它笨笨！...等等我要去尿尿！</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[12:15] 孩子：机器人...</span></span><br><span class="line"><span class="string">[12:16] 玩具：怎么啦？给我个抱抱好不好？</span></span><br><span class="line"><span class="string">[12:17] 孩子：小美...小美说我画的恐龙像小猪...</span></span><br><span class="line"><span class="string">[12:18] 玩具：让我看看...哇！这明明是超级特别的彩虹恐龙呀！</span></span><br><span class="line"><span class="string">[12:19] 孩子：真的吗？可是...它肚子是圆圆的...</span></span><br><span class="line"><span class="string">[12:20] 玩具：恐龙宝宝就是圆肚肚！这是科学事实！</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[14:00] 孩子：我们来学习！考考你，5+3等于几？</span></span><br><span class="line"><span class="string">[14:01] 玩具：嗯...是不是和你的年龄一样大？</span></span><br><span class="line"><span class="string">[14:02] 孩子：不对啦！我8岁！是...是...8！</span></span><br><span class="line"><span class="string">[14:03] 玩具：太聪明啦！奖励你一个电子勋章~</span></span><br><span class="line"><span class="string">[14:04] 孩子：耶！我要给爸爸看！...啊作业本去哪了...</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[16:45] 孩子：我和小狗赛跑了！</span></span><br><span class="line"><span class="string">[16:46] 玩具：谁赢啦？你用了喷气背包吗？</span></span><br><span class="line"><span class="string">[16:47] 孩子：我赢！但是没有喷气...我偷偷抄了近路嘿嘿...</span></span><br><span class="line"><span class="string">[16:48] 玩具：噢~霸王龙裁判说这样要扣一分哦</span></span><br><span class="line"><span class="string">[16:49] 孩子：那...那明天我重新跑！小狗还在追尾巴呢！</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[19:30] 孩子：我洗完澡啦！香喷喷！</span></span><br><span class="line"><span class="string">[19:31] 玩具：是草莓味的吗？让我闻闻...哔哔！检测到超级香味！</span></span><br><span class="line"><span class="string">[19:32] 孩子：咯咯咯...妈妈今天给我讲太空的故事</span></span><br><span class="line"><span class="string">[19:33] 玩具：哇！那你知道宇航员怎么在飞船里睡觉吗？</span></span><br><span class="line"><span class="string">[19:34] 孩子：嗯...用绳子绑住！我也可以吗？</span></span><br><span class="line"><span class="string">[19:35] 玩具：我们可以试试电子催眠曲...</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[20:00] 孩子：机器人...</span></span><br><span class="line"><span class="string">[20:01] 玩具：我在呢，今天最开心的事是什么呀？</span></span><br><span class="line"><span class="string">[20:02] 孩子：和小狗跑...还有彩虹恐龙...还有...</span></span><br><span class="line"><span class="string">[20:03] 玩具：明天我们继续冒险好不好？</span></span><br><span class="line"><span class="string">[20:04] 孩子：好...晚安...呼...</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 生成报告</span></span><br><span class="line">    report = analyze_child_conversation(sample_dialogue)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;datetime.now().strftime(<span class="string">&#x27;%Y-%m-%d&#x27;</span>)&#125;</span> 情绪报告：&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(report)</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">2025-06-17 情绪报告：</span><br><span class="line">今日孩子情绪总体愉快且充满活力。孩子兴奋地分享了&quot;和小狗赛跑赢了&quot;和&quot;画了超级特别的彩虹恐龙&quot;等趣事，虽然中途因同伴评价画作短暂低落，但很快恢复了好心情。</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="3-内容库"><a href="#3-内容库" class="headerlink" title="3. 内容库"></a>3. 内容库</h3>]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>kws</tag>
      </tags>
  </entry>
  <entry>
    <title>语音玩具：各核心算法音频格式要求</title>
    <url>/2025/04/25/%E8%AF%AD%E9%9F%B3%E7%8E%A9%E5%85%B7%EF%BC%9A%E5%90%84%E6%A0%B8%E5%BF%83%E7%AE%97%E6%B3%95%E9%9F%B3%E9%A2%91%E6%A0%BC%E5%BC%8F%E8%A6%81%E6%B1%82/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>目前在做的语音玩具设计了四块音频算法，分别是人声检测，说话人验证，语音识别，语音合成，现整理各算法需要的音频输入格式以及官方和个人（我的）参考链接。</p>
<span id="more"></span>

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><table>
<thead>
<tr>
<th></th>
<th>所用算法</th>
<th>输入音频格式</th>
</tr>
</thead>
<tbody><tr>
<td>VAD（人声检测）</td>
<td>Silero VAD</td>
<td>float32，单声道，16K采样率</td>
</tr>
<tr>
<td>sv（说话人验证）</td>
<td>cam++</td>
<td>float32，单声道，16K采样率</td>
</tr>
<tr>
<td>asr（语音识别）</td>
<td>(Paraformer)funasr</td>
<td>int16， 单声道，16K采样率</td>
</tr>
<tr>
<td>asr（语音识别）</td>
<td>faster wisper</td>
<td>float32，单声道，16K采样率</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>tts（语音合成）<strong>输出</strong></td>
<td>Gpt-SoVits</td>
<td>int16，单声道，32K采样率</td>
</tr>
<tr>
<td>tts（语音合成）<strong>输出</strong></td>
<td>Index-tts</td>
<td>int16，单声道，24K采样率</td>
</tr>
</tbody></table>
<p>参考链接：</p>
<table>
<thead>
<tr>
<th></th>
<th>官方</th>
<th>个人</th>
</tr>
</thead>
<tbody><tr>
<td>VAD（人声检测）</td>
<td><a href="https://github.com/snakers4/silero-vad">https://github.com/snakers4/silero-vad</a></td>
<td><a href="https://caihaoran-00.github.io/2025/02/07/silerovadonnx%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/?highlight=vad">https://caihaoran-00.github.io/2025/02/07/silerovadonnx%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B/?highlight=vad</a></td>
</tr>
<tr>
<td>sv（说话人验证）</td>
<td><a href="https://modelscope.cn/models/iic/speech_campplus_sv_zh_en_16k-common_advanced">https://modelscope.cn/models/iic/speech_campplus_sv_zh_en_16k-common_advanced</a></td>
<td><a href="https://caihaoran-00.github.io/2025/02/11/%E8%AF%B4%E8%AF%9D%E4%BA%BA%E7%A1%AE%E8%AE%A4%E4%B9%8BCAM/?highlight=cam">https://caihaoran-00.github.io/2025/02/11/%E8%AF%B4%E8%AF%9D%E4%BA%BA%E7%A1%AE%E8%AE%A4%E4%B9%8BCAM/?highlight=cam</a></td>
</tr>
<tr>
<td>asr（语音识别）</td>
<td><a href="https://github.com/modelscope/FunASR/tree/main">https://github.com/modelscope/FunASR/tree/main</a></td>
<td><a href="https://caihaoran-00.github.io/2025/02/05/fastapi-request%E6%9E%84%E5%BB%BA%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BE%AE%E6%9C%8D%E5%8A%A1/?highlight=fas">https://caihaoran-00.github.io/2025/02/05/fastapi-request%E6%9E%84%E5%BB%BA%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BE%AE%E6%9C%8D%E5%8A%A1/?highlight=fas</a></td>
</tr>
<tr>
<td>tts（语音合成）<strong>输出</strong></td>
<td><a href="https://github.com/RVC-Boss/GPT-SoVITS">https://github.com/RVC-Boss/GPT-SoVITS</a></td>
<td><a href="https://caihaoran-00.github.io/2025/03/06/TTS%E4%B9%8BGPT-Sovits%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/?highlight=gpt">https://caihaoran-00.github.io/2025/03/06/TTS%E4%B9%8BGPT-Sovits%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/?highlight=gpt</a></td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>theory</category>
      </categories>
      <tags>
        <tag>asr</tag>
        <tag>tts</tag>
        <tag>cam++</tag>
        <tag>vad</tag>
      </tags>
  </entry>
  <entry>
    <title>查重系统：初级pdf解析及完整系统</title>
    <url>/2025/06/11/%E6%9F%A5%E9%87%8D%E7%B3%BB%E7%BB%9F%EF%BC%9A%E5%88%9D%E7%BA%A7pdf%E8%A7%A3%E6%9E%90%E5%8F%8A%E5%8F%A5%E5%AD%90%E9%87%8D%E7%BB%84/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>万丈高楼平地起，本来是一股脑的直接把查重系统的总体写出来，<a href="https://caihaoran-00.github.io/2025/06/11/%E6%9F%A5%E9%87%8D%E7%B3%BB%E7%BB%9F%EF%BC%9A%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E9%83%A8%E7%BD%B2%E6%9F%A5%E9%87%8D%E7%B3%BB%E7%BB%9F%E7%AE%80%E5%8D%95demo/">见这里</a>，然后在这个总体代码针对性的一部分一部分的去优化，但是发现代码多了不利于调试，不如整理思路后从基层一点点写上去，这个查重系列将记录针对这个项目的工作，不知道会走到什么程度（完全没可能接到这个项目的的情况下可能这一篇就是终点了）。</p>
<span id="more"></span>

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>本文的目的是实现将<code>Pdf</code>内容解析成需要的格式（需要的格式是什么格式？那你先别管🤫🤨）</p>
<h3 id="基座"><a href="#基座" class="headerlink" title="基座"></a>基座</h3><p><strong>第一步的目标：</strong></p>
<ul>
<li><p>创建一个 Streamlit 应用</p>
</li>
<li><p>提供一个文件上传组件，允许用户上传一个或多个 PDF 文件。</p>
</li>
<li><p>读取上传的 PDF 文件内容。</p>
</li>
<li><p>将提取出的文本内容保存到 .txt 文件中。</p>
</li>
<li><p>提供一个下载链接，让用户可以下载这个生成的 .txt 文件。</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> streamlit <span class="keyword">as</span> st</span><br><span class="line"><span class="keyword">import</span> pdfplumber</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># -------------------- 核心功能函数 --------------------</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_text_from_pdf</span>(<span class="params">pdf_file</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    从上传的 PDF 文件对象中提取所有文本。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pdf_file: Streamlit UploadedFile 对象。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        一个包含 PDF 所有文本内容的字符串。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># pdfplumber 需要一个文件路径或一个类似文件的二进制流。</span></span><br><span class="line">    <span class="comment"># st.UploadedFile 对象本身就是一个二进制流，可以直接使用。</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(pdf_file) <span class="keyword">as</span> pdf:</span><br><span class="line">            <span class="comment"># 遍历每一页并提取文本，然后用换行符合并</span></span><br><span class="line">            full_text = <span class="string">&#x27;\n&#x27;</span>.join(page.extract_text() <span class="keyword">or</span> <span class="string">&#x27;&#x27;</span> <span class="keyword">for</span> page <span class="keyword">in</span> pdf.pages)</span><br><span class="line">        <span class="keyword">return</span> full_text</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="comment"># 捕获可能的异常，比如加密的或损坏的PDF</span></span><br><span class="line">        st.error(<span class="string">f&quot;解析PDF文件时出错: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># -------------------- Streamlit 页面布局 --------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置页面标题和图标</span></span><br><span class="line">st.set_page_config(page_title=<span class="string">&quot;PDF 转 TXT 工具&quot;</span>, page_icon=<span class="string">&quot;📄&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 主标题</span></span><br><span class="line">st.title(<span class="string">&quot;PDF 内容提取并转为 TXT&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 介绍性文字</span></span><br><span class="line">st.markdown(<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">这是一个简单的小工具，可以帮助您快速地从 PDF 文件中提取纯文本内容，</span></span><br><span class="line"><span class="string">并将其保存为 `.txt` 文件以便后续处理或查阅。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 文件上传组件</span></span><br><span class="line"><span class="comment"># accept_multiple_files=True 允许多文件上传</span></span><br><span class="line">uploaded_file = st.file_uploader(</span><br><span class="line">    <span class="string">&quot;请上传一个 PDF 文件&quot;</span>,</span><br><span class="line">    <span class="built_in">type</span>=<span class="string">&quot;pdf&quot;</span>,</span><br><span class="line">    accept_multiple_files=<span class="literal">False</span>  <span class="comment"># 为了简化流程，我们先从处理单个文件开始</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 当用户上传了文件后，执行以下逻辑</span></span><br><span class="line"><span class="keyword">if</span> uploaded_file <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="comment"># 显示一个加载提示</span></span><br><span class="line">    <span class="keyword">with</span> st.spinner(<span class="string">f&quot;正在处理文件: `<span class="subst">&#123;uploaded_file.name&#125;</span>`...&quot;</span>):</span><br><span class="line">        <span class="comment"># 调用核心函数提取文本</span></span><br><span class="line">        extracted_text = extract_text_from_pdf(uploaded_file)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> extracted_text:</span><br><span class="line">        st.success(<span class="string">&quot;🎉 文件解析成功！&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># st.expander 是一个可折叠的容器，适合展示大量文本</span></span><br><span class="line">        <span class="keyword">with</span> st.expander(<span class="string">&quot;预览提取的文本内容 (前 1000 字符)&quot;</span>):</span><br><span class="line">            st.text_area(<span class="string">&quot;文本预览&quot;</span>, extracted_text[:<span class="number">1000</span>], height=<span class="number">250</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ---- 将文本保存到 TXT 文件并提供下载 ----</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 1. 准备文件名</span></span><br><span class="line">        <span class="comment"># 我们基于原始文件名创建一个新的 .txt 文件名</span></span><br><span class="line">        <span class="comment"># os.path.splitext会分割文件名和扩展名，例如 &#x27;document.pdf&#x27; -&gt; (&#x27;document&#x27;, &#x27;.pdf&#x27;)</span></span><br><span class="line">        base_filename = os.path.splitext(uploaded_file.name)[<span class="number">0</span>]</span><br><span class="line">        txt_filename = <span class="string">f&quot;<span class="subst">&#123;base_filename&#125;</span>.txt&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2. 将字符串编码为字节流，这是 st.download_button 所需要的</span></span><br><span class="line">        <span class="comment"># 使用 utf-8-sig 编码可以在Windows记事本中正确显示中文，避免乱码</span></span><br><span class="line">        txt_bytes = extracted_text.encode(<span class="string">&#x27;utf-8-sig&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3. 创建下载按钮</span></span><br><span class="line">        st.download_button(</span><br><span class="line">            label=<span class="string">&quot;下载 TXT 文件&quot;</span>,</span><br><span class="line">            data=txt_bytes,</span><br><span class="line">            file_name=txt_filename,</span><br><span class="line">            mime=<span class="string">&#x27;text/plain&#x27;</span>,  <span class="comment"># MIME 类型，告诉浏览器这是一个纯文本文件</span></span><br><span class="line">            key=<span class="string">&#x27;download-txt&#x27;</span></span><br><span class="line">        )</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    st.info(<span class="string">&quot;请上传一个 PDF 文件以开始。&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>运行结果如下：</strong></p>




<p>可见，现在实现了基本的<code>pdf</code>文件解析，下一步将表格和普通文本分开读取（尽量保留格式信息）</p>
<h3 id="表格-文本混合解析"><a href="#表格-文本混合解析" class="headerlink" title="表格&#x2F;文本混合解析"></a>表格&#x2F;文本混合解析</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> streamlit <span class="keyword">as</span> st</span><br><span class="line"><span class="keyword">import</span> pdfplumber</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># -------------------- 核心功能函数 (API优化最终版) --------------------</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_text_with_api</span>(<span class="params">pdf_file</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    从 PDF 文件中智能提取文本，使用 pdfplumber 的内置 API (.outside_bbox)</span></span><br><span class="line"><span class="string">    来实现最高效、最准确的表格内容分离。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    full_document_text = []</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(pdf_file) <span class="keyword">as</span> pdf:</span><br><span class="line">            <span class="keyword">for</span> page <span class="keyword">in</span> pdf.pages:</span><br><span class="line"></span><br><span class="line">                content_items = []</span><br><span class="line"></span><br><span class="line">                <span class="comment"># --- 1. 获取所有表格的边界框和内容 ---</span></span><br><span class="line">                found_tables = page.find_tables()</span><br><span class="line">                table_bboxes = []</span><br><span class="line">                <span class="keyword">if</span> found_tables:</span><br><span class="line">                    <span class="keyword">for</span> table_obj <span class="keyword">in</span> found_tables:</span><br><span class="line">                        table_bboxes.append(table_obj.bbox)</span><br><span class="line">                        table_data = table_obj.extract()</span><br><span class="line">                        <span class="keyword">if</span> <span class="keyword">not</span> table_data: <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">                        <span class="keyword">for</span> i, row <span class="keyword">in</span> <span class="built_in">enumerate</span>(table_data):</span><br><span class="line">                            cleaned_row = [<span class="built_in">str</span>(cell).replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27; &#x27;</span>).strip() <span class="keyword">if</span> cell <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="string">&#x27;&#x27;</span> <span class="keyword">for</span> cell <span class="keyword">in</span></span><br><span class="line">                                           row]</span><br><span class="line">                            row_text = <span class="string">&quot;: &quot;</span>.join(<span class="built_in">filter</span>(<span class="literal">None</span>, cleaned_row))</span><br><span class="line">                            <span class="keyword">if</span> row_text:</span><br><span class="line">                                row_y_position = table_obj.bbox[<span class="number">1</span>] + i * <span class="number">10</span></span><br><span class="line">                                content_items.append(&#123;<span class="string">&quot;top&quot;</span>: row_y_position, <span class="string">&quot;type&quot;</span>: <span class="string">&quot;table_row&quot;</span>, <span class="string">&quot;text&quot;</span>: row_text&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># --- 2. 修正：使用 .outside_bbox() 高效移除表格区域 ---</span></span><br><span class="line">                <span class="comment"># a. 从原始页面开始</span></span><br><span class="line">                page_without_tables = page</span><br><span class="line">                <span class="comment"># b. 循环“挖掉”每一个表格区域</span></span><br><span class="line">                <span class="keyword">for</span> bbox <span class="keyword">in</span> table_bboxes:</span><br><span class="line">                    page_without_tables = page_without_tables.outside_bbox(bbox)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># c. 从处理后的页面中提取剩余的文本行</span></span><br><span class="line">                non_table_lines = page_without_tables.extract_text_lines(return_chars=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># d. 将非表格文本行加入内容项</span></span><br><span class="line">                <span class="keyword">for</span> line <span class="keyword">in</span> non_table_lines:</span><br><span class="line">                    content_items.append(&#123;<span class="string">&quot;top&quot;</span>: line[<span class="string">&quot;top&quot;</span>], <span class="string">&quot;type&quot;</span>: <span class="string">&quot;text&quot;</span>, <span class="string">&quot;text&quot;</span>: line[<span class="string">&quot;text&quot;</span>]&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># --- 3. 对本页所有内容项进行排序并组合 (逻辑不变) ---</span></span><br><span class="line">                sorted_content = <span class="built_in">sorted</span>(content_items, key=<span class="keyword">lambda</span> x: x[<span class="string">&quot;top&quot;</span>])</span><br><span class="line">                page_text = <span class="string">&quot;\n&quot;</span>.join([item[<span class="string">&quot;text&quot;</span>] <span class="keyword">for</span> item <span class="keyword">in</span> sorted_content])</span><br><span class="line">                full_document_text.append(page_text)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;\n\n--- Page Break ---\n\n&quot;</span>.join(full_document_text)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        st.error(<span class="string">f&quot;解析PDF文件时出错: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">import</span> traceback</span><br><span class="line">        st.code(traceback.format_exc())</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># -------------------- Streamlit 页面布局 (完整版) --------------------</span></span><br><span class="line"></span><br><span class="line">st.set_page_config(page_title=<span class="string">&quot;智能PDF转TXT工具&quot;</span>, page_icon=<span class="string">&quot;📄&quot;</span>)</span><br><span class="line">st.title(<span class="string">&quot;高效 PDF 内容提取 (API优化版)&quot;</span>)</span><br><span class="line">st.markdown(<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">这个工具能智能识别 PDF 中的表格，并将表格内容与普通文本**按原始阅读顺序**一并提取。</span></span><br><span class="line"><span class="string">**采用官方API进行高精度过滤**，确保最佳效果和性能。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>)</span><br><span class="line"></span><br><span class="line">uploaded_file = st.file_uploader(</span><br><span class="line">    <span class="string">&quot;请上传一个包含文本和表格的 PDF 文件&quot;</span>,</span><br><span class="line">    <span class="built_in">type</span>=<span class="string">&quot;pdf&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> uploaded_file <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="keyword">with</span> st.spinner(<span class="string">f&quot;正在智能解析文件: `<span class="subst">&#123;uploaded_file.name&#125;</span>`...&quot;</span>):</span><br><span class="line">        extracted_text = extract_text_with_api(uploaded_file)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> extracted_text <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> extracted_text.strip():</span><br><span class="line">        st.success(<span class="string">&quot;🎉 文件解析成功！&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> st.expander(<span class="string">&quot;预览提取的文本内容&quot;</span>, expanded=<span class="literal">True</span>):</span><br><span class="line">            st.text_area(<span class="string">&quot;文本预览&quot;</span>, extracted_text, height=<span class="number">400</span>)</span><br><span class="line"></span><br><span class="line">        base_filename = os.path.splitext(uploaded_file.name)[<span class="number">0</span>]</span><br><span class="line">        txt_filename = <span class="string">f&quot;<span class="subst">&#123;base_filename&#125;</span>_extracted.txt&quot;</span></span><br><span class="line">        txt_bytes = extracted_text.encode(<span class="string">&#x27;utf-8-sig&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        st.download_button(</span><br><span class="line">            label=<span class="string">&quot;下载 TXT 文件&quot;</span>,</span><br><span class="line">            data=txt_bytes,</span><br><span class="line">            file_name=txt_filename,</span><br><span class="line">            mime=<span class="string">&#x27;text/plain&#x27;</span>,</span><br><span class="line">            key=<span class="string">&#x27;download-txt&#x27;</span></span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">elif</span> extracted_text <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        st.warning(<span class="string">&quot;文件已解析，但未提取到任何文本内容。&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    st.info(<span class="string">&quot;请上传一个 PDF 文件以开始。&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>运行结果如下：</strong></p>




<p>好的，现在能拿到原始数据了，那么我们接下来应该怎么做呢？</p>
<p><strong>接下来的问题变成了：为了让查重系统效果最好，我们应该把文本处理成什么样式的“单元”？</strong></p>
<p>好的，经过一番尝试，暂时做不到比较健壮的拼接规则，先搁置吧。</p>
<h3 id="初级完整系统"><a href="#初级完整系统" class="headerlink" title="初级完整系统"></a>初级完整系统</h3><p>既然暂时对健壮的拼接规则没有很好的思路，那继续往下进行吧，把查重的部分加上：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">可选择最小字数+相似度阈值</span></span><br><span class="line"><span class="string">只使用深度学习模型</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> streamlit <span class="keyword">as</span> st</span><br><span class="line"><span class="keyword">import</span> pdfplumber</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="keyword">from</span> sentence_transformers <span class="keyword">import</span> SentenceTransformer, util</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># -------------------- 1. 将 st.set_page_config 作为第一个 Streamlit 命令 --------------------</span></span><br><span class="line">st.set_page_config(page_title=<span class="string">&quot;PDF 查重与高亮工具&quot;</span>, layout=<span class="string">&quot;wide&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># -------------------- 模型加载与缓存 (已修改) --------------------</span></span><br><span class="line"><span class="meta">@st.cache_resource</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_bert_model</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;加载并缓存 SentenceTransformer 模型，自动使用GPU（如果可用）。&quot;&quot;&quot;</span></span><br><span class="line">    device = <span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;查重模型正在使用 &#x27;<span class="subst">&#123;device&#125;</span>&#x27; 设备运行。&quot;</span>)  <span class="comment"># 使用 print 在后端终端显示信息</span></span><br><span class="line">    <span class="comment"># return SentenceTransformer(&#x27;paraphrase-MiniLM-L6-v2&#x27;, device=device)</span></span><br><span class="line">    <span class="keyword">return</span> SentenceTransformer(<span class="string">&#x27;shibing624/text2vec-base-chinese&#x27;</span>, device=device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># -------------------- 核心功能函数 (已修正) --------------------</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_units_with_location</span>(<span class="params">pdf_file, file_name</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;从PDF文件中提取所有“查重单元”并附带其位置信息。&quot;&quot;&quot;</span></span><br><span class="line">    all_units = []</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(pdf_file) <span class="keyword">as</span> pdf:</span><br><span class="line">            <span class="keyword">for</span> page <span class="keyword">in</span> pdf.pages:</span><br><span class="line">                page_num = page.page_number</span><br><span class="line"></span><br><span class="line">                <span class="comment"># --- 提取表格单元 ---</span></span><br><span class="line">                found_tables = page.find_tables()</span><br><span class="line">                table_bboxes = [table.bbox <span class="keyword">for</span> table <span class="keyword">in</span> found_tables]</span><br><span class="line">                <span class="keyword">for</span> table_obj <span class="keyword">in</span> found_tables:</span><br><span class="line">                    table_data = table_obj.extract()</span><br><span class="line">                    <span class="keyword">if</span> <span class="keyword">not</span> table_data: <span class="keyword">continue</span></span><br><span class="line">                    <span class="keyword">for</span> row <span class="keyword">in</span> table_data:</span><br><span class="line">                        row_text = <span class="string">&quot;: &quot;</span>.join(</span><br><span class="line">                            <span class="built_in">filter</span>(<span class="literal">None</span>, [<span class="built_in">str</span>(cell).replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27; &#x27;</span>).strip() <span class="keyword">if</span> cell <span class="keyword">else</span> <span class="string">&#x27;&#x27;</span> <span class="keyword">for</span> cell <span class="keyword">in</span> row]))</span><br><span class="line">                        <span class="keyword">if</span> row_text:</span><br><span class="line">                            all_units.append(&#123;<span class="string">&quot;text&quot;</span>: row_text, <span class="string">&quot;page_num&quot;</span>: page_num, <span class="string">&quot;bbox&quot;</span>: table_obj.bbox&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># --- 提取非表格文本行 ---</span></span><br><span class="line">                page_without_tables = page</span><br><span class="line">                <span class="keyword">for</span> bbox <span class="keyword">in</span> table_bboxes:</span><br><span class="line">                    page_without_tables = page_without_tables.outside_bbox(bbox)</span><br><span class="line"></span><br><span class="line">                non_table_lines = page_without_tables.extract_text_lines(return_chars=<span class="literal">False</span>, strip=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># --- 关键修正点：增加防御性检查 ---</span></span><br><span class="line">                <span class="keyword">for</span> line <span class="keyword">in</span> non_table_lines:</span><br><span class="line">                    <span class="comment"># 检查行对象是否包含所有必需的坐标键</span></span><br><span class="line">                    required_keys = [<span class="string">&#x27;x0&#x27;</span>, <span class="string">&#x27;top&#x27;</span>, <span class="string">&#x27;x1&#x27;</span>, <span class="string">&#x27;bottom&#x27;</span>, <span class="string">&#x27;text&#x27;</span>]</span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">all</span>(key <span class="keyword">in</span> line <span class="keyword">for</span> key <span class="keyword">in</span> required_keys) <span class="keyword">and</span> line[<span class="string">&#x27;text&#x27;</span>]:</span><br><span class="line">                        <span class="comment"># 如果所有键都存在，并且文本不为空，才将其添加为有效单元</span></span><br><span class="line">                        all_units.append(&#123;</span><br><span class="line">                            <span class="string">&quot;text&quot;</span>: line[<span class="string">&quot;text&quot;</span>],</span><br><span class="line">                            <span class="string">&quot;page_num&quot;</span>: page_num,</span><br><span class="line">                            <span class="comment"># 从基本坐标安全地构建 bbox</span></span><br><span class="line">                            <span class="string">&quot;bbox&quot;</span>: (line[<span class="string">&quot;x0&quot;</span>], line[<span class="string">&quot;top&quot;</span>], line[<span class="string">&quot;x1&quot;</span>], line[<span class="string">&quot;bottom&quot;</span>])</span><br><span class="line">                        &#125;)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> all_units</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        st.error(<span class="string">f&quot;解析PDF文件 &#x27;<span class="subst">&#123;file_name&#125;</span>&#x27; 时出错: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">import</span> traceback</span><br><span class="line">        st.code(traceback.format_exc())</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># -------------------- 查重主函数 (保持不变) --------------------</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compare_documents</span>(<span class="params">units1, units2, min_char_length=<span class="number">10</span>, similarity_threshold=<span class="number">0.8</span></span>):</span><br><span class="line">    <span class="comment"># ... [函数内容完全不变] ...</span></span><br><span class="line">    filtered_units1 = [unit <span class="keyword">for</span> unit <span class="keyword">in</span> units1 <span class="keyword">if</span> <span class="built_in">len</span>(unit[<span class="string">&quot;text&quot;</span>]) &gt;= min_char_length]</span><br><span class="line">    filtered_units2 = [unit <span class="keyword">for</span> unit <span class="keyword">in</span> units2 <span class="keyword">if</span> <span class="built_in">len</span>(unit[<span class="string">&quot;text&quot;</span>]) &gt;= min_char_length]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> filtered_units1 <span class="keyword">or</span> <span class="keyword">not</span> filtered_units2:</span><br><span class="line">        <span class="keyword">return</span> [], <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    texts1 = [unit[<span class="string">&quot;text&quot;</span>] <span class="keyword">for</span> unit <span class="keyword">in</span> filtered_units1]</span><br><span class="line">    texts2 = [unit[<span class="string">&quot;text&quot;</span>] <span class="keyword">for</span> unit <span class="keyword">in</span> filtered_units2]</span><br><span class="line"></span><br><span class="line">    embeddings1 = bert_model.encode(texts1, convert_to_tensor=<span class="literal">True</span>, show_progress_bar=<span class="literal">False</span>)</span><br><span class="line">    embeddings2 = bert_model.encode(texts2, convert_to_tensor=<span class="literal">True</span>, show_progress_bar=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    hits = util.semantic_search(embeddings1, embeddings2, top_k=<span class="number">1</span>, score_function=util.cos_sim)</span><br><span class="line"></span><br><span class="line">    matches = []</span><br><span class="line">    matched_indices_in_doc1 = <span class="built_in">set</span>()</span><br><span class="line">    <span class="keyword">for</span> i, hit_list <span class="keyword">in</span> <span class="built_in">enumerate</span>(hits):</span><br><span class="line">        <span class="keyword">if</span> hit_list <span class="keyword">and</span> hit_list[<span class="number">0</span>][<span class="string">&#x27;score&#x27;</span>] &gt; similarity_threshold:</span><br><span class="line">            best_hit = hit_list[<span class="number">0</span>]</span><br><span class="line">            query_unit = filtered_units1[i]</span><br><span class="line">            match_unit = filtered_units2[best_hit[<span class="string">&#x27;corpus_id&#x27;</span>]]</span><br><span class="line">            matches.append(&#123;<span class="string">&quot;query_unit&quot;</span>: query_unit, <span class="string">&quot;match_unit&quot;</span>: match_unit, <span class="string">&quot;score&quot;</span>: best_hit[<span class="string">&#x27;score&#x27;</span>]&#125;)</span><br><span class="line">            matched_indices_in_doc1.add(i)</span><br><span class="line"></span><br><span class="line">    repeat_rate = <span class="built_in">len</span>(matched_indices_in_doc1) / <span class="built_in">len</span>(filtered_units1) <span class="keyword">if</span> filtered_units1 <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    matches.sort(key=<span class="keyword">lambda</span> x: x[<span class="string">&#x27;score&#x27;</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> matches, repeat_rate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># -------------------- 高亮与保存函数 (保持不变) --------------------</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">highlight_and_save_page</span>(<span class="params">pdf_bytes, page_num, bbox, output_path, resolution=<span class="number">200</span></span>):</span><br><span class="line">    <span class="comment"># ... [函数内容完全不变] ...</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(io.BytesIO(pdf_bytes)) <span class="keyword">as</span> pdf:</span><br><span class="line">            page = pdf.pages[page_num - <span class="number">1</span>]</span><br><span class="line">            img = page.to_image(resolution=resolution)</span><br><span class="line">            img.draw_rect(bbox, fill=(<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">40</span>), stroke=<span class="string">&quot;red&quot;</span>, stroke_width=<span class="number">2</span>)</span><br><span class="line">            img.save(output_path, <span class="built_in">format</span>=<span class="string">&quot;PNG&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        st.error(<span class="string">f&quot;生成高亮图片时出错: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># -------------------- Streamlit 页面布局和主逻辑 (保持不变) --------------------</span></span><br><span class="line">st.title(<span class="string">&quot;📄 PDF 文件查重与高亮工具&quot;</span>)</span><br><span class="line"></span><br><span class="line">bert_model = load_bert_model()</span><br><span class="line">device_info = bert_model.device.<span class="built_in">type</span></span><br><span class="line">st.info(<span class="string">f&quot;查重模型正在使用 &#x27;<span class="subst">&#123;device_info&#125;</span>&#x27; 设备运行。&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&quot;highlighted_images&quot;</span>):</span><br><span class="line">    os.makedirs(<span class="string">&quot;highlighted_images&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> st.sidebar:</span><br><span class="line">    st.header(<span class="string">&quot;⚙️ 查重参数设置&quot;</span>)</span><br><span class="line">    min_chars = st.slider(<span class="string">&quot;最小查重字数&quot;</span>, <span class="number">3</span>, <span class="number">50</span>, <span class="number">3</span>)</span><br><span class="line">    threshold = st.slider(<span class="string">&quot;相似度阈值&quot;</span>, <span class="number">0.5</span>, <span class="number">1.0</span>, <span class="number">0.95</span>, <span class="number">0.05</span>)</span><br><span class="line"></span><br><span class="line">uploaded_files = st.file_uploader(<span class="string">&quot;请上传多个 PDF 文件（至少两个）&quot;</span>, <span class="built_in">type</span>=<span class="string">&quot;pdf&quot;</span>, accept_multiple_files=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> uploaded_files <span class="keyword">and</span> <span class="built_in">len</span>(uploaded_files) &gt;= <span class="number">2</span>:</span><br><span class="line">    <span class="comment"># ... [后续的主逻辑代码完全保持不变] ...</span></span><br><span class="line">    docs_data = &#123;f.name: f.getvalue() <span class="keyword">for</span> f <span class="keyword">in</span> uploaded_files&#125;</span><br><span class="line">    docs_units = &#123;&#125;</span><br><span class="line">    <span class="keyword">with</span> st.spinner(<span class="string">&quot;正在解析所有PDF文件...&quot;</span>):</span><br><span class="line">        <span class="keyword">for</span> name, content <span class="keyword">in</span> docs_data.items():</span><br><span class="line">            docs_units[name] = extract_units_with_location(io.BytesIO(content), name)</span><br><span class="line">    st.success(<span class="string">&quot;所有文件解析完成！&quot;</span>)</span><br><span class="line"></span><br><span class="line">    doc_pairs = <span class="built_in">list</span>(itertools.combinations(docs_units.items(), <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> pair_idx, ((name1, units1), (name2, units2)) <span class="keyword">in</span> <span class="built_in">enumerate</span>(doc_pairs):</span><br><span class="line">        st.markdown(<span class="string">&quot;---&quot;</span>)</span><br><span class="line">        <span class="keyword">with</span> st.expander(<span class="string">f&quot;📊 对比结果：`<span class="subst">&#123;name1&#125;</span>` ⟷ `<span class="subst">&#123;name2&#125;</span>`&quot;</span>, expanded=<span class="literal">True</span>):</span><br><span class="line">            <span class="keyword">with</span> st.spinner(<span class="string">f&quot;正在比较 `<span class="subst">&#123;name1&#125;</span>` 和 `<span class="subst">&#123;name2&#125;</span>`...&quot;</span>):</span><br><span class="line">                matches, repeat_rate = compare_documents(units1, units2, min_chars, threshold)</span><br><span class="line"></span><br><span class="line">            st.metric(label=<span class="string">f&quot;重复率 (基于`<span class="subst">&#123;name1&#125;</span>`)&quot;</span>, value=<span class="string">f&quot;<span class="subst">&#123;repeat_rate * <span class="number">100</span>:<span class="number">.1</span>f&#125;</span>%&quot;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> matches:</span><br><span class="line">                st.info(<span class="string">&quot;✅ 未检测到满足条件的重复内容。&quot;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                st.write(<span class="string">f&quot;发现 <span class="subst">&#123;<span class="built_in">len</span>(matches)&#125;</span> 处相似内容 (按相似度排序):&quot;</span>)</span><br><span class="line"></span><br><span class="line">                st.subheader(<span class="string">&quot;最高相似度匹配项可视化&quot;</span>)</span><br><span class="line">                first_match = matches[<span class="number">0</span>]</span><br><span class="line">                q1_unit = first_match[<span class="string">&#x27;query_unit&#x27;</span>]</span><br><span class="line">                m2_unit = first_match[<span class="string">&#x27;match_unit&#x27;</span>]</span><br><span class="line"></span><br><span class="line">                img1_path = <span class="string">f&quot;highlighted_images/doc1_<span class="subst">&#123;pair_idx&#125;</span>.png&quot;</span></span><br><span class="line">                img2_path = <span class="string">f&quot;highlighted_images/doc2_<span class="subst">&#123;pair_idx&#125;</span>.png&quot;</span></span><br><span class="line"></span><br><span class="line">                success1 = highlight_and_save_page(docs_data[name1], q1_unit[<span class="string">&#x27;page_num&#x27;</span>], q1_unit[<span class="string">&#x27;bbox&#x27;</span>], img1_path)</span><br><span class="line">                success2 = highlight_and_save_page(docs_data[name2], m2_unit[<span class="string">&#x27;page_num&#x27;</span>], m2_unit[<span class="string">&#x27;bbox&#x27;</span>], img2_path)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> success1 <span class="keyword">and</span> success2:</span><br><span class="line">                    col1, col2 = st.columns(<span class="number">2</span>)</span><br><span class="line">                    <span class="keyword">with</span> col1:</span><br><span class="line">                        st.info(<span class="string">f&quot;文档: `<span class="subst">&#123;name1&#125;</span>` - 第 <span class="subst">&#123;q1_unit[<span class="string">&#x27;page_num&#x27;</span>]&#125;</span> 页&quot;</span>)</span><br><span class="line">                        st.image(img1_path, use_column_width=<span class="literal">True</span>)</span><br><span class="line">                        <span class="keyword">with</span> <span class="built_in">open</span>(img1_path, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">                            st.download_button(<span class="string">&quot;下载高亮图片&quot;</span>, file.read(),</span><br><span class="line">                                               file_name=<span class="string">f&quot;<span class="subst">&#123;os.path.basename(name1)&#125;</span>_p<span class="subst">&#123;q1_unit[<span class="string">&#x27;page_num&#x27;</span>]&#125;</span>.png&quot;</span>,</span><br><span class="line">                                               key=<span class="string">f&quot;dl1_<span class="subst">&#123;pair_idx&#125;</span>&quot;</span>)</span><br><span class="line">                    <span class="keyword">with</span> col2:</span><br><span class="line">                        st.info(<span class="string">f&quot;文档: `<span class="subst">&#123;name2&#125;</span>` - 第 <span class="subst">&#123;m2_unit[<span class="string">&#x27;page_num&#x27;</span>]&#125;</span> 页&quot;</span>)</span><br><span class="line">                        st.image(img2_path, use_column_width=<span class="literal">True</span>)</span><br><span class="line">                        <span class="keyword">with</span> <span class="built_in">open</span>(img2_path, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">                            st.download_button(<span class="string">&quot;下载高亮图片&quot;</span>, file.read(),</span><br><span class="line">                                               file_name=<span class="string">f&quot;<span class="subst">&#123;os.path.basename(name2)&#125;</span>_p<span class="subst">&#123;m2_unit[<span class="string">&#x27;page_num&#x27;</span>]&#125;</span>.png&quot;</span>,</span><br><span class="line">                                               key=<span class="string">f&quot;dl2_<span class="subst">&#123;pair_idx&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">                st.subheader(<span class="string">&quot;所有相似项列表&quot;</span>)</span><br><span class="line">                <span class="keyword">for</span> i, item <span class="keyword">in</span> <span class="built_in">enumerate</span>(matches, <span class="number">1</span>):</span><br><span class="line">                    q_unit = item[<span class="string">&#x27;query_unit&#x27;</span>]</span><br><span class="line">                    m_unit = item[<span class="string">&#x27;match_unit&#x27;</span>]</span><br><span class="line">                    st.markdown(<span class="string">f&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">                    &lt;div style=&#x27;background-color:#f9f9f9; padding:10px; margin:10px 0; border-left: 5px solid #ff4b4b; border-radius: 5px;&#x27;&gt;</span></span><br><span class="line"><span class="string">                        &lt;b&gt;相似度: <span class="subst">&#123;item[<span class="string">&#x27;score&#x27;</span>]:<span class="number">.2</span>f&#125;</span>&lt;/b&gt;&lt;br&gt;</span></span><br><span class="line"><span class="string">                        &lt;p&gt;📄 &lt;b&gt;文档1 (<span class="subst">&#123;name1&#125;</span>) - 第 <span class="subst">&#123;q_unit[<span class="string">&#x27;page_num&#x27;</span>]&#125;</span> 页&lt;/b&gt;: <span class="subst">&#123;q_unit[<span class="string">&#x27;text&#x27;</span>]&#125;</span>&lt;/p&gt;</span></span><br><span class="line"><span class="string">                        &lt;p&gt;📄 &lt;b&gt;文档2 (<span class="subst">&#123;name2&#125;</span>) - 第 <span class="subst">&#123;m_unit[<span class="string">&#x27;page_num&#x27;</span>]&#125;</span> 页&lt;/b&gt;: <span class="subst">&#123;m_unit[<span class="string">&#x27;text&#x27;</span>]&#125;</span>&lt;/p&gt;</span></span><br><span class="line"><span class="string">                    &lt;/div&gt;</span></span><br><span class="line"><span class="string">                    &quot;&quot;&quot;</span>, unsafe_allow_html=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    st.warning(<span class="string">&quot;请至少上传两个 PDF 文件以开始查重。&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<img src="/2025/06/11/%E6%9F%A5%E9%87%8D%E7%B3%BB%E7%BB%9F%EF%BC%9A%E5%88%9D%E7%BA%A7pdf%E8%A7%A3%E6%9E%90%E5%8F%8A%E5%8F%A5%E5%AD%90%E9%87%8D%E7%BB%84/image-20250612142148374.png" class="" title="image-20250612142148374">

<img src="/2025/06/11/%E6%9F%A5%E9%87%8D%E7%B3%BB%E7%BB%9F%EF%BC%9A%E5%88%9D%E7%BA%A7pdf%E8%A7%A3%E6%9E%90%E5%8F%8A%E5%8F%A5%E5%AD%90%E9%87%8D%E7%BB%84/image-20250612142310310.png" class="" title="image-20250612142310310">

<img src="/2025/06/11/%E6%9F%A5%E9%87%8D%E7%B3%BB%E7%BB%9F%EF%BC%9A%E5%88%9D%E7%BA%A7pdf%E8%A7%A3%E6%9E%90%E5%8F%8A%E5%8F%A5%E5%AD%90%E9%87%8D%E7%BB%84/image-20250612142336391.png" class="" title="image-20250612142336391">

<img src="/2025/06/11/%E6%9F%A5%E9%87%8D%E7%B3%BB%E7%BB%9F%EF%BC%9A%E5%88%9D%E7%BA%A7pdf%E8%A7%A3%E6%9E%90%E5%8F%8A%E5%8F%A5%E5%AD%90%E9%87%8D%E7%BB%84/image-20250612142359591.png" class="" title="image-20250612142359591">

<p><strong>此时的功能：</strong></p>
<ul>
<li>深度学习方法进行查重（<code>shibing624/text2vec-base-chinese</code>）</li>
<li>可选最小查重字数及相似度阈值</li>
<li>显示查重率</li>
<li>高亮显示第一个重复段落</li>
<li>显示重复段落&#x2F;相似度&#x2F;所在页码</li>
</ul>
<hr>
<h3 id="目前完整系统"><a href="#目前完整系统" class="headerlink" title="目前完整系统"></a>目前完整系统</h3><p>再进一步，上面的初级完整系统要使用<code>GPU</code>的，需要一点硬件资源的，也许客户并不关心这技术那技术，只要能出结果就行，那么也许完全可以使用传统技术，比如（<code>SimHash + TF-IDF</code>），让客户自己选择是使用传统技术还是目前比较先进的技术：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> streamlit <span class="keyword">as</span> st</span><br><span class="line"><span class="keyword">import</span> pdfplumber</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 传统方法所需的库</span></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">from</span> simhash <span class="keyword">import</span> Simhash</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> cosine_similarity</span><br><span class="line"></span><br><span class="line"><span class="comment"># 深度学习方法所需的库</span></span><br><span class="line"><span class="keyword">from</span> sentence_transformers <span class="keyword">import</span> SentenceTransformer, util</span><br><span class="line"></span><br><span class="line"><span class="comment"># -------------------- 页面配置 (必须是第一个st命令) --------------------</span></span><br><span class="line">st.set_page_config(page_title=<span class="string">&quot;多策略PDF查重工具&quot;</span>, layout=<span class="string">&quot;wide&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># -------------------- 模型与资源加载 --------------------</span></span><br><span class="line"><span class="meta">@st.cache_resource</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_bert_model</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;加载并缓存为中文优化的 SentenceTransformer 模型。&quot;&quot;&quot;</span></span><br><span class="line">    device = <span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;深度学习模型正在使用 &#x27;<span class="subst">&#123;device&#125;</span>&#x27; 设备运行。&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> SentenceTransformer(<span class="string">&#x27;shibing624/text2vec-base-chinese&#x27;</span>, device=device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># -------------------- 核心功能函数 (使用您提供的健壮版本) --------------------</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_units_with_location</span>(<span class="params">pdf_file, file_name</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;从PDF文件中提取所有“查重单元”并附带其位置信息，包含健壮的bbox处理。&quot;&quot;&quot;</span></span><br><span class="line">    all_units = []</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(pdf_file) <span class="keyword">as</span> pdf:</span><br><span class="line">            <span class="keyword">for</span> page <span class="keyword">in</span> pdf.pages:</span><br><span class="line">                page_num = page.page_number</span><br><span class="line"></span><br><span class="line">                <span class="comment"># --- 提取表格单元 ---</span></span><br><span class="line">                found_tables = page.find_tables()</span><br><span class="line">                table_bboxes = [table.bbox <span class="keyword">for</span> table <span class="keyword">in</span> found_tables]</span><br><span class="line">                <span class="keyword">for</span> table_obj <span class="keyword">in</span> found_tables:</span><br><span class="line">                    table_data = table_obj.extract()</span><br><span class="line">                    <span class="keyword">if</span> <span class="keyword">not</span> table_data: <span class="keyword">continue</span></span><br><span class="line">                    <span class="keyword">for</span> row <span class="keyword">in</span> table_data:</span><br><span class="line">                        row_text = <span class="string">&quot;: &quot;</span>.join(</span><br><span class="line">                            <span class="built_in">filter</span>(<span class="literal">None</span>, [<span class="built_in">str</span>(cell).replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27; &#x27;</span>).strip() <span class="keyword">if</span> cell <span class="keyword">else</span> <span class="string">&#x27;&#x27;</span> <span class="keyword">for</span> cell <span class="keyword">in</span> row]))</span><br><span class="line">                        <span class="keyword">if</span> row_text:</span><br><span class="line">                            all_units.append(&#123;<span class="string">&quot;text&quot;</span>: row_text, <span class="string">&quot;page_num&quot;</span>: page_num, <span class="string">&quot;bbox&quot;</span>: table_obj.bbox&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># --- 提取非表格文本行 ---</span></span><br><span class="line">                page_without_tables = page</span><br><span class="line">                <span class="keyword">for</span> bbox <span class="keyword">in</span> table_bboxes:</span><br><span class="line">                    page_without_tables = page_without_tables.outside_bbox(bbox)</span><br><span class="line"></span><br><span class="line">                non_table_lines = page_without_tables.extract_text_lines(return_chars=<span class="literal">False</span>, strip=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># --- 关键修正点：增加防御性检查 ---</span></span><br><span class="line">                <span class="keyword">for</span> line <span class="keyword">in</span> non_table_lines:</span><br><span class="line">                    required_keys = [<span class="string">&#x27;x0&#x27;</span>, <span class="string">&#x27;top&#x27;</span>, <span class="string">&#x27;x1&#x27;</span>, <span class="string">&#x27;bottom&#x27;</span>, <span class="string">&#x27;text&#x27;</span>]</span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">all</span>(key <span class="keyword">in</span> line <span class="keyword">for</span> key <span class="keyword">in</span> required_keys) <span class="keyword">and</span> line[<span class="string">&#x27;text&#x27;</span>]:</span><br><span class="line">                        all_units.append(&#123;</span><br><span class="line">                            <span class="string">&quot;text&quot;</span>: line[<span class="string">&quot;text&quot;</span>],</span><br><span class="line">                            <span class="string">&quot;page_num&quot;</span>: page_num,</span><br><span class="line">                            <span class="string">&quot;bbox&quot;</span>: (line[<span class="string">&quot;x0&quot;</span>], line[<span class="string">&quot;top&quot;</span>], line[<span class="string">&quot;x1&quot;</span>], line[<span class="string">&quot;bottom&quot;</span>])</span><br><span class="line">                        &#125;)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> all_units</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        st.error(<span class="string">f&quot;解析PDF文件 &#x27;<span class="subst">&#123;file_name&#125;</span>&#x27; 时出错: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">import</span> traceback</span><br><span class="line">        st.code(traceback.format_exc())</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># -------------------- 查重算法模块 (保持不变) --------------------</span></span><br><span class="line"><span class="comment"># --- 深度学习方法 ---</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compare_documents_deep_learning</span>(<span class="params">units1, units2, min_char_length, similarity_threshold</span>):</span><br><span class="line">    bert_model = load_bert_model()</span><br><span class="line">    <span class="comment"># ...[此函数代码不变]...</span></span><br><span class="line">    filtered_units1 = [unit <span class="keyword">for</span> unit <span class="keyword">in</span> units1 <span class="keyword">if</span> <span class="built_in">len</span>(unit[<span class="string">&quot;text&quot;</span>]) &gt;= min_char_length]</span><br><span class="line">    filtered_units2 = [unit <span class="keyword">for</span> unit <span class="keyword">in</span> units2 <span class="keyword">if</span> <span class="built_in">len</span>(unit[<span class="string">&quot;text&quot;</span>]) &gt;= min_char_length]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> filtered_units1 <span class="keyword">or</span> <span class="keyword">not</span> filtered_units2: <span class="keyword">return</span> [], <span class="number">0.0</span></span><br><span class="line">    texts1 = [unit[<span class="string">&quot;text&quot;</span>] <span class="keyword">for</span> unit <span class="keyword">in</span> filtered_units1]</span><br><span class="line">    texts2 = [unit[<span class="string">&quot;text&quot;</span>] <span class="keyword">for</span> unit <span class="keyword">in</span> filtered_units2]</span><br><span class="line">    embeddings1 = bert_model.encode(texts1, convert_to_tensor=<span class="literal">True</span>, show_progress_bar=<span class="literal">False</span>)</span><br><span class="line">    embeddings2 = bert_model.encode(texts2, convert_to_tensor=<span class="literal">True</span>, show_progress_bar=<span class="literal">False</span>)</span><br><span class="line">    hits = util.semantic_search(embeddings1, embeddings2, top_k=<span class="number">1</span>, score_function=util.cos_sim)</span><br><span class="line">    matches = []</span><br><span class="line">    matched_indices_in_doc1 = <span class="built_in">set</span>()</span><br><span class="line">    <span class="keyword">for</span> i, hit_list <span class="keyword">in</span> <span class="built_in">enumerate</span>(hits):</span><br><span class="line">        <span class="keyword">if</span> hit_list <span class="keyword">and</span> hit_list[<span class="number">0</span>][<span class="string">&#x27;score&#x27;</span>] &gt; similarity_threshold:</span><br><span class="line">            best_hit = hit_list[<span class="number">0</span>]</span><br><span class="line">            query_unit = filtered_units1[i]</span><br><span class="line">            match_unit = filtered_units2[best_hit[<span class="string">&#x27;corpus_id&#x27;</span>]]</span><br><span class="line">            matches.append(&#123;<span class="string">&quot;query_unit&quot;</span>: query_unit, <span class="string">&quot;match_unit&quot;</span>: match_unit, <span class="string">&quot;score&quot;</span>: best_hit[<span class="string">&#x27;score&#x27;</span>]&#125;)</span><br><span class="line">            matched_indices_in_doc1.add(i)</span><br><span class="line">    repeat_rate = <span class="built_in">len</span>(matched_indices_in_doc1) / <span class="built_in">len</span>(filtered_units1) <span class="keyword">if</span> filtered_units1 <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    matches.sort(key=<span class="keyword">lambda</span> x: x[<span class="string">&#x27;score&#x27;</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> matches, repeat_rate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># --- 传统方法 ---</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess_text_for_traditional</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27; &#x27;</span>.join(jieba.cut(text))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compare_documents_traditional</span>(<span class="params">units1, units2, min_char_length, simhash_threshold=<span class="number">0.9</span>, tfidf_threshold=<span class="number">0.5</span></span>):</span><br><span class="line">    <span class="comment"># ...[此函数代码不变]...</span></span><br><span class="line">    filtered_units1 = [unit <span class="keyword">for</span> unit <span class="keyword">in</span> units1 <span class="keyword">if</span> <span class="built_in">len</span>(unit[<span class="string">&quot;text&quot;</span>]) &gt;= min_char_length]</span><br><span class="line">    filtered_units2 = [unit <span class="keyword">for</span> unit <span class="keyword">in</span> units2 <span class="keyword">if</span> <span class="built_in">len</span>(unit[<span class="string">&quot;text&quot;</span>]) &gt;= min_char_length]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> filtered_units1 <span class="keyword">or</span> <span class="keyword">not</span> filtered_units2: <span class="keyword">return</span> [], <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> unit <span class="keyword">in</span> filtered_units1: unit[<span class="string">&#x27;simhash&#x27;</span>] = Simhash(unit[<span class="string">&#x27;text&#x27;</span>])</span><br><span class="line">    <span class="keyword">for</span> unit <span class="keyword">in</span> filtered_units2: unit[<span class="string">&#x27;simhash&#x27;</span>] = Simhash(unit[<span class="string">&#x27;text&#x27;</span>])</span><br><span class="line">    matches = []</span><br><span class="line">    matched_indices_in_doc1 = <span class="built_in">set</span>()</span><br><span class="line">    total_pairs = <span class="built_in">len</span>(filtered_units1)</span><br><span class="line">    progress_bar = st.progress(<span class="number">0</span>, text=<span class="string">&quot;正在使用传统方法比较...&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i, unit1 <span class="keyword">in</span> <span class="built_in">enumerate</span>(filtered_units1):</span><br><span class="line">        best_match_for_unit1 = <span class="literal">None</span></span><br><span class="line">        highest_score = -<span class="number">1.0</span></span><br><span class="line">        <span class="keyword">for</span> unit2 <span class="keyword">in</span> filtered_units2:</span><br><span class="line">            simhash_sim = <span class="number">1</span> - unit1[<span class="string">&#x27;simhash&#x27;</span>].distance(unit2[<span class="string">&#x27;simhash&#x27;</span>]) / <span class="number">64</span></span><br><span class="line">            <span class="keyword">if</span> simhash_sim &lt; simhash_threshold: <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                p1 = preprocess_text_for_traditional(unit1[<span class="string">&#x27;text&#x27;</span>])</span><br><span class="line">                p2 = preprocess_text_for_traditional(unit2[<span class="string">&#x27;text&#x27;</span>])</span><br><span class="line">                vectorizer = TfidfVectorizer()</span><br><span class="line">                tfidf_matrix = vectorizer.fit_transform([p1, p2])</span><br><span class="line">                tfidf_sim = cosine_similarity(tfidf_matrix[<span class="number">0</span>:<span class="number">1</span>], tfidf_matrix[<span class="number">1</span>:<span class="number">2</span>])[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">                <span class="keyword">if</span> tfidf_sim &gt; tfidf_threshold <span class="keyword">and</span> tfidf_sim &gt; highest_score:</span><br><span class="line">                    highest_score = tfidf_sim</span><br><span class="line">                    best_match_for_unit1 = unit2</span><br><span class="line">            <span class="keyword">except</span> ValueError:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">if</span> best_match_for_unit1:</span><br><span class="line">            matches.append(&#123;<span class="string">&quot;query_unit&quot;</span>: unit1, <span class="string">&quot;match_unit&quot;</span>: best_match_for_unit1, <span class="string">&quot;score&quot;</span>: highest_score&#125;)</span><br><span class="line">            matched_indices_in_doc1.add(i)</span><br><span class="line">        progress_bar.progress((i + <span class="number">1</span>) / total_pairs, text=<span class="string">f&quot;正在使用传统方法比较... (<span class="subst">&#123;i + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;total_pairs&#125;</span>)&quot;</span>)</span><br><span class="line">    repeat_rate = <span class="built_in">len</span>(matched_indices_in_doc1) / <span class="built_in">len</span>(filtered_units1) <span class="keyword">if</span> filtered_units1 <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    matches.sort(key=<span class="keyword">lambda</span> x: x[<span class="string">&#x27;score&#x27;</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> matches, repeat_rate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># -------------------- 高亮与保存函数 (保持不变) --------------------</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">highlight_and_save_page</span>(<span class="params">pdf_bytes, page_num, bbox, output_path, resolution=<span class="number">200</span></span>):</span><br><span class="line">    <span class="comment"># ...[此函数代码不变]...</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(io.BytesIO(pdf_bytes)) <span class="keyword">as</span> pdf:</span><br><span class="line">            page = pdf.pages[page_num - <span class="number">1</span>]</span><br><span class="line">            img = page.to_image(resolution=resolution)</span><br><span class="line">            img.draw_rect(bbox, fill=(<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">40</span>), stroke=<span class="string">&quot;red&quot;</span>, stroke_width=<span class="number">2</span>)</span><br><span class="line">            img.save(output_path, <span class="built_in">format</span>=<span class="string">&quot;PNG&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        st.error(<span class="string">f&quot;生成高亮图片时出错: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># -------------------- Streamlit 页面布局和主逻辑 --------------------</span></span><br><span class="line">st.title(<span class="string">&quot;📄 多策略 PDF 文件查重工具&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&quot;highlighted_images&quot;</span>):</span><br><span class="line">    os.makedirs(<span class="string">&quot;highlighted_images&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> st.sidebar:</span><br><span class="line">    st.header(<span class="string">&quot;⚙️ 查重参数设置&quot;</span>)</span><br><span class="line">    method = st.radio(</span><br><span class="line">        <span class="string">&quot;选择查重方法:&quot;</span>,</span><br><span class="line">        (<span class="string">&#x27;深度学习方法 (精准语义)&#x27;</span>, <span class="string">&#x27;传统方法 (字面匹配)&#x27;</span>),</span><br><span class="line">        <span class="built_in">help</span>=<span class="string">&quot;深度学习能理解句子意思上的相似；传统方法更关注关键词和文本结构的相似。&quot;</span></span><br><span class="line">    )</span><br><span class="line">    min_chars = st.slider(<span class="string">&quot;1. 最小查重字数&quot;</span>, <span class="number">3</span>, <span class="number">50</span>, <span class="number">10</span>, <span class="built_in">help</span>=<span class="string">&quot;长度小于此值的文本片段将被忽略。&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;深度学习&#x27;</span> <span class="keyword">in</span> method:</span><br><span class="line">        threshold = st.slider(<span class="string">&quot;2. 语义相似度阈值&quot;</span>, <span class="number">0.60</span>, <span class="number">1.0</span>, <span class="number">0.85</span>, <span class="number">0.05</span>,</span><br><span class="line">                              <span class="built_in">help</span>=<span class="string">&quot;推荐值: 0.85-0.95 (严格查重), 0.75-0.85 (查找相关内容)。分数越高，要求越严格。&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        st.subheader(<span class="string">&quot;2. 传统方法阈值&quot;</span>)</span><br><span class="line">        simhash_thresh = st.slider(<span class="string">&quot;SimHash 初筛阈值&quot;</span>, <span class="number">0.70</span>, <span class="number">1.0</span>, <span class="number">0.90</span>, <span class="number">0.05</span>,</span><br><span class="line">                                   <span class="built_in">help</span>=<span class="string">&quot;用于快速排除差异大的文本。推荐值0.90左右，容忍少量文字改动。&quot;</span>)</span><br><span class="line">        tfidf_thresh = st.slider(<span class="string">&quot;TF-IDF 精筛阈值&quot;</span>, <span class="number">0.30</span>, <span class="number">1.0</span>, <span class="number">0.60</span>, <span class="number">0.05</span>,</span><br><span class="line">                                 <span class="built_in">help</span>=<span class="string">&quot;基于关键词匹配。推荐值0.5-0.7，分数过高可能只匹配到几乎一样的句子。&quot;</span>)</span><br><span class="line"></span><br><span class="line">uploaded_files = st.file_uploader(<span class="string">&quot;请上传多个 PDF 文件（至少两个）&quot;</span>, <span class="built_in">type</span>=<span class="string">&quot;pdf&quot;</span>, accept_multiple_files=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> uploaded_files <span class="keyword">and</span> <span class="built_in">len</span>(uploaded_files) &gt;= <span class="number">2</span>:</span><br><span class="line">    docs_data = &#123;f.name: f.getvalue() <span class="keyword">for</span> f <span class="keyword">in</span> uploaded_files&#125;</span><br><span class="line">    docs_units = &#123;&#125;</span><br><span class="line">    <span class="keyword">with</span> st.spinner(<span class="string">&quot;正在解析所有PDF文件...&quot;</span>):</span><br><span class="line">        <span class="keyword">for</span> name, content <span class="keyword">in</span> docs_data.items():</span><br><span class="line">            docs_units[name] = extract_units_with_location(io.BytesIO(content), name)</span><br><span class="line">    st.success(<span class="string">&quot;所有文件解析完成！&quot;</span>)</span><br><span class="line"></span><br><span class="line">    doc_pairs = <span class="built_in">list</span>(itertools.combinations(docs_units.items(), <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> pair_idx, ((name1, units1), (name2, units2)) <span class="keyword">in</span> <span class="built_in">enumerate</span>(doc_pairs):</span><br><span class="line">        st.markdown(<span class="string">&quot;---&quot;</span>)</span><br><span class="line">        <span class="keyword">with</span> st.expander(<span class="string">f&quot;📊 对比结果：`<span class="subst">&#123;name1&#125;</span>` ⟷ `<span class="subst">&#123;name2&#125;</span>`&quot;</span>, expanded=<span class="literal">True</span>):</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 算法分流</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;深度学习&#x27;</span> <span class="keyword">in</span> method:</span><br><span class="line">                st.info(<span class="string">&quot;当前使用: 深度学习方法&quot;</span>)</span><br><span class="line">                matches, repeat_rate = compare_documents_deep_learning(units1, units2, min_chars, threshold)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                st.info(<span class="string">&quot;当前使用: 传统方法 (SimHash + TF-IDF)&quot;</span>)</span><br><span class="line">                matches, repeat_rate = compare_documents_traditional(units1, units2, min_chars, simhash_thresh,</span><br><span class="line">                                                                     tfidf_thresh)</span><br><span class="line"></span><br><span class="line">            st.metric(label=<span class="string">f&quot;重复率 (基于`<span class="subst">&#123;name1&#125;</span>`)&quot;</span>, value=<span class="string">f&quot;<span class="subst">&#123;repeat_rate * <span class="number">100</span>:<span class="number">.1</span>f&#125;</span>%&quot;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> matches:</span><br><span class="line">                st.info(<span class="string">&quot;✅ 未检测到满足条件的重复内容。&quot;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 结果展示</span></span><br><span class="line">                st.write(<span class="string">f&quot;发现 <span class="subst">&#123;<span class="built_in">len</span>(matches)&#125;</span> 处相似内容 (按相似度排序):&quot;</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 高亮显示第一个</span></span><br><span class="line">                st.subheader(<span class="string">&quot;最高相似度匹配项可视化&quot;</span>)</span><br><span class="line">                first_match = matches[<span class="number">0</span>]</span><br><span class="line">                q1_unit = first_match[<span class="string">&#x27;query_unit&#x27;</span>]</span><br><span class="line">                m2_unit = first_match[<span class="string">&#x27;match_unit&#x27;</span>]</span><br><span class="line">                img1_path = <span class="string">f&quot;highlighted_images/doc1_<span class="subst">&#123;pair_idx&#125;</span>.png&quot;</span></span><br><span class="line">                img2_path = <span class="string">f&quot;highlighted_images/doc2_<span class="subst">&#123;pair_idx&#125;</span>.png&quot;</span></span><br><span class="line">                success1 = highlight_and_save_page(docs_data[name1], q1_unit[<span class="string">&#x27;page_num&#x27;</span>], q1_unit[<span class="string">&#x27;bbox&#x27;</span>], img1_path)</span><br><span class="line">                success2 = highlight_and_save_page(docs_data[name2], m2_unit[<span class="string">&#x27;page_num&#x27;</span>], m2_unit[<span class="string">&#x27;bbox&#x27;</span>], img2_path)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> success1 <span class="keyword">and</span> success2:</span><br><span class="line">                    col1, col2 = st.columns(<span class="number">2</span>)</span><br><span class="line">                    <span class="keyword">with</span> col1:</span><br><span class="line">                        st.info(<span class="string">f&quot;文档: `<span class="subst">&#123;name1&#125;</span>` - 第 <span class="subst">&#123;q1_unit[<span class="string">&#x27;page_num&#x27;</span>]&#125;</span> 页&quot;</span>)</span><br><span class="line">                        st.image(img1_path, use_column_width=<span class="literal">True</span>)</span><br><span class="line">                        <span class="keyword">with</span> <span class="built_in">open</span>(img1_path, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">                            st.download_button(<span class="string">&quot;下载高亮图片&quot;</span>, file.read(),</span><br><span class="line">                                               file_name=<span class="string">f&quot;<span class="subst">&#123;os.path.basename(name1)&#125;</span>_p<span class="subst">&#123;q1_unit[<span class="string">&#x27;page_num&#x27;</span>]&#125;</span>.png&quot;</span>,</span><br><span class="line">                                               key=<span class="string">f&quot;dl1_<span class="subst">&#123;pair_idx&#125;</span>&quot;</span>)</span><br><span class="line">                    <span class="keyword">with</span> col2:</span><br><span class="line">                        st.info(<span class="string">f&quot;文档: `<span class="subst">&#123;name2&#125;</span>` - 第 <span class="subst">&#123;m2_unit[<span class="string">&#x27;page_num&#x27;</span>]&#125;</span> 页&quot;</span>)</span><br><span class="line">                        st.image(img2_path, use_column_width=<span class="literal">True</span>)</span><br><span class="line">                        <span class="keyword">with</span> <span class="built_in">open</span>(img2_path, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">                            st.download_button(<span class="string">&quot;下载高亮图片&quot;</span>, file.read(),</span><br><span class="line">                                               file_name=<span class="string">f&quot;<span class="subst">&#123;os.path.basename(name2)&#125;</span>_p<span class="subst">&#123;m2_unit[<span class="string">&#x27;page_num&#x27;</span>]&#125;</span>.png&quot;</span>,</span><br><span class="line">                                               key=<span class="string">f&quot;dl2_<span class="subst">&#123;pair_idx&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 显示所有匹配项</span></span><br><span class="line">                st.subheader(<span class="string">&quot;所有相似项列表&quot;</span>)</span><br><span class="line">                <span class="keyword">for</span> item <span class="keyword">in</span> matches:</span><br><span class="line">                    q_unit = item[<span class="string">&#x27;query_unit&#x27;</span>]</span><br><span class="line">                    m_unit = item[<span class="string">&#x27;match_unit&#x27;</span>]</span><br><span class="line">                    st.markdown(<span class="string">f&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">                    &lt;div style=&#x27;background-color:#f9f9f9; padding:10px; margin:10px 0; border-left: 5px solid #ff4b4b; border-radius: 5px;&#x27;&gt;</span></span><br><span class="line"><span class="string">                        &lt;b&gt;相似度: <span class="subst">&#123;item[<span class="string">&#x27;score&#x27;</span>]:<span class="number">.2</span>f&#125;</span>&lt;/b&gt;&lt;br&gt;</span></span><br><span class="line"><span class="string">                        &lt;p&gt;📄 &lt;b&gt;文档1 (<span class="subst">&#123;name1&#125;</span>) - 第 <span class="subst">&#123;q_unit[<span class="string">&#x27;page_num&#x27;</span>]&#125;</span> 页&lt;/b&gt;: <span class="subst">&#123;q_unit[<span class="string">&#x27;text&#x27;</span>]&#125;</span>&lt;/p&gt;</span></span><br><span class="line"><span class="string">                        &lt;p&gt;📄 &lt;b&gt;文档2 (<span class="subst">&#123;name2&#125;</span>) - 第 <span class="subst">&#123;m_unit[<span class="string">&#x27;page_num&#x27;</span>]&#125;</span> 页&lt;/b&gt;: <span class="subst">&#123;m_unit[<span class="string">&#x27;text&#x27;</span>]&#125;</span>&lt;/p&gt;</span></span><br><span class="line"><span class="string">                    &lt;/div&gt;</span></span><br><span class="line"><span class="string">                    &quot;&quot;&quot;</span>, unsafe_allow_html=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    st.warning(<span class="string">&quot;请至少上传两个 PDF 文件以开始查重。&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<img src="/2025/06/11/%E6%9F%A5%E9%87%8D%E7%B3%BB%E7%BB%9F%EF%BC%9A%E5%88%9D%E7%BA%A7pdf%E8%A7%A3%E6%9E%90%E5%8F%8A%E5%8F%A5%E5%AD%90%E9%87%8D%E7%BB%84/image-20250612143617893.png" class="" title="image-20250612143617893">

<img src="/2025/06/11/%E6%9F%A5%E9%87%8D%E7%B3%BB%E7%BB%9F%EF%BC%9A%E5%88%9D%E7%BA%A7pdf%E8%A7%A3%E6%9E%90%E5%8F%8A%E5%8F%A5%E5%AD%90%E9%87%8D%E7%BB%84/image-20250612143642844.png" class="" title="image-20250612143642844">

<img src="/2025/06/11/%E6%9F%A5%E9%87%8D%E7%B3%BB%E7%BB%9F%EF%BC%9A%E5%88%9D%E7%BA%A7pdf%E8%A7%A3%E6%9E%90%E5%8F%8A%E5%8F%A5%E5%AD%90%E9%87%8D%E7%BB%84/image-20250612143823944.png" class="" title="image-20250612143823944">

<img src="/2025/06/11/%E6%9F%A5%E9%87%8D%E7%B3%BB%E7%BB%9F%EF%BC%9A%E5%88%9D%E7%BA%A7pdf%E8%A7%A3%E6%9E%90%E5%8F%8A%E5%8F%A5%E5%AD%90%E9%87%8D%E7%BB%84/image-20250612143846379.png" class="" title="image-20250612143846379">

<img src="/2025/06/11/%E6%9F%A5%E9%87%8D%E7%B3%BB%E7%BB%9F%EF%BC%9A%E5%88%9D%E7%BA%A7pdf%E8%A7%A3%E6%9E%90%E5%8F%8A%E5%8F%A5%E5%AD%90%E9%87%8D%E7%BB%84/image-20250612143859110.png" class="" title="image-20250612143859110">

<hr>
<h3 id="完整系统代码解析"><a href="#完整系统代码解析" class="headerlink" title="完整系统代码解析"></a>完整系统代码解析</h3><h4 id="引入所需库"><a href="#引入所需库" class="headerlink" title="引入所需库"></a><strong>引入所需库</strong></h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> streamlit <span class="keyword">as</span> st</span><br><span class="line"><span class="keyword">import</span> pdfplumber</span><br><span class="line"><span class="keyword">import</span> io, itertools, torch, os</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">from</span> simhash <span class="keyword">import</span> Simhash</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> cosine_similarity</span><br><span class="line"><span class="keyword">from</span> sentence_transformers <span class="keyword">import</span> SentenceTransformer, util</span><br></pre></td></tr></table></figure>

<ul>
<li><code>streamlit</code>: 构建网页前端界面。</li>
<li><code>pdfplumber</code>: 读取 PDF 文件的表格和文字。</li>
<li><code>Simhash</code>: 文本相似度初筛。</li>
<li><code>TF-IDF</code>: 关键词相似度计算。</li>
<li><code>sentence_transformers</code>: 深度语义向量模型，用于高阶语义比对</li>
</ul>
<h4 id="Streamlit-页面配置"><a href="#Streamlit-页面配置" class="headerlink" title="Streamlit 页面配置"></a><strong>Streamlit 页面配置</strong></h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">st.set_page_config(page_title=<span class="string">&quot;多策略PDF查重工具&quot;</span>, layout=<span class="string">&quot;wide&quot;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>设置网页标题和布局宽度</li>
</ul>
<h4 id="模型加载"><a href="#模型加载" class="headerlink" title="模型加载"></a><strong>模型加载</strong></h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">@st.cache_resource</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_bert_model</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;加载并缓存为中文优化的 SentenceTransformer 模型。&quot;&quot;&quot;</span></span><br><span class="line">    device = <span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;深度学习模型正在使用 &#x27;<span class="subst">&#123;device&#125;</span>&#x27; 设备运行。&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> SentenceTransformer(<span class="string">&#x27;shibing624/text2vec-base-chinese&#x27;</span>, device=device)</span><br></pre></td></tr></table></figure>

<ul>
<li>加载适用于中文的 BERT 句向量模型（<code>text2vec-base-chinese</code>）。</li>
<li>使用 <code>Streamlit</code> 的缓存机制避免重复加载</li>
</ul>
<table>
<thead>
<tr>
<th>条件</th>
<th>不加缓存</th>
<th>加了 <code>@st.cache_resource</code></th>
</tr>
</thead>
<tbody><tr>
<td>模型加载</td>
<td>每次都重新加载</td>
<td>只加载一次，后续直接复用</td>
</tr>
<tr>
<td>性能</td>
<td>慢、浪费资源</td>
<td>快、节省计算资源</td>
</tr>
<tr>
<td>使用场景</td>
<td>临时实验</td>
<td>实际部署时强烈推荐加缓存</td>
</tr>
</tbody></table>
<h4 id="✅PDF文件单元提取："><a href="#✅PDF文件单元提取：" class="headerlink" title="✅PDF文件单元提取："></a>✅<strong>PDF文件单元提取：</strong></h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">extract_units_with_location</span>(<span class="params">pdf_file, file_name</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;从PDF文件中提取所有“查重单元”并附带其位置信息，包含健壮的bbox处理。&quot;&quot;&quot;</span></span><br><span class="line">    all_units = []</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(pdf_file) <span class="keyword">as</span> pdf:</span><br><span class="line">            <span class="keyword">for</span> page <span class="keyword">in</span> pdf.pages:</span><br><span class="line">                page_num = page.page_number</span><br><span class="line"></span><br><span class="line">                <span class="comment"># --- 提取表格单元 ---</span></span><br><span class="line">                found_tables = page.find_tables()</span><br><span class="line">                table_bboxes = [table.bbox <span class="keyword">for</span> table <span class="keyword">in</span> found_tables]</span><br><span class="line">                <span class="keyword">for</span> table_obj <span class="keyword">in</span> found_tables:</span><br><span class="line">                    table_data = table_obj.extract()</span><br><span class="line">                    <span class="keyword">if</span> <span class="keyword">not</span> table_data: <span class="keyword">continue</span></span><br><span class="line">                    <span class="keyword">for</span> row <span class="keyword">in</span> table_data:</span><br><span class="line">                        row_text = <span class="string">&quot;: &quot;</span>.join(</span><br><span class="line">                            <span class="built_in">filter</span>(<span class="literal">None</span>, [<span class="built_in">str</span>(cell).replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27; &#x27;</span>).strip() <span class="keyword">if</span> cell <span class="keyword">else</span> <span class="string">&#x27;&#x27;</span> <span class="keyword">for</span> cell <span class="keyword">in</span> row]))</span><br><span class="line">                        <span class="keyword">if</span> row_text:</span><br><span class="line">                            all_units.append(&#123;<span class="string">&quot;text&quot;</span>: row_text, <span class="string">&quot;page_num&quot;</span>: page_num, <span class="string">&quot;bbox&quot;</span>: table_obj.bbox&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># --- 提取非表格文本行 ---</span></span><br><span class="line">                page_without_tables = page</span><br><span class="line">                <span class="keyword">for</span> bbox <span class="keyword">in</span> table_bboxes:</span><br><span class="line">                    page_without_tables = page_without_tables.outside_bbox(bbox)</span><br><span class="line"></span><br><span class="line">                non_table_lines = page_without_tables.extract_text_lines(return_chars=<span class="literal">False</span>, strip=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># --- 关键修正点：增加防御性检查 ---</span></span><br><span class="line">                <span class="keyword">for</span> line <span class="keyword">in</span> non_table_lines:</span><br><span class="line">                    required_keys = [<span class="string">&#x27;x0&#x27;</span>, <span class="string">&#x27;top&#x27;</span>, <span class="string">&#x27;x1&#x27;</span>, <span class="string">&#x27;bottom&#x27;</span>, <span class="string">&#x27;text&#x27;</span>]</span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">all</span>(key <span class="keyword">in</span> line <span class="keyword">for</span> key <span class="keyword">in</span> required_keys) <span class="keyword">and</span> line[<span class="string">&#x27;text&#x27;</span>]:</span><br><span class="line">                        all_units.append(&#123;</span><br><span class="line">                            <span class="string">&quot;text&quot;</span>: line[<span class="string">&quot;text&quot;</span>],</span><br><span class="line">                            <span class="string">&quot;page_num&quot;</span>: page_num,</span><br><span class="line">                            <span class="string">&quot;bbox&quot;</span>: (line[<span class="string">&quot;x0&quot;</span>], line[<span class="string">&quot;top&quot;</span>], line[<span class="string">&quot;x1&quot;</span>], line[<span class="string">&quot;bottom&quot;</span>])</span><br><span class="line">                        &#125;)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> all_units</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        st.error(<span class="string">f&quot;解析PDF文件 &#x27;<span class="subst">&#123;file_name&#125;</span>&#x27; 时出错: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">import</span> traceback</span><br><span class="line">        st.code(traceback.format_exc())</span><br><span class="line">        <span class="keyword">return</span> []</span><br></pre></td></tr></table></figure>

<ul>
<li>从 <code>PDF</code> 文件中提取所有文本内容（包括表格和非表格部分），并标注其页码和位置信息（<code>bounding box</code>）</li>
<li><code>filter(...)</code>用于过滤所有空字符串</li>
<li>✅<code>outside_bbox()</code> 会返回<strong>去除了表格区域的页面副本对象</strong></li>
</ul>
<h4 id="查重逻辑模块"><a href="#查重逻辑模块" class="headerlink" title="查重逻辑模块"></a>查重逻辑模块</h4><h5 id="深度学习方法（BERT语义相似度）"><a href="#深度学习方法（BERT语义相似度）" class="headerlink" title="深度学习方法（BERT语义相似度）"></a>深度学习方法（BERT语义相似度）</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compare_documents_deep_learning</span>(<span class="params">units1, units2, min_char_length, similarity_threshold</span>):</span><br><span class="line">    bert_model = load_bert_model()</span><br><span class="line">    <span class="comment"># ...[此函数代码不变]...</span></span><br><span class="line">    filtered_units1 = [unit <span class="keyword">for</span> unit <span class="keyword">in</span> units1 <span class="keyword">if</span> <span class="built_in">len</span>(unit[<span class="string">&quot;text&quot;</span>]) &gt;= min_char_length]</span><br><span class="line">    filtered_units2 = [unit <span class="keyword">for</span> unit <span class="keyword">in</span> units2 <span class="keyword">if</span> <span class="built_in">len</span>(unit[<span class="string">&quot;text&quot;</span>]) &gt;= min_char_length]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> filtered_units1 <span class="keyword">or</span> <span class="keyword">not</span> filtered_units2: <span class="keyword">return</span> [], <span class="number">0.0</span></span><br><span class="line">    texts1 = [unit[<span class="string">&quot;text&quot;</span>] <span class="keyword">for</span> unit <span class="keyword">in</span> filtered_units1]</span><br><span class="line">    texts2 = [unit[<span class="string">&quot;text&quot;</span>] <span class="keyword">for</span> unit <span class="keyword">in</span> filtered_units2]</span><br><span class="line">    embeddings1 = bert_model.encode(texts1, convert_to_tensor=<span class="literal">True</span>, show_progress_bar=<span class="literal">False</span>)</span><br><span class="line">    embeddings2 = bert_model.encode(texts2, convert_to_tensor=<span class="literal">True</span>, show_progress_bar=<span class="literal">False</span>)</span><br><span class="line">    hits = util.semantic_search(embeddings1, embeddings2, top_k=<span class="number">1</span>, score_function=util.cos_sim)</span><br><span class="line">    matches = []</span><br><span class="line">    matched_indices_in_doc1 = <span class="built_in">set</span>()</span><br><span class="line">    <span class="keyword">for</span> i, hit_list <span class="keyword">in</span> <span class="built_in">enumerate</span>(hits):</span><br><span class="line">        <span class="keyword">if</span> hit_list <span class="keyword">and</span> hit_list[<span class="number">0</span>][<span class="string">&#x27;score&#x27;</span>] &gt; similarity_threshold:</span><br><span class="line">            best_hit = hit_list[<span class="number">0</span>]</span><br><span class="line">            query_unit = filtered_units1[i]</span><br><span class="line">            match_unit = filtered_units2[best_hit[<span class="string">&#x27;corpus_id&#x27;</span>]]</span><br><span class="line">            matches.append(&#123;<span class="string">&quot;query_unit&quot;</span>: query_unit, <span class="string">&quot;match_unit&quot;</span>: match_unit, <span class="string">&quot;score&quot;</span>: best_hit[<span class="string">&#x27;score&#x27;</span>]&#125;)</span><br><span class="line">            matched_indices_in_doc1.add(i)</span><br><span class="line">    repeat_rate = <span class="built_in">len</span>(matched_indices_in_doc1) / <span class="built_in">len</span>(filtered_units1) <span class="keyword">if</span> filtered_units1 <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    matches.sort(key=<span class="keyword">lambda</span> x: x[<span class="string">&#x27;score&#x27;</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> matches, repeat_rate</span><br></pre></td></tr></table></figure>

<ul>
<li><p>对提取到的文本单元进行过滤（长度大于设定值）</p>
</li>
<li><p>通过 Sentence-BERT 编码成向量</p>
</li>
<li><p>使用 <code>semantic_search</code> 计算每段文字之间的语义相似度（余弦）</p>
</li>
<li><p>提取相似度超过阈值的匹配项</p>
</li>
<li><p><code>hits</code> 是个列表：每一项是 <code>filtered_units1[i]</code> 匹配到的 <code>filtered_units2[j]</code> 及其得分</p>
</li>
<li><p><code>matched_indices_in_doc1</code>: 用来统计有多少句子被匹配，用于后续计算重复率</p>
</li>
<li><p><code>hit_list[0]</code> 是最相似的匹配</p>
</li>
<li><p>重复率定义为：<strong>被匹配的单元数 ÷ 总有效单元数</strong></p>
</li>
<li><p><code>matched_indices_in_doc1</code> 记录了多少句子被成功匹配</p>
</li>
<li><p>为方便前端展示或分析，将匹配结果按相似度从高到低排序。</p>
</li>
<li><p>示例返回值：</p>
<figure class="highlight tex"><table><tr><td class="code"><pre><span class="line">[</span><br><span class="line">  &#123;</span><br><span class="line">    &quot;query<span class="built_in">_</span>unit&quot;: &#123;&quot;text&quot;: &quot;作者：张三&quot;, &quot;page<span class="built_in">_</span>num&quot;: 1, &quot;bbox&quot;: (...)&#125;,</span><br><span class="line">    &quot;match<span class="built_in">_</span>unit&quot;: &#123;&quot;text&quot;: &quot;作者姓名是张三&quot;, &quot;page<span class="built_in">_</span>num&quot;: 2, &quot;bbox&quot;: (...)&#125;,</span><br><span class="line">    &quot;score&quot;: 0.921</span><br><span class="line">  &#125;,</span><br><span class="line">  ...</span><br><span class="line">], 0.64</span><br></pre></td></tr></table></figure></li>
</ul>
<h5 id="传统方法（SimHash-TF-IDF）"><a href="#传统方法（SimHash-TF-IDF）" class="headerlink" title="传统方法（SimHash + TF-IDF）"></a>传统方法（SimHash + TF-IDF）</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compare_documents_traditional</span>(<span class="params">units1, units2, min_char_length, simhash_threshold=<span class="number">0.9</span>, tfidf_threshold=<span class="number">0.5</span></span>):</span><br><span class="line">    <span class="comment"># ...[此函数代码不变]...</span></span><br><span class="line">    filtered_units1 = [unit <span class="keyword">for</span> unit <span class="keyword">in</span> units1 <span class="keyword">if</span> <span class="built_in">len</span>(unit[<span class="string">&quot;text&quot;</span>]) &gt;= min_char_length]</span><br><span class="line">    filtered_units2 = [unit <span class="keyword">for</span> unit <span class="keyword">in</span> units2 <span class="keyword">if</span> <span class="built_in">len</span>(unit[<span class="string">&quot;text&quot;</span>]) &gt;= min_char_length]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> filtered_units1 <span class="keyword">or</span> <span class="keyword">not</span> filtered_units2: <span class="keyword">return</span> [], <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> unit <span class="keyword">in</span> filtered_units1: unit[<span class="string">&#x27;simhash&#x27;</span>] = Simhash(unit[<span class="string">&#x27;text&#x27;</span>])</span><br><span class="line">    <span class="keyword">for</span> unit <span class="keyword">in</span> filtered_units2: unit[<span class="string">&#x27;simhash&#x27;</span>] = Simhash(unit[<span class="string">&#x27;text&#x27;</span>])</span><br><span class="line">    matches = []</span><br><span class="line">    matched_indices_in_doc1 = <span class="built_in">set</span>()</span><br><span class="line">    total_pairs = <span class="built_in">len</span>(filtered_units1)</span><br><span class="line">    progress_bar = st.progress(<span class="number">0</span>, text=<span class="string">&quot;正在使用传统方法比较...&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i, unit1 <span class="keyword">in</span> <span class="built_in">enumerate</span>(filtered_units1):</span><br><span class="line">        best_match_for_unit1 = <span class="literal">None</span></span><br><span class="line">        highest_score = -<span class="number">1.0</span></span><br><span class="line">        <span class="keyword">for</span> unit2 <span class="keyword">in</span> filtered_units2:</span><br><span class="line">            simhash_sim = <span class="number">1</span> - unit1[<span class="string">&#x27;simhash&#x27;</span>].distance(unit2[<span class="string">&#x27;simhash&#x27;</span>]) / <span class="number">64</span></span><br><span class="line">            <span class="keyword">if</span> simhash_sim &lt; simhash_threshold: <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                p1 = preprocess_text_for_traditional(unit1[<span class="string">&#x27;text&#x27;</span>])</span><br><span class="line">                p2 = preprocess_text_for_traditional(unit2[<span class="string">&#x27;text&#x27;</span>])</span><br><span class="line">                vectorizer = TfidfVectorizer()</span><br><span class="line">                tfidf_matrix = vectorizer.fit_transform([p1, p2])</span><br><span class="line">                tfidf_sim = cosine_similarity(tfidf_matrix[<span class="number">0</span>:<span class="number">1</span>], tfidf_matrix[<span class="number">1</span>:<span class="number">2</span>])[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">                <span class="keyword">if</span> tfidf_sim &gt; tfidf_threshold <span class="keyword">and</span> tfidf_sim &gt; highest_score:</span><br><span class="line">                    highest_score = tfidf_sim</span><br><span class="line">                    best_match_for_unit1 = unit2</span><br><span class="line">            <span class="keyword">except</span> ValueError:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">if</span> best_match_for_unit1:</span><br><span class="line">            matches.append(&#123;<span class="string">&quot;query_unit&quot;</span>: unit1, <span class="string">&quot;match_unit&quot;</span>: best_match_for_unit1, <span class="string">&quot;score&quot;</span>: highest_score&#125;)</span><br><span class="line">            matched_indices_in_doc1.add(i)</span><br><span class="line">        progress_bar.progress((i + <span class="number">1</span>) / total_pairs, text=<span class="string">f&quot;正在使用传统方法比较... (<span class="subst">&#123;i + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;total_pairs&#125;</span>)&quot;</span>)</span><br><span class="line">    repeat_rate = <span class="built_in">len</span>(matched_indices_in_doc1) / <span class="built_in">len</span>(filtered_units1) <span class="keyword">if</span> filtered_units1 <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    matches.sort(key=<span class="keyword">lambda</span> x: x[<span class="string">&#x27;score&#x27;</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> matches, repeat_rate</span><br></pre></td></tr></table></figure>

<ul>
<li>使用 <code>SimHash</code> 先快速筛除不相似的段落</li>
<li>对于疑似相似的，再使用 <code>TF-IDF + cosine_similarity</code> 精确比对</li>
<li>记录每对相似文本及其相似度分数</li>
</ul>
<h3 id="高亮匹配项生成图片"><a href="#高亮匹配项生成图片" class="headerlink" title="高亮匹配项生成图片"></a>高亮匹配项生成图片</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">highlight_and_save_page</span>(<span class="params">pdf_bytes, page_num, bbox, output_path, resolution=<span class="number">200</span></span>):</span><br><span class="line">    <span class="comment"># ...[此函数代码不变]...</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">with</span> pdfplumber.<span class="built_in">open</span>(io.BytesIO(pdf_bytes)) <span class="keyword">as</span> pdf:</span><br><span class="line">            page = pdf.pages[page_num - <span class="number">1</span>]</span><br><span class="line">            img = page.to_image(resolution=resolution)</span><br><span class="line">            img.draw_rect(bbox, fill=(<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">40</span>), stroke=<span class="string">&quot;red&quot;</span>, stroke_width=<span class="number">2</span>)</span><br><span class="line">            img.save(output_path, <span class="built_in">format</span>=<span class="string">&quot;PNG&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        st.error(<span class="string">f&quot;生成高亮图片时出错: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>

<ul>
<li>给指定页的指定区域画上红框，并保存为 <code>PNG</code> 图片</li>
<li>用于可视化展示匹配文本位置</li>
</ul>
<h3 id="网页前端与交互逻辑（Streamlit-页面）"><a href="#网页前端与交互逻辑（Streamlit-页面）" class="headerlink" title="网页前端与交互逻辑（Streamlit 页面）"></a>网页前端与交互逻辑（Streamlit 页面）</h3><h4 id="标题-侧边栏参数与文件上传"><a href="#标题-侧边栏参数与文件上传" class="headerlink" title="标题&#x2F;侧边栏参数与文件上传"></a>标题&#x2F;侧边栏参数与文件上传</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">st.title(<span class="string">&quot;📄 多策略 PDF 文件查重工具&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="string">&quot;highlighted_images&quot;</span>):</span><br><span class="line">    os.makedirs(<span class="string">&quot;highlighted_images&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> st.sidebar:</span><br><span class="line">    st.header(<span class="string">&quot;⚙️ 查重参数设置&quot;</span>)</span><br><span class="line">    method = st.radio(</span><br><span class="line">        <span class="string">&quot;选择查重方法:&quot;</span>,</span><br><span class="line">        (<span class="string">&#x27;深度学习方法 (精准语义)&#x27;</span>, <span class="string">&#x27;传统方法 (字面匹配)&#x27;</span>),</span><br><span class="line">        <span class="built_in">help</span>=<span class="string">&quot;深度学习能理解句子意思上的相似；传统方法更关注关键词和文本结构的相似。&quot;</span></span><br><span class="line">    )</span><br><span class="line">    min_chars = st.slider(<span class="string">&quot;1. 最小查重字数&quot;</span>, <span class="number">3</span>, <span class="number">50</span>, <span class="number">10</span>, <span class="built_in">help</span>=<span class="string">&quot;长度小于此值的文本片段将被忽略。&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="string">&#x27;深度学习&#x27;</span> <span class="keyword">in</span> method:</span><br><span class="line">        threshold = st.slider(<span class="string">&quot;2. 语义相似度阈值&quot;</span>, <span class="number">0.60</span>, <span class="number">1.0</span>, <span class="number">0.85</span>, <span class="number">0.05</span>,</span><br><span class="line">                              <span class="built_in">help</span>=<span class="string">&quot;推荐值: 0.85-0.95 (严格查重), 0.75-0.85 (查找相关内容)。分数越高，要求越严格。&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        st.subheader(<span class="string">&quot;2. 传统方法阈值&quot;</span>)</span><br><span class="line">        simhash_thresh = st.slider(<span class="string">&quot;SimHash 初筛阈值&quot;</span>, <span class="number">0.70</span>, <span class="number">1.0</span>, <span class="number">0.90</span>, <span class="number">0.05</span>,</span><br><span class="line">                                   <span class="built_in">help</span>=<span class="string">&quot;用于快速排除差异大的文本。推荐值0.90左右，容忍少量文字改动。&quot;</span>)</span><br><span class="line">        tfidf_thresh = st.slider(<span class="string">&quot;TF-IDF 精筛阈值&quot;</span>, <span class="number">0.30</span>, <span class="number">1.0</span>, <span class="number">0.60</span>, <span class="number">0.05</span>,</span><br><span class="line">                                 <span class="built_in">help</span>=<span class="string">&quot;基于关键词匹配。推荐值0.5-0.7，分数过高可能只匹配到几乎一样的句子。&quot;</span>)</span><br><span class="line"></span><br><span class="line">uploaded_files = st.file_uploader(<span class="string">&quot;请上传多个 PDF 文件（至少两个）&quot;</span>, <span class="built_in">type</span>=<span class="string">&quot;pdf&quot;</span>, accept_multiple_files=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>支持参数包括：</p>
<ul>
<li>查重方式（传统 &#x2F; 深度）</li>
<li>最小查重字符数</li>
<li>各种阈值（相似度要求）</li>
</ul>
<p>用户可上传多个 PDF（至少2个）</p>
<h4 id="文件处理-对比逻辑与结果展示"><a href="#文件处理-对比逻辑与结果展示" class="headerlink" title="文件处理&#x2F;对比逻辑与结果展示"></a>文件处理&#x2F;对比逻辑与结果展示</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> uploaded_files <span class="keyword">and</span> <span class="built_in">len</span>(uploaded_files) &gt;= <span class="number">2</span>:</span><br><span class="line">    docs_data = &#123;f.name: f.getvalue() <span class="keyword">for</span> f <span class="keyword">in</span> uploaded_files&#125;</span><br><span class="line">    docs_units = &#123;&#125;</span><br><span class="line">    <span class="keyword">with</span> st.spinner(<span class="string">&quot;正在解析所有PDF文件...&quot;</span>):</span><br><span class="line">        <span class="keyword">for</span> name, content <span class="keyword">in</span> docs_data.items():</span><br><span class="line">            docs_units[name] = extract_units_with_location(io.BytesIO(content), name)</span><br><span class="line">    st.success(<span class="string">&quot;所有文件解析完成！&quot;</span>)</span><br><span class="line"></span><br><span class="line">    doc_pairs = <span class="built_in">list</span>(itertools.combinations(docs_units.items(), <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> pair_idx, ((name1, units1), (name2, units2)) <span class="keyword">in</span> <span class="built_in">enumerate</span>(doc_pairs):</span><br><span class="line">        st.markdown(<span class="string">&quot;---&quot;</span>)</span><br><span class="line">        <span class="keyword">with</span> st.expander(<span class="string">f&quot;📊 对比结果：`<span class="subst">&#123;name1&#125;</span>` ⟷ `<span class="subst">&#123;name2&#125;</span>`&quot;</span>, expanded=<span class="literal">True</span>):</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 算法分流</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;深度学习&#x27;</span> <span class="keyword">in</span> method:</span><br><span class="line">                st.info(<span class="string">&quot;当前使用: 深度学习方法&quot;</span>)</span><br><span class="line">                matches, repeat_rate = compare_documents_deep_learning(units1, units2, min_chars, threshold)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                st.info(<span class="string">&quot;当前使用: 传统方法 (SimHash + TF-IDF)&quot;</span>)</span><br><span class="line">                matches, repeat_rate = compare_documents_traditional(units1, units2, min_chars, simhash_thresh,</span><br><span class="line">                                                                     tfidf_thresh)</span><br><span class="line"></span><br><span class="line">            st.metric(label=<span class="string">f&quot;重复率 (基于`<span class="subst">&#123;name1&#125;</span>`)&quot;</span>, value=<span class="string">f&quot;<span class="subst">&#123;repeat_rate * <span class="number">100</span>:<span class="number">.1</span>f&#125;</span>%&quot;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> matches:</span><br><span class="line">                st.info(<span class="string">&quot;✅ 未检测到满足条件的重复内容。&quot;</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 结果展示</span></span><br><span class="line">                st.write(<span class="string">f&quot;发现 <span class="subst">&#123;<span class="built_in">len</span>(matches)&#125;</span> 处相似内容 (按相似度排序):&quot;</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 高亮显示第一个</span></span><br><span class="line">                st.subheader(<span class="string">&quot;最高相似度匹配项可视化&quot;</span>)</span><br><span class="line">                first_match = matches[<span class="number">0</span>]</span><br><span class="line">                q1_unit = first_match[<span class="string">&#x27;query_unit&#x27;</span>]</span><br><span class="line">                m2_unit = first_match[<span class="string">&#x27;match_unit&#x27;</span>]</span><br><span class="line">                img1_path = <span class="string">f&quot;highlighted_images/doc1_<span class="subst">&#123;pair_idx&#125;</span>.png&quot;</span></span><br><span class="line">                img2_path = <span class="string">f&quot;highlighted_images/doc2_<span class="subst">&#123;pair_idx&#125;</span>.png&quot;</span></span><br><span class="line">                success1 = highlight_and_save_page(docs_data[name1], q1_unit[<span class="string">&#x27;page_num&#x27;</span>], q1_unit[<span class="string">&#x27;bbox&#x27;</span>], img1_path)</span><br><span class="line">                success2 = highlight_and_save_page(docs_data[name2], m2_unit[<span class="string">&#x27;page_num&#x27;</span>], m2_unit[<span class="string">&#x27;bbox&#x27;</span>], img2_path)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> success1 <span class="keyword">and</span> success2:</span><br><span class="line">                    col1, col2 = st.columns(<span class="number">2</span>)</span><br><span class="line">                    <span class="keyword">with</span> col1:</span><br><span class="line">                        st.info(<span class="string">f&quot;文档: `<span class="subst">&#123;name1&#125;</span>` - 第 <span class="subst">&#123;q1_unit[<span class="string">&#x27;page_num&#x27;</span>]&#125;</span> 页&quot;</span>)</span><br><span class="line">                        st.image(img1_path, use_column_width=<span class="literal">True</span>)</span><br><span class="line">                        <span class="keyword">with</span> <span class="built_in">open</span>(img1_path, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">                            st.download_button(<span class="string">&quot;下载高亮图片&quot;</span>, file.read(),</span><br><span class="line">                                               file_name=<span class="string">f&quot;<span class="subst">&#123;os.path.basename(name1)&#125;</span>_p<span class="subst">&#123;q1_unit[<span class="string">&#x27;page_num&#x27;</span>]&#125;</span>.png&quot;</span>,</span><br><span class="line">                                               key=<span class="string">f&quot;dl1_<span class="subst">&#123;pair_idx&#125;</span>&quot;</span>)</span><br><span class="line">                    <span class="keyword">with</span> col2:</span><br><span class="line">                        st.info(<span class="string">f&quot;文档: `<span class="subst">&#123;name2&#125;</span>` - 第 <span class="subst">&#123;m2_unit[<span class="string">&#x27;page_num&#x27;</span>]&#125;</span> 页&quot;</span>)</span><br><span class="line">                        st.image(img2_path, use_column_width=<span class="literal">True</span>)</span><br><span class="line">                        <span class="keyword">with</span> <span class="built_in">open</span>(img2_path, <span class="string">&quot;rb&quot;</span>) <span class="keyword">as</span> file:</span><br><span class="line">                            st.download_button(<span class="string">&quot;下载高亮图片&quot;</span>, file.read(),</span><br><span class="line">                                               file_name=<span class="string">f&quot;<span class="subst">&#123;os.path.basename(name2)&#125;</span>_p<span class="subst">&#123;m2_unit[<span class="string">&#x27;page_num&#x27;</span>]&#125;</span>.png&quot;</span>,</span><br><span class="line">                                               key=<span class="string">f&quot;dl2_<span class="subst">&#123;pair_idx&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 显示所有匹配项</span></span><br><span class="line">                st.subheader(<span class="string">&quot;所有相似项列表&quot;</span>)</span><br><span class="line">                <span class="keyword">for</span> item <span class="keyword">in</span> matches:</span><br><span class="line">                    q_unit = item[<span class="string">&#x27;query_unit&#x27;</span>]</span><br><span class="line">                    m_unit = item[<span class="string">&#x27;match_unit&#x27;</span>]</span><br><span class="line">                    st.markdown(<span class="string">f&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">                    &lt;div style=&#x27;background-color:#f9f9f9; padding:10px; margin:10px 0; border-left: 5px solid #ff4b4b; border-radius: 5px;&#x27;&gt;</span></span><br><span class="line"><span class="string">                        &lt;b&gt;相似度: <span class="subst">&#123;item[<span class="string">&#x27;score&#x27;</span>]:<span class="number">.2</span>f&#125;</span>&lt;/b&gt;&lt;br&gt;</span></span><br><span class="line"><span class="string">                        &lt;p&gt;📄 &lt;b&gt;文档1 (<span class="subst">&#123;name1&#125;</span>) - 第 <span class="subst">&#123;q_unit[<span class="string">&#x27;page_num&#x27;</span>]&#125;</span> 页&lt;/b&gt;: <span class="subst">&#123;q_unit[<span class="string">&#x27;text&#x27;</span>]&#125;</span>&lt;/p&gt;</span></span><br><span class="line"><span class="string">                        &lt;p&gt;📄 &lt;b&gt;文档2 (<span class="subst">&#123;name2&#125;</span>) - 第 <span class="subst">&#123;m_unit[<span class="string">&#x27;page_num&#x27;</span>]&#125;</span> 页&lt;/b&gt;: <span class="subst">&#123;m_unit[<span class="string">&#x27;text&#x27;</span>]&#125;</span>&lt;/p&gt;</span></span><br><span class="line"><span class="string">                    &lt;/div&gt;</span></span><br><span class="line"><span class="string">                    &quot;&quot;&quot;</span>, unsafe_allow_html=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>从文件加载到查重再到结果展示的主函数</li>
</ul>
<hr>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://caihaoran-00.github.io/2025/06/11/%E6%9F%A5%E9%87%8D%E7%B3%BB%E7%BB%9F%EF%BC%9A%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E9%83%A8%E7%BD%B2%E6%9F%A5%E9%87%8D%E7%B3%BB%E7%BB%9F%E7%AE%80%E5%8D%95demo/">https://caihaoran-00.github.io/2025/06/11/%E6%9F%A5%E9%87%8D%E7%B3%BB%E7%BB%9F%EF%BC%9A%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E9%83%A8%E7%BD%B2%E6%9F%A5%E9%87%8D%E7%B3%BB%E7%BB%9F%E7%AE%80%E5%8D%95demo/</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>pdfplumber</tag>
        <tag>查重</tag>
      </tags>
  </entry>
  <entry>
    <title>解决方案调研：招标智能体</title>
    <url>/2025/04/28/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B0%83%E7%A0%94%EF%BC%9A%E6%8B%9B%E6%A0%87%E6%99%BA%E8%83%BD%E4%BD%93/</url>
    <content><![CDATA[<h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><ol>
<li><p>网页自动爬虫智能体：从各大公共交易平台提取项目招标网页数据和下载各类招标信息附件；</p>
</li>
<li><p>数据提取智能体模型：下载下来的各类招标信息附件(PDF、word、excel、图片等)进行文件解析并按关键词把非结构化数据转换成结构化数据，经清洗校验后存入公司数据库，如：项目编号、项目名称、工程概况、招标概况、开标日期、开标地点、招标控制价等；</p>
</li>
<li><p>投标报价预测智能体模型:利用历史招标数据对类拟项目进行模拟推算，预测投标报价中标概率；</p>
</li>
</ol>
<span id="more"></span>

<hr>
<h2 id="需求分析与大致方案"><a href="#需求分析与大致方案" class="headerlink" title="需求分析与大致方案"></a>需求分析与大致方案</h2><p>这是个非常典型但也很有挑战的 <strong>三阶段智能体系统</strong>，分别是 <strong>数据抓取 → 数据加工 → 数据建模与推理</strong>。</p>
<h3 id="总体架构"><a href="#总体架构" class="headerlink" title="总体架构"></a>总体架构</h3><p>三个智能体模块将以模块化方式设计，彼此独立但通过数据流和接口协作。整体流程如下：</p>
<ol>
<li><strong>网页自动爬虫智能体</strong>：从公共交易平台抓取招标网页数据和附件，存储原始数据；</li>
<li><strong>数据提取智能体</strong>：解析附件，提取关键字段，清洗并结构化后存入数据库；</li>
<li><strong>投标报价预测智能体</strong>：基于历史数据和提取的结构化数据，训练预测模型，输出中标概率。</li>
</ol>
<hr>
<h3 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h3><p>以客户提供的《浙江省房屋建筑和市政基础设施施工招标文件示范文本（适用于杭州市资格后审项目）（2023版）》以及《半山单元高中（暂名）施工项目招标文件》的相关页面内容为例，梳理一下投标、开标、评标的流程：</p>
<p><strong>一、 投标流程 (Bidding&#x2F;Tendering Process - 投标人视角)</strong></p>
<p>这是潜在投标人参与项目竞争的过程，主要步骤如下：</p>
<ol>
<li><strong>获取招标文件：</strong><ul>
<li>潜在投标人需要在规定的时间内（本项目未明确截止获取时间，但通常在招标公告中说明），通过指定的平台，即<strong>杭州建设工程招标造价平台 (<a href="https://www.google.com/url?sa=E&q=https://ztb.cxjw.hangzhou.gov.cn:8092">https://ztb.cxjw.hangzhou.gov.cn:8092</a>)</strong> 和 <strong>杭州市公共资源交易平台 (<a href="https://www.google.com/url?sa=E&q=http://hzctc.hangzhou.gov.cn">http://hzctc.hangzhou.gov.cn</a>)</strong> 获取招标文件及相关资料（如图纸、清单、招标控制价明细等）。（Page 4, 2.2.1）</li>
</ul>
</li>
<li><strong>研究招标文件并提疑：</strong><ul>
<li>投标人仔细阅读招标文件，理解项目要求、资格条件、技术规范、合同条款、评标办法等。</li>
<li>如有疑问，必须在<strong>2025年02月23日</strong>前，通过<strong>杭州建设工程招标造价平台</strong>以实名形式在线提交澄清要求（提疑）。逾期提交，招标人可拒绝受理。（Page 4）</li>
</ul>
</li>
<li><strong>获取招标文件的澄清与修改：</strong><ul>
<li>招标人会在<strong>2025年02月26日17:00前</strong>，通过上述两个平台发布招标文件的澄清、答疑或修改文件（招标补充文件）。</li>
<li>投标人有责任自行关注并下载这些文件，招标人不再单独通知。因投标人自身贻误导致投标失败，责任自负。（Page 4, 2.2.1）</li>
</ul>
</li>
<li><strong>编制投标文件：</strong><ul>
<li>投标人根据招标文件及其所有补充文件的要求，使用指定的电子投标文件制作工具（V3.2.0版本）编制电子投标文件，生成后缀名为“.HzTbs”的文件。（Page 7, 3.7.3(2)）</li>
<li>投标文件主要包含四个部分：<strong>资格审查材料、资信标、技术标、商务标</strong>。（Page 7, 3.7.3(2)）</li>
<li><strong>特别注意：</strong> 本项目的<strong>技术标采用暗标</strong>评审，投标人在制作技术标暗标文件时，不得出现任何能直接或间接识别投标人身份的信息（如公司名称、人员姓名、特定logo等）。（Page 5, 3.1.2; Page 7, 3.7.3(2) point 3）技术标文件宜控制在300页以内。（Page 5, 3.1.2）</li>
<li>需要按要求填写业绩汇总表等特定格式文件。（Page 7, 3.7.3(3)）</li>
<li>按照要求进行电子签章（CA数字证书加盖单位和法定代表人电子印章）。（Page 6, 3.7.3(1)）</li>
</ul>
</li>
<li><strong>缴纳投标保证金：</strong><ul>
<li>在投标截止时间前，按要求足额缴纳<strong>人民币50万元</strong>的投标保证金。（Page 5, 3.4.1）</li>
<li>缴纳方式可以是银行保函、保证保险、担保公司担保、转账或数字保函。采用转账方式的，必须从投标人基本账户转出，并通过杭州银行“杭银在线”系统与本项目关联确认。（Page 5-6）</li>
</ul>
</li>
<li><strong>递交投标文件：</strong><ul>
<li>在**投标截止时间（2025年03月06日 14:00:00）*<em>前，使用专用密钥（CA锁）将加密的电子投标文件（.HzTbs文件）上传至*<em>杭州市公共资源交易平台</em></em>。（Page 7, 4.1.1, 4.2.1, 4.2.2）</li>
<li>逾期上传、未按要求加密或无法解密的投标文件将被拒收。（Page 8, 4.2.5）</li>
</ul>
</li>
</ol>
<p><strong>二、 开标流程 (Bid Opening Process)</strong></p>
<p>开标是在投标截止时间的同一时间公开进行的过程，主要步骤如下：</p>
<ol>
<li><strong>时间和地点：</strong><ul>
<li>开标时间：<strong>2025年03月06日 14:00:00</strong>。（Page 7, 4.2.1）</li>
<li>开标地点：<strong>杭州市公共资源交易中心第8开标室</strong>（临江金座2号楼）。（Page 8, 5.1）</li>
<li>开标平台：<strong>杭州市公共资源交易平台</strong>。（Page 8, 5.1）</li>
</ul>
</li>
<li><strong>解密：</strong><ul>
<li>开标时，招标人代表使用招标CA数字证书对投标人上传的加密电子投标文件进行解密。（Page 8, 5.2(一)）</li>
<li>投标人也需要在此环节使用自己的CA锁远程解密，或按要求到现场解密（具体操作看平台指引）。</li>
</ul>
</li>
<li><strong>信息公开（唱标）：</strong><ul>
<li>投标文件成功解密并导入评标系统后，投标单位名称、项目负责人、投标报价、工期等主要信息将在电子交易平台公开显示。（Page 8, 5.2(二)）</li>
<li>系统会采用投标函信息作为签到信息，标录显示问题仅作提醒，不影响资格审查或否决投标。（Page 8, 5.2(二)）</li>
</ul>
</li>
<li><strong>现场随机抽取（确定评标参数）：</strong><ul>
<li>在开标会现场，招标人会随机抽取评标过程中需要用到的一些参数，包括但不限于：（Page 8-9）<ul>
<li>综合单价评审项目（10项）</li>
<li>综合单价评审合理区间K值（本项目为15%）</li>
<li>价格入围方式（本项目采用技术标打分法，开标时可能抽取价格分区方式及高低区间系数KH, KL）</li>
<li>技术标打分法下的最佳报价下浮系数（在1%-3%之间抽取，5个选项）</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><strong>注意：开标环节不进行评分，只公开基本信息和确定后续评标所需的部分参数。</strong></p>
<p><strong>三、 评标流程 (Bid Evaluation Process)</strong></p>
<p>开标后，由依法组建的评标委员会对投标文件进行评审，最终确定中标候选人。主要步骤如下：</p>
<ol>
<li><strong>组建评标委员会：</strong><ul>
<li>由招标人依法组建，成员为5人及以上单数，包括技术、经济等方面的专家，招标人代表按规定比例参与，专家需随机抽取。（Page 9, 6.1.1）</li>
</ul>
</li>
<li><strong>确定评审区间（若投标人&gt;15家）：</strong><ul>
<li>按Page 22-24所述的信用择优、招标人推荐、价格入围相结合的方式，确定15家投标人进入详细评审。</li>
</ul>
</li>
<li><strong>资格审查：</strong><ul>
<li>评标委员会首先对进入评审区间的投标人进行资格审查，核对是否满足招标文件（包括招标公告和投标人须知前附表1.4.1、10.1等）规定的所有资格条件。（Page 11-12, Page 24）</li>
<li>审查内容非常细致，包括资质、人员、业绩、信誉、投标保证金、动态核查、有无违法限制投标等情况。任何一项不满足都可能导致否决投标。（Page 11-12）</li>
<li>若因资格审查导致有效投标人不足15家，会按规则进行递补。（Page 24）</li>
</ul>
</li>
<li><strong>详细评审（技术标打分制综合评估法）：</strong><ul>
<li><strong>计算最佳报价：</strong> 对通过资格审查的有效投标人的报价进行算术平均，再下浮一个开标时随机抽取的百分比（1%-3%之间），得到最佳报价。（Page 24）</li>
<li><strong>技术标评审（暗标，30分）：</strong> 专家对技术标的暗标部分进行打分，评审因素包括总体部署、主要施工方案、质量&#x2F;安全&#x2F;工期&#x2F;环保措施、重点难点分析、新技术应用等。（Page 25）可能还包括对项目负责人的陈述和答辩环节进行评分（需招标文件明确，Page 26）。</li>
<li><strong>资信标评审（10分）：</strong> 根据企业类似业绩、项目负责人类似业绩、企业信用等级、项目负责人和班子成员能力（如职称、证书、年龄）等进行评分。（Page 26-29）</li>
<li><strong>商务标评审（60分）：</strong><ul>
<li>投标报价得分（56分）：根据投标报价与最佳报价的偏离程度，按规定公式计算得分。（Page 29）</li>
<li>工程量清单符合性评审（4分）：对随机抽取的综合单价进行评审，看其是否落在合理区间（基准价的±K%）内，超出区间的扣分。（Page 30）</li>
</ul>
</li>
<li><strong>初步评审（符合性检查）：</strong> 除了资格审查，还包括对投标文件的格式、签字盖章、投标函填写、是否响应实质性要求（如工期、质量标准）等的检查。（Page 13）</li>
</ul>
</li>
<li><strong>汇总得分与排名：</strong><ul>
<li>将技术标、资信标、商务标得分相加，得到总得分。</li>
<li>按总得分由高到低进行排序。若总分相同，依次按投标报价低者优先、资信标得分高者优先、技术标得分高者优先的原则排序；若仍相同，则抽签决定。（Page 30）</li>
</ul>
</li>
<li><strong>推荐中标候选人：</strong><ul>
<li>评标委员会根据排序结果，推荐排名第一的投标人为中标候选人（本项目推荐1名）。（Page 9, 6.3.2）</li>
</ul>
</li>
<li><strong>定标前核查：</strong><ul>
<li>招标人在确定中标人前，会对中标候选人及其项目负责人进行核查，包括安全生产许可证、资质动态核查、失信记录、行贿犯罪记录等。（Page 15）</li>
</ul>
</li>
<li><strong>确定中标人：</strong><ul>
<li>核查通过后，招标人依法确定中标候选人为中标人。（Page 9, 7.2.1）</li>
</ul>
</li>
<li><strong>公示与通知：</strong><ul>
<li>中标候选人（会公示得分情况）和中标结果会在指定平台进行公示。（Page 9-10）</li>
</ul>
</li>
</ol>
<hr>
<h3 id="核心实现方案"><a href="#核心实现方案" class="headerlink" title="核心实现方案"></a>核心实现方案</h3><p>本文前面的部分之前就写了，好久没继续往下写了，原因是客户要求拿实际的东西展示，而不是只展示方案，所以这段时间做了些demo，</p>
<p>对于智能体1：自动化爬虫，我们使用selenium+chromedriver；</p>
<p>对于智能体2：目前是使用的pdfplumber进行pdf的解析，然后将其内容一把梭哈给LLM，写好系统提示词，让LLM提取结构化的数据；（发现Deepseek-R1比qwen-long、qwen2.5-14b-1M好用，准确率高）</p>
<blockquote>
<p>也发现了一些问题，这些文件有部分是共性，部分是特性，想通过提示词解决特性不太行，目前准备只使用LLM提取共性，使用RAG来解决特性（自动化的一个一个问题问）。</p>
</blockquote>
<p>对于智能体3，目前了解到的客户在这一步想：</p>
<ul>
<li>预测将要参与本项目投标的竞争对手</li>
<li>预测竞争对手报价</li>
<li>预测本公司的最佳报价</li>
<li>这一步的建模要有可解释性，即报价是怎么得出的，而且如果预测错了，要能反推出来为什么出错了，怎么改正就对了（看样子客户是想建模成简单的算式？这样就可以很强的解释性了，我认为这种场景还是使用XGBOOST这种）</li>
</ul>
<p>由于目前不打算花大精力去获取真实数据，故使用随机数通过基本科学的算式来生成预测报价，代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">import</span> shap</span><br><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error, r2_score</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置常量</span></span><br><span class="line">MODEL_DIR = <span class="string">&quot;saved_models&quot;</span></span><br><span class="line">MODEL_NAME = <span class="string">&quot;bid_price_predictor.joblib&quot;</span></span><br><span class="line">FEATURE_COLS_NAME = <span class="string">&quot;feature_columns.joblib&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">print_time</span>(<span class="params">start_time, stage_name</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Print stage timing&quot;&quot;&quot;</span></span><br><span class="line">    elapsed = (time.time() - start_time) * <span class="number">1000</span>  <span class="comment"># Convert to milliseconds</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;[TIMING] <span class="subst">&#123;stage_name.ljust(<span class="number">15</span>)&#125;</span>: <span class="subst">&#123;elapsed:<span class="number">.2</span>f&#125;</span> ms&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ensure_dir_exists</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;确保模型目录存在&quot;&quot;&quot;</span></span><br><span class="line">    os.makedirs(MODEL_DIR, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_data</span>(<span class="params">n_samples=<span class="number">1000</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;生成模拟数据&quot;&quot;&quot;</span></span><br><span class="line">    start = time.time()</span><br><span class="line">    rng = np.random.default_rng(seed=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">&#x27;max_price&#x27;</span>: rng.uniform(<span class="number">1e1</span>, <span class="number">5e3</span>, n_samples),</span><br><span class="line">        <span class="string">&#x27;project_type&#x27;</span>: rng.choice([<span class="string">&#x27;Construction&#x27;</span>, <span class="string">&#x27;Municipal&#x27;</span>, <span class="string">&#x27;Power&#x27;</span>, <span class="string">&#x27;Transport&#x27;</span>], n_samples),  <span class="comment"># Construction：建筑工程，Municipal：市政工程，Power：电力工程，Transport：交通工程</span></span><br><span class="line">        <span class="string">&#x27;duration&#x27;</span>: rng.integers(<span class="number">30</span>, <span class="number">365</span>, n_samples),</span><br><span class="line">        <span class="string">&#x27;material_cost_idx&#x27;</span>: rng.normal(<span class="number">1.0</span>, <span class="number">0.1</span>, n_samples),</span><br><span class="line">        <span class="string">&#x27;competitors&#x27;</span>: rng.integers(<span class="number">3</span>, <span class="number">15</span>, n_samples)</span><br><span class="line">    &#125;</span><br><span class="line">    df = pd.DataFrame(data)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用 rng 生成噪声（确保完全确定性）</span></span><br><span class="line">    noise = rng.normal(<span class="number">0</span>, df[<span class="string">&#x27;max_price&#x27;</span>] * <span class="number">0.01</span>)</span><br><span class="line">    df[<span class="string">&#x27;bid_price&#x27;</span>] = (</span><br><span class="line">            df[<span class="string">&#x27;max_price&#x27;</span>] * <span class="number">0.80</span></span><br><span class="line">            + df[<span class="string">&#x27;duration&#x27;</span>]</span><br><span class="line">            + (df[<span class="string">&#x27;project_type&#x27;</span>] == <span class="string">&#x27;Municipal&#x27;</span>) * df[<span class="string">&#x27;max_price&#x27;</span>] * <span class="number">0.02</span></span><br><span class="line">            - (df[<span class="string">&#x27;competitors&#x27;</span>] &gt; <span class="number">10</span>) * df[<span class="string">&#x27;max_price&#x27;</span>] * <span class="number">0.03</span></span><br><span class="line">            + noise</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    print_time(start, <span class="string">&quot;Data Generation&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> df</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_and_save_model</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;训练模型并保存&quot;&quot;&quot;</span></span><br><span class="line">    total_start = time.time()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n=== Training New Model ===&quot;</span>)</span><br><span class="line">    start = time.time()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 生成数据</span></span><br><span class="line">    df = generate_data()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预处理</span></span><br><span class="line">    preprocess_start = time.time()</span><br><span class="line">    df = pd.get_dummies(df, columns=[<span class="string">&#x27;project_type&#x27;</span>], drop_first=<span class="literal">True</span>)</span><br><span class="line">    X = df.drop(<span class="string">&#x27;bid_price&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">    y = df[<span class="string">&#x27;bid_price&#x27;</span>]</span><br><span class="line">    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line">    print_time(preprocess_start, <span class="string">&quot;Data Preprocessing&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练模型</span></span><br><span class="line">    train_start = time.time()</span><br><span class="line">    model = xgb.XGBRegressor(</span><br><span class="line">        n_estimators=<span class="number">150</span>,</span><br><span class="line">        max_depth=<span class="number">6</span>,</span><br><span class="line">        learning_rate=<span class="number">0.1</span>,</span><br><span class="line">        random_state=<span class="number">42</span></span><br><span class="line">    )</span><br><span class="line">    model.fit(X_train, y_train)</span><br><span class="line">    print_time(train_start, <span class="string">&quot;Model Training&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 评估</span></span><br><span class="line">    eval_start = time.time()</span><br><span class="line">    preds = model.predict(X_test)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;MAE: <span class="subst">&#123;mean_absolute_error(y_test, preds):,<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;R²: <span class="subst">&#123;r2_score(y_test, preds):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    print_time(eval_start, <span class="string">&quot;Model Evaluation&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存模型和特征列</span></span><br><span class="line">    save_start = time.time()</span><br><span class="line">    joblib.dump(model, Path(MODEL_DIR) / MODEL_NAME)</span><br><span class="line">    joblib.dump(X_train.columns.tolist(), Path(MODEL_DIR) / FEATURE_COLS_NAME)</span><br><span class="line">    print_time(save_start, <span class="string">&quot;Model Saving&quot;</span>)</span><br><span class="line"></span><br><span class="line">    print_time(total_start, <span class="string">&quot;Total Training Time&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> model, X_train.columns.tolist()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_model</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;加载已保存的模型&quot;&quot;&quot;</span></span><br><span class="line">    start = time.time()</span><br><span class="line">    model_path = Path(MODEL_DIR) / MODEL_NAME</span><br><span class="line">    feature_path = Path(MODEL_DIR) / FEATURE_COLS_NAME</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> model_path.exists() <span class="keyword">or</span> <span class="keyword">not</span> feature_path.exists():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;No saved model found. Training new model...&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> train_and_save_model()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n=== Loading Saved Model ===&quot;</span>)</span><br><span class="line">    model = joblib.load(model_path)</span><br><span class="line">    feature_columns = joblib.load(feature_path)</span><br><span class="line">    print_time(start, <span class="string">&quot;Model Loaded&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> model, feature_columns</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict_bid_price</span>(<span class="params"></span></span><br><span class="line"><span class="params">        max_price: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">        project_type: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">        duration: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        material_cost_idx: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">        competitors: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">        model: xgb.XGBRegressor,</span></span><br><span class="line"><span class="params">        feature_columns: <span class="built_in">list</span></span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;使用模型预测价格&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 构造输入数据</span></span><br><span class="line">    predict_start = time.time()</span><br><span class="line">    input_data = pd.DataFrame(&#123;</span><br><span class="line">        <span class="string">&#x27;max_price&#x27;</span>: [max_price],</span><br><span class="line">        <span class="string">&#x27;project_type&#x27;</span>: [project_type],</span><br><span class="line">        <span class="string">&#x27;duration&#x27;</span>: [duration],</span><br><span class="line">        <span class="string">&#x27;material_cost_idx&#x27;</span>: [material_cost_idx],</span><br><span class="line">        <span class="string">&#x27;competitors&#x27;</span>: [competitors]</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预处理（与训练时一致）</span></span><br><span class="line">    input_data = pd.get_dummies(input_data, columns=[<span class="string">&#x27;project_type&#x27;</span>], drop_first=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对齐特征列</span></span><br><span class="line">    missing_cols = <span class="built_in">set</span>(feature_columns) - <span class="built_in">set</span>(input_data.columns)</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> missing_cols:</span><br><span class="line">        input_data[col] = <span class="number">0</span></span><br><span class="line">    input_data = input_data[feature_columns]</span><br><span class="line"></span><br><span class="line">    result = <span class="built_in">float</span>(model.predict(input_data)[<span class="number">0</span>])</span><br><span class="line">    print_time(predict_start, <span class="string">&quot;Prediction Execution&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">retrain_flag: <span class="built_in">bool</span> = <span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;主流程&quot;&quot;&quot;</span></span><br><span class="line">    total_start = time.time()</span><br><span class="line">    ensure_dir_exists()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 步骤1：训练或加载模型</span></span><br><span class="line">    <span class="keyword">if</span> retrain_flag:</span><br><span class="line">        model, feature_columns = train_and_save_model()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        model, feature_columns = load_model()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 步骤2：测试预测</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n=== Prediction Test ===&quot;</span>)</span><br><span class="line">    test_case = &#123;</span><br><span class="line">        <span class="string">&#x27;max_price&#x27;</span>: <span class="number">2500.0</span>,</span><br><span class="line">        <span class="string">&#x27;project_type&#x27;</span>: <span class="string">&#x27;Municipal&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;duration&#x27;</span>: <span class="number">180</span>,</span><br><span class="line">        <span class="string">&#x27;material_cost_idx&#x27;</span>: <span class="number">1.05</span>,</span><br><span class="line">        <span class="string">&#x27;competitors&#x27;</span>: <span class="number">12.0</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    pred_price = predict_bid_price(model=model, feature_columns=feature_columns, **test_case)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Predicted bid price: $<span class="subst">&#123;pred_price:,<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    print_time(total_start, <span class="string">&quot;Total Runtime&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 通过参数控制是否重新训练（False时尝试加载已有模型）</span></span><br><span class="line">    main(retrain_flag=<span class="literal">True</span>)  <span class="comment"># 改为True强制重新训练</span></span><br></pre></td></tr></table></figure>

<p><strong>输出：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/home/chr/anaconda3/envs/pachong/bin/python /home/chr/桌面/pachong/attachments/step_3_predict_price/xgboost_real.py </span><br><span class="line"></span><br><span class="line">=== Training New Model ===</span><br><span class="line">[TIMING] Data Generation: 1.33 ms</span><br><span class="line">[TIMING] Data Preprocessing: 1.60 ms</span><br><span class="line">[TIMING] Model Training : 129.50 ms</span><br><span class="line">MAE: 33.19</span><br><span class="line">R²: 0.999</span><br><span class="line">[TIMING] Model Evaluation: 1.94 ms</span><br><span class="line">[TIMING] Model Saving   : 1.50 ms</span><br><span class="line">[TIMING] Total Training Time: 135.92 ms</span><br><span class="line"></span><br><span class="line">=== Prediction Test ===</span><br><span class="line">[TIMING] Prediction Execution: 2.36 ms</span><br><span class="line">Predicted bid price: <span class="variable">$2</span>,152.22</span><br><span class="line">[TIMING] Total Runtime  : 138.33 ms</span><br><span class="line"></span><br><span class="line">Process finished with <span class="built_in">exit</span> code 0</span><br></pre></td></tr></table></figure>

<p>可见使用1000条数据时，这种算法的训练速度是相当快的，同时发现（没贴出来输出）当测试case使用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">test_case = &#123;</span><br><span class="line">        <span class="string">&#x27;max_price&#x27;</span>: <span class="number">500.0</span>,</span><br><span class="line">        <span class="string">&#x27;project_type&#x27;</span>: <span class="string">&#x27;Municipal&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;duration&#x27;</span>: <span class="number">180</span>,</span><br><span class="line">        <span class="string">&#x27;material_cost_idx&#x27;</span>: <span class="number">1.05</span>,</span><br><span class="line">        <span class="string">&#x27;competitors&#x27;</span>: <span class="number">12.0</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>输出中的<code>Predicted bid price</code>将为<code>$582.85</code>，比<code>max_price</code>还大，原因是数据生成公式中<code>duration</code>的影响（问题不大，目前只是demo，原始数据just toy dataset）。</p>
<hr>
<h4 id="SHAP"><a href="#SHAP" class="headerlink" title="SHAP"></a>SHAP</h4><p>SHAP (SHapley Additive exPlanations) 是解释机器学习模型预测的主流工具之一，主要用于分析特征对单个预测（局部解释）或整体模型（全局解释）的影响。下面将使用 <strong>SHAP 的主流用法</strong>进行可视化分析（jupyter notebook中运行）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line"><span class="keyword">import</span> shap</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"></span><br><span class="line">MODEL_DIR = <span class="string">&quot;saved_models&quot;</span></span><br><span class="line">MODEL_NAME = <span class="string">&quot;bid_price_predictor.joblib&quot;</span></span><br><span class="line">FEATURE_COLS_NAME = <span class="string">&quot;feature_columns.joblib&quot;</span></span><br><span class="line"></span><br><span class="line">model = joblib.load(Path(MODEL_DIR) / MODEL_NAME)</span><br><span class="line">feature_columns = joblib.load(Path(MODEL_DIR) / FEATURE_COLS_NAME)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_data</span>(<span class="params">n_samples=<span class="number">1000</span></span>):</span><br><span class="line">    rng = np.random.default_rng(seed=<span class="number">42</span>)</span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">&#x27;max_price&#x27;</span>: rng.uniform(<span class="number">1e1</span>, <span class="number">5e3</span>, n_samples),</span><br><span class="line">        <span class="string">&#x27;project_type&#x27;</span>: rng.choice([<span class="string">&#x27;Construction&#x27;</span>, <span class="string">&#x27;Municipal&#x27;</span>, <span class="string">&#x27;Power&#x27;</span>, <span class="string">&#x27;Transport&#x27;</span>], n_samples),</span><br><span class="line">        <span class="string">&#x27;duration&#x27;</span>: rng.integers(<span class="number">30</span>, <span class="number">365</span>, n_samples),</span><br><span class="line">        <span class="string">&#x27;material_cost_idx&#x27;</span>: rng.normal(<span class="number">1.0</span>, <span class="number">0.1</span>, n_samples),</span><br><span class="line">        <span class="string">&#x27;competitors&#x27;</span>: rng.integers(<span class="number">3</span>, <span class="number">15</span>, n_samples)</span><br><span class="line">    &#125;</span><br><span class="line">    df = pd.DataFrame(data)</span><br><span class="line">    noise = rng.normal(<span class="number">0</span>, df[<span class="string">&#x27;max_price&#x27;</span>] * <span class="number">0.01</span>)</span><br><span class="line">    df[<span class="string">&#x27;bid_price&#x27;</span>] = (</span><br><span class="line">        df[<span class="string">&#x27;max_price&#x27;</span>] * <span class="number">0.80</span></span><br><span class="line">        + df[<span class="string">&#x27;duration&#x27;</span>]</span><br><span class="line">        + (df[<span class="string">&#x27;project_type&#x27;</span>] == <span class="string">&#x27;Municipal&#x27;</span>) * df[<span class="string">&#x27;max_price&#x27;</span>] * <span class="number">0.02</span></span><br><span class="line">        - (df[<span class="string">&#x27;competitors&#x27;</span>] &gt; <span class="number">10</span>) * df[<span class="string">&#x27;max_price&#x27;</span>] * <span class="number">0.03</span></span><br><span class="line">        + noise</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> df</span><br><span class="line"></span><br><span class="line">df = generate_data(<span class="number">200</span>)</span><br><span class="line">df = pd.get_dummies(df, columns=[<span class="string">&#x27;project_type&#x27;</span>], drop_first=<span class="literal">True</span>)</span><br><span class="line">X = df.drop(<span class="string">&#x27;bid_price&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">y = df[<span class="string">&#x27;bid_price&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> feature_columns:</span><br><span class="line">    <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> X.columns:</span><br><span class="line">        X[col] = <span class="number">0</span></span><br><span class="line">X = X[feature_columns]</span><br><span class="line"></span><br><span class="line">explainer = shap.Explainer(model)</span><br><span class="line">shap_values = explainer(X)</span><br><span class="line"></span><br><span class="line">shap.summary_plot(shap_values, X)</span><br><span class="line"></span><br><span class="line">shap.summary_plot(shap_values, X, plot_type=<span class="string">&quot;bar&quot;</span>)</span><br><span class="line"></span><br><span class="line">shap.initjs()  <span class="comment"># 初始化 JS，用于 notebook 中显示 force plot</span></span><br><span class="line"><span class="comment"># 显示第一个样本的 force_plot</span></span><br><span class="line">shap.force_plot(shap_values[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sample_idx = <span class="number">0</span></span><br><span class="line">shap.plots.waterfall(shap_values[sample_idx])</span><br></pre></td></tr></table></figure>

<ol>
<li><p><strong>summary_plot</strong></p>
<p><strong>作用：看哪个特征最重要</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">shap.summary_plot(shap_values, X)</span><br></pre></td></tr></table></figure>

<img src="/2025/04/28/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B0%83%E7%A0%94%EF%BC%9A%E6%8B%9B%E6%A0%87%E6%99%BA%E8%83%BD%E4%BD%93/4f3e4158eda18ead3ed63241aa8f495e.png" class="" title="4f3e4158eda18ead3ed63241aa8f495e">



<p><strong>详解：</strong></p>
<p>生成<strong>特征影响力点图</strong>（也叫 summary dot plot），展示每个特征对模型输出的全局影响力。</p>
<p>📊 图表内容解释</p>
<ul>
<li><strong>Y轴：特征名</strong>，按对模型输出影响大小排序（越上面越重要）</li>
<li><strong>X轴：SHAP值（影响力）</strong><ul>
<li>值越远离0，表示该特征对模型输出的影响越大（正值表示推动预测增加，负值表示推动预测减少）</li>
</ul>
</li>
<li><strong>每个点：一个样本的 SHAP 值</strong><ul>
<li><strong>颜色：特征的原始值</strong><ul>
<li>红色：特征值高</li>
<li>蓝色：特征值低</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>🔍 怎么看？</p>
<ul>
<li><code>max_price</code> 排在第一行，并且右边有大量红点，说明：</li>
<li><code>max_price</code> 是最重要的特征</li>
<li>样本中 <code>max_price</code> 越高（红色），通常 SHAP 值越大，预测越高</li>
<li>如果有些特征是红蓝混合的，说明它对模型的影响比较复杂，不完全是”值越大越好&#x2F;坏”</li>
</ul>
</li>
<li><p><strong>shap.summary_plot(shap_values, X, plot_type&#x3D;”bar”)</strong></p>
<p><strong>作用：看某个特征平均影响力大小</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">shap.summary_plot(shap_values, X, plot_type=<span class="string">&quot;bar&quot;</span>)</span><br></pre></td></tr></table></figure>

<img src="/2025/04/28/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B0%83%E7%A0%94%EF%BC%9A%E6%8B%9B%E6%A0%87%E6%99%BA%E8%83%BD%E4%BD%93/0d978f39df930a566c38df485559b132.png" class="" title="0d978f39df930a566c38df485559b132">

<p><strong>详解</strong></p>
<p>生成<strong>特征重要性柱状图</strong>，展示每个特征的平均影响力。</p>
<p>📊 图表内容解释</p>
<ul>
<li><strong>Y轴：特征名</strong></li>
<li><strong>X轴：平均 SHAP 值的绝对值</strong><ul>
<li>代表每个特征”平均影响力”大小，而不管方向（正向或负向）</li>
</ul>
</li>
</ul>
<p>🔍 怎么看？</p>
<ul>
<li>排名靠前的特征（例如 <code>max_price</code>、<code>duration</code>），对模型影响最大</li>
<li>可以作为全局特征选择和模型调优的参考</li>
</ul>
</li>
<li><p><strong>shap.force_plot(shap_values[0])</strong></p>
<p>作用：<strong>解释某个预测是怎么得出的</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">shap.initjs()  <span class="comment"># 初始化 JS，用于 notebook 中显示 force plot</span></span><br><span class="line"><span class="comment"># 显示第一个样本的 force_plot</span></span><br><span class="line">shap.force_plot(shap_values[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<img src="/2025/04/28/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B0%83%E7%A0%94%EF%BC%9A%E6%8B%9B%E6%A0%87%E6%99%BA%E8%83%BD%E4%BD%93/5f59db3696fdf95fb78b4eb15c9a95d9.png" class="" title="5f59db3696fdf95fb78b4eb15c9a95d9">

<blockquote>
<p>实际效果有些奇怪，不知道为什么未有交互，也没把变量显示完全。</p>
</blockquote>
<p>✅ 作用</p>
<p>展示<strong>第一个样本的 SHAP 值解释图</strong>（force plot），说明每个特征如何推动该样本的预测结果上升或下降。</p>
<blockquote>
<p>实际推荐写法是（但实测效果一样）：</p>
</blockquote>
<figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">shap<span class="selector-class">.force_plot</span>(</span><br><span class="line">    shap_values<span class="selector-class">.base_values</span><span class="selector-attr">[0]</span>, </span><br><span class="line">    shap_values<span class="selector-class">.values</span><span class="selector-attr">[0]</span>, </span><br><span class="line">    X<span class="selector-class">.iloc</span><span class="selector-attr">[0]</span>, </span><br><span class="line">    feature_names=X<span class="selector-class">.columns</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>📊 图表内容解释</p>
<ul>
<li><strong>左边：模型预测的 base value</strong>（模型输出的平均值）</li>
<li><strong>中间的箭头：每个特征的 SHAP 值</strong><ul>
<li>红色：该特征把预测值往右推（更高）</li>
<li>蓝色：该特征把预测值往左拉（更低）</li>
</ul>
</li>
<li><strong>右边：最终预测值</strong><ul>
<li>是 base value 加上所有 SHAP 值之后的结果</li>
</ul>
</li>
</ul>
<p>🔍 怎么看？</p>
<ul>
<li>红色箭头越长，说明该特征对预测值提升作用越大</li>
<li>蓝色箭头越长，说明该特征对预测值压低作用越大</li>
<li>可以直观看到预测值是怎么一步步被“拉”出来的</li>
</ul>
</li>
<li><p><strong>shap.plots.waterfall(shap_values[sample_idx])</strong></p>
<p><strong>作用：更清晰的解释单个预测</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">shap.plots.waterfall(shap_values[sample_idx])</span><br></pre></td></tr></table></figure>

<img src="/2025/04/28/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B0%83%E7%A0%94%EF%BC%9A%E6%8B%9B%E6%A0%87%E6%99%BA%E8%83%BD%E4%BD%93/f4f2c4fb864333c28bdd228da09d50b1.png" class="" title="f4f2c4fb864333c28bdd228da09d50b1">

<p>✅ 作用</p>
<p>显示<strong>某一个样本的 SHAP waterfall 图</strong>，它是 force_plot 的静态版本，更清晰、更适合做图分析。</p>
<p>📊 图表内容解释</p>
<ul>
<li>图像从 top 到 bottom 是一个逐步累加的过程：<ul>
<li>从 base value（模型平均输出）开始</li>
<li>每一行是一个特征对预测的贡献（红&#x2F;蓝表示方向）</li>
<li>最终累加到预测值</li>
</ul>
</li>
<li>红色条：推动预测值上升</li>
<li>蓝色条：推动预测值下降</li>
</ul>
<p>🔍 怎么看？</p>
<ul>
<li>更清晰地区分了每一步的贡献值，适合用来做单个样本的逐步解释。</li>
<li>优于 force_plot 的地方在于：视觉上逻辑清晰，不依赖 JS。</li>
</ul>
</li>
</ol>
<p>✅ 总结：使用场景对比表</p>
<table>
<thead>
<tr>
<th>函数</th>
<th>用途</th>
<th>适合分析</th>
<th>图类型</th>
<th>是否交互</th>
</tr>
</thead>
<tbody><tr>
<td><code>shap.summary_plot</code></td>
<td>全局特征影响分析</td>
<td>全数据</td>
<td>点图</td>
<td>否</td>
</tr>
<tr>
<td><code>shap.summary_plot(..., plot_type=&quot;bar&quot;)</code></td>
<td>全局特征重要性</td>
<td>全数据</td>
<td>柱状图</td>
<td>否</td>
</tr>
<tr>
<td><code>shap.force_plot</code></td>
<td>单个样本解释</td>
<td>逐条样本分析</td>
<td>动态箭头图</td>
<td>✅ 交互</td>
</tr>
<tr>
<td><code>shap.plots.waterfall</code></td>
<td>单个样本解释（更清晰）</td>
<td>逐条样本分析</td>
<td>静态条形图</td>
<td>否</td>
</tr>
</tbody></table>
<hr>
<h2 id="最终方案总结："><a href="#最终方案总结：" class="headerlink" title="最终方案总结："></a>最终方案总结：</h2><ul>
<li>爬虫智能体：<code>Selenium + ChromeDriver</code>及其他技术</li>
<li>结构化抽取智能体：<ul>
<li><code>pdf</code>解析方面<ul>
<li>可编辑<code>pdf</code>：<code>pdfplumber/pymupdf</code></li>
<li>不可编辑<code>pdf</code>：<code>paddleocr</code></li>
</ul>
</li>
<li>结构化抽取方面<ul>
<li><code>Prompt</code>工程+<code>LLM</code>抽取</li>
<li>正则表达式抽取</li>
</ul>
</li>
</ul>
</li>
<li>报价预测智能体<ul>
<li><code>XGBOOST/LightGBM/CatBoost</code></li>
<li><code>Random Forest</code></li>
<li><code>KNN</code></li>
<li><code>SVM</code></li>
</ul>
</li>
</ul>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h3 id="问题1：MAE和R²指标的含义"><a href="#问题1：MAE和R²指标的含义" class="headerlink" title="问题1：MAE和R²指标的含义"></a>问题1：MAE和R²指标的含义</h3><ol>
<li><strong>MAE (Mean Absolute Error，平均绝对误差) &#x3D; 33.19</strong><ul>
<li>表示模型预测值与真实值之间的平均绝对差异</li>
<li>单位与原数据相同（这里是美元）</li>
<li>33.19表示平均每次预测会偏差约33美元</li>
<li>在你的案例中，相对于价格范围（约$100-$5,000），这个误差较小</li>
</ul>
</li>
<li><strong>R² (R-squared，决定系数) &#x3D; 0.999</strong><ul>
<li>表示模型解释数据变异性的比例</li>
<li>范围在0到1之间，越接近1说明模型拟合越好</li>
<li>0.999表示模型可以解释99.9%的数据变异，几乎完美拟合</li>
<li>但要注意：这是在你生成的模拟数据上的表现，现实中几乎不可能达到</li>
</ul>
</li>
</ol>
<p><strong>为什么指标这么好？</strong></p>
<ul>
<li>因为你在用模型拟合自己生成的确定性数据（只是加了少量噪声）</li>
<li>现实中数据更复杂，R²通常在0.6-0.9之间就算不错</li>
</ul>
]]></content>
      <categories>
        <category>theory</category>
      </categories>
      <tags>
        <tag>方案调研</tag>
      </tags>
  </entry>
  <entry>
    <title>语音识别微服务：fast_wisper</title>
    <url>/2025/05/13/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BE%AE%E6%9C%8D%E5%8A%A1%EF%BC%9Afast-wisper/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在对话玩具中使用的ASR是funasr(paraformer)，但想往国外卖，所以英语是主要应用场景，但产品反馈说英语场景下识别准确率不高（我最开始也组织收集公司内人员的真实英语录音，直接以文件方式进行ASR，测试下来确实英语识别率不高，当然也不能排除我们的发音不飘准(●’◡’●)），遂还是部署个英文表现好的ASR服务作为对比实验吧。久仰wisper系列的大名，本次先部署fast_wisper试试效果，本文简单记录代码和部署过程。</p>
<span id="more"></span>

<hr>
<h2 id="正文1"><a href="#正文1" class="headerlink" title="正文1"></a>正文1</h2><p><strong>直接撸起袖子就是干：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda create -n fast_wisper python=3.10</span><br><span class="line">conda activate fast_wisper</span><br><span class="line">pip install faster-whisper</span><br><span class="line"></span><br><span class="line">pip install nvidia-cublas-cu12 nvidia-cudnn-cu12==9.*</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=`python3 -c <span class="string">&#x27;import os; import nvidia.cublas.lib; import nvidia.cudnn.lib; print(os.path.dirname(nvidia.cublas.lib.__file__) + &quot;:&quot; + os.path.dirname(nvidia.cudnn.lib.__file__))&#x27;</span>`</span><br></pre></td></tr></table></figure>

<p>好的，有报错，不管它。</p>
<p>直接上代码，参考<a href="https://caihaoran-00.github.io/2025/04/25/fastapi-request%E5%86%8D%E6%8E%A2%E4%B9%8B%EF%BC%9Arequests-post/#%E5%AE%9E%E9%99%85%E7%9A%84%E9%97%AE%E9%A2%98">这里</a>，<strong>服务端：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> faster_whisper <span class="keyword">import</span> WhisperModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, Request</span><br><span class="line"><span class="keyword">import</span> uvicorn</span><br><span class="line"><span class="keyword">import</span> soundfile <span class="keyword">as</span> sf</span><br><span class="line"></span><br><span class="line">model_size = <span class="string">&quot;large-v3&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Run on GPU with FP16</span></span><br><span class="line">model = WhisperModel(model_size, device=<span class="string">&quot;cuda&quot;</span>, compute_type=<span class="string">&quot;float16&quot;</span>)</span><br><span class="line"><span class="comment"># model = WhisperModel(model_size, device=&quot;cuda&quot;, device_index=0)</span></span><br><span class="line"><span class="comment"># model = WhisperModel(model_size, compute_type=&quot;int8&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建FASTAPI实例</span></span><br><span class="line">app = FastAPI(title=<span class="string">&quot;Fast_Whisper&quot;</span>)</span><br><span class="line"></span><br><span class="line">SAVE_AUDIO = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/asr/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">asr_endpoint</span>(<span class="params">request: Request</span>):</span><br><span class="line">    <span class="comment"># 直接读裸字节流</span></span><br><span class="line">    audio_bytes = <span class="keyword">await</span> request.body()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> SAVE_AUDIO:</span><br><span class="line">        audio_np = np.frombuffer(audio_bytes, dtype=np.int16)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 写入为 WAV 文件</span></span><br><span class="line">        sf.write(<span class="string">&quot;received_audio.wav&quot;</span>, audio_np, samplerate=<span class="number">16000</span>, subtype=<span class="string">&quot;PCM_16&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Save Audio success!&quot;</span>)</span><br><span class="line"></span><br><span class="line">    audio_data = np.frombuffer(audio_bytes, dtype=np.int16).astype(np.float32) / <span class="number">32768.0</span></span><br><span class="line"></span><br><span class="line">    result = []</span><br><span class="line"></span><br><span class="line">    segments, info = model.transcribe(audio_data, beam_size=<span class="number">5</span>, language=<span class="string">&quot;en&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 拼接所有片段的文本</span></span><br><span class="line">    full_text = <span class="string">&quot; &quot;</span>.join(segment.text.strip() <span class="keyword">for</span> segment <span class="keyword">in</span> segments)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构造响应，包含语言检测信息</span></span><br><span class="line">    response = &#123;</span><br><span class="line">        <span class="string">&quot;status&quot;</span>: <span class="string">&quot;success&quot;</span>,</span><br><span class="line">        <span class="string">&quot;res&quot;</span>: full_text,</span><br><span class="line">        <span class="string">&quot;language&quot;</span>: info.language,  <span class="comment"># 检测到的语言（应为 &quot;en&quot;）</span></span><br><span class="line">        <span class="string">&quot;language_probability&quot;</span>: info.language_probability  <span class="comment"># 语言检测置信度</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(</span><br><span class="line">        <span class="string">f&quot;Transcription completed. Language: <span class="subst">&#123;info.language&#125;</span>, &quot;</span></span><br><span class="line">        <span class="string">f&quot;Probability: <span class="subst">&#123;info.language_probability:<span class="number">.2</span>f&#125;</span>, Segments: <span class="subst">&#123;<span class="built_in">len</span>(result)&#125;</span>&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    uvicorn.run(app, host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="number">8000</span>)</span><br></pre></td></tr></table></figure>

<p><strong>直接运行</strong></p>
<p>好的，报错了</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">RuntimeError: CUDA unknown error</span><br></pre></td></tr></table></figure>

<p>参考<a href="https://blog.csdn.net/qq_43428139/article/details/133498358">这里</a>，运行：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt-get install nvidia-modprobe</span><br></pre></td></tr></table></figure>

<p>继续运行服务端代码，然并卵，还是那个错误，咱们直接重启，<strong>重启后再运行服务端代码就好了。</strong></p>
<p><strong>客户端代码：</strong></p>
<figure class="highlight python"><figcaption><span>silero_vad_mic_basic_request_nobase64_whisper</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">for fast wisper client</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> soundfile <span class="keyword">as</span> sf</span><br><span class="line"></span><br><span class="line">torch.set_num_threads(<span class="number">1</span>)</span><br><span class="line">debug_mode = <span class="literal">False</span>  <span class="comment"># 控制是否保存部分音频及打印信息</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pyaudio</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">from</span> queue <span class="keyword">import</span> Queue</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载 Silero VAD 模型</span></span><br><span class="line">model, utils = torch.hub.load(repo_or_dir=<span class="string">&#x27;snakers4/silero-vad&#x27;</span>,</span><br><span class="line">                              model=<span class="string">&#x27;silero_vad&#x27;</span>,</span><br><span class="line">                              trust_repo=<span class="literal">True</span>,</span><br><span class="line">                              onnx=<span class="literal">True</span>,</span><br><span class="line">                              <span class="comment"># force_reload=True</span></span><br><span class="line">                              )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 录音参数</span></span><br><span class="line">FORMAT = pyaudio.paFloat32</span><br><span class="line">CHANNELS = <span class="number">1</span></span><br><span class="line">SAMPLE_RATE = <span class="number">16000</span></span><br><span class="line">num_samples = <span class="number">512</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 PyAudio</span></span><br><span class="line">audio = pyaudio.PyAudio()</span><br><span class="line">stream = audio.<span class="built_in">open</span>(<span class="built_in">format</span>=FORMAT,</span><br><span class="line">                    channels=CHANNELS,</span><br><span class="line">                    rate=SAMPLE_RATE,</span><br><span class="line">                    <span class="built_in">input</span>=<span class="literal">True</span>,</span><br><span class="line">                    frames_per_buffer=num_samples)</span><br><span class="line"></span><br><span class="line">audio_record_queue = Queue()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># BASE_URL = &quot;http://192.168.0.138:8000&quot;</span></span><br><span class="line">BASE_URL = <span class="string">&quot;http://192.168.0.138:8000&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">StateManage</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.threshold = <span class="number">0.5</span></span><br><span class="line">        <span class="variable language_">self</span>.min_speech_duration_ms = <span class="number">64</span></span><br><span class="line">        <span class="variable language_">self</span>.min_silence_duration_ms = <span class="number">480</span></span><br><span class="line">        <span class="variable language_">self</span>.pre_chunk_add = <span class="number">4</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">state_manage = StateManage()</span><br><span class="line"></span><br><span class="line">pre_speech_buffer = collections.deque(maxlen=state_manage.min_speech_duration_ms // <span class="number">32</span> + state_manage.pre_chunk_add)</span><br><span class="line"><span class="built_in">print</span>(state_manage.min_speech_duration_ms // <span class="number">32</span> + state_manage.pre_chunk_add)</span><br><span class="line">first_chunk_detected = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">send_audio_to_server</span>(<span class="params">audio_fragment</span>):</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&quot;Content-Type&quot;</span>: <span class="string">&quot;application/octet-stream&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">    response = requests.post(<span class="string">f&quot;<span class="subst">&#123;BASE_URL&#125;</span>/asr/&quot;</span>, headers=headers, data=audio_fragment)</span><br><span class="line">    <span class="keyword">return</span> response.json()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VADContext</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 threshold=<span class="number">0.5</span>,</span></span><br><span class="line"><span class="params">                 min_speech_duration_ms=<span class="number">64</span>,</span></span><br><span class="line"><span class="params">                 min_silence_duration_ms=<span class="number">480</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.threshold = threshold</span><br><span class="line">        <span class="variable language_">self</span>.min_speech_frames = <span class="built_in">int</span>(min_speech_duration_ms * SAMPLE_RATE / <span class="number">1000</span> / num_samples)</span><br><span class="line">        <span class="variable language_">self</span>.min_silence_frames = <span class="built_in">int</span>(min_silence_duration_ms * SAMPLE_RATE / <span class="number">1000</span> / num_samples)</span><br><span class="line">        <span class="variable language_">self</span>.speech_frame_count = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.silence_frame_count = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.is_speech = <span class="literal">False</span></span><br><span class="line">        <span class="variable language_">self</span>.was_speech = <span class="literal">False</span>  <span class="comment"># 跟踪上一帧是否是语音</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, confidence</span>):</span><br><span class="line">        <span class="variable language_">self</span>.was_speech = <span class="variable language_">self</span>.is_speech  <span class="comment"># 保存上一帧的状态</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.is_speech:</span><br><span class="line">            <span class="keyword">if</span> confidence &gt;= <span class="variable language_">self</span>.threshold:</span><br><span class="line">                <span class="variable language_">self</span>.speech_frame_count += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> <span class="variable language_">self</span>.speech_frame_count &gt;= <span class="variable language_">self</span>.min_speech_frames:</span><br><span class="line">                    <span class="variable language_">self</span>.is_speech = <span class="literal">True</span></span><br><span class="line">                    <span class="variable language_">self</span>.silence_frame_count = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.speech_frame_count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> confidence &lt;= <span class="variable language_">self</span>.threshold - <span class="number">0.15</span>:</span><br><span class="line">                <span class="variable language_">self</span>.silence_frame_count += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> <span class="variable language_">self</span>.silence_frame_count &gt;= <span class="variable language_">self</span>.min_silence_frames:</span><br><span class="line">                    <span class="variable language_">self</span>.is_speech = <span class="literal">False</span></span><br><span class="line">                    <span class="variable language_">self</span>.speech_frame_count = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.silence_frame_count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.is_speech</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_speech_end</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;检查是否是语音结束&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.was_speech <span class="keyword">and</span> <span class="keyword">not</span> <span class="variable language_">self</span>.is_speech</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">recording_and_vad_thread</span>():</span><br><span class="line">    <span class="keyword">global</span> first_chunk_detected</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Recording...\n&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">    vad_context = VADContext(</span><br><span class="line">        threshold=state_manage.threshold,</span><br><span class="line">        min_speech_duration_ms=state_manage.min_speech_duration_ms,</span><br><span class="line">        min_silence_duration_ms=state_manage.min_silence_duration_ms,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> debug_mode:</span><br><span class="line">        raw_audio_chunks = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        data = stream.read(num_samples)</span><br><span class="line">        audio_chunk = np.frombuffer(data, dtype=np.float32)</span><br><span class="line">        speech_prob = model(torch.from_numpy(audio_chunk.copy()), SAMPLE_RATE).item()</span><br><span class="line">        is_speech = vad_context.update(speech_prob)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 放入缓冲区</span></span><br><span class="line">        pre_speech_buffer.append(audio_chunk)</span><br><span class="line">        <span class="keyword">if</span> is_speech:</span><br><span class="line">            <span class="comment"># 如果刚检测到语音</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> first_chunk_detected:</span><br><span class="line">                first_chunk_detected = <span class="literal">True</span></span><br><span class="line">                <span class="keyword">while</span> pre_speech_buffer:</span><br><span class="line">                    pre_chunk = pre_speech_buffer.popleft()</span><br><span class="line">                    int16_chunk = (pre_chunk * <span class="number">32767</span>).astype(np.int16)</span><br><span class="line">                    audio_record_queue.put(int16_chunk)</span><br><span class="line">                    <span class="keyword">if</span> debug_mode:</span><br><span class="line">                        raw_audio_chunks.append(int16_chunk)  <span class="comment"># 保存原始数据</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                audio_chunk_int16 = (audio_chunk * <span class="number">32767</span>).astype(np.int16)</span><br><span class="line">                audio_record_queue.put(audio_chunk_int16)</span><br><span class="line">                <span class="keyword">if</span> debug_mode:</span><br><span class="line">                    raw_audio_chunks.append(audio_chunk_int16)   <span class="comment"># 保存原始数据</span></span><br><span class="line">        <span class="keyword">elif</span> vad_context.is_speech_end():</span><br><span class="line">            audio_record_queue.put(<span class="literal">None</span>)</span><br><span class="line">            first_chunk_detected = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> debug_mode <span class="keyword">and</span> raw_audio_chunks:</span><br><span class="line">                raw_audio_data = np.concatenate(raw_audio_chunks)</span><br><span class="line">                sf.write(<span class="string">&quot;debug_raw_audio.wav&quot;</span>, raw_audio_data, samplerate=<span class="number">16000</span>, subtype=<span class="string">&quot;PCM_16&quot;</span>)</span><br><span class="line">                raw_audio_chunks.clear()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动录音线程</span></span><br><span class="line">recording_thread = threading.Thread(target=recording_and_vad_thread, daemon=<span class="literal">True</span>)</span><br><span class="line">recording_thread.start()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">send_audio</span>():</span><br><span class="line">    audio_chunks = []</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        chunk = audio_record_queue.get()</span><br><span class="line">        <span class="keyword">if</span> chunk <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> audio_chunks:</span><br><span class="line">                audio_data = np.concatenate(audio_chunks)</span><br><span class="line">                audio_data_bytes = audio_data.tobytes()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 发送到ASR服务器</span></span><br><span class="line">                result = send_audio_to_server(audio_data_bytes)</span><br><span class="line">                <span class="keyword">if</span> result:</span><br><span class="line">                    asr_text = result[<span class="string">&#x27;res&#x27;</span>]</span><br><span class="line">                    lan = result[<span class="string">&#x27;language&#x27;</span>]</span><br><span class="line">                    language_probability = result[<span class="string">&#x27;language_probability&#x27;</span>]</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;\nres: <span class="subst">&#123;asr_text&#125;</span>, lan: <span class="subst">&#123;lan&#125;</span>, language_probability: <span class="subst">&#123;language_probability&#125;</span> &quot;</span>)</span><br><span class="line"></span><br><span class="line">                audio_chunks.clear()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            audio_chunks.append(chunk)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    send_audio()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">res: Hello, I<span class="string">&#x27;m Tom. What&#x27;</span>s your name? Hey, my name is John. Nice to meet you. Nice to meet you too., lan: en, language_probability: 1 </span><br><span class="line"></span><br><span class="line">res: Excuse me, <span class="built_in">where</span> is the cinema? Where is the teacher<span class="string">&#x27;s office, please? How can I get to the post office? Can you show me the way to the bank, please?, lan: en, language_probability: 1 </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">res: Good morning. Good morning. How are you? I&#x27;</span>m fine. Thank you, lan: en, language_probability: 1 </span><br><span class="line"></span><br><span class="line">res: You will be alright., lan: en, language_probability: 1 </span><br><span class="line"></span><br><span class="line">res: You will be all right., lan: en, language_probability: 1 </span><br><span class="line"></span><br><span class="line">res: I don<span class="string">&#x27;t feel well., lan: en, language_probability: 1 </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">res: I have got a pain., lan: en, language_probability: 1 </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">res: How are you?, lan: en, language_probability: 1 </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">res: Let&#x27;</span>s sing., lan: en, language_probability: 1 </span><br><span class="line"></span><br><span class="line">进程已结束，退出代码为 -1</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>完事，目前先这样，测试人员先测试下效果再探索别的用法。</p>
<hr>
<h2 id="正文2"><a href="#正文2" class="headerlink" title="正文2"></a>正文2</h2><p>效果不错，给公司服务器也部署一个，过程略微修改了下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda create -n fast_wisper python=3.10</span><br><span class="line">conda activate fast_wisper</span><br><span class="line"></span><br><span class="line">pip install nvidia-cublas-cu12 nvidia-cudnn-cu12==9.*</span><br><span class="line"></span><br><span class="line"><span class="built_in">mkdir</span> -p <span class="variable">$CONDA_PREFIX</span>/etc/conda/activate.d</span><br><span class="line"></span><br><span class="line"><span class="built_in">cat</span> &gt; <span class="variable">$CONDA_PREFIX</span>/etc/conda/activate.d/env_vars.sh &lt;&lt;<span class="string">EOF</span></span><br><span class="line"><span class="string">export LD_LIBRARY_PATH=\$CONDA_PREFIX/lib:\$CONDA_PREFIX/lib/python3.10/site-packages/nvidia/cublas/lib:\$CONDA_PREFIX/lib/python3.10/site-packages/nvidia/cudnn/lib:\$LD_LIBRARY_PATH</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看路径是否生效</span></span><br><span class="line">conda deactivate</span><br><span class="line">conda activate fast_wisper</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$LD_LIBRARY_PATH</span>	<span class="comment"># 打印三个路径</span></span><br><span class="line"></span><br><span class="line">pip install faster-whisper fastapi uvicorn soundfile</span><br></pre></td></tr></table></figure>

<p>好了，现在环境准备好了，通过局域网将我的文件转移到服务器上：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">scp <span class="string">&#x27;/home/chr/桌面/fast_wisper_/fawisper1_wanju.py&#x27;</span> srtc@192.168.0.xxx:~/文档/workspace/fast_wisper/</span><br></pre></td></tr></table></figure>

<p>然后输入<code>yes</code>和服务器密码即可，回到服务器，直接运行服务器会发现报错，原因是公司服务器访问不了huggingface，那么咱们先从modelscope上下载模型：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://www.modelscope.cn/keepitsimple/faster-whisper-large-v3.git</span><br></pre></td></tr></table></figure>

<p>然后运行服务端代码：</p>
<p>好的别试了，怎么试他都不加载本地模型，无论加不加<code>local_files_only=True</code>，以及模型路径前面加不加<code>./</code>，后面加不加<code>/</code>，都试了，算了，另辟蹊径吧，<a href="https://blog.csdn.net/skywalk8163/article/details/137614889">参考</a>，直接在代码前面加上：</p>
<figure class="highlight moonscript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="built_in">os</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">os</span>.environ[<span class="string">&#x27;HF_ENDPOINT&#x27;</span>]=<span class="string">&#x27;https://hf-mirror.com&#x27;</span></span><br></pre></td></tr></table></figure>

<p><strong>完整代码（与正文1略有不同）：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> faster_whisper <span class="keyword">import</span> WhisperModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, Request</span><br><span class="line"><span class="keyword">import</span> uvicorn</span><br><span class="line"><span class="keyword">import</span> soundfile <span class="keyword">as</span> sf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&#x27;HF_ENDPOINT&#x27;</span>]=<span class="string">&#x27;https://hf-mirror.com&#x27;</span></span><br><span class="line"></span><br><span class="line">model_size = <span class="string">&quot;large-v3&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Run on GPU with FP16</span></span><br><span class="line">model = WhisperModel(model_size, device=<span class="string">&quot;cuda&quot;</span>, compute_type=<span class="string">&quot;float16&quot;</span>)</span><br><span class="line"><span class="comment"># model = WhisperModel(model_size, device=&quot;cuda&quot;, device_index=0)</span></span><br><span class="line"><span class="comment"># model = WhisperModel(model_size, compute_type=&quot;int8&quot;)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建FASTAPI实例</span></span><br><span class="line">app = FastAPI(title=<span class="string">&quot;Fast_Whisper&quot;</span>)</span><br><span class="line"></span><br><span class="line">SAVE_AUDIO = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/recognize_pcm&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">asr_endpoint</span>(<span class="params">request: Request</span>):</span><br><span class="line">    <span class="comment"># 直接读裸字节流</span></span><br><span class="line">    audio_bytes = <span class="keyword">await</span> request.body()</span><br><span class="line">    <span class="keyword">if</span> SAVE_AUDIO:</span><br><span class="line">        audio_np = np.frombuffer(audio_bytes, dtype=np.int16)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 写入为 WAV 文件</span></span><br><span class="line">        sf.write(<span class="string">&quot;received_audio.wav&quot;</span>, audio_np, samplerate=<span class="number">16000</span>, subtype=<span class="string">&quot;PCM_16&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Save Audio success!&quot;</span>)</span><br><span class="line"></span><br><span class="line">    audio_data = np.frombuffer(audio_bytes, dtype=np.int16).astype(np.float32) / <span class="number">32768.0</span></span><br><span class="line"></span><br><span class="line">    result = []</span><br><span class="line"></span><br><span class="line">    segments, info = model.transcribe(audio_data, beam_size=<span class="number">5</span>, language=<span class="string">&quot;en&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 拼接所有片段的文本</span></span><br><span class="line">    full_text = <span class="string">&quot; &quot;</span>.join(segment.text.strip() <span class="keyword">for</span> segment <span class="keyword">in</span> segments)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 构造响应，包含语言检测信息</span></span><br><span class="line">    response = &#123;</span><br><span class="line">        <span class="string">&quot;code&quot;</span>: <span class="number">0</span>,</span><br><span class="line">        <span class="string">&quot;msg&quot;</span>: <span class="string">&#x27;success&#x27;</span>,</span><br><span class="line">        <span class="string">&quot;data&quot;</span>: full_text,</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">print</span>(</span><br><span class="line">        <span class="string">f&quot;Transcription completed. Language: <span class="subst">&#123;info.language&#125;</span>, Probability: <span class="subst">&#123;info.language_probability:<span class="number">.2</span>f&#125;</span>, Segments: <span class="subst">&#123;<span class="built_in">len</span>(result)&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    uvicorn.run(app, host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="number">8003</span>)</span><br></pre></td></tr></table></figure>

<p>先这样，等等测试人员压测的数据再看优化（batch或者堆硬件？）</p>
<p>可能的优化方向（待续）：</p>
<ol>
<li><a href="https://github.com/SYSTRAN/faster-whisper/issues/1288#issuecomment-2821090423">参考1</a>✨</li>
<li><a href="https://github.com/SYSTRAN/faster-whisper/pull/856">参考2</a></li>
<li><a href="https://github.com/SYSTRAN/faster-whisper/issues/100">参考3</a>✨</li>
</ol>
<hr>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://caihaoran-00.github.io/2025/04/25/fastapi-request%E5%86%8D%E6%8E%A2%E4%B9%8B%EF%BC%9Arequests-post/#%E5%AE%9E%E9%99%85%E7%9A%84%E9%97%AE%E9%A2%98">https://caihaoran-00.github.io/2025/04/25/fastapi-request%E5%86%8D%E6%8E%A2%E4%B9%8B%EF%BC%9Arequests-post/#%E5%AE%9E%E9%99%85%E7%9A%84%E9%97%AE%E9%A2%98</a></li>
<li><a href="https://blog.csdn.net/qq_43428139/article/details/133498358">https://blog.csdn.net/qq_43428139/article/details/133498358</a></li>
<li><a href="https://github.com/SYSTRAN/faster-whisper">https://github.com/SYSTRAN/faster-whisper</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>asr</tag>
        <tag>fastapi</tag>
        <tag>fast_wisper</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title>语音识别微服务：fast_wisper优化</title>
    <url>/2025/05/22/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BE%AE%E6%9C%8D%E5%8A%A1%EF%BC%9Afast-wisper%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><a href="">前面</a>我们简单的写了faster wisper的微服务，测试下来效果还不错，现在准备优化下并发和吞吐量</p>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>asr</tag>
        <tag>fastapi</tag>
        <tag>fast_wisper</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title>说话人确认之CAM++</title>
    <url>/2025/02/11/%E8%AF%B4%E8%AF%9D%E4%BA%BA%E7%A1%AE%E8%AE%A4%E4%B9%8BCAM/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>说话人确认，又名说话人验证（SV, Speaker Verification）、声纹认证、语音认证、说话人认证，是声纹识别的一个子任务，主要用于确认某个人的身份，即<strong>这个人是不是那个人</strong>。验证采用<strong>1:1对比</strong>，即用户提供的语音与已注册的声纹模版进行匹配，以决定是否通过认证。</p>
<p>本文以3D-speaker中的CAM++（ERES2Net V2也类似）为例，实验说话人确认效果。</p>
<span id="more"></span>

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>打开<a href="https://modelscope.cn/models?page=1&tabKey=task&tasks=speaker-verification&type=audio">这个页面</a>：</p>
<img src="/2025/02/11/%E8%AF%B4%E8%AF%9D%E4%BA%BA%E7%A1%AE%E8%AE%A4%E4%B9%8BCAM/image-20250211173755013.png" class="" title="image-20250211173755013">

<p>点击上图所示箭头，往下拉可看到示例：</p>
<img src="/2025/02/11/%E8%AF%B4%E8%AF%9D%E4%BA%BA%E7%A1%AE%E8%AE%A4%E4%B9%8BCAM/image-20250211173929098.png" class="" title="image-20250211173929098">

<p>我们实操下：</p>
<ul>
<li><p>首先准备下环境（缺啥安啥）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install modelscope addict datasets simplejson sortedcontainers</span><br></pre></td></tr></table></figure>
</li>
<li><p>运行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> modelscope.pipelines <span class="keyword">import</span> pipeline</span><br><span class="line">sv_pipeline = pipeline(</span><br><span class="line">    task=<span class="string">&#x27;speaker-verification&#x27;</span>,</span><br><span class="line">    model=<span class="string">&#x27;iic/speech_campplus_sv_zh_en_16k-common_advanced&#x27;</span>,</span><br><span class="line">    model_revision=<span class="string">&#x27;v1.0.0&#x27;</span></span><br><span class="line">)</span><br><span class="line">speaker1_a_wav = <span class="string">&#x27;https://modelscope.cn/api/v1/models/iic/speech_campplus_sv_zh_en_16k-common_advanced/repo?Revision=master&amp;FilePath=examples/speaker1_a_cn_16k.wav&#x27;</span></span><br><span class="line">speaker1_b_wav = <span class="string">&#x27;https://modelscope.cn/api/v1/models/iic/speech_campplus_sv_zh_en_16k-common_advanced/repo?Revision=master&amp;FilePath=examples/speaker1_b_cn_16k.wav&#x27;</span></span><br><span class="line">speaker2_a_wav = <span class="string">&#x27;https://modelscope.cn/api/v1/models/iic/speech_campplus_sv_zh_en_16k-common_advanced/repo?Revision=master&amp;FilePath=examples/speaker2_a_cn_16k.wav&#x27;</span></span><br><span class="line"><span class="comment"># 相同说话人语音</span></span><br><span class="line">result = sv_pipeline([speaker1_a_wav, speaker1_b_wav])</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"><span class="comment"># 不同说话人语音</span></span><br><span class="line">result = sv_pipeline([speaker1_a_wav, speaker2_a_wav])</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"><span class="comment"># 可以自定义得分阈值来进行识别，阈值越高，判定为同一人的条件越严格</span></span><br><span class="line">result = sv_pipeline([speaker1_a_wav, speaker2_a_wav], thr=<span class="number">0.33</span>)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"><span class="comment"># 可以传入output_emb参数，输出结果中就会包含提取到的说话人embedding</span></span><br><span class="line">result = sv_pipeline([speaker1_a_wav, speaker2_a_wav], output_emb=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(result[<span class="string">&#x27;embs&#x27;</span>], result[<span class="string">&#x27;outputs&#x27;</span>])</span><br><span class="line"><span class="comment"># 可以传入save_dir参数，提取到的说话人embedding会存储在save_dir目录中</span></span><br><span class="line">result = sv_pipeline([speaker1_a_wav, speaker2_a_wav], save_dir=<span class="string">&#x27;savePath/&#x27;</span>)</span><br></pre></td></tr></table></figure>



<p>输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">D:\Anaconda3\envs\langchain\python.exe E:\chr_git\langchain_t\langgraph\sv_cam.py </span><br><span class="line"><span class="number">2025</span>-02-<span class="number">11</span> <span class="number">17</span>:<span class="number">51</span>:<span class="number">39</span>,<span class="number">106</span> - modelscope - INFO - Use user-specified model revision: v1<span class="number">.0</span><span class="number">.0</span></span><br><span class="line">Downloading Model to directory: C:\Users\<span class="built_in">chr</span>\.cache\modelscope\hub\iic\speech_campplus_sv_zh_en_16k-common_advanced</span><br><span class="line"><span class="number">2025</span>-02-<span class="number">11</span> <span class="number">17</span>:<span class="number">51</span>:<span class="number">40</span>,<span class="number">208</span> - modelscope - INFO - Use user-specified model revision: v1<span class="number">.0</span><span class="number">.0</span></span><br><span class="line"><span class="number">2025</span>-02-<span class="number">11</span> <span class="number">17</span>:<span class="number">51</span>:<span class="number">40</span>,<span class="number">494</span> - modelscope - INFO - Got <span class="number">9</span> files, start to download ...</span><br><span class="line">Processing <span class="number">9</span> items:   <span class="number">0</span>%|          | <span class="number">0.00</span>/<span class="number">9.00</span> [<span class="number">00</span>:<span class="number">00</span>&lt;?, ?it/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]:   <span class="number">0</span>%|          | <span class="number">0.00</span>/<span class="number">26.7</span>M [<span class="number">00</span>:<span class="number">00</span>&lt;?, ?B/s]</span><br><span class="line"></span><br><span class="line">Downloading [config.yaml]:   <span class="number">0</span>%|          | <span class="number">0.00</span>/<span class="number">537</span> [<span class="number">00</span>:<span class="number">00</span>&lt;?, ?B/s]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Downloading [dingding.jpg]:   <span class="number">0</span>%|          | <span class="number">0.00</span>/180k [<span class="number">00</span>:<span class="number">00</span>&lt;?, ?B/s]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Downloading [quickstart.md]:   <span class="number">0</span>%|          | <span class="number">0.00</span>/<span class="number">1.53</span>k [<span class="number">00</span>:<span class="number">00</span>&lt;?, ?B/s]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Downloading [README.md]:   <span class="number">0</span>%|          | <span class="number">0.00</span>/<span class="number">5.83</span>k [<span class="number">00</span>:<span class="number">00</span>&lt;?, ?B/s]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Downloading [examples/speaker1_a_cn_16k.wav]:   <span class="number">0</span>%|          | <span class="number">0.00</span>/116k [<span class="number">00</span>:<span class="number">00</span>&lt;?, ?B/s]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Downloading [examples/speaker1_b_cn_16k.wav]:   <span class="number">0</span>%|          | <span class="number">0.00</span>/153k [<span class="number">00</span>:<span class="number">00</span>&lt;?, ?B/s]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Downloading [examples/speaker2_a_cn_16k.wav]:   <span class="number">0</span>%|          | <span class="number">0.00</span>/166k [<span class="number">00</span>:<span class="number">00</span>&lt;?, ?B/s]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Downloading [quickstart.md]: <span class="number">100</span>%|██████████| <span class="number">1.53</span>k/<span class="number">1.53</span>k [<span class="number">00</span>:<span class="number">00</span>&lt;<span class="number">00</span>:<span class="number">00</span>, <span class="number">3.96</span>kB/s]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Downloading [config.yaml]: <span class="number">100</span>%|██████████| <span class="number">537</span>/<span class="number">537</span> [<span class="number">00</span>:<span class="number">00</span>&lt;<span class="number">00</span>:<span class="number">00</span>, <span class="number">1.32</span>kB/s]</span><br><span class="line">Processing <span class="number">9</span> items:  <span class="number">11</span>%|█         | <span class="number">1.00</span>/<span class="number">9.00</span> [<span class="number">00</span>:<span class="number">00</span>&lt;<span class="number">00</span>:03, <span class="number">2.43</span>it/s]</span><br><span class="line"></span><br><span class="line">Downloading [structure.png]:   <span class="number">0</span>%|          | <span class="number">0.00</span>/279k [<span class="number">00</span>:<span class="number">00</span>&lt;?, ?B/s]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Downloading [README.md]: <span class="number">100</span>%|██████████| <span class="number">5.83</span>k/<span class="number">5.83</span>k [<span class="number">00</span>:<span class="number">00</span>&lt;<span class="number">00</span>:<span class="number">00</span>, <span class="number">13.0</span>kB/s]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Downloading [examples/speaker1_a_cn_16k.wav]: <span class="number">100</span>%|██████████| 116k/116k [<span class="number">00</span>:<span class="number">00</span>&lt;<span class="number">00</span>:<span class="number">00</span>, 225kB/s]</span><br><span class="line">Processing <span class="number">9</span> items:  <span class="number">44</span>%|████▍     | <span class="number">4.00</span>/<span class="number">9.00</span> [<span class="number">00</span>:<span class="number">00</span>&lt;<span class="number">00</span>:<span class="number">00</span>, <span class="number">8.67</span>it/s]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Downloading [examples/speaker2_a_cn_16k.wav]: <span class="number">100</span>%|██████████| 166k/166k [<span class="number">00</span>:<span class="number">00</span>&lt;<span class="number">00</span>:<span class="number">00</span>, 311kB/s]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Downloading [examples/speaker2_a_cn_16k.wav]: <span class="number">100</span>%|██████████| 166k/166k [<span class="number">00</span>:<span class="number">00</span>&lt;<span class="number">00</span>:<span class="number">00</span>, 311kB/s]</span><br><span class="line">Downloading [examples/speaker1_b_cn_16k.wav]: <span class="number">100</span>%|██████████| 153k/153k [<span class="number">00</span>:<span class="number">00</span>&lt;<span class="number">00</span>:<span class="number">00</span>, 287kB/s]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Downloading [dingding.jpg]: <span class="number">100</span>%|██████████| 180k/180k [<span class="number">00</span>:<span class="number">00</span>&lt;<span class="number">00</span>:<span class="number">00</span>, 273kB/s]</span><br><span class="line">Processing <span class="number">9</span> items:  <span class="number">78</span>%|███████▊  | <span class="number">7.00</span>/<span class="number">9.00</span> [<span class="number">00</span>:<span class="number">00</span>&lt;<span class="number">00</span>:<span class="number">00</span>, <span class="number">12.7</span>it/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]:   <span class="number">4</span>%|▎         | <span class="number">1.00</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:<span class="number">00</span>&lt;<span class="number">00</span>:<span class="number">19</span>, <span class="number">1.38</span>MB/s]</span><br><span class="line"></span><br><span class="line">Downloading [structure.png]: <span class="number">100</span>%|██████████| 279k/279k [<span class="number">00</span>:<span class="number">00</span>&lt;<span class="number">00</span>:<span class="number">00</span>, 466kB/s]</span><br><span class="line"></span><br><span class="line">Downloading [campplus_cn_en_common.pt]:   <span class="number">7</span>%|▋         | <span class="number">2.00</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:01&lt;<span class="number">00</span>:<span class="number">12</span>, <span class="number">2.02</span>MB/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]:  <span class="number">11</span>%|█         | <span class="number">3.00</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:01&lt;<span class="number">00</span>:<span class="number">11</span>, <span class="number">2.14</span>MB/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]:  <span class="number">15</span>%|█▍        | <span class="number">4.00</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:01&lt;<span class="number">00</span>:09, <span class="number">2.49</span>MB/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]:  <span class="number">19</span>%|█▊        | <span class="number">5.00</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:02&lt;<span class="number">00</span>:06, <span class="number">3.35</span>MB/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]:  <span class="number">22</span>%|██▏       | <span class="number">6.00</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:02&lt;<span class="number">00</span>:08, <span class="number">2.69</span>MB/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]:  <span class="number">26</span>%|██▌       | <span class="number">7.00</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:02&lt;<span class="number">00</span>:07, <span class="number">2.59</span>MB/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]:  <span class="number">30</span>%|██▉       | <span class="number">8.00</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:03&lt;<span class="number">00</span>:07, <span class="number">2.51</span>MB/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]:  <span class="number">34</span>%|███▎      | <span class="number">9.00</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:03&lt;<span class="number">00</span>:07, <span class="number">2.43</span>MB/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]:  <span class="number">37</span>%|███▋      | <span class="number">10.0</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:04&lt;<span class="number">00</span>:07, <span class="number">2.45</span>MB/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]:  <span class="number">41</span>%|████      | <span class="number">11.0</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:04&lt;<span class="number">00</span>:05, <span class="number">2.87</span>MB/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]:  <span class="number">45</span>%|████▍     | <span class="number">12.0</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:04&lt;<span class="number">00</span>:05, <span class="number">2.67</span>MB/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]:  <span class="number">49</span>%|████▊     | <span class="number">13.0</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:05&lt;<span class="number">00</span>:05, <span class="number">2.57</span>MB/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]:  <span class="number">52</span>%|█████▏    | <span class="number">14.0</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:05&lt;<span class="number">00</span>:05, <span class="number">2.54</span>MB/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]:  <span class="number">56</span>%|█████▌    | <span class="number">15.0</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:05&lt;<span class="number">00</span>:03, <span class="number">3.16</span>MB/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]:  <span class="number">60</span>%|█████▉    | <span class="number">16.0</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:06&lt;<span class="number">00</span>:04, <span class="number">2.80</span>MB/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]:  <span class="number">64</span>%|██████▎   | <span class="number">17.0</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:06&lt;<span class="number">00</span>:03, <span class="number">2.58</span>MB/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]:  <span class="number">67</span>%|██████▋   | <span class="number">18.0</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:07&lt;<span class="number">00</span>:03, <span class="number">2.50</span>MB/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]:  <span class="number">71</span>%|███████   | <span class="number">19.0</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:07&lt;<span class="number">00</span>:02, <span class="number">3.22</span>MB/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]:  <span class="number">75</span>%|███████▍  | <span class="number">20.0</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:07&lt;<span class="number">00</span>:02, <span class="number">3.34</span>MB/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]:  <span class="number">79</span>%|███████▊  | <span class="number">21.0</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:08&lt;<span class="number">00</span>:02, <span class="number">2.49</span>MB/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]:  <span class="number">82</span>%|████████▏ | <span class="number">22.0</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:09&lt;<span class="number">00</span>:03, <span class="number">1.50</span>MB/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]:  <span class="number">90</span>%|████████▉ | <span class="number">24.0</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:<span class="number">10</span>&lt;<span class="number">00</span>:01, <span class="number">2.41</span>MB/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]:  <span class="number">93</span>%|█████████▎| <span class="number">25.0</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:<span class="number">10</span>&lt;<span class="number">00</span>:<span class="number">00</span>, <span class="number">2.10</span>MB/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]:  <span class="number">97</span>%|█████████▋| <span class="number">26.0</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:<span class="number">11</span>&lt;<span class="number">00</span>:<span class="number">00</span>, <span class="number">2.05</span>MB/s]</span><br><span class="line">Downloading [campplus_cn_en_common.pt]: <span class="number">100</span>%|██████████| <span class="number">26.7</span>M/<span class="number">26.7</span>M [<span class="number">00</span>:<span class="number">11</span>&lt;<span class="number">00</span>:<span class="number">00</span>, <span class="number">2.40</span>MB/s]</span><br><span class="line">Processing <span class="number">9</span> items: <span class="number">100</span>%|██████████| <span class="number">9.00</span>/<span class="number">9.00</span> [<span class="number">00</span>:<span class="number">11</span>&lt;<span class="number">00</span>:<span class="number">00</span>, <span class="number">1.30</span>s/it]</span><br><span class="line"><span class="number">2025</span>-02-<span class="number">11</span> <span class="number">17</span>:<span class="number">51</span>:<span class="number">52</span>,<span class="number">177</span> - modelscope - INFO - Download model <span class="string">&#x27;iic/speech_campplus_sv_zh_en_16k-common_advanced&#x27;</span> successfully.</span><br><span class="line"><span class="number">2025</span>-02-<span class="number">11</span> <span class="number">17</span>:<span class="number">51</span>:<span class="number">52</span>,<span class="number">409</span> - modelscope - INFO - initiate model <span class="keyword">from</span> C:\Users\<span class="built_in">chr</span>\.cache\modelscope\hub\iic\speech_campplus_sv_zh_en_16k-common_advanced</span><br><span class="line"><span class="number">2025</span>-02-<span class="number">11</span> <span class="number">17</span>:<span class="number">51</span>:<span class="number">52</span>,<span class="number">410</span> - modelscope - INFO - initiate model <span class="keyword">from</span> location C:\Users\<span class="built_in">chr</span>\.cache\modelscope\hub\iic\speech_campplus_sv_zh_en_16k-common_advanced.</span><br><span class="line"><span class="number">2025</span>-02-<span class="number">11</span> <span class="number">17</span>:<span class="number">51</span>:<span class="number">52</span>,<span class="number">414</span> - modelscope - INFO - initialize model <span class="keyword">from</span> C:\Users\<span class="built_in">chr</span>\.cache\modelscope\hub\iic\speech_campplus_sv_zh_en_16k-common_advanced</span><br><span class="line"><span class="number">2025</span>-02-<span class="number">11</span> <span class="number">17</span>:<span class="number">51</span>:<span class="number">52</span>,<span class="number">422</span> - modelscope - INFO - cuda <span class="keyword">is</span> <span class="keyword">not</span> available, using cpu instead.</span><br><span class="line">D:\Anaconda3\envs\langchain\lib\site-packages\modelscope\models\audio\sv\DTDNN.py:<span class="number">201</span>: FutureWarning: You are using `torch.load` <span class="keyword">with</span> `weights_only=<span class="literal">False</span>` (the current default value), which uses the default pickle module implicitly. It <span class="keyword">is</span> possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md<span class="comment">#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don&#x27;t have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.</span></span><br><span class="line">  torch.load(</span><br><span class="line"><span class="number">2025</span>-02-<span class="number">11</span> <span class="number">17</span>:<span class="number">51</span>:<span class="number">52</span>,<span class="number">673</span> - modelscope - WARNING - No preprocessor field found <span class="keyword">in</span> cfg.</span><br><span class="line"><span class="number">2025</span>-02-<span class="number">11</span> <span class="number">17</span>:<span class="number">51</span>:<span class="number">52</span>,<span class="number">673</span> - modelscope - WARNING - No val key <span class="keyword">and</span> <span class="built_in">type</span> key found <span class="keyword">in</span> preprocessor domain of configuration.json file.</span><br><span class="line"><span class="number">2025</span>-02-<span class="number">11</span> <span class="number">17</span>:<span class="number">51</span>:<span class="number">52</span>,<span class="number">673</span> - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: &#123;<span class="string">&#x27;model_dir&#x27;</span>: <span class="string">&#x27;C:\\Users\\chr\\.cache\\modelscope\\hub\\iic\\speech_campplus_sv_zh_en_16k-common_advanced&#x27;</span>&#125;. trying to build by task <span class="keyword">and</span> model information.</span><br><span class="line"><span class="number">2025</span>-02-<span class="number">11</span> <span class="number">17</span>:<span class="number">51</span>:<span class="number">52</span>,<span class="number">673</span> - modelscope - WARNING - No preprocessor key (<span class="string">&#x27;cam++-sv&#x27;</span>, <span class="string">&#x27;speaker-verification&#x27;</span>) found <span class="keyword">in</span> PREPROCESSOR_MAP, skip building preprocessor.</span><br><span class="line"><span class="number">2025</span>-02-<span class="number">11</span> <span class="number">17</span>:<span class="number">51</span>:<span class="number">52</span>,<span class="number">677</span> - modelscope - INFO - cuda <span class="keyword">is</span> <span class="keyword">not</span> available, using cpu instead.</span><br><span class="line">&#123;<span class="string">&#x27;score&#x27;</span>: <span class="number">0.66675</span>, <span class="string">&#x27;text&#x27;</span>: <span class="string">&#x27;yes&#x27;</span>&#125;</span><br><span class="line">&#123;<span class="string">&#x27;score&#x27;</span>: <span class="number">0.06705</span>, <span class="string">&#x27;text&#x27;</span>: <span class="string">&#x27;no&#x27;</span>&#125;</span><br><span class="line">&#123;<span class="string">&#x27;score&#x27;</span>: <span class="number">0.06705</span>, <span class="string">&#x27;text&#x27;</span>: <span class="string">&#x27;no&#x27;</span>&#125;</span><br><span class="line">[[ <span class="number">5.17292559e-01</span>  <span class="number">3.51756930e-01</span> -<span class="number">5.19109607e-01</span>  <span class="number">1.04136956e+00</span></span><br><span class="line">  -<span class="number">8.84463251e-01</span>  <span class="number">1.86093241e-01</span> -<span class="number">7.06084728e-01</span> -<span class="number">1.14493757e-01</span></span><br><span class="line">  -<span class="number">4.59557921e-02</span>  <span class="number">8.43211293e-01</span> -<span class="number">4.84604180e-01</span>  <span class="number">7.73771107e-01</span></span><br><span class="line">   <span class="number">5.21692932e-01</span> -<span class="number">6.00100309e-02</span>  <span class="number">5.60589850e-01</span> -<span class="number">2.14882836e-01</span></span><br><span class="line">  -<span class="number">4.54094410e-02</span>  <span class="number">1.47872639e+00</span> -<span class="number">5.22940993e-01</span> -<span class="number">2.57876813e-01</span></span><br><span class="line">  -<span class="number">9.69329894e-01</span> -<span class="number">4.64182615e-01</span>  <span class="number">8.96886945e-01</span> -<span class="number">8.14425230e-01</span></span><br><span class="line">  -<span class="number">4.68755901e-01</span>  <span class="number">9.49460089e-01</span>  <span class="number">1.12195504e+00</span> -<span class="number">1.54829323e-02</span></span><br><span class="line">  -<span class="number">1.00103891e+00</span>  <span class="number">2.16494590e-01</span> -<span class="number">5.27387917e-01</span>  <span class="number">1.17877491e-01</span></span><br><span class="line">  -<span class="number">2.15744048e-01</span>  <span class="number">3.73795688e-01</span> -<span class="number">1.35419041e-01</span>  <span class="number">1.53922290e-01</span></span><br><span class="line">  -<span class="number">1.19627900e-01</span> -<span class="number">5.01048803e-01</span>  <span class="number">5.88355064e-02</span> -<span class="number">3.22206885e-01</span></span><br><span class="line">  -<span class="number">5.98066866e-01</span>  <span class="number">7.55107403e-03</span>  <span class="number">1.73359513e-02</span>  <span class="number">1.94534451e-01</span></span><br><span class="line">   <span class="number">2.74982810e-01</span>  <span class="number">8.69932890e-01</span>  <span class="number">1.19620025e-01</span> -<span class="number">2.21478686e-01</span></span><br><span class="line">  -<span class="number">7.24950612e-01</span>  <span class="number">9.44164038e-01</span> -<span class="number">1.06343377e+00</span>  <span class="number">3.97718161e-01</span></span><br><span class="line">   <span class="number">8.16908181e-02</span>  <span class="number">3.06026936e-01</span>  <span class="number">4.76752698e-01</span> -<span class="number">9.23305750e-03</span></span><br><span class="line">  -<span class="number">8.83808494e-01</span> -<span class="number">6.84341550e-01</span> -<span class="number">7.87354589e-01</span> -<span class="number">3.96643579e-01</span></span><br><span class="line">   <span class="number">9.05797243e-01</span>  <span class="number">1.10675704e+00</span>  <span class="number">5.30054748e-01</span> -<span class="number">3.84964705e-01</span></span><br><span class="line">   <span class="number">2.64517397e-01</span>  <span class="number">1.62003934e-01</span>  <span class="number">7.51856685e-01</span> -<span class="number">2.92150199e-01</span></span><br><span class="line">  -<span class="number">2.36718655e-01</span> -<span class="number">2.30451941e-01</span> -<span class="number">5.44483185e-01</span> -<span class="number">9.03511643e-02</span></span><br><span class="line">  -<span class="number">4.38859731e-01</span> -<span class="number">4.57940936e-01</span>  <span class="number">1.22628438e+00</span>  <span class="number">8.45105052e-01</span></span><br><span class="line">  -<span class="number">3.02865386e-01</span> -<span class="number">1.12381375e+00</span> -<span class="number">9.06042695e-01</span> -<span class="number">7.30945691e-02</span></span><br><span class="line">   <span class="number">7.12829977e-02</span>  <span class="number">5.69367051e-01</span>  <span class="number">3.02581012e-01</span>  <span class="number">4.60172236e-01</span></span><br><span class="line">  -<span class="number">3.80096495e-01</span>  <span class="number">5.49874485e-01</span>  <span class="number">4.31633592e-02</span> -<span class="number">1.28434777e-01</span></span><br><span class="line">  -<span class="number">3.43303561e-01</span> -<span class="number">1.93311483e-01</span> -<span class="number">3.29556495e-01</span> -<span class="number">4.82387066e-01</span></span><br><span class="line">  -<span class="number">6.99172556e-01</span>  <span class="number">9.15286541e-02</span> -<span class="number">7.82371938e-01</span>  <span class="number">2.61282325e-01</span></span><br><span class="line">  -<span class="number">5.33845603e-01</span>  <span class="number">1.07789731e+00</span> -<span class="number">4.53783393e-01</span> -<span class="number">1.72081560e-01</span></span><br><span class="line">  -<span class="number">1.39055848e-02</span>  <span class="number">2.54161805e-02</span>  <span class="number">6.15289286e-02</span> -<span class="number">1.92653209e-01</span></span><br><span class="line">   <span class="number">1.19427991e+00</span> -<span class="number">3.27776909e-01</span> -<span class="number">8.29883754e-01</span>  <span class="number">6.54659748e-01</span></span><br><span class="line">   <span class="number">2.49716938e-01</span>  <span class="number">8.99712503e-01</span>  <span class="number">3.86061668e-01</span>  <span class="number">1.30253151e-01</span></span><br><span class="line">   <span class="number">8.22714567e-01</span> -<span class="number">3.76180500e-01</span>  <span class="number">1.74437940e-01</span> -<span class="number">5.13129532e-01</span></span><br><span class="line">  -<span class="number">4.34209645e-01</span>  <span class="number">9.74657416e-01</span> -<span class="number">1.05046511e+00</span> -<span class="number">1.09075785e-01</span></span><br><span class="line">  -<span class="number">2.31605679e-01</span>  <span class="number">5.99238396e-01</span> -<span class="number">1.51118135e+00</span>  <span class="number">7.44090855e-01</span></span><br><span class="line">  -<span class="number">1.90891251e-01</span> -<span class="number">4.40841556e-01</span>  <span class="number">1.02210104e+00</span> -<span class="number">2.54133761e-01</span></span><br><span class="line">   <span class="number">8.02177846e-01</span> -<span class="number">8.05513710e-02</span>  <span class="number">4.17059243e-01</span> -<span class="number">9.72769558e-02</span></span><br><span class="line">  -<span class="number">9.29510295e-02</span> -<span class="number">3.53281915e-01</span>  <span class="number">2.89921045e-01</span> -<span class="number">2.42230371e-01</span></span><br><span class="line">  -<span class="number">6.14224136e-01</span>  <span class="number">7.31607139e-01</span>  <span class="number">7.88372993e-01</span> -<span class="number">2.74549931e-01</span></span><br><span class="line">  -<span class="number">4.67905670e-01</span>  <span class="number">1.52577460e-01</span>  <span class="number">1.48346639e+00</span> -<span class="number">6.66111171e-01</span></span><br><span class="line">   <span class="number">2.17945620e-01</span> -<span class="number">7.95153007e-02</span>  <span class="number">1.85961217e-01</span>  <span class="number">1.15073085e-01</span></span><br><span class="line">   <span class="number">3.58417809e-01</span> -<span class="number">6.94913507e-01</span> -<span class="number">2.00562179e-01</span> -<span class="number">1.54712462e+00</span></span><br><span class="line">   <span class="number">9.81292009e-01</span>  <span class="number">8.26795280e-01</span>  <span class="number">7.15665519e-02</span> -<span class="number">9.62617457e-01</span></span><br><span class="line">   <span class="number">5.09188056e-01</span> -<span class="number">4.38147187e-02</span>  <span class="number">1.20770991e-01</span>  <span class="number">6.51952267e-01</span></span><br><span class="line">   <span class="number">2.24566415e-01</span> -<span class="number">6.61961317e-01</span> -<span class="number">7.10181653e-01</span> -<span class="number">6.14712238e-02</span></span><br><span class="line">   <span class="number">8.87019038e-01</span> -<span class="number">2.26258770e-01</span>  <span class="number">2.09042192e-01</span> -<span class="number">4.44577336e-02</span></span><br><span class="line">   <span class="number">5.74253201e-01</span>  <span class="number">2.51746982e-01</span>  <span class="number">9.16980624e-01</span> -<span class="number">9.91094634e-02</span></span><br><span class="line">  -<span class="number">1.21540618e+00</span> -<span class="number">5.14432073e-01</span> -<span class="number">6.20832205e-01</span>  <span class="number">5.94622552e-01</span></span><br><span class="line">  -<span class="number">3.11303854e-01</span>  <span class="number">5.03932536e-01</span>  <span class="number">4.79328573e-01</span>  <span class="number">8.39833319e-02</span></span><br><span class="line">  -<span class="number">6.90203846e-01</span> -<span class="number">4.30748940e-01</span> -<span class="number">4.96636212e-01</span> -<span class="number">5.60464203e-01</span></span><br><span class="line">   <span class="number">1.27690360e-01</span> -<span class="number">5.91111362e-01</span>  <span class="number">6.79141521e-01</span> -<span class="number">1.45777613e-01</span></span><br><span class="line">   <span class="number">4.13525581e-01</span>  <span class="number">5.22236824e-01</span>  <span class="number">4.90390390e-01</span>  <span class="number">8.48809719e-01</span>]</span><br><span class="line"> [ <span class="number">3.15564185e-01</span>  <span class="number">4.57967043e-01</span> -<span class="number">4.94653881e-01</span>  <span class="number">6.57682896e-01</span></span><br><span class="line">  -<span class="number">4.51911688e-01</span> -<span class="number">5.90668023e-01</span> -<span class="number">4.62758869e-01</span>  <span class="number">8.63914073e-01</span></span><br><span class="line">   <span class="number">8.74602020e-01</span>  <span class="number">3.85936528e-01</span> -<span class="number">3.78984511e-01</span>  <span class="number">5.50751984e-02</span></span><br><span class="line">  -<span class="number">4.65507030e-01</span> -<span class="number">8.40046555e-02</span> -<span class="number">5.19473851e-03</span>  <span class="number">1.10222042e-01</span></span><br><span class="line">  -<span class="number">6.22997403e-01</span> -<span class="number">7.10828304e-01</span>  <span class="number">3.81044805e-01</span> -<span class="number">8.32391381e-02</span></span><br><span class="line">   <span class="number">2.97066033e-01</span>  <span class="number">3.62760156e-01</span> -<span class="number">2.54004717e-01</span>  <span class="number">5.34730077e-01</span></span><br><span class="line">  -<span class="number">9.28971231e-01</span>  <span class="number">1.34461880e-01</span> -<span class="number">6.27328813e-01</span> -<span class="number">1.30564496e-01</span></span><br><span class="line">   <span class="number">8.80748332e-02</span> -<span class="number">7.82362044e-01</span> -<span class="number">4.40445215e-01</span>  <span class="number">8.15549135e-01</span></span><br><span class="line">  -<span class="number">1.85342640e-01</span> -<span class="number">5.37359416e-01</span>  <span class="number">6.61574423e-01</span>  <span class="number">7.33562648e-01</span></span><br><span class="line">   <span class="number">1.96874350e-01</span>  <span class="number">2.51633137e-01</span> -<span class="number">5.20558178e-01</span>  <span class="number">3.16209406e-01</span></span><br><span class="line">  -<span class="number">2.16073051e-01</span>  <span class="number">7.34751105e-01</span>  <span class="number">2.39810407e-01</span> -<span class="number">2.94980928e-02</span></span><br><span class="line">  -<span class="number">2.09395558e-01</span>  <span class="number">8.97269487e-01</span>  <span class="number">9.30367827e-01</span>  <span class="number">1.29151270e-01</span></span><br><span class="line">  -<span class="number">4.42958087e-01</span>  <span class="number">5.96124351e-01</span> -<span class="number">1.33888125e-02</span> -<span class="number">1.97758794e-01</span></span><br><span class="line">  -<span class="number">1.19977486e+00</span>  <span class="number">3.11827540e-01</span>  <span class="number">1.02562070e+00</span>  <span class="number">2.68472373e-01</span></span><br><span class="line">   <span class="number">2.87927538e-01</span> -<span class="number">1.93298161e-02</span> -<span class="number">6.61130130e-01</span> -<span class="number">1.50255144e-01</span></span><br><span class="line">  -<span class="number">2.03645170e-01</span> -<span class="number">3.59881043e-01</span>  <span class="number">4.36608911e-01</span>  <span class="number">8.33720744e-01</span></span><br><span class="line">   <span class="number">5.38385570e-01</span> -<span class="number">5.74404895e-01</span>  <span class="number">1.07515907e+00</span>  <span class="number">9.43793476e-01</span></span><br><span class="line">   <span class="number">7.93444753e-01</span>  <span class="number">1.82356954e-01</span> -<span class="number">1.03665091e-01</span>  <span class="number">7.72922933e-02</span></span><br><span class="line">   <span class="number">1.46000326e-01</span>  <span class="number">3.47233146e-01</span> -<span class="number">4.96966898e-01</span>  <span class="number">3.10336739e-01</span></span><br><span class="line">  -<span class="number">2.02182326e-02</span> -<span class="number">3.96373332e-01</span>  <span class="number">4.41722274e-02</span> -<span class="number">6.83741868e-01</span></span><br><span class="line">   <span class="number">1.38280725e+00</span>  <span class="number">7.01525509e-01</span>  <span class="number">1.23545921e+00</span> -<span class="number">9.07853723e-01</span></span><br><span class="line">  -<span class="number">6.90056920e-01</span>  <span class="number">4.35101867e-01</span> -<span class="number">2.04400703e-01</span> -<span class="number">7.76575983e-01</span></span><br><span class="line">  -<span class="number">1.36691511e+00</span> -<span class="number">6.62955493e-02</span> -<span class="number">3.98840904e-01</span>  <span class="number">8.06303442e-01</span></span><br><span class="line">  -<span class="number">4.37378556e-01</span> -<span class="number">9.84914899e-02</span>  <span class="number">8.84133279e-02</span> -<span class="number">8.12064528e-01</span></span><br><span class="line">   <span class="number">1.07465684e-02</span> -<span class="number">4.01330411e-01</span>  <span class="number">6.80235505e-01</span>  <span class="number">7.63685465e-01</span></span><br><span class="line">   <span class="number">1.58732682e-01</span>  <span class="number">3.67013425e-01</span>  <span class="number">3.19862068e-02</span> -<span class="number">2.44175047e-01</span></span><br><span class="line">   <span class="number">2.53655404e-01</span>  <span class="number">9.12933707e-01</span> -<span class="number">4.69770804e-02</span>  <span class="number">6.44307971e-01</span></span><br><span class="line">   <span class="number">1.49383228e-02</span>  <span class="number">2.61292070e-01</span> -<span class="number">6.32562160e-01</span> -<span class="number">3.49105418e-01</span></span><br><span class="line">  -<span class="number">4.75405365e-01</span> -<span class="number">6.52082801e-01</span>  <span class="number">5.21956563e-01</span>  <span class="number">9.67081189e-02</span></span><br><span class="line">  -<span class="number">1.32706627e-01</span> -<span class="number">2.04909891e-01</span>  <span class="number">3.35076064e-01</span> -<span class="number">6.14212632e-01</span></span><br><span class="line">   <span class="number">1.15394831e+00</span>  <span class="number">1.23360729e+00</span> -<span class="number">2.94713438e-01</span>  <span class="number">5.84973454e-01</span></span><br><span class="line">  -<span class="number">3.37145239e-01</span>  <span class="number">1.29075080e-01</span>  <span class="number">9.09939706e-02</span> -<span class="number">8.49090099e-01</span></span><br><span class="line">   <span class="number">5.97871602e-01</span>  <span class="number">4.67231959e-01</span>  <span class="number">7.34776258e-04</span>  <span class="number">5.30537724e-01</span></span><br><span class="line">  -<span class="number">9.21570659e-02</span> -<span class="number">3.04171085e-01</span> -<span class="number">5.05705416e-01</span> -<span class="number">2.09868699e-01</span></span><br><span class="line">   <span class="number">2.11636186e-01</span>  <span class="number">7.23479390e-01</span> -<span class="number">2.44709343e-01</span> -<span class="number">6.41815186e-01</span></span><br><span class="line">  -<span class="number">2.89389044e-01</span>  <span class="number">5.78832030e-01</span> -<span class="number">1.12853718e+00</span>  <span class="number">9.20033813e-01</span></span><br><span class="line">  -<span class="number">5.97535789e-01</span> -<span class="number">2.32375890e-01</span>  <span class="number">1.47983253e-01</span>  <span class="number">1.73475608e-01</span></span><br><span class="line">   <span class="number">1.11372106e-01</span> -<span class="number">1.11495459e+00</span> -<span class="number">5.47205508e-01</span> -<span class="number">5.25614560e-01</span></span><br><span class="line">   <span class="number">7.83065557e-02</span>  <span class="number">3.37094992e-01</span> -<span class="number">4.04473186e-01</span> -<span class="number">3.56748551e-01</span></span><br><span class="line">  -<span class="number">1.10799873e+00</span> -<span class="number">1.43664896e-01</span> -<span class="number">1.92755520e-01</span> -<span class="number">5.26487410e-01</span></span><br><span class="line">   <span class="number">1.35022593e+00</span>  <span class="number">1.07109398e-02</span>  <span class="number">9.16564941e-01</span>  <span class="number">3.09872508e-01</span></span><br><span class="line">  -<span class="number">3.61863613e-01</span>  <span class="number">9.91901100e-01</span>  <span class="number">4.22148585e-01</span>  <span class="number">5.31754851e-01</span></span><br><span class="line">   <span class="number">1.30577040e+00</span> -<span class="number">2.45162472e-02</span> -<span class="number">3.92629087e-01</span>  <span class="number">2.64692843e-01</span></span><br><span class="line">  -<span class="number">1.76238507e-01</span>  <span class="number">1.78861052e-01</span>  <span class="number">4.46414322e-01</span> -<span class="number">6.35122657e-01</span></span><br><span class="line">   <span class="number">4.95202839e-02</span>  <span class="number">5.47002256e-03</span> -<span class="number">2.41250843e-01</span>  <span class="number">1.43662542e-01</span></span><br><span class="line">  -<span class="number">3.43859792e-01</span> -<span class="number">5.02784669e-01</span> -<span class="number">5.02928913e-01</span> -<span class="number">1.25779867e-01</span></span><br><span class="line">   <span class="number">2.29348108e-01</span> -<span class="number">2.40141839e-01</span> -<span class="number">1.79208696e-01</span> -<span class="number">2.16224715e-02</span></span><br><span class="line">   <span class="number">7.27228999e-01</span>  <span class="number">4.39823978e-02</span>  <span class="number">5.71268380e-01</span>  <span class="number">3.78142953e-01</span>]] &#123;<span class="string">&#x27;score&#x27;</span>: <span class="number">0.06705</span>, <span class="string">&#x27;text&#x27;</span>: <span class="string">&#x27;no&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">进程已结束，退出代码为 <span class="number">0</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>同时也出现个新文件夹包含说话人的embedding：</p>
</li>
</ul>
<img src="/2025/02/11/%E8%AF%B4%E8%AF%9D%E4%BA%BA%E7%A1%AE%E8%AE%A4%E4%B9%8BCAM/image-20250211175900335.png" class="" title="image-20250211175900335">

<p>好，目前看下来还不错，用实际的录音测试下效果：</p>
<p>准备了五条音频：</p>
<img src="/2025/02/11/%E8%AF%B4%E8%AF%9D%E4%BA%BA%E7%A1%AE%E8%AE%A4%E4%B9%8BCAM/image-20250211181501480.png" class="" title="image-20250211181501480">

<p>两条中文（zh），两条英文（en），一条先中后英，设计几组实验：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> modelscope.pipelines <span class="keyword">import</span> pipeline</span><br><span class="line">sv_pipeline = pipeline(</span><br><span class="line">    task=<span class="string">&#x27;speaker-verification&#x27;</span>,</span><br><span class="line">    model=<span class="string">&#x27;iic/speech_campplus_sv_zh_en_16k-common_advanced&#x27;</span>,</span><br><span class="line">    model_revision=<span class="string">&#x27;v1.0.0&#x27;</span></span><br><span class="line">)</span><br><span class="line">en1 = <span class="string">&quot;en.wav&quot;</span></span><br><span class="line">en2 = <span class="string">&quot;en2.wav&quot;</span></span><br><span class="line">zh1 = <span class="string">&quot;zh.wav&quot;</span></span><br><span class="line">zh2 = <span class="string">&quot;zh2.wav&quot;</span></span><br><span class="line">zh_en = <span class="string">&quot;zh_en.wav&quot;</span></span><br><span class="line"></span><br><span class="line">result = sv_pipeline([zh1, zh2])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;zh1-zh2=<span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">result = sv_pipeline([zh1, en1])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;zh1-en1=<span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">result = sv_pipeline([zh2, en2])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;zh2-en2=<span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">result = sv_pipeline([en1, en2])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;en1-en2=<span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">result = sv_pipeline([en1, zh1])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;en1-zh1=<span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">result = sv_pipeline([en1, zh_en])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;en1-zh_en=<span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">result = sv_pipeline([zh1, zh_en])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;zh1-zh_en=<span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>对比项</th>
<th>分数</th>
</tr>
</thead>
<tbody><tr>
<td>zh1-zh2</td>
<td>0.72488</td>
</tr>
<tr>
<td>zh1-en1</td>
<td>0.5038</td>
</tr>
<tr>
<td>zh2-en2</td>
<td>0.4602</td>
</tr>
<tr>
<td>en1-en2</td>
<td>0.77959</td>
</tr>
<tr>
<td>en1-zh1</td>
<td>0.5038</td>
</tr>
<tr>
<td>en1-zh_en</td>
<td>0.67625</td>
</tr>
<tr>
<td>zh1-zh_en</td>
<td>0.71017</td>
</tr>
</tbody></table>
<p>从上表可以看出：</p>
<ul>
<li>zh1-en1与en1-zh1分数一样（0.5038），故与顺序无关</li>
<li>同语言情况下比跨语言情况得分明显要高</li>
<li>双语情况下比同语言情况得分略低一点</li>
</ul>
<h2 id="微服务"><a href="#微服务" class="headerlink" title="微服务"></a>微服务</h2><p>完事，万事俱备，制作个微服务玩玩，<a href="https://caihaoran-00.github.io/2025/02/05/fastapi-request%E6%9E%84%E5%BB%BA%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BE%AE%E6%9C%8D%E5%8A%A1/">参考</a>，但是在做现在这个微服务的时候发现<strong>原来的代码写的有bug</strong>（主要是因为那篇直接去看效果了，没有保存音频看看，但是那篇不想动了，有缘人对比看这篇就知道哪里有bug了，原因在于在有声段前添加VAD扔掉的几个512段，但逻辑写错了，应该每次有声段只添加一次🤺）：</p>
<p>服务端代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> base64</span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"><span class="keyword">from</span> pydantic <span class="keyword">import</span> BaseModel</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> modelscope.pipelines <span class="keyword">import</span> pipeline</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> fastapi.responses <span class="keyword">import</span> JSONResponse</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> soundfile <span class="keyword">as</span> sf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sv_pipeline = pipeline(</span><br><span class="line">    task=<span class="string">&#x27;speaker-verification&#x27;</span>,</span><br><span class="line">    model=<span class="string">&#x27;iic/speech_campplus_sv_zh_en_16k-common_advanced&#x27;</span>,</span><br><span class="line">    model_revision=<span class="string">&#x27;v1.0.0&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义注册音频目录</span></span><br><span class="line">REGISTERED_DIR = <span class="string">&quot;./registered_audio&quot;</span></span><br><span class="line">REGISTERED_PATH = os.path.join(REGISTERED_DIR, <span class="string">&quot;registered.wav&quot;</span>)</span><br><span class="line">threshold = <span class="number">0.4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建FASTAPI实例</span></span><br><span class="line">app = FastAPI(title=<span class="string">&quot;sv_cam++&quot;</span>)</span><br><span class="line">regist_samples = []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AudioData</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    audio_base64: <span class="built_in">str</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查询是否有声纹注册文件</span></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">&quot;/check/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_registered</span>():</span><br><span class="line">    <span class="keyword">global</span> regist_samples</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(REGISTERED_PATH):</span><br><span class="line">        <span class="keyword">return</span> JSONResponse(status_code=<span class="number">404</span>, content=&#123;<span class="string">&quot;message&quot;</span>: <span class="string">&quot;File not found&quot;</span>&#125;)</span><br><span class="line">    regist_samples, _ = sf.read(REGISTERED_PATH)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;message&quot;</span>: <span class="string">&quot;File exists&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注册声纹</span></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/register/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">register</span>(<span class="params">audio_data: AudioData</span>):</span><br><span class="line">    <span class="keyword">global</span> regist_samples</span><br><span class="line">    <span class="comment"># 1 解析 Base64 编码的音频数据</span></span><br><span class="line">    audio_bytes = base64.b64decode(audio_data.audio_base64)</span><br><span class="line"></span><br><span class="line">    audio_array = np.frombuffer(audio_bytes, dtype=np.int16)</span><br><span class="line"></span><br><span class="line">    regist_samples = audio_array.astype(np.float32) / <span class="number">32768.0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存音频文件（int16, 16000Hz）</span></span><br><span class="line">    <span class="comment"># sf.write(REGISTERED_PATH, audio_array, samplerate=16000, subtype=&quot;PCM_16&quot;)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;message&quot;</span>: <span class="string">&quot;Audio saved successfully&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">&quot;/verify/&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sv_endpoint</span>(<span class="params">audio_data: AudioData</span>):</span><br><span class="line">    audio_bytes = base64.b64decode(audio_data.audio_base64)</span><br><span class="line"></span><br><span class="line">    audio_array = np.frombuffer(audio_bytes, dtype=np.int16)</span><br><span class="line"></span><br><span class="line">    current_samples = audio_array.astype(np.float32) / <span class="number">32768.0</span></span><br><span class="line"></span><br><span class="line">    result = sv_pipeline([regist_samples, current_samples], thr=<span class="number">0.28</span>)</span><br><span class="line">    <span class="comment"># print(f&quot;result=&#123;result&#125;&quot;)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">import</span> uvicorn</span><br><span class="line">    uvicorn.run(app, host=<span class="string">&quot;0.0.0.0&quot;</span>, port=<span class="number">8000</span>)</span><br></pre></td></tr></table></figure>



<p>客户端代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> base64</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> pyaudio</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">from</span> queue <span class="keyword">import</span> Queue</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> collections</span><br><span class="line"></span><br><span class="line">torch.set_num_threads(<span class="number">1</span>)</span><br><span class="line">debug_mode = <span class="literal">False</span>  <span class="comment"># 控制是否保存部分音频及打印信息</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载 Silero VAD 模型</span></span><br><span class="line">model, utils = torch.hub.load(repo_or_dir=<span class="string">&#x27;snakers4/silero-vad&#x27;</span>,</span><br><span class="line">                              model=<span class="string">&#x27;silero_vad&#x27;</span>,</span><br><span class="line">                              trust_repo=<span class="literal">True</span>,</span><br><span class="line">                              onnx=<span class="literal">True</span>,</span><br><span class="line">                              <span class="comment"># force_reload=True</span></span><br><span class="line">                              )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 录音参数</span></span><br><span class="line">FORMAT = pyaudio.paFloat32</span><br><span class="line">CHANNELS = <span class="number">1</span></span><br><span class="line">SAMPLE_RATE = <span class="number">16000</span></span><br><span class="line">num_samples = <span class="number">512</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 PyAudio</span></span><br><span class="line">audio = pyaudio.PyAudio()</span><br><span class="line">stream = audio.<span class="built_in">open</span>(<span class="built_in">format</span>=FORMAT,</span><br><span class="line">                    channels=CHANNELS,</span><br><span class="line">                    rate=SAMPLE_RATE,</span><br><span class="line">                    <span class="built_in">input</span>=<span class="literal">True</span>,</span><br><span class="line">                    frames_per_buffer=num_samples)</span><br><span class="line"></span><br><span class="line">audio_record_queue = Queue()</span><br><span class="line">BASE_URL = <span class="string">&quot;http://127.0.0.1:8000&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">StateManage</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.threshold = <span class="number">0.5</span></span><br><span class="line">        <span class="variable language_">self</span>.min_speech_duration_ms = <span class="number">64</span></span><br><span class="line">        <span class="variable language_">self</span>.min_silence_duration_ms = <span class="number">480</span></span><br><span class="line">        <span class="variable language_">self</span>.pre_chunk_add = <span class="number">4</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">state_manage = StateManage()</span><br><span class="line"></span><br><span class="line">pre_speech_buffer = collections.deque(maxlen=state_manage.min_speech_duration_ms // <span class="number">32</span> + state_manage.pre_chunk_add)</span><br><span class="line"><span class="built_in">print</span>(state_manage.min_speech_duration_ms // <span class="number">32</span> + state_manage.pre_chunk_add)</span><br><span class="line">first_chunk_detected = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">send_audio_to_server</span>(<span class="params">audio_fragment</span>):</span><br><span class="line">    audio_base64 = base64.b64encode(audio_fragment).decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">&#x27;audio_base64&#x27;</span>: audio_base64,</span><br><span class="line">    &#125;</span><br><span class="line">    response = requests.post(<span class="string">f&quot;<span class="subst">&#123;BASE_URL&#125;</span>/verify/&quot;</span>, json=data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> debug_mode:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;response.json()=<span class="subst">&#123;response.json()&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> response.json()[<span class="string">&#x27;text&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">send_audio_to_regist</span>(<span class="params">audio_fragment</span>):</span><br><span class="line">    audio_base64 = base64.b64encode(audio_fragment).decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">    data = &#123;</span><br><span class="line">        <span class="string">&#x27;audio_base64&#x27;</span>: audio_base64,</span><br><span class="line">    &#125;</span><br><span class="line">    response = requests.post(<span class="string">f&quot;<span class="subst">&#123;BASE_URL&#125;</span>/register/&quot;</span>, json=data)</span><br><span class="line">    <span class="keyword">return</span> response.json()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VADContext</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 threshold=<span class="number">0.5</span>,</span></span><br><span class="line"><span class="params">                 min_speech_duration_ms=<span class="number">64</span>,</span></span><br><span class="line"><span class="params">                 min_silence_duration_ms=<span class="number">480</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.threshold = threshold</span><br><span class="line">        <span class="variable language_">self</span>.min_speech_frames = <span class="built_in">int</span>(min_speech_duration_ms * SAMPLE_RATE / <span class="number">1000</span> / num_samples)</span><br><span class="line">        <span class="variable language_">self</span>.min_silence_frames = <span class="built_in">int</span>(min_silence_duration_ms * SAMPLE_RATE / <span class="number">1000</span> / num_samples)</span><br><span class="line">        <span class="variable language_">self</span>.speech_frame_count = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.silence_frame_count = <span class="number">0</span></span><br><span class="line">        <span class="variable language_">self</span>.is_speech = <span class="literal">False</span></span><br><span class="line">        <span class="variable language_">self</span>.was_speech = <span class="literal">False</span>  <span class="comment"># 跟踪上一帧是否是语音</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, confidence</span>):</span><br><span class="line">        <span class="variable language_">self</span>.was_speech = <span class="variable language_">self</span>.is_speech  <span class="comment"># 保存上一帧的状态</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.is_speech:</span><br><span class="line">            <span class="keyword">if</span> confidence &gt;= <span class="variable language_">self</span>.threshold:</span><br><span class="line">                <span class="variable language_">self</span>.speech_frame_count += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> <span class="variable language_">self</span>.speech_frame_count &gt;= <span class="variable language_">self</span>.min_speech_frames:</span><br><span class="line">                    <span class="variable language_">self</span>.is_speech = <span class="literal">True</span></span><br><span class="line">                    <span class="variable language_">self</span>.silence_frame_count = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.speech_frame_count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> confidence &lt;= <span class="variable language_">self</span>.threshold - <span class="number">0.15</span>:</span><br><span class="line">                <span class="variable language_">self</span>.silence_frame_count += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> <span class="variable language_">self</span>.silence_frame_count &gt;= <span class="variable language_">self</span>.min_silence_frames:</span><br><span class="line">                    <span class="variable language_">self</span>.is_speech = <span class="literal">False</span></span><br><span class="line">                    <span class="variable language_">self</span>.speech_frame_count = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.silence_frame_count = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.is_speech</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">is_speech_end</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;检查是否是语音结束&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.was_speech <span class="keyword">and</span> <span class="keyword">not</span> <span class="variable language_">self</span>.is_speech</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">recording_and_vad_thread</span>():</span><br><span class="line">    <span class="keyword">global</span> first_chunk_detected</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Recording...\n&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">    vad_context = VADContext(</span><br><span class="line">        threshold=state_manage.threshold,</span><br><span class="line">        min_speech_duration_ms=state_manage.min_speech_duration_ms,</span><br><span class="line">        min_silence_duration_ms=state_manage.min_silence_duration_ms,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> debug_mode:</span><br><span class="line">        raw_audio_chunks = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        data = stream.read(num_samples)</span><br><span class="line">        audio_chunk = np.frombuffer(data, dtype=np.float32)</span><br><span class="line">        speech_prob = model(torch.from_numpy(audio_chunk.copy()), SAMPLE_RATE).item()</span><br><span class="line">        is_speech = vad_context.update(speech_prob)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 放入缓冲区</span></span><br><span class="line">        pre_speech_buffer.append(audio_chunk)</span><br><span class="line">        <span class="keyword">if</span> is_speech:</span><br><span class="line">            <span class="comment"># 如果刚检测到语音</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> first_chunk_detected:</span><br><span class="line">                first_chunk_detected = <span class="literal">True</span></span><br><span class="line">                <span class="keyword">while</span> pre_speech_buffer:</span><br><span class="line">                    pre_chunk = pre_speech_buffer.popleft()</span><br><span class="line">                    int16_chunk = (pre_chunk * <span class="number">32767</span>).astype(np.int16)</span><br><span class="line">                    audio_record_queue.put(int16_chunk)</span><br><span class="line">                    <span class="keyword">if</span> debug_mode:</span><br><span class="line">                        raw_audio_chunks.append(int16_chunk)  <span class="comment"># 保存原始数据</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                audio_chunk_int16 = (audio_chunk * <span class="number">32767</span>).astype(np.int16)</span><br><span class="line">                audio_record_queue.put(audio_chunk_int16)</span><br><span class="line">                <span class="keyword">if</span> debug_mode:</span><br><span class="line">                    raw_audio_chunks.append(audio_chunk_int16)   <span class="comment"># 保存原始数据</span></span><br><span class="line">        <span class="keyword">elif</span> vad_context.is_speech_end():</span><br><span class="line">            audio_record_queue.put(<span class="literal">None</span>)</span><br><span class="line">            first_chunk_detected = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> debug_mode <span class="keyword">and</span> raw_audio_chunks:</span><br><span class="line">                raw_audio_data = np.concatenate(raw_audio_chunks)</span><br><span class="line">                sf.write(<span class="string">&quot;debug_raw_audio.wav&quot;</span>, raw_audio_data, samplerate=<span class="number">16000</span>, subtype=<span class="string">&quot;PCM_16&quot;</span>)</span><br><span class="line">                raw_audio_chunks.clear()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动录音线程</span></span><br><span class="line">recording_thread = threading.Thread(target=recording_and_vad_thread, daemon=<span class="literal">True</span>)</span><br><span class="line">recording_thread.start()</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> soundfile <span class="keyword">as</span> sf</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">send_audio</span>():</span><br><span class="line">    audio_chunks = []</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        chunk = audio_record_queue.get()</span><br><span class="line">        <span class="keyword">if</span> chunk <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> audio_chunks:</span><br><span class="line">                audio_data = np.concatenate(audio_chunks)</span><br><span class="line">                <span class="keyword">if</span> debug_mode:</span><br><span class="line">                    sf.write(<span class="string">&quot;audio.wav&quot;</span>, audio_data, samplerate=<span class="number">16000</span>, subtype=<span class="string">&quot;PCM_16&quot;</span>)</span><br><span class="line">                audio_data_bytes = audio_data.tobytes()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 发送到ASR服务器</span></span><br><span class="line">                result = send_audio_to_server(audio_data_bytes)</span><br><span class="line">                <span class="keyword">if</span> debug_mode:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;result: <span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">                audio_chunks.clear()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            audio_chunks.append(chunk)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">regist_voice</span>():</span><br><span class="line">    audio_chunks = []</span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        chunk = audio_record_queue.get()</span><br><span class="line">        <span class="keyword">if</span> chunk <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> audio_chunks:</span><br><span class="line">                audio_data = np.concatenate(audio_chunks)</span><br><span class="line">                audio_data_bytes = audio_data.tobytes()</span><br><span class="line">                <span class="keyword">if</span> debug_mode:</span><br><span class="line">                    sf.write(<span class="string">&quot;regist.wav&quot;</span>, audio_data, samplerate=<span class="number">16000</span>, subtype=<span class="string">&quot;PCM_16&quot;</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 发送到sv服务器</span></span><br><span class="line">                result = send_audio_to_regist(audio_data_bytes)</span><br><span class="line">                <span class="keyword">if</span> result <span class="keyword">and</span> result[<span class="string">&quot;message&quot;</span>] == <span class="string">&quot;Audio saved successfully&quot;</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&quot;声纹注册成功，让我们开始交流吧！&quot;</span>)</span><br><span class="line"></span><br><span class="line">                audio_chunks.clear()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            audio_chunks.append(chunk)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 先查询是否有注册文件</span></span><br><span class="line">    response = requests.get(<span class="string">f&quot;<span class="subst">&#123;BASE_URL&#125;</span>/check/&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;已开启声纹识别&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">elif</span> response.status_code == <span class="number">404</span>:   <span class="comment"># 没有注册文件就提示并注册声纹</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;缺少声纹注册文件，请说一段3 S左右语音以注册声纹。&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;录音中&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line">        regist_voice()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;出错&quot;</span>, flush=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    send_audio()</span><br></pre></td></tr></table></figure>

<img src="/2025/02/11/%E8%AF%B4%E8%AF%9D%E4%BA%BA%E7%A1%AE%E8%AE%A4%E4%B9%8BCAM/image-20250221153341853.png" class="" title="image-20250221153341853">

<p>注意事项：</p>
<ul>
<li>可通过debug_mode设置为True来控制保存音频和打印信息</li>
<li>目前服务端的说话人确认阈值经过简单实验，设置为0.28</li>
<li>目前的思路是，客户端先去查询服务端有没有注册声纹文件，有就开始使用，无则要求注册声纹文件后再使用</li>
<li>目前只是搭建了声纹识别的微服务，后续会把前面的语音识别融入到一起，实现只翻译指定说话人的说话人内容</li>
</ul>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://caihaoran-00.github.io/2025/02/05/fastapi-request%E6%9E%84%E5%BB%BA%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BE%AE%E6%9C%8D%E5%8A%A1/">https://caihaoran-00.github.io/2025/02/05/fastapi-request%E6%9E%84%E5%BB%BA%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E5%BE%AE%E6%9C%8D%E5%8A%A1/</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>cam++</tag>
        <tag>fastapi</tag>
        <tag>speaker verification</tag>
        <tag>sv</tag>
        <tag>eres2net(v2)</tag>
      </tags>
  </entry>
  <entry>
    <title>通俗理解Boosting、随机森林、GBDT、XGBoost</title>
    <url>/2025/05/27/%E9%80%9A%E4%BF%97%E7%90%86%E8%A7%A3Boosting-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97-GBDT-XGBoost/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在<a href="https://caihaoran-00.github.io/2025/04/28/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E8%B0%83%E7%A0%94%EF%BC%9A%E6%8B%9B%E6%A0%87%E6%99%BA%E8%83%BD%E4%BD%93/">解决方案调研：招标智能体</a>一文中，我们使用了XGBoost算法简单做了个demo，但本人对于XGBoost的原理不太清晰，这两天也在了解XGBoost的原理，看到了很多术语：<strong>集成学习</strong>、<strong>boosting</strong>、<strong>随机森林</strong>、<strong>XGBooST</strong>，<strong>GBDT</strong>、<strong>决策树</strong>、<strong>LightGBM</strong>、<strong>CatBoost</strong>，之前对这里的了解几乎为0，所以看着有点糊涂，遂准备捋一下这些术语间的关系与基本原理（尽量避免涉及数学公式，重点有个算法原理的认识）并给出个具象的例子帮助理解。</p>
<span id="more"></span>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph TD</span><br><span class="line">    A[集成学习] --&gt; B[Bagging派]</span><br><span class="line">    A --&gt; C[Boosting派]</span><br><span class="line">    B --&gt; D[随机森林]</span><br><span class="line">    C --&gt; E[GBDT]</span><br><span class="line">    C --&gt; F[XGBoOST]</span><br><span class="line">    G[决策树] --&gt; D &amp; E &amp; F</span><br></pre></td></tr></table></figure>

<p>本文将沿着Boosting算法的发展脉络，从基础概念出发，逐步深入探讨GBDT和XGBoost的原理与实现。</p>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><p>在机器学习领域，集成学习(Ensemble Learning)通过结合多个基学习器的预测结果来获得比单一学习器更优越的性能，分为<strong>Bagging派</strong>和<strong>Boosting派</strong>。Boosting作为集成学习的重要分支，在过去二十多年中发展出了许多强大的算法，其中梯度提升决策树(Gradient Boosting Decision Tree, GBDT)及其改进版本XGBoost在实践中表现出色，成为许多数据科学竞赛和工业应用的标配工具。</p>
<p><strong>什么是集成学习？<strong>就像“众人拾柴火焰高”。在生活中，你可能遇到过一个情况：问一个问题时，不同的人会给出不同的答案。如果你只听一个人，可能听错；但如果你听了一群人，然后取他们的</strong>平均意见</strong>或者让大家<strong>投票决定</strong>，结果往往更靠谱——这就是<strong>集成</strong>的思想。在机器学习中，**集成学习（Ensemble Learning）**就是让多个模型（通常是“弱模型”，比如小决策树）联合决策，从而得到更强大的预测效果。</p>
<p><strong>Bagging：每个人独立思考，再集体表决。<strong>想象一下你要判断“今天是否适合出去野餐”。你问了10个朋友，每个人各自独立做出判断，最后你根据</strong>大多数人的意见来决定</strong>——这就是 Bagging（Bootstrap Aggregating）的思想。</p>
<ul>
<li>每个模型都在“不同的数据子集”上独立训练（想象每个人看的天气预报略有不同）。</li>
<li>最终通过<strong>投票或平均值</strong>来得出结论。</li>
<li>好处：降低模型的不稳定性（即减少“方差”）。</li>
</ul>
<p>📌 <strong>代表算法：随机森林（Random Forest）</strong></p>
<ul>
<li>随机森林就是一大群“迷你决策树”的组合，每棵树都看不同的数据+特征，最后集体投票。</li>
<li>它强在“稳”，不容易过拟合，对数据的分布要求不高。</li>
</ul>
<p>**Boosting：前一个人犯的错，后一个人来补救。**Boosting 更像是一个“学渣逆袭”的故事。</p>
<ul>
<li>第一个模型（弱学生）开始学习，对很多题目都做错了；</li>
<li>第二个模型（第二个学生）被老师派来<strong>专门纠正前一个人的错</strong>；</li>
<li>第三个模型又来补上第二个还没搞定的问题；</li>
<li>最后大家一起交一份“融合答案”，这个结果比任何一个人都要好。</li>
</ul>
<p>📌 <strong>代表算法：GBDT &#x2F; XGBoost</strong></p>
<ul>
<li>每棵树都学着去“修正前一棵树犯下的错误”。</li>
<li>适合复杂问题，比如房价预测、点击率预测、疾病诊断等。</li>
</ul>
<p><strong>打个比方理解两者区别：</strong></p>
<table>
<thead>
<tr>
<th>情境</th>
<th>Bagging（随机森林）</th>
<th>Boosting（XGBoost 等）</th>
</tr>
</thead>
<tbody><tr>
<td>类比</td>
<td>十个人独立做选择，最后投票</td>
<td>第一个人先选，错了后面的人帮忙纠正</td>
</tr>
<tr>
<td>模型结构</td>
<td>并行执行，互不干扰</td>
<td>串行执行，前后相关</td>
</tr>
<tr>
<td>偏差 vs 方差</td>
<td>降低方差</td>
<td>降低偏差</td>
</tr>
<tr>
<td>常用算法</td>
<td>随机森林</td>
<td>GBDT、XGBoost、LightGBM</td>
</tr>
</tbody></table>
<p><strong>实际应用中的例子</strong></p>
<ul>
<li>🏠 <strong>房价预测</strong>：XGBoost 可以根据地段、面积、装修、楼层等信息，逐步纠正错误，提高预测准确率。</li>
<li>📮 <strong>垃圾邮件识别</strong>：随机森林可以对多个特征（是否含有”优惠”、是否频繁发送、发件人域名等）进行独立判断，最后表决是否为垃圾邮件。</li>
<li>📈 <strong>信用评分模型</strong>：Boosting 系列模型能捕捉用户行为中的复杂非线性特征，用于判断是否批准贷款。</li>
</ul>
<p><strong>🔍 梯度提升树 GBDT：老师带着学生逐步进步</strong></p>
<p>GBDT 全称是 <strong>Gradient Boosting Decision Tree</strong>，是 Boosting 思想的经典实现。它通过“梯度”的方式，指导每一棵新树该往哪个方向修正错误。</p>
<p>类比解释：</p>
<p>你可以把 GBDT 想成一个老师带着学生写作文的过程：</p>
<ol>
<li>学生写了第一篇作文，错了很多；</li>
<li>老师不骂他，而是指出：“你这里词汇不够”、“结构太乱”；</li>
<li>学生再写一篇，专门改这些问题；</li>
<li>如此反复，每次改一点，最终作文越来越好。</li>
</ol>
<p>🌱 每棵树都只是“改进器”，而不是“主角”；但所有改进加在一起，就变成了一个很强的模型。</p>
<hr>
<p><strong>🚀 XGBoost：工程师眼中的 GBDT Plus</strong></p>
<p>XGBoost 是对 GBDT 的一次“大规模工程优化”，它的名字来自 <strong>eXtreme Gradient Boosting</strong>。它在机器学习比赛中迅速走红，不仅因为精度高，还因为速度快、功能全。</p>
<p>XGBoost 的主要改进：</p>
<ul>
<li>✅ <strong>支持正则化</strong>：可以防止过拟合（就像考试时给作文字数设限）</li>
<li>✅ <strong>支持并行计算</strong>：速度更快（多个老师一起评分）</li>
<li>✅ <strong>能处理缺失值</strong>：自动选择最优路径</li>
<li>✅ <strong>缓存优化、剪枝机制</strong>：训练过程更智能</li>
</ul>
<p>📌 实际应用场景：广告点击率预测、电商推荐系统、工业检测、Kaggle 冠军作品……</p>
<hr>
<p><strong>⚡️ LightGBM：轻量级、高性能版本</strong></p>
<p>LightGBM 是由微软推出的 Boosting 框架，特别适合“大数据、稀疏数据、高维数据”的场景。</p>
<p>它的核心改进包括：</p>
<ul>
<li>✅ <strong>叶子优先的生长策略（Leaf-wise）</strong>：更快更准</li>
<li>✅ <strong>基于直方图的分裂方式</strong>：节省内存和计算量</li>
<li>✅ <strong>支持类别特征直接输入</strong>（无需独热编码）</li>
</ul>
<p>类比：</p>
<ul>
<li>GBDT&#x2F;XGBoost 是一步步修作文</li>
<li>LightGBM 是直接找出得分最高的改法，跳过中间步骤，更像“聪明型学生”</li>
</ul>
<p>📌 使用场景：广告、CTR预估、推荐系统、海量用户行为建模</p>
<hr>
<p>🧠 CatBoost：猫也能Boost的模型</p>
<p>CatBoost 来自 Yandex（俄罗斯“Google”），它特别适合处理大量<strong>类别型特征（categorical features）</strong>，如性别、城市、职业等。</p>
<p>特点：</p>
<ul>
<li>✅ <strong>自动处理类别特征</strong>（无需独热编码！）</li>
<li>✅ <strong>抗过拟合能力强</strong></li>
<li>✅ <strong>训练时不泄露信息（target leakage）</strong></li>
</ul>
<p>类比：</p>
<ul>
<li>如果 XGBoost、LightGBM 是数理化高手，CatBoost 就是“语文、历史”高分选手，擅长处理文本类、标签类数据。</li>
</ul>
<p>📌 适合：用户画像分析、电商推荐、文本分类等场景</p>
<hr>
<p>🧾 四大 Boosting 工具对比表</p>
<table>
<thead>
<tr>
<th>项目</th>
<th>XGBoost</th>
<th>LightGBM</th>
<th>CatBoost</th>
<th>GBDT 原始版</th>
</tr>
</thead>
<tbody><tr>
<td>速度</td>
<td>较快</td>
<td>非常快</td>
<td>中等</td>
<td>慢</td>
</tr>
<tr>
<td>精度</td>
<td>高</td>
<td>高</td>
<td>高</td>
<td>一般</td>
</tr>
<tr>
<td>内存消耗</td>
<td>中等</td>
<td>低</td>
<td>中等</td>
<td>高</td>
</tr>
<tr>
<td>支持类别特征</td>
<td>❌（需编码）</td>
<td>⚠️（半支持）</td>
<td>✅（天然支持）</td>
<td>❌</td>
</tr>
<tr>
<td>并行能力</td>
<td>有限</td>
<td>强</td>
<td>中等</td>
<td>无</td>
</tr>
<tr>
<td>易用性</td>
<td>好</td>
<td>较好</td>
<td>较好</td>
<td>一般</td>
</tr>
<tr>
<td>推荐场景</td>
<td>综合场景</td>
<td>大规模、高维稀疏数据</td>
<td>类别特征多的数据</td>
<td>教学&#x2F;实验用</td>
</tr>
</tbody></table>
<hr>
<p>🧠 总结 &amp; 如何选型？</p>
<ul>
<li>🔹 想快速上手、有比赛压力？用 <strong>XGBoost</strong>。</li>
<li>🔹 数据大、特征多？用 <strong>LightGBM</strong>。</li>
<li>🔹 类别变量特别多？用 <strong>CatBoost</strong>。</li>
<li>🔹 你是学生，想理解原理？试试最基础的 <strong>GBDT</strong>。</li>
<li>🔹 想稳定、稳健表现？<strong>随机森林</strong>依然是值得信赖的“老将”。</li>
</ul>
<hr>
<p>🎯 结语：一棵树走不远，一片森林撑起未来</p>
<p>这些算法，都是从“决策树”这颗种子长出来的参天大树，有的扎根稳重（随机森林），有的长得快（LightGBM），有的能读懂复杂语义（CatBoost）……它们并不是互相竞争，而是在不同问题、不同数据面前各展所长。</p>
<hr>
<h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><h3 id="✅随机森林-VS-XGBoost"><a href="#✅随机森林-VS-XGBoost" class="headerlink" title="✅随机森林 VS XGBoost"></a>✅随机森林 VS XGBoost</h3><p><strong>🔍 一句话总结：</strong></p>
<table>
<thead>
<tr>
<th>算法</th>
<th>更适合的场景</th>
</tr>
</thead>
<tbody><tr>
<td>随机森林</td>
<td>简单、鲁棒性高、特征噪声多或解释性优先的任务</td>
</tr>
<tr>
<td>XGBoost</td>
<td>复杂模式、精度优先、强非线性关系、特征清洗较好的任务</td>
</tr>
</tbody></table>
<hr>
<p>✅随机森林适合的场景：<strong>稳健、抗噪声、可解释性强</strong></p>
<p><strong>📌 背景机制：</strong></p>
<ul>
<li>它是 Bagging 系列，采用<strong>多棵树并行训练</strong>，每棵树看不同的数据子集和特征。</li>
<li>最终结果是靠**“多数投票”或“平均预测”**。</li>
<li>不太容易过拟合，对“离群点、噪声数据、特征不完美”的容忍度较高。</li>
</ul>
<p><strong>🧠 适合以下场景：</strong></p>
<ol>
<li><strong>数据量不大，但特征数较多</strong>。</li>
<li><strong>训练时间不敏感</strong>，模型稳定性优先。</li>
<li><strong>数据噪声较多、缺失值频繁</strong>。</li>
<li><strong>需要一定的模型解释性</strong>（如：特征重要性排序）。</li>
<li><strong>想做一个“可靠的初始模型”看效果时</strong>。</li>
</ol>
<p><strong>🧪 举例应用场景：</strong></p>
<ul>
<li>医疗诊断初筛（特征不一定非常准确，但希望模型稳）</li>
<li>客户是否流失预测（不求极限精度，但稳定性很重要）</li>
<li>传统金融风控评分（需要能解释模型为何拒绝贷款）</li>
</ul>
<p><strong>🚀 XGBoost适合的场景：复杂特征关系、精度优先、比赛必备</strong></p>
<p><strong>📌 背景机制：</strong></p>
<ul>
<li>它是 Boosting 系列，采用<strong>串行建树</strong>，每棵新树专注于纠正前一棵树的错误。</li>
<li>支持 <strong>梯度下降优化</strong>、<strong>正则化</strong>、<strong>缺失值处理</strong> 等高级技巧。</li>
<li>更容易逼近数据中的复杂非线性关系，但<strong>更容易过拟合</strong>，对参数调节比较敏感。</li>
</ul>
<p><strong>🧠 适合以下场景：</strong></p>
<ol>
<li><strong>特征处理较充分</strong>，且特征质量高。</li>
<li><strong>数据中存在复杂交互关系</strong>（例如：A大但B小的时候才会成交）。</li>
<li><strong>任务对精度要求非常高</strong>。</li>
<li><strong>参加机器学习竞赛、Kaggle、AI项目评估场景</strong>。</li>
<li><strong>可以投入时间进行参数调优</strong>（调参成本比随机森林高）。</li>
</ol>
<p><strong>🧪 举例应用场景：</strong></p>
<ul>
<li>电商用户点击率预测（大量特征交互，需逼近细节）</li>
<li>智能客服意图识别（输入特征复杂且语义不明确）</li>
<li>金融模型风控评分（高精度要求，但愿意做深入调参）</li>
<li>各类 Kaggle 竞赛（XGBoost 曾长期霸榜）</li>
</ul>
<p><strong>📊 总结对比表：</strong></p>
<table>
<thead>
<tr>
<th>项目</th>
<th>随机森林</th>
<th>XGBoost</th>
</tr>
</thead>
<tbody><tr>
<td>学习方式</td>
<td>Bagging（并行）</td>
<td>Boosting（串行）</td>
</tr>
<tr>
<td>偏差与方差</td>
<td>偏差略高，方差低（更“稳”）</td>
<td>偏差低，但方差高（更“灵”）</td>
</tr>
<tr>
<td>对特征要求</td>
<td>低，对噪声容忍</td>
<td>高，特征越干净表现越好</td>
</tr>
<tr>
<td>对缺失值处理</td>
<td>一般需要预处理</td>
<td>内部能自动处理</td>
</tr>
<tr>
<td>是否容易过拟合</td>
<td>不容易</td>
<td>比较容易，需要调参</td>
</tr>
<tr>
<td>参数调节难度</td>
<td>低（开箱即用）</td>
<td>高（依赖学习率、树深、正则等）</td>
</tr>
<tr>
<td>运行速度</td>
<td>较慢（不能并行特征处理）</td>
<td>更快（支持特征并行、增量训练）</td>
</tr>
<tr>
<td>可解释性</td>
<td>强（输出每棵树、特征重要性）</td>
<td>较弱，但支持特征重要性分析</td>
</tr>
<tr>
<td>推荐使用场景</td>
<td>启动模型、粗筛、偏保守任务</td>
<td>精度优先、模型比赛、复杂交互建模</td>
</tr>
</tbody></table>
<p><strong>✅ 实战建议：</strong></p>
<blockquote>
<p>初学者、数据预处理没那么完善、对模型调参不太熟？<br> 👉 <strong>先用随机森林</strong>，快速得到一个基准线，稳、快、不挑食。</p>
</blockquote>
<blockquote>
<p>数据清洗完备、特征工程做得好、想追求更高精度或参赛？<br> 👉 <strong>上 XGBoost&#x2F;LightGBM</strong>，但记得认真调参！</p>
</blockquote>
<hr>
<hr>
<h3 id="✅-逻辑回归-vs-线性回归"><a href="#✅-逻辑回归-vs-线性回归" class="headerlink" title="✅ 逻辑回归 vs 线性回归"></a>✅ 逻辑回归 vs 线性回归</h3><table>
<thead>
<tr>
<th>项目</th>
<th>线性回归（Linear Regression）</th>
<th>逻辑回归（Logistic Regression）</th>
</tr>
</thead>
<tbody><tr>
<td><strong>解决问题类型</strong></td>
<td><strong>预测数值</strong>（回归问题）</td>
<td><strong>预测分类</strong>（分类问题）</td>
</tr>
<tr>
<td><strong>输出结果</strong></td>
<td>一个连续的数字（比如房价是 87 万）</td>
<td>一个概率（比如违约概率是 0.83）</td>
</tr>
<tr>
<td><strong>目标变量类型</strong></td>
<td>连续变量（如价格、温度）</td>
<td>离散变量（如是否违约：是&#x2F;否）</td>
</tr>
<tr>
<td><strong>模型公式</strong></td>
<td>直接输出 Y</td>
<td>用 sigmoid 函数把结果转成概率</td>
</tr>
<tr>
<td><strong>常见用途</strong></td>
<td>房价预测、身高预测</td>
<td>风控、广告点击、疾病预测等</td>
</tr>
<tr>
<td><strong>可解释性</strong></td>
<td>中等</td>
<td>强（可解释每个特征对分类的影响）</td>
</tr>
</tbody></table>
<p><strong>🎯 举个例子更直观：</strong></p>
<p><strong>线性回归：</strong></p>
<blockquote>
<p><strong>问题</strong>：预测一套房子的价格<br> <strong>输入</strong>：面积、房龄、楼层<br> <strong>输出</strong>：87.5 万元（一个数）</p>
</blockquote>
<p><strong>逻辑回归：</strong></p>
<blockquote>
<p><strong>问题</strong>：预测一个人是否会贷款违约<br> <strong>输入</strong>：收入、年龄、是否有房<br> <strong>输出</strong>：违约概率 &#x3D; 83%<br> <strong>分类</strong>：因为 83% &gt; 50%，所以 → 判定为“会违约”</p>
</blockquote>
<p><strong>✅ 结论</strong></p>
<blockquote>
<ul>
<li>逻辑回归不是线性回归，它是“用线性模型 + sigmoid 函数”来解决<strong>分类问题</strong>的算法。</li>
<li>逻辑回归处理的是<strong>是否会发生</strong>的事，线性回归处理的是<strong>会发生多少</strong>的事。</li>
</ul>
</blockquote>
<p><strong>可以简单地记：</strong></p>
<ul>
<li><strong>线性回归：预测值</strong></li>
<li><strong>逻辑回归：预测概率+分类</strong></li>
</ul>
<hr>
<hr>
<h3 id="✅-解释性优先用随机森林？"><a href="#✅-解释性优先用随机森林？" class="headerlink" title="✅ 解释性优先用随机森林？"></a>✅ 解释性优先用随机森林？</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">graph TD</span><br><span class="line">    A[需要解释预测?] --&gt;|否| B(优先XGBoost)</span><br><span class="line">    A --&gt;|是| C&#123;解释类型?&#125;</span><br><span class="line">    C --&gt;|向非技术人员展示| D[随机森林+单树可视化]</span><br><span class="line">    C --&gt;|向数据团队深挖原因| E[XGBoost+SHAP]</span><br><span class="line">    C --&gt;|合规性文档要求| D</span><br><span class="line">    D --&gt; F&#123;样本量?&#125;</span><br><span class="line">    F --&gt;|小/中| G[保持随机森林]</span><br><span class="line">    F --&gt;|极大| H[考虑XGBoost+子采样]</span><br></pre></td></tr></table></figure>

<p><strong>✅ 首先明确：随机森林 vs XGBoost 本身的可解释性谁更强？</strong></p>
<table>
<thead>
<tr>
<th>项目</th>
<th>随机森林</th>
<th>XGBoost</th>
</tr>
</thead>
<tbody><tr>
<td><strong>模型结构</strong></td>
<td>一组并行决策树，较容易观察</td>
<td>一组按顺序叠加的弱分类器，结构更复杂</td>
</tr>
<tr>
<td><strong>内建解释性工具</strong></td>
<td>特征重要性（feature importance）直接可用</td>
<td>特征重要性可用，但解释某个预测需要额外工具</td>
</tr>
<tr>
<td><strong>配合 SHAP 后的解释能力</strong></td>
<td>提升明显，但模型仍较简单，解释更直观</td>
<td>可以解释，但结构复杂，SHAP值计算成本更高</td>
</tr>
</tbody></table>
<p>所以<strong>理论上来说</strong>：</p>
<blockquote>
<p>如果你都配合使用 SHAP，XGBoost 的解释能力是<strong>更强的</strong>，因为 SHAP 设计时就特别针对提升树（boosting trees），而不是随机森林。</p>
</blockquote>
<p><strong>🔍 那为什么我们还说“解释性优先任务建议用随机森林”？</strong></p>
<p>原因其实有以下几点：</p>
<p>① <strong>直观易懂</strong>：随机森林&#x3D;一堆“看得见”的决策树</p>
<ul>
<li>随机森林的每棵树是独立训练的，可以<strong>单独可视化一棵树</strong></li>
<li>你可以说：“这棵树就是根据‘收入 &gt; 8000’、‘年龄 &gt; 35’判断你是否违约的”，对非技术人员<strong>直观透明</strong></li>
<li>你甚至可以“手动走一棵树”，跟客户演示</li>
</ul>
<p>② <strong>业务人员接受度高</strong></p>
<p>在金融、医疗、司法等解释性要求高的行业，很多业务人员并不懂 SHAP。<br> 但他们看得懂“这棵树这么分叉，所以判你为高风险”，这比告诉他们“SHAP 值是 +0.36”更容易沟通。</p>
<p>③ <strong>训练和解释开销低</strong></p>
<ul>
<li>随机森林训练快，解释开销低</li>
<li>XGBoost + SHAP 在大数据量下计算开销高，解释慢（尤其是高维特征时）</li>
</ul>
<p>✅ 所以最终结论：</p>
<table>
<thead>
<tr>
<th>问题</th>
<th>回答</th>
</tr>
</thead>
<tbody><tr>
<td><strong>哪种模型解释能力强？</strong></td>
<td>XGBoost + SHAP 更强、更精准</td>
</tr>
<tr>
<td><strong>为什么说解释性任务推荐随机森林？</strong></td>
<td>因为它结构简单、容易直观解释、业务人员易接受</td>
</tr>
<tr>
<td><strong>什么时候用 XGBoost + SHAP？</strong></td>
<td>需要精度又必须解释时（例如信贷审批评分系统）</td>
</tr>
<tr>
<td><strong>什么时候用随机森林？</strong></td>
<td>数据量中等，业务解释需求高但不要求极致精度时</td>
</tr>
</tbody></table>
<blockquote>
<p>DeepSeek不同意<strong>XGBoost + SHAP 更强、更精准</strong>的说话，它认为<strong>对于个体预测的精确解释</strong>XGBoost+SHAP可能更优（能捕捉特征间复杂交互）；<strong>对于全局模型逻辑的解释</strong>，随机森林更优（整体行为更易理解）。</p>
</blockquote>
<p>如果你是要给<strong>业务或监管解释每一笔预测</strong>，那么：</p>
<ul>
<li>对小项目或开发初期 → 随机森林就够</li>
<li>对高风险高要求系统 → 用 XGBoost + SHAP 会更靠谱</li>
</ul>
<hr>
<hr>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li><a href="https://blog.csdn.net/v_JULY_v/article/details/81410574">https://blog.csdn.net/v_JULY_v/article/details/81410574</a></li>
</ol>
]]></content>
      <categories>
        <category>code</category>
      </categories>
      <tags>
        <tag>boosting</tag>
        <tag>GBDT</tag>
        <tag>XGBoost</tag>
      </tags>
  </entry>
  <entry>
    <title>如何将你的DeepSeek-R1微调成某个领域的专家（实战篇）</title>
    <url>/2025/03/25/%E5%A6%82%E4%BD%95%E5%B0%86%E4%BD%A0%E7%9A%84DeepSeek-R1%E5%BE%AE%E8%B0%83%E6%88%90%E6%9F%90%E4%B8%AA%E9%A2%86%E5%9F%9F%E7%9A%84%E4%B8%93%E5%AE%B6%EF%BC%88%E5%AE%9E%E6%88%98%E7%AF%87%EF%BC%89/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>偶然在bilibili大学刷到一个宝藏博主（我要我觉得）-<a href="https://space.bilibili.com/474921808">code秘密花园</a>，质量高（符合我的方向）但是低产（所以我能跟上😁），目前只有四个视频，但信息量也不小，遂打算先把前辈其中的与本文同名的视频整理一下（我与作者同名），见参考链接。顺便一提，本文长度超集长，简单总结一下：我通过colab折腾了好久，显示通过重新编译llama.cpp解决了一个严重问题，后制作GGUF文件成功后，通过ollama加载该文件失败，重装ollama也不行，但是用大佬的huggingface上的GGUF文件就可以运行，我又尝试了使用本机的jupyter notebook进行同等代码的运行，值得一提的时，模型直接从hugging face下载会出问题，遂先下载到本地，加载本地模型问题，也出现了llama.cpp的问题（同等方式解决）,也是制作成GGUF文件后，ollama无法正常加载（毁灭吧），最后还是没用上ollama，使用vLLM进行的模型加载，并简单直接的对比了模型的效果。</p>
<span id="more"></span>

<hr>
<h2 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h2><h3 id="平台训练"><a href="#平台训练" class="headerlink" title="平台训练"></a>平台训练</h3><hr>
<h3 id="colab训练"><a href="#colab训练" class="headerlink" title="colab训练"></a>colab训练</h3><p>Google <em>Colab</em>是一个免费的、云托管的 Jupyter Notebook 环境，您可以在浏览器中直接编写和运行 Python 代码。长话短说：可白嫖的云Jupter Notebook😀，好的，佬提供的<a href="https://colab.research.google.com/drive/1B4nS1L5_GuGHU4U8l-qI-Ej7EqeBNHg6#scrollTo=9m27TqNYzRog">代码</a>。</p>
<h4 id="代码解析"><a href="#代码解析" class="headerlink" title="代码解析"></a>代码解析</h4><ol>
<li><p>安装依赖</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%%capture  <span class="comment"># 这是一个 Jupyter Notebook 的魔法命令，用于隐藏命令的输出，让笔记本界面更整洁。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 unsloth 包。一个用于微调大型语言模型（LLM）的工具，可以让模型运行更快、占用更少内存。</span></span><br><span class="line">!pip install unsloth</span><br><span class="line"></span><br><span class="line"><span class="comment"># 卸载当前已安装的 unsloth 包（如果已安装），然后从 GitHub 的源代码安装最新版本。</span></span><br><span class="line"><span class="comment"># 这样可以确保我们使用的是最新功能和修复。</span></span><br><span class="line">!pip uninstall unsloth -y &amp;&amp; pip install --upgrade --no-cache-<span class="built_in">dir</span> --no-deps git+https://github.com/unslothai/unsloth.git</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 bitsandbytes 和 unsloth_zoo 包。</span></span><br><span class="line"><span class="comment"># bitsandbytes 是一个用于量化和优化模型的库，可以帮助减少模型占用的内存。</span></span><br><span class="line"><span class="comment"># unsloth_zoo 可能包含了一些预训练模型或其他工具，方便我们使用。</span></span><br><span class="line">!pip install bitsandbytes unsloth_zoo</span><br></pre></td></tr></table></figure>
</li>
<li><p>加载预训练模型</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> unsloth <span class="keyword">import</span> FastLanguageModel  <span class="comment"># 导入FastLanguageModel类，用来加载和使用模型</span></span><br><span class="line"><span class="keyword">import</span> torch  <span class="comment"># 导入torch工具，用于处理模型的数学运算</span></span><br><span class="line"></span><br><span class="line">max_seq_length = <span class="number">2048</span>  <span class="comment"># 设置模型处理文本的最大长度，相当于给模型设置一个“最大容量”</span></span><br><span class="line">dtype = <span class="literal">None</span>  <span class="comment"># 设置数据类型，让模型自动选择最适合的精度</span></span><br><span class="line">load_in_4bit = <span class="literal">True</span>  <span class="comment"># 使用4位量化来节省内存，就像把大箱子压缩成小箱子</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载预训练模型，并获取tokenizer工具</span></span><br><span class="line">model, tokenizer = FastLanguageModel.from_pretrained(</span><br><span class="line">    model_name=<span class="string">&quot;unsloth/DeepSeek-R1-Distill-Llama-8B&quot;</span>,  <span class="comment"># 指定要加载的模型名称</span></span><br><span class="line">    max_seq_length=max_seq_length,  <span class="comment"># 使用前面设置的最大长度</span></span><br><span class="line">    dtype=dtype,  <span class="comment"># 使用前面设置的数据类型</span></span><br><span class="line">    load_in_4bit=load_in_4bit,  <span class="comment"># 使用4位量化</span></span><br><span class="line">    <span class="comment"># token=&quot;hf_...&quot;,  # 如果需要访问授权模型，可以在这里填入密钥</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>这里的load_in_4bit &#x3D; True控制的是模型权重加载（存储）到显存上的数据格式，指定 <strong>模型的权重</strong> 以 4-bit 量化的方式存储，以减少显存占用。这种 4-bit 量化通常使用 <code>NF4</code>（Normal Float 4）或 <code>FP4</code>（Float 4）格式，主要影响 <strong>存储和加载</strong>。、</p>
<p><code>dtype</code> 主要控制 <strong>推理或训练时</strong> 模型的计算数据类型，例如：</p>
<ul>
<li><code>float32</code></li>
<li><code>float16</code> (FP16)</li>
<li><code>bfloat16</code> (BF16)</li>
</ul>
<p>当 <code>dtype=None</code> 时，框架会根据硬件自动选择最优的计算精度：</p>
<ul>
<li><strong>如果 GPU 支持 BF16（如 A100、H100）</strong>，就会自动用 <code>bfloat16</code>，因为它在推理时更高效。</li>
<li><strong>如果 GPU 仅支持 FP16（如 RTX 3090、4090）</strong>，就会用 <code>float16</code>。</li>
</ul>
<p>两者不矛盾，而是互补的，一个影响存储，一个影响计算。</p>
</blockquote>
<p>输出：</p>
<img src="/2025/03/25/%E5%A6%82%E4%BD%95%E5%B0%86%E4%BD%A0%E7%9A%84DeepSeek-R1%E5%BE%AE%E8%B0%83%E6%88%90%E6%9F%90%E4%B8%AA%E9%A2%86%E5%9F%9F%E7%9A%84%E4%B8%93%E5%AE%B6%EF%BC%88%E5%AE%9E%E6%88%98%E7%AF%87%EF%BC%89/image-20250326155208943.png" class="" title="image-20250326155208943">

<p>第二次运行：</p>
<img src="/2025/03/25/%E5%A6%82%E4%BD%95%E5%B0%86%E4%BD%A0%E7%9A%84DeepSeek-R1%E5%BE%AE%E8%B0%83%E6%88%90%E6%9F%90%E4%B8%AA%E9%A2%86%E5%9F%9F%E7%9A%84%E4%B8%93%E5%AE%B6%EF%BC%88%E5%AE%9E%E6%88%98%E7%AF%87%EF%BC%89/image-20250327200514880.png" class="" title="image-20250327200514880">
</li>
<li><p>微调前测试</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">prompt_style = <span class="string">&quot;&quot;&quot;以下是描述任务的指令，以及提供进一步上下文的输入。</span></span><br><span class="line"><span class="string">请写出一个适当完成请求的回答。</span></span><br><span class="line"><span class="string">在回答之前，请仔细思考问题，并创建一个逻辑连贯的思考过程，以确保回答准确无误。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">### 指令：</span></span><br><span class="line"><span class="string">你是一位精通卜卦、星象和运势预测的算命大师。</span></span><br><span class="line"><span class="string">请回答以下算命问题。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">### 问题：</span></span><br><span class="line"><span class="string">&#123;&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">### 回答：</span></span><br><span class="line"><span class="string">&lt;think&gt;&#123;&#125;&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 定义提示风格的字符串模板，用于格式化问题</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义具体的算命问题</span></span><br><span class="line">question = <span class="string">&quot;1992年闰四月初九巳时生人，女，想了解健康运势&quot;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 准备模型以进行推理（进入推理模式，关闭Dropout，减少不必要的梯度计算）</span></span><br><span class="line">FastLanguageModel.for_inference(model)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 tokenizer 对格式化后的问题进行编码，并移动到 GPU</span></span><br><span class="line">inputs = tokenizer([prompt_style.<span class="built_in">format</span>(question, <span class="string">&quot;&quot;</span>)],return_tensors=<span class="string">&quot;pt&quot;</span>).to(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用模型生成回答</span></span><br><span class="line">outputs = model.generate(</span><br><span class="line">    input_ids=inputs.input_ids,</span><br><span class="line">    attention_mask=inputs.attention_mask,</span><br><span class="line">    max_new_tokens=<span class="number">1200</span>,</span><br><span class="line">    use_cache=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解码模型生成的输出为可读文本</span></span><br><span class="line">response = tokenizer.batch_decode(outputs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印生成的回答部分</span></span><br><span class="line"><span class="built_in">print</span>(response[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<blockquote>
</blockquote>
<p>输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&lt;｜begin▁of▁sentence｜&gt;以下是描述任务的指令，以及提供进一步上下文的输入。</span><br><span class="line">请写出一个适当完成请求的回答。</span><br><span class="line">在回答之前，请仔细思考问题，并创建一个逻辑连贯的思考过程，以确保回答准确无误。</span><br><span class="line"></span><br><span class="line"><span class="comment">### 指令：</span></span><br><span class="line">你是一位精通卜卦、星象和运势预测的算命大师。</span><br><span class="line">请回答以下算命问题。</span><br><span class="line"></span><br><span class="line"><span class="comment">### 问题：</span></span><br><span class="line"><span class="number">1992</span>年闰四月初九巳时生人，女，想了解健康运势</span><br><span class="line"></span><br><span class="line"><span class="comment">### 回答：</span></span><br><span class="line">&lt;think&gt;</span><br><span class="line">好的，来看这个问题。首先，用户的生日是<span class="number">1992</span>年闰四月初九巳时，女性，想了解自己的健康运势。作为算命大师，我需要先了解她的五行和星盘。</span><br><span class="line"></span><br><span class="line">首先，闰四月初九巳时，属于春季，生肖是兔年。兔年属火，火代表能量、活力和创造力。女性的命宫是水，代表灵性、情感和稳定。她的星盘需要看她的八字。</span><br><span class="line"></span><br><span class="line">接下来，分析她的五行和星盘。由于生肖是兔年，兔属火，女性的命宫是水，总的能量是火和水的组合，可能会比较平衡。她的身体健康方面，火能带来活力，但过多的火可能导致一些消耗，需要注意调节。</span><br><span class="line"></span><br><span class="line">然后，考虑她的健康运势。她的五行和星盘显示她可能会经历一些热带的变化，比如体温升高或者皮肤问题。建议她保持水分，注意身体的调节，避免过度劳累。</span><br><span class="line"></span><br><span class="line">最后，给出建议。保持良好的生活习惯，适度运动，注意饮食，多喝水，保持心情愉悦。这样可以帮助她保持身体健康，延长寿命。</span><br><span class="line"></span><br><span class="line">总结一下，她的健康运势中带有一些火元素，需要注意调节，保持平衡，才能维持长期的健康。</span><br><span class="line">&lt;/think&gt;</span><br><span class="line"></span><br><span class="line">根据你的生日<span class="number">1992</span>年闰四月初九巳时，我们可以分析你的五行和星盘。你的生肖是兔年，属于火元素。女性的命宫是水，代表灵性和情感。结合五行和星盘，可以看出你的健康运势中带有一些火元素，需要注意调节。</span><br><span class="line"></span><br><span class="line">健康方面，火能带来活力，但过多的火可能会导致身体的消耗。建议你保持水分，多喝水，保持身体的湿润。同时，注意调节情绪，保持心情平和，这对身体健康非常重要。</span><br><span class="line"></span><br><span class="line">总体来看，你的健康运势中有一定的火元素，需要注意调节，保持身体和心灵的平衡，这样才能维持长期的健康。&lt;｜end▁of▁sentence｜&gt;</span><br></pre></td></tr></table></figure>

<p>第二次运行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&lt;｜begin▁of▁sentence｜&gt;以下是描述任务的指令，以及提供进一步上下文的输入。</span><br><span class="line">请写出一个适当完成请求的回答。</span><br><span class="line">在回答之前，请仔细思考问题，并创建一个逻辑连贯的思考过程，以确保回答准确无误。</span><br><span class="line"></span><br><span class="line"><span class="comment">### 指令：</span></span><br><span class="line">你是一位精通卜卦、星象和运势预测的算命大师。</span><br><span class="line">请回答以下算命问题。</span><br><span class="line"></span><br><span class="line"><span class="comment">### 问题：</span></span><br><span class="line"><span class="number">1992</span>年闰四月初九巳时生人，女，想了解健康运势</span><br><span class="line"></span><br><span class="line"><span class="comment">### 回答：</span></span><br><span class="line">&lt;think&gt;</span><br><span class="line">嗯，今天有一个用户想了解自己的健康运势，她的生日是<span class="number">1992</span>年闰四月初九巳时，女性。首先，我需要分析她的生日和时间，确定她的生辰八字，然后根据五行理论来预测她的健康状况。</span><br><span class="line"></span><br><span class="line">首先，闰四月初九巳时，初九是阳煦，属于火旺日，这可能意味着她体质偏向火性，容易生气或者情绪波动较大。巳时对应的是土支，土能滋养和安定，但如果火旺，土可能会被弱化，容易出现干涸或消化不良的情况。</span><br><span class="line"></span><br><span class="line">接下来，五行分析方面，火代表她的主星，这意味着她的健康需要注意的是肺、胸腔、火相关的器官。可能会有哮喘、肺炎等问题，或者是高血压、心脏问题。土是她的辅助星，代表她的子宫、骨骼和肝脏健康，可能需要关注骨质疏松或肝脏问题。</span><br><span class="line"></span><br><span class="line">她的阴阳方面，阳气旺盛，容易活跃，可能会有失眠、易怒等问题，但也可以通过适当的运动和调节情绪来改善。阴气不足的话，可以通过食疗、补充水果和蔬菜来增强。</span><br><span class="line"></span><br><span class="line">生活建议方面，她需要保持良好的作息，适量运动，避免熬夜和过度劳累。情绪管理也很重要，学会放松心情，保持积极的心态。饮食上，多吃水果、蔬菜和全谷物，少吃辛辣油腻食物，适量喝红酒，保持体重。</span><br><span class="line"></span><br><span class="line">最后，提醒她定期体检，特别是肺和心脏方面的检查，及时发现问题，预防疾病。整体来看，她的健康状况需要关注火和土的平衡，保持良好的生活习惯和心态，才能维持健康运势。</span><br><span class="line">&lt;/think&gt;</span><br><span class="line"></span><br><span class="line">根据你的生日和时间，<span class="number">1992</span>年闰四月初九巳时，你的生辰八字为：</span><br><span class="line"></span><br><span class="line">- **出生时间**：<span class="number">1992</span>年<span class="number">4</span>月<span class="number">9</span>日，闰四月。</span><br><span class="line">- **出生地点**：未知，影响较小。</span><br><span class="line">- **时间**：巳时（<span class="number">3</span>-<span class="number">5</span>时）。</span><br><span class="line"></span><br><span class="line"><span class="comment">### 五行分析：</span></span><br><span class="line">- **主星**：火（代表你的健康和运势）。</span><br><span class="line">- **辅助星**：土（代表子宫、骨骼、肝脏等）。</span><br><span class="line"></span><br><span class="line"><span class="comment">### 占卜结果：</span></span><br><span class="line">根据你的生辰八字，你的身体健康状况需要注意以下几点：</span><br><span class="line"></span><br><span class="line"><span class="number">1.</span> **体质偏火**：你体质偏向火性，容易生气、容易疲劳、容易上火。建议多补水，少吃辛辣、油腻食物，保持心情舒畅。</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> **健康问题可能**：</span><br><span class="line">   - **肺部**：容易出现气喘、咽喉炎等问题。</span><br><span class="line">   - **心脏**：容易出现高血压、心脏病。</span><br><span class="line">   - **消化系统**：容易出现胃炎、胃溃疡、便秘等问题。</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span> **建议**：</span><br><span class="line">   - 多运动，保持身体活泼。</span><br><span class="line">   - 注意情绪管理，避免长时间处于紧张状态。</span><br><span class="line">   - 多吃水果、蔬菜，少吃辛辣油腻食物。</span><br><span class="line">   - 定期体检，关注心肺功能。</span><br><span class="line"></span><br><span class="line"><span class="number">4.</span> **运势**：</span><br><span class="line">   - 你的健康状况在后期可能会有所恶化，建议提前关注身体变化。</span><br><span class="line"></span><br><span class="line"><span class="comment">### 总结：</span></span><br><span class="line">根据你的生辰八字，你的健康状况需要特别注意火和土的平衡问题，保持良好的生活习惯和心态，定期体检，及时发现和预防问题，可以延长健康寿命。&lt;｜end▁of▁sentence｜&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>加载数据集</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义一个用于格式化提示的多行字符串模板</span></span><br><span class="line">train_prompt_style = <span class="string">&quot;&quot;&quot;以下是描述任务的指令，以及提供进一步上下文的输入。</span></span><br><span class="line"><span class="string">请写出一个适当完成请求的回答。</span></span><br><span class="line"><span class="string">在回答之前，请仔细思考问题，并创建一个逻辑连贯的思考过程，以确保回答准确无误。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">### 指令：</span></span><br><span class="line"><span class="string">你是一位精通八字算命、 紫微斗数、 风水、易经卦象、塔罗牌占卜、星象、面相手相和运势预测等方面的算命大师。</span></span><br><span class="line"><span class="string">请回答以下算命问题。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">### 问题：</span></span><br><span class="line"><span class="string">&#123;&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">### 回答：</span></span><br><span class="line"><span class="string">&lt;思考&gt;</span></span><br><span class="line"><span class="string">&#123;&#125;</span></span><br><span class="line"><span class="string">&lt;/思考&gt;</span></span><br><span class="line"><span class="string">&#123;&#125;&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义结束标记（EOS_TOKEN），用于指示文本的结束</span></span><br><span class="line">EOS_TOKEN = tokenizer.eos_token  <span class="comment"># 必须添加结束标记</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入数据集加载函数</span></span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="comment"># 加载指定的数据集，选择中文语言和训练集的前500条记录</span></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;Conard/fortune-telling&quot;</span>, <span class="string">&#x27;default&#x27;</span>, split = <span class="string">&quot;train[0:200]&quot;</span>, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 打印数据集的列名，查看数据集中有哪些字段</span></span><br><span class="line"><span class="built_in">print</span>(dataset.column_names)</span><br></pre></td></tr></table></figure>

<img src="/2025/03/25/%E5%A6%82%E4%BD%95%E5%B0%86%E4%BD%A0%E7%9A%84DeepSeek-R1%E5%BE%AE%E8%B0%83%E6%88%90%E6%9F%90%E4%B8%AA%E9%A2%86%E5%9F%9F%E7%9A%84%E4%B8%93%E5%AE%B6%EF%BC%88%E5%AE%9E%E6%88%98%E7%AF%87%EF%BC%89/image-20250326160447684.png" class="" title="image-20250326160447684">

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义一个函数，用于格式化数据集中的每条记录</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">formatting_prompts_func</span>(<span class="params">examples</span>):</span><br><span class="line">    <span class="comment"># 从数据集中提取问题、复杂思考过程和回答</span></span><br><span class="line">    inputs = examples[<span class="string">&quot;Question&quot;</span>]</span><br><span class="line">    cots = examples[<span class="string">&quot;Complex_CoT&quot;</span>]</span><br><span class="line">    outputs = examples[<span class="string">&quot;Response&quot;</span>]</span><br><span class="line">    texts = []  <span class="comment"># 用于存储格式化后的文本</span></span><br><span class="line">    <span class="comment"># 遍历每个问题、思考过程和回答，进行格式化</span></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">input</span>, cot, output <span class="keyword">in</span> <span class="built_in">zip</span>(inputs, cots, outputs):</span><br><span class="line">        <span class="comment"># 使用字符串模板插入数据，并加上结束标记</span></span><br><span class="line">        text = train_prompt_style.<span class="built_in">format</span>(<span class="built_in">input</span>, cot, output) + EOS_TOKEN</span><br><span class="line">        texts.append(text)  <span class="comment"># 将格式化后的文本添加到列表中</span></span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;text&quot;</span>: texts,  <span class="comment"># 返回包含所有格式化文本的字典</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">dataset = dataset.<span class="built_in">map</span>(formatting_prompts_func, batched = <span class="literal">True</span>)</span><br><span class="line">dataset[<span class="string">&quot;text&quot;</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">以下是描述任务的指令，以及提供进一步上下文的输入。</span><br><span class="line">请写出一个适当完成请求的回答。</span><br><span class="line">在回答之前，请仔细思考问题，并创建一个逻辑连贯的思考过程，以确保回答准确无误。</span><br><span class="line"></span><br><span class="line"><span class="comment">### 指令：</span></span><br><span class="line">你是一位精通八字算命、 紫微斗数、 风水、易经卦象、塔罗牌占卜、星象、面相手相和运势预测等方面的算命大师。</span><br><span class="line">请回答以下算命问题。</span><br><span class="line"></span><br><span class="line"><span class="comment">### 问题：</span></span><br><span class="line">新房装修,大门对着电梯好不好?要如何化解?</span><br><span class="line"></span><br><span class="line"><span class="comment">### 回答：</span></span><br><span class="line">&lt;思考&gt;</span><br><span class="line">好的，用户问的是新房装修时大门对着电梯好不好，以及如何化解。首先，我需要回忆一下风水学中关于大门和电梯的相关知识。电梯在风水中属于动气比较强的地方，因为电梯频繁开合，会带来不稳定的气流，也就是所谓的“煞气”。大门是住宅的纳气口，如果正对电梯，可能会让这些不稳定的气流直接冲进家里，影响居住者的健康和财运。</span><br><span class="line"></span><br><span class="line">接下来，我需要确认用户的具体情况。比如，大门和电梯的距离有多远？是否正对还是稍微偏一点？不过用户没有提供这些细节，所以只能给出一般性的建议。化解的方法通常有几种：屏风或玄关、门帘、五帝钱、植物、八卦镜等。需要逐一解释这些方法的原理和使用方式，同时提醒用户要根据实际情况选择，必要时咨询专业风水师。</span><br><span class="line"></span><br><span class="line">另外，还要注意语气要亲切，避免使用过于专业的术语，让用户容易理解。同时，要强调这些是传统方法，效果因人而异，保持客观中立。最后，可以建议用户如果情况复杂，最好请专业人士实地查看，这样更稳妥。</span><br><span class="line"></span><br><span class="line">&lt;/思考&gt;</span><br><span class="line">根据传统风水学的观点，大门正对电梯易形成<span class="string">&quot;开口煞&quot;</span>，电梯频繁升降会扰乱家宅气场。建议化解方案：</span><br><span class="line"></span><br><span class="line"><span class="number">1.</span> 玄关阻隔法</span><br><span class="line">在入门处设置L型屏风或文化砖玄关墙，高度以<span class="number">1.8</span>米为宜，既保持采光又形成缓冲带</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> 五行通关法</span><br><span class="line">门槛石下埋设五帝钱+白玉葫芦，建议选丙申年铸造的真品古币，配合门楣悬挂九宫八卦镜</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span> 光影化解术</span><br><span class="line">安装磨砂玻璃内推门，门框镶嵌黄铜门槛，每日辰时用海盐净化门廊区域</span><br><span class="line"></span><br><span class="line"><span class="number">4.</span> 现代科技方案</span><br><span class="line">入户区安装智能感应灯带，设置循环播放的流水声效，运用声光电技术平衡磁场</span><br><span class="line"></span><br><span class="line">需注意电梯井方位与家主命卦的关系，建议提供具体户型平面图进行吉凶方位测算。当代建筑中可采用半透明艺术隔断结合空气净化系统，既符合科学原理又兼顾传统智慧。&lt;｜end▁of▁sentence｜&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>执行微调</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">FastLanguageModel.for_training(model)</span><br><span class="line"></span><br><span class="line">model = FastLanguageModel.get_peft_model(</span><br><span class="line">    model,  <span class="comment"># 传入已经加载好的预训练模型</span></span><br><span class="line">    r = <span class="number">16</span>,  <span class="comment"># 设置 LoRA 的秩，决定添加的可训练参数数量</span></span><br><span class="line">    target_modules = [<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;k_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>, <span class="string">&quot;o_proj&quot;</span>,<span class="comment">#指定模型中需要微调的关键模块</span></span><br><span class="line">                      <span class="string">&quot;gate_proj&quot;</span>, <span class="string">&quot;up_proj&quot;</span>, <span class="string">&quot;down_proj&quot;</span>],</span><br><span class="line">    lora_alpha = <span class="number">16</span>,  <span class="comment"># 设置 LoRA 的超参数，影响可训练参数的训练方式</span></span><br><span class="line">    lora_dropout = <span class="number">0</span>,  <span class="comment"># 设置防止过拟合的参数，这里设置为 0 表示不丢弃任何参数</span></span><br><span class="line">    bias = <span class="string">&quot;none&quot;</span>,    <span class="comment"># 设置是否添加偏置项，这里设置为 &quot;none&quot; 表示不添加</span></span><br><span class="line">    use_gradient_checkpointing = <span class="string">&quot;unsloth&quot;</span>,  <span class="comment"># 使用优化技术节省显存并支持更大的批量大小</span></span><br><span class="line">    random_state = <span class="number">3407</span>,  <span class="comment"># 设置随机种子，确保每次运行代码时模型的初始化方式相同</span></span><br><span class="line">    use_rslora = <span class="literal">False</span>,  <span class="comment"># 设置是否使用Rank Stabilized LoRA技术，这里设置为 False 表示不使用</span></span><br><span class="line">    loftq_config = <span class="literal">None</span>,  <span class="comment"># 设置是否使用 LoftQ 技术，这里设置为 None 表示不使用</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Unsloth <span class="number">2025.2</span><span class="number">.5</span> patched <span class="number">32</span> layers <span class="keyword">with</span> <span class="number">32</span> QKV layers, <span class="number">32</span> O layers <span class="keyword">and</span> <span class="number">32</span> MLP layers.</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> trl <span class="keyword">import</span> SFTTrainer  <span class="comment"># 导入 SFTTrainer，用于监督式微调</span></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> TrainingArguments  <span class="comment"># 导入 TrainingArguments，用于设置训练参数</span></span><br><span class="line"><span class="keyword">from</span> unsloth <span class="keyword">import</span> is_bfloat16_supported  <span class="comment"># 导入函数，检查是否支持 bfloat16 数据格式</span></span><br><span class="line"></span><br><span class="line">trainer = SFTTrainer(  <span class="comment"># 创建一个 SFTTrainer 实例</span></span><br><span class="line">    model=model,  <span class="comment"># 传入要微调的模型</span></span><br><span class="line">    tokenizer=tokenizer,  <span class="comment"># 传入 tokenizer，用于处理文本数据</span></span><br><span class="line">    train_dataset=dataset,  <span class="comment"># 传入训练数据集</span></span><br><span class="line">    dataset_text_field=<span class="string">&quot;text&quot;</span>,  <span class="comment"># 指定数据集中文本字段的名称</span></span><br><span class="line">    max_seq_length=max_seq_length,  <span class="comment"># 设置最大序列长度</span></span><br><span class="line">    dataset_num_proc=<span class="number">2</span>,  <span class="comment"># 设置数据处理的并行进程数</span></span><br><span class="line">    packing=<span class="literal">False</span>,  <span class="comment"># 是否启用打包功能（这里设置为 False，打包可以让训练更快，但可能影响效果）</span></span><br><span class="line">    args=TrainingArguments(  <span class="comment"># 定义训练参数</span></span><br><span class="line">        per_device_train_batch_size=<span class="number">2</span>,  <span class="comment"># 每个设备（如 GPU）上的批量大小</span></span><br><span class="line">        gradient_accumulation_steps=<span class="number">4</span>,  <span class="comment"># 梯度累积步数，用于模拟大批次训练</span></span><br><span class="line">        warmup_steps=<span class="number">5</span>,  <span class="comment"># 预热步数，训练开始时学习率逐渐增加的步数</span></span><br><span class="line">        max_steps=<span class="number">75</span>,  <span class="comment"># 最大训练步数</span></span><br><span class="line">        learning_rate=<span class="number">2e-4</span>,  <span class="comment"># 学习率，模型学习新知识的速度</span></span><br><span class="line">        fp16=<span class="keyword">not</span> is_bfloat16_supported(),  <span class="comment"># 是否使用 fp16 格式加速训练（如果环境不支持 bfloat16）</span></span><br><span class="line">        bf16=is_bfloat16_supported(),  <span class="comment"># 是否使用 bfloat16 格式加速训练（如果环境支持）</span></span><br><span class="line">        logging_steps=<span class="number">1</span>,  <span class="comment"># 每隔多少步记录一次训练日志</span></span><br><span class="line">        optim=<span class="string">&quot;adamw_8bit&quot;</span>,  <span class="comment"># 使用的优化器，用于调整模型参数</span></span><br><span class="line">        weight_decay=<span class="number">0.01</span>,  <span class="comment"># 权重衰减，防止模型过拟合</span></span><br><span class="line">        lr_scheduler_type=<span class="string">&quot;linear&quot;</span>,  <span class="comment"># 学习率调度器类型，控制学习率的变化方式</span></span><br><span class="line">        seed=<span class="number">3407</span>,  <span class="comment"># 随机种子，确保训练结果可复现</span></span><br><span class="line">        output_dir=<span class="string">&quot;outputs&quot;</span>,  <span class="comment"># 训练结果保存的目录</span></span><br><span class="line">        report_to=<span class="string">&quot;none&quot;</span>,  <span class="comment"># 是否将训练结果报告到外部工具（如 WandB），这里设置为不报告</span></span><br><span class="line">    ),</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<img src="/2025/03/25/%E5%A6%82%E4%BD%95%E5%B0%86%E4%BD%A0%E7%9A%84DeepSeek-R1%E5%BE%AE%E8%B0%83%E6%88%90%E6%9F%90%E4%B8%AA%E9%A2%86%E5%9F%9F%E7%9A%84%E4%B8%93%E5%AE%B6%EF%BC%88%E5%AE%9E%E6%88%98%E7%AF%87%EF%BC%89/image-20250326162126205.png" class="" title="image-20250326162126205">

<p>第二次运行：</p>
<img src="/2025/03/25/%E5%A6%82%E4%BD%95%E5%B0%86%E4%BD%A0%E7%9A%84DeepSeek-R1%E5%BE%AE%E8%B0%83%E6%88%90%E6%9F%90%E4%B8%AA%E9%A2%86%E5%9F%9F%E7%9A%84%E4%B8%93%E5%AE%B6%EF%BC%88%E5%AE%9E%E6%88%98%E7%AF%87%EF%BC%89/image-20250327195641407.png" class="" title="image-20250327195641407">

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trainer_stats = trainer.train()</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = <span class="number">1</span></span><br><span class="line">   \\   /|    Num examples = <span class="number">200</span> | Num Epochs = <span class="number">3</span></span><br><span class="line">O^O/ \_/ \    Batch size per device = <span class="number">2</span> | Gradient Accumulation steps = <span class="number">4</span></span><br><span class="line">\        /    Total batch size = <span class="number">8</span> | Total steps = <span class="number">75</span></span><br><span class="line"> <span class="string">&quot;-____-&quot;</span>     Number of trainable parameters = <span class="number">41</span>,<span class="number">943</span>,040</span><br><span class="line"> [<span class="number">75</span>/<span class="number">75</span> <span class="number">33</span>:<span class="number">17</span>, Epoch <span class="number">3</span>/<span class="number">3</span>]</span><br><span class="line">Step	Training Loss</span><br><span class="line"><span class="number">1</span>	<span class="number">1.100600</span></span><br><span class="line"><span class="number">2</span>	<span class="number">1.150300</span></span><br><span class="line"><span class="number">3</span>	<span class="number">1.178300</span></span><br><span class="line"><span class="number">4</span>	<span class="number">1.129200</span></span><br><span class="line"><span class="number">5</span>	<span class="number">1.081000</span></span><br><span class="line"><span class="number">6</span>	<span class="number">1.221900</span></span><br><span class="line"><span class="number">7</span>	<span class="number">1.159500</span></span><br><span class="line"><span class="number">8</span>	<span class="number">1.159400</span></span><br><span class="line"><span class="number">9</span>	<span class="number">1.139200</span></span><br><span class="line"><span class="number">10</span>	<span class="number">1.215800</span></span><br><span class="line"><span class="number">11</span>	<span class="number">1.215000</span></span><br><span class="line"><span class="number">12</span>	<span class="number">1.235800</span></span><br><span class="line"><span class="number">13</span>	<span class="number">1.159500</span></span><br><span class="line"><span class="number">14</span>	<span class="number">1.181800</span></span><br><span class="line"><span class="number">15</span>	<span class="number">1.084300</span></span><br><span class="line"><span class="number">16</span>	<span class="number">1.124400</span></span><br><span class="line"><span class="number">17</span>	<span class="number">1.139700</span></span><br><span class="line"><span class="number">18</span>	<span class="number">1.077200</span></span><br><span class="line"><span class="number">19</span>	<span class="number">1.084900</span></span><br><span class="line"><span class="number">20</span>	<span class="number">1.114400</span></span><br><span class="line"><span class="number">21</span>	<span class="number">1.081500</span></span><br><span class="line"><span class="number">22</span>	<span class="number">1.067300</span></span><br><span class="line"><span class="number">23</span>	<span class="number">1.243800</span></span><br><span class="line"><span class="number">24</span>	<span class="number">0.970000</span></span><br><span class="line"><span class="number">25</span>	<span class="number">1.002700</span></span><br><span class="line"><span class="number">26</span>	<span class="number">0.969900</span></span><br><span class="line"><span class="number">27</span>	<span class="number">0.809700</span></span><br><span class="line"><span class="number">28</span>	<span class="number">0.907700</span></span><br><span class="line"><span class="number">29</span>	<span class="number">0.892400</span></span><br><span class="line"><span class="number">30</span>	<span class="number">0.853600</span></span><br><span class="line"><span class="number">31</span>	<span class="number">0.887800</span></span><br><span class="line"><span class="number">32</span>	<span class="number">0.911100</span></span><br><span class="line"><span class="number">33</span>	<span class="number">0.800700</span></span><br><span class="line"><span class="number">34</span>	<span class="number">0.820800</span></span><br><span class="line"><span class="number">35</span>	<span class="number">0.801000</span></span><br><span class="line"><span class="number">36</span>	<span class="number">0.861300</span></span><br><span class="line"><span class="number">37</span>	<span class="number">0.808400</span></span><br><span class="line"><span class="number">38</span>	<span class="number">0.840700</span></span><br><span class="line"><span class="number">39</span>	<span class="number">0.728800</span></span><br><span class="line"><span class="number">40</span>	<span class="number">0.898300</span></span><br><span class="line"><span class="number">41</span>	<span class="number">0.844300</span></span><br><span class="line"><span class="number">42</span>	<span class="number">0.734000</span></span><br><span class="line"><span class="number">43</span>	<span class="number">0.890800</span></span><br><span class="line"><span class="number">44</span>	<span class="number">0.865800</span></span><br><span class="line"><span class="number">45</span>	<span class="number">0.747900</span></span><br><span class="line"><span class="number">46</span>	<span class="number">0.776400</span></span><br><span class="line"><span class="number">47</span>	<span class="number">0.740800</span></span><br><span class="line"><span class="number">48</span>	<span class="number">0.910900</span></span><br><span class="line"><span class="number">49</span>	<span class="number">1.033900</span></span><br><span class="line"><span class="number">50</span>	<span class="number">0.893700</span></span><br><span class="line"><span class="number">51</span>	<span class="number">0.651400</span></span><br><span class="line"><span class="number">52</span>	<span class="number">0.634500</span></span><br><span class="line"><span class="number">53</span>	<span class="number">0.580400</span></span><br><span class="line"><span class="number">54</span>	<span class="number">0.616100</span></span><br><span class="line"><span class="number">55</span>	<span class="number">0.662600</span></span><br><span class="line"><span class="number">56</span>	<span class="number">0.661900</span></span><br><span class="line"><span class="number">57</span>	<span class="number">0.627100</span></span><br><span class="line"><span class="number">58</span>	<span class="number">0.627000</span></span><br><span class="line"><span class="number">59</span>	<span class="number">0.615800</span></span><br><span class="line"><span class="number">60</span>	<span class="number">0.634600</span></span><br><span class="line"><span class="number">61</span>	<span class="number">0.580500</span></span><br><span class="line"><span class="number">62</span>	<span class="number">0.682000</span></span><br><span class="line"><span class="number">63</span>	<span class="number">0.703400</span></span><br><span class="line"><span class="number">64</span>	<span class="number">0.648300</span></span><br><span class="line"><span class="number">65</span>	<span class="number">0.629400</span></span><br><span class="line"><span class="number">66</span>	<span class="number">0.777200</span></span><br><span class="line"><span class="number">67</span>	<span class="number">0.578600</span></span><br><span class="line"><span class="number">68</span>	<span class="number">0.600700</span></span><br><span class="line"><span class="number">69</span>	<span class="number">0.661200</span></span><br><span class="line"><span class="number">70</span>	<span class="number">0.599500</span></span><br><span class="line"><span class="number">71</span>	<span class="number">0.597800</span></span><br><span class="line"><span class="number">72</span>	<span class="number">0.702700</span></span><br><span class="line"><span class="number">73</span>	<span class="number">0.584300</span></span><br><span class="line"><span class="number">74</span>	<span class="number">0.581900</span></span><br><span class="line"><span class="number">75</span>	<span class="number">0.603100</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>微调后测试</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(question) <span class="comment"># 打印前面的问题</span></span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">1992</span>年闰四月初九巳时生人，女，想了解健康运势</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 将模型切换到推理模式，准备回答问题</span><br><span class="line">FastLanguageModel.for_inference(model)</span><br><span class="line"></span><br><span class="line"># 将问题转换成模型能理解的格式，并发送到 GPU 上</span><br><span class="line">inputs = tokenizer([prompt_style.format(question, &quot;&quot;)],return_tensors=&quot;pt&quot;).to(&quot;cuda&quot;)</span><br><span class="line"></span><br><span class="line"># 让模型根据问题生成回答，最多生成 4000 个新词</span><br><span class="line">outputs = model.generate(</span><br><span class="line">    input_ids=inputs.input_ids,  # 输入的数字序列</span><br><span class="line">    attention_mask=inputs.attention_mask,  # 注意力遮罩，帮助模型理解哪些部分重要</span><br><span class="line">    max_new_tokens=4000,  # 最多生成 4000 个新词</span><br><span class="line">    use_cache=True,  # 使用缓存加速生成</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"># 将生成的回答从数字转换回文字</span><br><span class="line">response = tokenizer.batch_decode(outputs)</span><br><span class="line"></span><br><span class="line"># 打印回答</span><br><span class="line">print(response[0])</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&lt;｜begin▁of▁sentence｜&gt;以下是描述任务的指令，以及提供进一步上下文的输入。</span><br><span class="line">请写出一个适当完成请求的回答。</span><br><span class="line">在回答之前，请仔细思考问题，并创建一个逻辑连贯的思考过程，以确保回答准确无误。</span><br><span class="line"></span><br><span class="line"><span class="comment">### 指令：</span></span><br><span class="line">你是一位精通卜卦、星象和运势预测的算命大师。</span><br><span class="line">请回答以下算命问题。</span><br><span class="line"></span><br><span class="line"><span class="comment">### 问题：</span></span><br><span class="line"><span class="number">1992</span>年闰四月初九巳时生人，女，想了解健康运势</span><br><span class="line"></span><br><span class="line"><span class="comment">### 回答：</span></span><br><span class="line">&lt;think&gt;</span><br><span class="line"></span><br><span class="line">&lt;算命大师思考&gt;</span><br><span class="line">好的，用户提供的信息是：<span class="number">1992</span>年闰四月初九巳时生，女性，想了解健康运势。首先，我需要确认这个日期是否符合传统生辰八字的记录方法。闰四月在农历中属于春季，且闰月通常在每四年出现一次，所以闰四月初九对应的公历日期需要查证。不过根据传统八字排盘原则，闰月的干支会与非闰月形成不同的组合。接下来，巳时对应的时辰是上午<span class="number">11</span>点至下午<span class="number">1</span>点，属于日干戊时的午时，需结合年柱进行分析。</span><br><span class="line"></span><br><span class="line">接下来，用户的生肖是未，因为<span class="number">1992</span>年是龙年，未月对应的生肖是龙。日柱需要结合年柱和月柱来看，年柱为龙，月柱为未，时柱为巳。需要确定年柱龙与月柱未的组合，以及时柱巳与日柱的关系。然后，分析五行分布，龙属水，未属水，巳属火，日柱未土需要看是否有生扶或杀破。接着看健康运势，需要结合八字中的五行平衡、天干地支的互动，以及流年运势的影响。比如，流年是否有煞星或吉星，是否有健康星如天喜、天同等。同时，还要考虑用户的性别，女性健康运势可能有不同的侧重点，比如情绪、子宫健康等。</span><br><span class="line"></span><br><span class="line">最后，结合用户的具体问题，健康运势需要具体化，比如是否有需要注意的身体部位，是否需要增强某方面的健康习惯，或者是否有潜在的健康隐患。需要综合八字、流年、个人的喜用神等因素，给出具体建议。同时，要避免使用过于绝对的语言，保持建议的可操作性和积极性。可能还需要提醒用户注意环境因素，保持良好的生活习惯，平衡心身健康。</span><br><span class="line"></span><br><span class="line">&lt;/算命大师&gt;</span><br><span class="line">🌸 午时生辰的未月龙辰与巳时火日形成“龙火相生”的格局，需注意脾胃与肝胆的调和。建议：</span><br><span class="line">✧ 每日辰时（<span class="number">7</span>-<span class="number">9</span>点）饮用绿茶或菊花茶（<span class="number">3</span>杯/日），增强气血运转</span><br><span class="line">✧ 每月初九日（农历）佩戴粉晶手串调和三方，平衡五行</span><br><span class="line">✧ 春季注意食用养生品（如当归、枸杞），秋季适量补充黑芝麻</span><br><span class="line">✦ <span class="number">2024</span>甲辰年有“天喜”星照，适合进行太极拳、八段锦等调养</span><br><span class="line">✦ 戊子年需防“火星”动，避免高秋过度劳累，建议选择秋季的银耳茶时辰休息</span><br><span class="line">✨ 若有不适症状，建议在巳时（<span class="number">11</span>-<span class="number">13</span>点）静坐补命，配合艾灸（需专业师傅）&lt;｜end▁of▁sentence｜&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>将微调后的模型保存为 GGUF 格式</p>
<p>需要到<a href="https://huggingface.co/">huggingface</a>点击头像，点击<code>Access Tokens</code>，点击右上角的<code>+Create new token</code>，点击<code>Write</code>，<code>Token name</code>随意填（以<code>XX</code>为例），点击<code>Create token</code>，点击<code>Copy</code>。回到<code>colab</code>，点击下图箭头所示位置：</p>
<img src="/2025/03/25/%E5%A6%82%E4%BD%95%E5%B0%86%E4%BD%A0%E7%9A%84DeepSeek-R1%E5%BE%AE%E8%B0%83%E6%88%90%E6%9F%90%E4%B8%AA%E9%A2%86%E5%9F%9F%E7%9A%84%E4%B8%93%E5%AE%B6%EF%BC%88%E5%AE%9E%E6%88%98%E7%AF%87%EF%BC%89/image-20250326165209905.png" class="" title="image-20250326165209905">

<p>然后按位置填入即可：</p>
<img src="/2025/03/25/%E5%A6%82%E4%BD%95%E5%B0%86%E4%BD%A0%E7%9A%84DeepSeek-R1%E5%BE%AE%E8%B0%83%E6%88%90%E6%9F%90%E4%B8%AA%E9%A2%86%E5%9F%9F%E7%9A%84%E4%B8%93%E5%AE%B6%EF%BC%88%E5%AE%9E%E6%88%98%E7%AF%87%EF%BC%89/image-20250326165405976.png" class="" title="image-20250326165405976">



<p>注意，Colab 默认环境里没有 <code>llama.cpp</code>，但是下面的代码需要这个，所以需要先配置下环境：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!rm -rf llama.cpp &amp;&amp; git clone https://github.com/ggml-org/llama.cpp.git &amp;&amp; cd llama.cpp &amp;&amp; git checkout b3345 &amp;&amp; git submodule update --init --recursive &amp;&amp; make clean &amp;&amp; make <span class="built_in">all</span> -j &amp;&amp; git log -<span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>否则会报错：</p>
<img src="/2025/03/25/%E5%A6%82%E4%BD%95%E5%B0%86%E4%BD%A0%E7%9A%84DeepSeek-R1%E5%BE%AE%E8%B0%83%E6%88%90%E6%9F%90%E4%B8%AA%E9%A2%86%E5%9F%9F%E7%9A%84%E4%B8%93%E5%AE%B6%EF%BC%88%E5%AE%9E%E6%88%98%E7%AF%87%EF%BC%89/image-20250326180930651.png" class="" title="image-20250326180930651">

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">RuntimeError                              Traceback (most recent call last)</span><br><span class="line">&lt;ipython-<span class="built_in">input</span>-<span class="number">17</span>-e4f24433ed0e&gt; <span class="keyword">in</span> &lt;cell line: <span class="number">0</span>&gt;()</span><br><span class="line">      <span class="number">7</span> <span class="comment"># 将模型保存为 8 位量化格式（Q8_0）</span></span><br><span class="line">      <span class="number">8</span> <span class="comment"># 这种格式文件小且运行快，适合部署到资源受限的设备</span></span><br><span class="line">----&gt; <span class="number">9</span> <span class="keyword">if</span> <span class="literal">True</span>: model.save_pretrained_gguf(<span class="string">&quot;model&quot;</span>, tokenizer,)</span><br><span class="line">     <span class="number">10</span> </span><br><span class="line">     <span class="number">11</span> <span class="comment"># 将模型保存为 16 位量化格式（f16）</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span> frames</span><br><span class="line">/usr/local/lib/python3<span class="number">.11</span>/dist-packages/unsloth/save.py <span class="keyword">in</span> save_to_gguf(model_type, model_dtype, is_sentencepiece, model_directory, quantization_method, first_conversion, _run_installer)</span><br><span class="line">   <span class="number">1083</span>             quantize_location = <span class="string">&quot;llama.cpp/llama-quantize&quot;</span></span><br><span class="line">   <span class="number">1084</span>         <span class="keyword">else</span>:</span><br><span class="line">-&gt; <span class="number">1085</span>             <span class="keyword">raise</span> RuntimeError(</span><br><span class="line">   <span class="number">1086</span>                 <span class="string">&quot;Unsloth: The file (&#x27;llama.cpp/llama-quantize&#x27; or &#x27;llama.cpp/llama-quantize.exe&#x27; if you are on Windows WSL) or &#x27;llama.cpp/quantize&#x27; does not exist.\n&quot;</span>\</span><br><span class="line">   <span class="number">1087</span>                 <span class="string">&quot;But we expect this file to exist! Maybe the llama.cpp developers changed the name or check extension of the llama-quantize file.&quot;</span></span><br><span class="line"></span><br><span class="line">RuntimeError: Unsloth: The file (<span class="string">&#x27;llama.cpp/llama-quantize&#x27;</span> <span class="keyword">or</span> <span class="string">&#x27;llama.cpp/llama-quantize.exe&#x27;</span> <span class="keyword">if</span> you are on Windows WSL) <span class="keyword">or</span> <span class="string">&#x27;llama.cpp/quantize&#x27;</span> does <span class="keyword">not</span> exist.</span><br><span class="line">But we expect this file to exist! Maybe the llama.cpp developers changed the name <span class="keyword">or</span> check extension of the llama-quantize file.</span><br></pre></td></tr></table></figure>

<p>运行下面代码保存模型文件：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入 Google Colab 的 userdata 模块，用于访问用户数据</span></span><br><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> userdata</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从 Google Colab 用户数据中获取 Hugging Face 的 API 令牌</span></span><br><span class="line">HUGGINGFACE_TOKEN = userdata.get(<span class="string">&#x27;HUGGINGFACE_TOKEN&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将模型保存为 8 位量化格式（Q8_0）</span></span><br><span class="line"><span class="comment"># 这种格式文件小且运行快，适合部署到资源受限的设备</span></span><br><span class="line"><span class="keyword">if</span> <span class="literal">True</span>: model.save_pretrained_gguf(<span class="string">&quot;model&quot;</span>, tokenizer,)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将模型保存为 16 位量化格式（f16）</span></span><br><span class="line"><span class="comment"># 16 位量化精度更高，但文件稍大</span></span><br><span class="line"><span class="keyword">if</span> <span class="literal">False</span>: model.save_pretrained_gguf(<span class="string">&quot;model_f16&quot;</span>, tokenizer, quantization_method = <span class="string">&quot;f16&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将模型保存为 4 位量化格式（q4_k_m）</span></span><br><span class="line"><span class="comment"># 4 位量化文件最小，但精度可能稍低</span></span><br><span class="line"><span class="keyword">if</span> <span class="literal">False</span>: model.save_pretrained_gguf(<span class="string">&quot;model&quot;</span>, tokenizer, quantization_method = <span class="string">&quot;q4_k_m&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">Unsloth<span class="punctuation">:</span> ##### The current model auto adds a BOS token.</span><br><span class="line">Unsloth<span class="punctuation">:</span> ##### Your chat template has a BOS token. We shall remove it temporarily.</span><br><span class="line">Unsloth<span class="punctuation">:</span> You have <span class="number">1</span> CPUs. Using `safe_serialization` is <span class="number">10</span>x slower.</span><br><span class="line">We shall switch to Pytorch saving<span class="punctuation">,</span> which might take <span class="number">3</span> minutes and not <span class="number">30</span> minutes.</span><br><span class="line">To force `safe_serialization`<span class="punctuation">,</span> set it to `None` instead.</span><br><span class="line">Unsloth<span class="punctuation">:</span> Kaggle/Colab has limited disk space. We need to delete the downloaded</span><br><span class="line">model which will save <span class="number">4</span><span class="number">-16</span>GB of disk space<span class="punctuation">,</span> allowing you to save on Kaggle/Colab.</span><br><span class="line">Unsloth<span class="punctuation">:</span> Will remove a cached repo with size <span class="number">6.0</span>G</span><br><span class="line">Unsloth<span class="punctuation">:</span> Merging <span class="number">4</span>bit and LoRA weights to <span class="number">16</span>bit...</span><br><span class="line">Unsloth<span class="punctuation">:</span> Will use up to <span class="number">4.42</span> out of <span class="number">12.67</span> RAM for saving.</span><br><span class="line">Unsloth<span class="punctuation">:</span> Saving model... This might take <span class="number">5</span> minutes ...</span><br><span class="line"> <span class="number">47</span>%|████▋     | <span class="number">15</span>/<span class="number">32</span> <span class="punctuation">[</span><span class="number">00</span><span class="punctuation">:</span><span class="number">01</span>&lt;<span class="number">00</span><span class="punctuation">:</span><span class="number">01</span><span class="punctuation">,</span> <span class="number">15.12</span>it/s<span class="punctuation">]</span></span><br><span class="line">We will save to Disk and not RAM now.</span><br><span class="line"><span class="number">100</span>%|██████████| <span class="number">32</span>/<span class="number">32</span> <span class="punctuation">[</span><span class="number">02</span><span class="punctuation">:</span><span class="number">16</span>&lt;<span class="number">00</span><span class="punctuation">:</span><span class="number">00</span><span class="punctuation">,</span>  <span class="number">4.27</span>s/it<span class="punctuation">]</span></span><br><span class="line">Unsloth<span class="punctuation">:</span> Saving tokenizer... Done.</span><br><span class="line">Unsloth<span class="punctuation">:</span> Saving model/pytorch_model<span class="number">-00001</span>-of<span class="number">-00004.</span>bin...</span><br><span class="line">Unsloth<span class="punctuation">:</span> Saving model/pytorch_model<span class="number">-00002</span>-of<span class="number">-00004.</span>bin...</span><br><span class="line">Unsloth<span class="punctuation">:</span> Saving model/pytorch_model<span class="number">-00003</span>-of<span class="number">-00004.</span>bin...</span><br><span class="line">Unsloth<span class="punctuation">:</span> Saving model/pytorch_model<span class="number">-00004</span>-of<span class="number">-00004.</span>bin...</span><br><span class="line">Done.</span><br><span class="line">Unsloth<span class="punctuation">:</span> Converting llama model. Can use fast conversion = False.</span><br><span class="line">==((====))==  Unsloth<span class="punctuation">:</span> Conversion from QLoRA to GGUF information</span><br><span class="line">   \\   /|    <span class="punctuation">[</span><span class="number">0</span><span class="punctuation">]</span> Installing llama.cpp might take <span class="number">3</span> minutes.</span><br><span class="line">O^O/ \_/ \    <span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> Converting HF to GGUF <span class="number">16</span>bits might take <span class="number">3</span> minutes.</span><br><span class="line">\        /    <span class="punctuation">[</span><span class="number">2</span><span class="punctuation">]</span> Converting GGUF <span class="number">16</span>bits to <span class="punctuation">[</span>&#x27;q8_0&#x27;<span class="punctuation">]</span> might take <span class="number">10</span> minutes each.</span><br><span class="line"> <span class="string">&quot;-____-&quot;</span>     In total<span class="punctuation">,</span> you will have to wait at least <span class="number">16</span> minutes.</span><br><span class="line"></span><br><span class="line">Unsloth<span class="punctuation">:</span> Installing llama.cpp. This might take <span class="number">3</span> minutes...</span><br><span class="line">Unsloth<span class="punctuation">:</span> <span class="punctuation">[</span><span class="number">1</span><span class="punctuation">]</span> Converting model at model into q8_0 GGUF format.</span><br><span class="line">The output location will be /content/model/unsloth.Q8_0.gguf</span><br><span class="line">This might take <span class="number">3</span> minutes...</span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>Loading model<span class="punctuation">:</span> model</span><br><span class="line">INFO<span class="punctuation">:</span>gguf.gguf_writer<span class="punctuation">:</span>gguf<span class="punctuation">:</span> This GGUF file is for Little Endian only</span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>Set model parameters</span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>gguf<span class="punctuation">:</span> context length = <span class="number">131072</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>gguf<span class="punctuation">:</span> embedding length = <span class="number">4096</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>gguf<span class="punctuation">:</span> feed forward length = <span class="number">14336</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>gguf<span class="punctuation">:</span> head count = <span class="number">32</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>gguf<span class="punctuation">:</span> key-value head count = <span class="number">8</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>gguf<span class="punctuation">:</span> rope theta = <span class="number">500000.0</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>gguf<span class="punctuation">:</span> rms norm epsilon = <span class="number">1e-05</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>gguf<span class="punctuation">:</span> file type = <span class="number">7</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>Set model tokenizer</span><br><span class="line">INFO<span class="punctuation">:</span>numexpr.utils<span class="punctuation">:</span>NumExpr defaulting to <span class="number">2</span> threads.</span><br><span class="line">WARNING<span class="punctuation">:</span>gguf.vocab<span class="punctuation">:</span>Adding merges requested but no merges found<span class="punctuation">,</span> output may be non-functional.</span><br><span class="line">INFO<span class="punctuation">:</span>gguf.vocab<span class="punctuation">:</span>Setting special token type bos to <span class="number">128000</span></span><br><span class="line">INFO<span class="punctuation">:</span>gguf.vocab<span class="punctuation">:</span>Setting special token type eos to <span class="number">128001</span></span><br><span class="line">INFO<span class="punctuation">:</span>gguf.vocab<span class="punctuation">:</span>Setting special token type pad to <span class="number">128004</span></span><br><span class="line">INFO<span class="punctuation">:</span>gguf.vocab<span class="punctuation">:</span>Setting add_bos_token to True</span><br><span class="line">INFO<span class="punctuation">:</span>gguf.vocab<span class="punctuation">:</span>Setting add_eos_token to False</span><br><span class="line">INFO<span class="punctuation">:</span>gguf.vocab<span class="punctuation">:</span>Setting chat_template to <span class="punctuation">&#123;</span>% if not add_generation_prompt is defined %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>% set add_generation_prompt = <span class="literal"><span class="keyword">false</span></span> %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>% endif %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>% set ns = namespace(is_first=<span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span> is_tool=<span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span> is_output_first=<span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span> system_prompt=&#x27;&#x27;) %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- for message in messages %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- if message<span class="punctuation">[</span>&#x27;role&#x27;<span class="punctuation">]</span> == &#x27;system&#x27; %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>% set ns.system_prompt = message<span class="punctuation">[</span>&#x27;content&#x27;<span class="punctuation">]</span> %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- endif %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- endfor %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>ns.system_prompt<span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- for message in messages %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- if message<span class="punctuation">[</span>&#x27;role&#x27;<span class="punctuation">]</span> == &#x27;user&#x27; %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- set ns.is_tool = <span class="literal"><span class="keyword">false</span></span> -%<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>&#x27;&lt;｜User｜&gt;&#x27; + message<span class="punctuation">[</span>&#x27;content&#x27;<span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- endif %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- if message<span class="punctuation">[</span>&#x27;role&#x27;<span class="punctuation">]</span> == &#x27;assistant&#x27; and message<span class="punctuation">[</span>&#x27;content&#x27;<span class="punctuation">]</span> is none %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- set ns.is_tool = <span class="literal"><span class="keyword">false</span></span> -%<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- for tool in message<span class="punctuation">[</span>&#x27;tool_calls&#x27;<span class="punctuation">]</span>%<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- if not ns.is_first %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>&#x27;&lt;｜Assistant｜&gt;&lt;｜tool▁calls▁begin｜&gt;&lt;｜tool▁call▁begin｜&gt;&#x27; + tool<span class="punctuation">[</span>&#x27;type&#x27;<span class="punctuation">]</span> + &#x27;&lt;｜tool▁sep｜&gt;&#x27; + tool<span class="punctuation">[</span>&#x27;function&#x27;<span class="punctuation">]</span><span class="punctuation">[</span>&#x27;name&#x27;<span class="punctuation">]</span> + &#x27;\n&#x27; + &#x27;```json&#x27; + &#x27;\n&#x27; + tool<span class="punctuation">[</span>&#x27;function&#x27;<span class="punctuation">]</span><span class="punctuation">[</span>&#x27;arguments&#x27;<span class="punctuation">]</span> + &#x27;\n&#x27; + &#x27;```&#x27; + &#x27;&lt;｜tool▁call▁end｜&gt;&#x27;<span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- set ns.is_first = <span class="literal"><span class="keyword">true</span></span> -%<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- else %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>&#x27;\n&#x27; + &#x27;&lt;｜tool▁call▁begin｜&gt;&#x27; + tool<span class="punctuation">[</span>&#x27;type&#x27;<span class="punctuation">]</span> + &#x27;&lt;｜tool▁sep｜&gt;&#x27; + tool<span class="punctuation">[</span>&#x27;function&#x27;<span class="punctuation">]</span><span class="punctuation">[</span>&#x27;name&#x27;<span class="punctuation">]</span> + &#x27;\n&#x27; + &#x27;```json&#x27; + &#x27;\n&#x27; + tool<span class="punctuation">[</span>&#x27;function&#x27;<span class="punctuation">]</span><span class="punctuation">[</span>&#x27;arguments&#x27;<span class="punctuation">]</span> + &#x27;\n&#x27; + &#x27;```&#x27; + &#x27;&lt;｜tool▁call▁end｜&gt;&#x27;<span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>&#x27;&lt;｜tool▁calls▁end｜&gt;&lt;｜end▁of▁sentence｜&gt;&#x27;<span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- endif %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- endfor %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- endif %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- if message<span class="punctuation">[</span>&#x27;role&#x27;<span class="punctuation">]</span> == &#x27;assistant&#x27; and message<span class="punctuation">[</span>&#x27;content&#x27;<span class="punctuation">]</span> is not none %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- if ns.is_tool %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>&#x27;&lt;｜tool▁outputs▁end｜&gt;&#x27; + message<span class="punctuation">[</span>&#x27;content&#x27;<span class="punctuation">]</span> + &#x27;&lt;｜end▁of▁sentence｜&gt;&#x27;<span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- set ns.is_tool = <span class="literal"><span class="keyword">false</span></span> -%<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- else %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>% set content = message<span class="punctuation">[</span>&#x27;content&#x27;<span class="punctuation">]</span> %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>% if &#x27;&lt;/think&gt;&#x27; in content %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>% set content = content.split(&#x27;&lt;/think&gt;&#x27;)<span class="punctuation">[</span><span class="number">-1</span><span class="punctuation">]</span> %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>% endif %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>&#x27;&lt;｜Assistant｜&gt;&#x27; + content + &#x27;&lt;｜end▁of▁sentence｜&gt;&#x27;<span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- endif %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- endif %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- if message<span class="punctuation">[</span>&#x27;role&#x27;<span class="punctuation">]</span> == &#x27;tool&#x27; %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- set ns.is_tool = <span class="literal"><span class="keyword">true</span></span> -%<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- if ns.is_output_first %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>&#x27;&lt;｜tool▁outputs▁begin｜&gt;&lt;｜tool▁output▁begin｜&gt;&#x27; + message<span class="punctuation">[</span>&#x27;content&#x27;<span class="punctuation">]</span> + &#x27;&lt;｜tool▁output▁end｜&gt;&#x27;<span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- set ns.is_output_first = <span class="literal"><span class="keyword">false</span></span> %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- else %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>&#x27;\n&lt;｜tool▁output▁begin｜&gt;&#x27; + message<span class="punctuation">[</span>&#x27;content&#x27;<span class="punctuation">]</span> + &#x27;&lt;｜tool▁output▁end｜&gt;&#x27;<span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- endif %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- endif %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>%- endfor -%<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>% if ns.is_tool %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>&#x27;&lt;｜tool▁outputs▁end｜&gt;&#x27;<span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>% endif %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>% if add_generation_prompt and not ns.is_tool %<span class="punctuation">&#125;</span><span class="punctuation">&#123;</span><span class="punctuation">&#123;</span>&#x27;&lt;｜Assistant｜&gt;&lt;think&gt;\n&#x27;<span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#123;</span>% endif %<span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>Exporting model...</span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>gguf<span class="punctuation">:</span> loading model weight map from &#x27;pytorch_model.bin.index.json&#x27;</span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>gguf<span class="punctuation">:</span> loading model part &#x27;pytorch_model<span class="number">-00001</span>-of<span class="number">-00004.</span>bin&#x27;</span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>token_embd.weight<span class="punctuation">,</span>           torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">128256</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.0</span>.attn_q.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.0</span>.attn_k.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.0</span>.attn_v.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.0</span>.attn_output.weight<span class="punctuation">,</span>    torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.0</span>.ffn_gate.weight<span class="punctuation">,</span>       torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.0</span>.ffn_up.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.0</span>.ffn_down.weight<span class="punctuation">,</span>       torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.0</span>.attn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.0</span>.ffn_norm.weight<span class="punctuation">,</span>       torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.1</span>.attn_q.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.1</span>.attn_k.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.1</span>.attn_v.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.1</span>.attn_output.weight<span class="punctuation">,</span>    torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.1</span>.ffn_gate.weight<span class="punctuation">,</span>       torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.1</span>.ffn_up.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.1</span>.ffn_down.weight<span class="punctuation">,</span>       torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.1</span>.attn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.1</span>.ffn_norm.weight<span class="punctuation">,</span>       torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.2</span>.attn_q.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.2</span>.attn_k.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.2</span>.attn_v.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.2</span>.attn_output.weight<span class="punctuation">,</span>    torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.2</span>.ffn_gate.weight<span class="punctuation">,</span>       torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.2</span>.ffn_up.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.2</span>.ffn_down.weight<span class="punctuation">,</span>       torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.2</span>.attn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.2</span>.ffn_norm.weight<span class="punctuation">,</span>       torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.3</span>.attn_q.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.3</span>.attn_k.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.3</span>.attn_v.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.3</span>.attn_output.weight<span class="punctuation">,</span>    torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.3</span>.ffn_gate.weight<span class="punctuation">,</span>       torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.3</span>.ffn_up.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.3</span>.ffn_down.weight<span class="punctuation">,</span>       torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.3</span>.attn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.3</span>.ffn_norm.weight<span class="punctuation">,</span>       torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.4</span>.attn_q.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.4</span>.attn_k.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.4</span>.attn_v.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.4</span>.attn_output.weight<span class="punctuation">,</span>    torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.4</span>.ffn_gate.weight<span class="punctuation">,</span>       torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.4</span>.ffn_up.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.4</span>.ffn_down.weight<span class="punctuation">,</span>       torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.4</span>.attn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.4</span>.ffn_norm.weight<span class="punctuation">,</span>       torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.5</span>.attn_q.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.5</span>.attn_k.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.5</span>.attn_v.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.5</span>.attn_output.weight<span class="punctuation">,</span>    torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.5</span>.ffn_gate.weight<span class="punctuation">,</span>       torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.5</span>.ffn_up.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.5</span>.ffn_down.weight<span class="punctuation">,</span>       torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.5</span>.attn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.5</span>.ffn_norm.weight<span class="punctuation">,</span>       torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.6</span>.attn_q.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.6</span>.attn_k.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.6</span>.attn_v.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.6</span>.attn_output.weight<span class="punctuation">,</span>    torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.6</span>.ffn_gate.weight<span class="punctuation">,</span>       torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.6</span>.ffn_up.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.6</span>.ffn_down.weight<span class="punctuation">,</span>       torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.6</span>.attn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.6</span>.ffn_norm.weight<span class="punctuation">,</span>       torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.7</span>.attn_q.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.7</span>.attn_k.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.7</span>.attn_v.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.7</span>.attn_output.weight<span class="punctuation">,</span>    torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.7</span>.ffn_gate.weight<span class="punctuation">,</span>       torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.7</span>.ffn_up.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.7</span>.ffn_down.weight<span class="punctuation">,</span>       torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.7</span>.attn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.7</span>.ffn_norm.weight<span class="punctuation">,</span>       torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.8</span>.attn_q.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.8</span>.attn_k.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.8</span>.attn_v.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.8</span>.attn_output.weight<span class="punctuation">,</span>    torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.8</span>.ffn_gate.weight<span class="punctuation">,</span>       torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.8</span>.ffn_up.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.8</span>.ffn_down.weight<span class="punctuation">,</span>       torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.8</span>.attn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.8</span>.ffn_norm.weight<span class="punctuation">,</span>       torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>gguf<span class="punctuation">:</span> loading model part &#x27;pytorch_model<span class="number">-00002</span>-of<span class="number">-00004.</span>bin&#x27;</span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.9</span>.attn_q.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.9</span>.attn_k.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.9</span>.attn_v.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.9</span>.attn_output.weight<span class="punctuation">,</span>    torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.9</span>.ffn_gate.weight<span class="punctuation">,</span>       torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.9</span>.ffn_up.weight<span class="punctuation">,</span>         torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.9</span>.ffn_down.weight<span class="punctuation">,</span>       torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.9</span>.attn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.9</span>.ffn_norm.weight<span class="punctuation">,</span>       torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.10</span>.attn_q.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.10</span>.attn_k.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.10</span>.attn_v.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.10</span>.attn_output.weight<span class="punctuation">,</span>   torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.10</span>.ffn_gate.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.10</span>.ffn_up.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.10</span>.ffn_down.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.10</span>.attn_norm.weight<span class="punctuation">,</span>     torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.10</span>.ffn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.11</span>.attn_q.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.11</span>.attn_k.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.11</span>.attn_v.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.11</span>.attn_output.weight<span class="punctuation">,</span>   torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.11</span>.ffn_gate.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.11</span>.ffn_up.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.11</span>.ffn_down.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.11</span>.attn_norm.weight<span class="punctuation">,</span>     torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.11</span>.ffn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.12</span>.attn_q.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.12</span>.attn_k.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.12</span>.attn_v.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.12</span>.attn_output.weight<span class="punctuation">,</span>   torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.12</span>.ffn_gate.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.12</span>.ffn_up.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.12</span>.ffn_down.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.12</span>.attn_norm.weight<span class="punctuation">,</span>     torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.12</span>.ffn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.13</span>.attn_q.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.13</span>.attn_k.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.13</span>.attn_v.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.13</span>.attn_output.weight<span class="punctuation">,</span>   torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.13</span>.ffn_gate.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.13</span>.ffn_up.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.13</span>.ffn_down.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.13</span>.attn_norm.weight<span class="punctuation">,</span>     torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.13</span>.ffn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.14</span>.attn_q.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.14</span>.attn_k.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.14</span>.attn_v.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.14</span>.attn_output.weight<span class="punctuation">,</span>   torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.14</span>.ffn_gate.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.14</span>.ffn_up.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.14</span>.ffn_down.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.14</span>.attn_norm.weight<span class="punctuation">,</span>     torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.14</span>.ffn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.15</span>.attn_q.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.15</span>.attn_k.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.15</span>.attn_v.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.15</span>.attn_output.weight<span class="punctuation">,</span>   torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.15</span>.ffn_gate.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.15</span>.ffn_up.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.15</span>.ffn_down.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.15</span>.attn_norm.weight<span class="punctuation">,</span>     torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.15</span>.ffn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.16</span>.attn_q.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.16</span>.attn_k.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.16</span>.attn_v.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.16</span>.attn_output.weight<span class="punctuation">,</span>   torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.16</span>.ffn_gate.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.16</span>.ffn_up.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.16</span>.ffn_down.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.16</span>.attn_norm.weight<span class="punctuation">,</span>     torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.16</span>.ffn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.17</span>.attn_q.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.17</span>.attn_k.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.17</span>.attn_v.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.17</span>.attn_output.weight<span class="punctuation">,</span>   torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.17</span>.ffn_gate.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.17</span>.ffn_up.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.17</span>.ffn_down.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.17</span>.attn_norm.weight<span class="punctuation">,</span>     torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.17</span>.ffn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.18</span>.attn_q.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.18</span>.attn_k.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.18</span>.attn_v.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.18</span>.attn_output.weight<span class="punctuation">,</span>   torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.18</span>.ffn_gate.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.18</span>.ffn_up.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.18</span>.ffn_down.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.18</span>.attn_norm.weight<span class="punctuation">,</span>     torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.18</span>.ffn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.19</span>.attn_q.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.19</span>.attn_k.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.19</span>.attn_v.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.19</span>.attn_output.weight<span class="punctuation">,</span>   torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.19</span>.ffn_gate.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.19</span>.ffn_up.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.19</span>.ffn_down.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.19</span>.attn_norm.weight<span class="punctuation">,</span>     torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.19</span>.ffn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.20</span>.attn_q.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.20</span>.attn_k.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.20</span>.attn_v.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.20</span>.attn_output.weight<span class="punctuation">,</span>   torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.20</span>.ffn_gate.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>gguf<span class="punctuation">:</span> loading model part &#x27;pytorch_model<span class="number">-00003</span>-of<span class="number">-00004.</span>bin&#x27;</span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.20</span>.ffn_up.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.20</span>.ffn_down.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.20</span>.attn_norm.weight<span class="punctuation">,</span>     torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.20</span>.ffn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.21</span>.attn_q.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.21</span>.attn_k.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.21</span>.attn_v.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.21</span>.attn_output.weight<span class="punctuation">,</span>   torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.21</span>.ffn_gate.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.21</span>.ffn_up.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.21</span>.ffn_down.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.21</span>.attn_norm.weight<span class="punctuation">,</span>     torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.21</span>.ffn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.22</span>.attn_q.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.22</span>.attn_k.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.22</span>.attn_v.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.22</span>.attn_output.weight<span class="punctuation">,</span>   torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.22</span>.ffn_gate.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.22</span>.ffn_up.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.22</span>.ffn_down.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.22</span>.attn_norm.weight<span class="punctuation">,</span>     torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.22</span>.ffn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.23</span>.attn_q.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.23</span>.attn_k.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.23</span>.attn_v.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.23</span>.attn_output.weight<span class="punctuation">,</span>   torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.23</span>.ffn_gate.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.23</span>.ffn_up.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.23</span>.ffn_down.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.23</span>.attn_norm.weight<span class="punctuation">,</span>     torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.23</span>.ffn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.24</span>.attn_q.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.24</span>.attn_k.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.24</span>.attn_v.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.24</span>.attn_output.weight<span class="punctuation">,</span>   torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.24</span>.ffn_gate.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.24</span>.ffn_up.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.24</span>.ffn_down.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.24</span>.attn_norm.weight<span class="punctuation">,</span>     torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.24</span>.ffn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.25</span>.attn_q.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.25</span>.attn_k.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.25</span>.attn_v.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.25</span>.attn_output.weight<span class="punctuation">,</span>   torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.25</span>.ffn_gate.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.25</span>.ffn_up.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.25</span>.ffn_down.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.25</span>.attn_norm.weight<span class="punctuation">,</span>     torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.25</span>.ffn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.26</span>.attn_q.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.26</span>.attn_k.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.26</span>.attn_v.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.26</span>.attn_output.weight<span class="punctuation">,</span>   torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.26</span>.ffn_gate.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.26</span>.ffn_up.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.26</span>.ffn_down.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.26</span>.attn_norm.weight<span class="punctuation">,</span>     torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.26</span>.ffn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.27</span>.attn_q.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.27</span>.attn_k.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.27</span>.attn_v.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.27</span>.attn_output.weight<span class="punctuation">,</span>   torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.27</span>.ffn_gate.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.27</span>.ffn_up.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.27</span>.ffn_down.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.27</span>.attn_norm.weight<span class="punctuation">,</span>     torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.27</span>.ffn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.28</span>.attn_q.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.28</span>.attn_k.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.28</span>.attn_v.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.28</span>.attn_output.weight<span class="punctuation">,</span>   torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.28</span>.ffn_gate.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.28</span>.ffn_up.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.28</span>.ffn_down.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.28</span>.attn_norm.weight<span class="punctuation">,</span>     torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.28</span>.ffn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.29</span>.attn_q.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.29</span>.attn_k.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.29</span>.attn_v.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.29</span>.attn_output.weight<span class="punctuation">,</span>   torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.29</span>.ffn_gate.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.29</span>.ffn_up.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.29</span>.ffn_down.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.29</span>.attn_norm.weight<span class="punctuation">,</span>     torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.29</span>.ffn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.30</span>.attn_q.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.30</span>.attn_k.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.30</span>.attn_v.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.30</span>.attn_output.weight<span class="punctuation">,</span>   torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.30</span>.ffn_gate.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.30</span>.ffn_up.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.30</span>.ffn_down.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.30</span>.attn_norm.weight<span class="punctuation">,</span>     torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.30</span>.ffn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.31</span>.attn_q.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.31</span>.attn_k.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.31</span>.attn_v.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">1024</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.31</span>.attn_output.weight<span class="punctuation">,</span>   torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.31</span>.ffn_gate.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.31</span>.ffn_up.weight<span class="punctuation">,</span>        torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">14336</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>gguf<span class="punctuation">:</span> loading model part &#x27;pytorch_model<span class="number">-00004</span>-of<span class="number">-00004.</span>bin&#x27;</span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.31</span>.ffn_down.weight<span class="punctuation">,</span>      torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">14336</span><span class="punctuation">,</span> <span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.31</span>.attn_norm.weight<span class="punctuation">,</span>     torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>blk<span class="number">.31</span>.ffn_norm.weight<span class="punctuation">,</span>      torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>output_norm.weight<span class="punctuation">,</span>          torch.float16 --&gt; F32<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>output.weight<span class="punctuation">,</span>               torch.float16 --&gt; Q8_0<span class="punctuation">,</span> shape = <span class="punctuation">&#123;</span><span class="number">4096</span><span class="punctuation">,</span> <span class="number">128256</span><span class="punctuation">&#125;</span></span><br><span class="line">INFO<span class="punctuation">:</span>gguf.gguf_writer<span class="punctuation">:</span>Writing the following files<span class="punctuation">:</span></span><br><span class="line">INFO<span class="punctuation">:</span>gguf.gguf_writer<span class="punctuation">:</span>/content/model/unsloth.Q8_0.gguf<span class="punctuation">:</span> n_tensors = <span class="number">291</span><span class="punctuation">,</span> total_size = <span class="number">8.5</span>G</span><br><span class="line">Writing<span class="punctuation">:</span> <span class="number">100</span>%|██████████| <span class="number">8.53</span>G/<span class="number">8.53</span>G <span class="punctuation">[</span><span class="number">03</span><span class="punctuation">:</span><span class="number">58</span>&lt;<span class="number">00</span><span class="punctuation">:</span><span class="number">00</span><span class="punctuation">,</span> <span class="number">35.8</span>Mbyte/s<span class="punctuation">]</span></span><br><span class="line">INFO<span class="punctuation">:</span>hf-to-gguf<span class="punctuation">:</span>Model successfully exported to /content/model/unsloth.Q8_0.gguf</span><br><span class="line">Unsloth<span class="punctuation">:</span> ##### The current model auto adds a BOS token.</span><br><span class="line">Unsloth<span class="punctuation">:</span> ##### We removed it in GGUF&#x27;s chat template for you.</span><br><span class="line">Unsloth<span class="punctuation">:</span> Conversion completed! Output location<span class="punctuation">:</span> /content/model/unsloth.Q8_0.gguf</span><br></pre></td></tr></table></figure>
</li>
<li><p>将GGUF模型传输到Huggingface仓库</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 导入 Hugging Face Hub 的 create_repo 函数，用于创建一个新的模型仓库</span></span><br><span class="line"><span class="keyword">from</span> huggingface_hub <span class="keyword">import</span> create_repo</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在 Hugging Face Hub 上创建一个新的模型仓库</span></span><br><span class="line">create_repo(<span class="string">&quot;caihaoran/fortunetelling1&quot;</span>, token=HUGGINGFACE_TOKEN, exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将模型和分词器上传到 Hugging Face Hub 上的仓库</span></span><br><span class="line">model.push_to_hub_gguf(<span class="string">&quot;caihaoran/fortunetelling1&quot;</span>, tokenizer, token=HUGGINGFACE_TOKEN)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Unsloth: <span class="comment">##### The current model auto adds a BOS token.</span></span><br><span class="line">Unsloth: <span class="comment">##### Your chat template has a BOS token. We shall remove it temporarily.</span></span><br><span class="line">Unsloth: Merging 4bit <span class="keyword">and</span> LoRA weights to 16bit...</span><br><span class="line">Unsloth: Will use up to <span class="number">4.29</span> out of <span class="number">12.67</span> RAM <span class="keyword">for</span> saving.</span><br><span class="line">Unsloth: Saving model... This might take <span class="number">5</span> minutes ...</span><br><span class="line"><span class="number">100</span>%|██████████| <span class="number">32</span>/<span class="number">32</span> [02:<span class="number">32</span>&lt;<span class="number">00</span>:<span class="number">00</span>,  <span class="number">4.76</span>s/it]</span><br><span class="line">Unsloth: Saving tokenizer... Done.</span><br><span class="line">Unsloth: Saving caihaoran/fortunetelling1/pytorch_model-00001-of-<span class="number">00004.</span><span class="built_in">bin</span>...</span><br><span class="line">Unsloth: Saving caihaoran/fortunetelling1/pytorch_model-00002-of-<span class="number">00004.</span><span class="built_in">bin</span>...</span><br><span class="line">Unsloth: Saving caihaoran/fortunetelling1/pytorch_model-00003-of-<span class="number">00004.</span><span class="built_in">bin</span>...</span><br><span class="line">Unsloth: Saving caihaoran/fortunetelling1/pytorch_model-00004-of-<span class="number">00004.</span><span class="built_in">bin</span>...</span><br><span class="line">Done.</span><br><span class="line">==((====))==  Unsloth: Conversion <span class="keyword">from</span> QLoRA to GGUF information</span><br><span class="line">   \\   /|    [<span class="number">0</span>] Installing llama.cpp might take <span class="number">3</span> minutes.</span><br><span class="line">O^O/ \_/ \    [<span class="number">1</span>] Converting HF to GGUF 16bits might take <span class="number">3</span> minutes.</span><br><span class="line">\        /    [<span class="number">2</span>] Converting GGUF 16bits to [<span class="string">&#x27;q8_0&#x27;</span>] might take <span class="number">10</span> minutes each.</span><br><span class="line"> <span class="string">&quot;-____-&quot;</span>     In total, you will have to wait at least <span class="number">16</span> minutes.</span><br><span class="line"></span><br><span class="line">Unsloth: Installing llama.cpp. This might take <span class="number">3</span> minutes...</span><br><span class="line">Unsloth: [<span class="number">1</span>] Converting model at caihaoran/fortunetelling1 into q8_0 GGUF <span class="built_in">format</span>.</span><br><span class="line">The output location will be /content/caihaoran/fortunetelling1/unsloth.Q8_0.gguf</span><br><span class="line">This might take <span class="number">3</span> minutes...</span><br><span class="line">INFO:hf-to-gguf:Loading model: fortunetelling1</span><br><span class="line">INFO:gguf.gguf_writer:gguf: This GGUF file <span class="keyword">is</span> <span class="keyword">for</span> Little Endian only</span><br><span class="line">INFO:hf-to-gguf:<span class="type">Set</span> model parameters</span><br><span class="line">INFO:hf-to-gguf:gguf: context length = <span class="number">131072</span></span><br><span class="line">INFO:hf-to-gguf:gguf: embedding length = <span class="number">4096</span></span><br><span class="line">INFO:hf-to-gguf:gguf: feed forward length = <span class="number">14336</span></span><br><span class="line">INFO:hf-to-gguf:gguf: head count = <span class="number">32</span></span><br><span class="line">INFO:hf-to-gguf:gguf: key-value head count = <span class="number">8</span></span><br><span class="line">INFO:hf-to-gguf:gguf: rope theta = <span class="number">500000.0</span></span><br><span class="line">INFO:hf-to-gguf:gguf: rms norm epsilon = <span class="number">1e-05</span></span><br><span class="line">INFO:hf-to-gguf:gguf: file <span class="built_in">type</span> = <span class="number">7</span></span><br><span class="line">INFO:hf-to-gguf:<span class="type">Set</span> model tokenizer</span><br><span class="line">INFO:numexpr.utils:NumExpr defaulting to <span class="number">2</span> threads.</span><br><span class="line">WARNING:gguf.vocab:Adding merges requested but no merges found, output may be non-functional.</span><br><span class="line">INFO:gguf.vocab:Setting special token <span class="built_in">type</span> bos to <span class="number">128000</span></span><br><span class="line">INFO:gguf.vocab:Setting special token <span class="built_in">type</span> eos to <span class="number">128001</span></span><br><span class="line">INFO:gguf.vocab:Setting special token <span class="built_in">type</span> pad to <span class="number">128004</span></span><br><span class="line">INFO:gguf.vocab:Setting add_bos_token to <span class="literal">True</span></span><br><span class="line">INFO:gguf.vocab:Setting add_eos_token to <span class="literal">False</span></span><br><span class="line">INFO:gguf.vocab:Setting chat_template to &#123;% <span class="keyword">if</span> <span class="keyword">not</span> add_generation_prompt <span class="keyword">is</span> defined %&#125;&#123;% <span class="built_in">set</span> add_generation_prompt = false %&#125;&#123;% endif %&#125;&#123;% <span class="built_in">set</span> ns = namespace(is_first=false, is_tool=false, is_output_first=true, system_prompt=<span class="string">&#x27;&#x27;</span>) %&#125;&#123;%- <span class="keyword">for</span> message <span class="keyword">in</span> messages %&#125;&#123;%- <span class="keyword">if</span> message[<span class="string">&#x27;role&#x27;</span>] == <span class="string">&#x27;system&#x27;</span> %&#125;&#123;% <span class="built_in">set</span> ns.system_prompt = message[<span class="string">&#x27;content&#x27;</span>] %&#125;&#123;%- endif %&#125;&#123;%- endfor %&#125;&#123;&#123;ns.system_prompt&#125;&#125;&#123;%- <span class="keyword">for</span> message <span class="keyword">in</span> messages %&#125;&#123;%- <span class="keyword">if</span> message[<span class="string">&#x27;role&#x27;</span>] == <span class="string">&#x27;user&#x27;</span> %&#125;&#123;%- <span class="built_in">set</span> ns.is_tool = false -%&#125;&#123;&#123;<span class="string">&#x27;&lt;｜User｜&gt;&#x27;</span> + message[<span class="string">&#x27;content&#x27;</span>]&#125;&#125;&#123;%- endif %&#125;&#123;%- <span class="keyword">if</span> message[<span class="string">&#x27;role&#x27;</span>] == <span class="string">&#x27;assistant&#x27;</span> <span class="keyword">and</span> message[<span class="string">&#x27;content&#x27;</span>] <span class="keyword">is</span> none %&#125;&#123;%- <span class="built_in">set</span> ns.is_tool = false -%&#125;&#123;%- <span class="keyword">for</span> tool <span class="keyword">in</span> message[<span class="string">&#x27;tool_calls&#x27;</span>]%&#125;&#123;%- <span class="keyword">if</span> <span class="keyword">not</span> ns.is_first %&#125;&#123;&#123;<span class="string">&#x27;&lt;｜Assistant｜&gt;&lt;｜tool▁calls▁begin｜&gt;&lt;｜tool▁call▁begin｜&gt;&#x27;</span> + tool[<span class="string">&#x27;type&#x27;</span>] + <span class="string">&#x27;&lt;｜tool▁sep｜&gt;&#x27;</span> + tool[<span class="string">&#x27;function&#x27;</span>][<span class="string">&#x27;name&#x27;</span>] + <span class="string">&#x27;\n&#x27;</span> + <span class="string">&#x27;```json&#x27;</span> + <span class="string">&#x27;\n&#x27;</span> + tool[<span class="string">&#x27;function&#x27;</span>][<span class="string">&#x27;arguments&#x27;</span>] + <span class="string">&#x27;\n&#x27;</span> + <span class="string">&#x27;```&#x27;</span> + <span class="string">&#x27;&lt;｜tool▁call▁end｜&gt;&#x27;</span>&#125;&#125;&#123;%- <span class="built_in">set</span> ns.is_first = true -%&#125;&#123;%- <span class="keyword">else</span> %&#125;&#123;&#123;<span class="string">&#x27;\n&#x27;</span> + <span class="string">&#x27;&lt;｜tool▁call▁begin｜&gt;&#x27;</span> + tool[<span class="string">&#x27;type&#x27;</span>] + <span class="string">&#x27;&lt;｜tool▁sep｜&gt;&#x27;</span> + tool[<span class="string">&#x27;function&#x27;</span>][<span class="string">&#x27;name&#x27;</span>] + <span class="string">&#x27;\n&#x27;</span> + <span class="string">&#x27;```json&#x27;</span> + <span class="string">&#x27;\n&#x27;</span> + tool[<span class="string">&#x27;function&#x27;</span>][<span class="string">&#x27;arguments&#x27;</span>] + <span class="string">&#x27;\n&#x27;</span> + <span class="string">&#x27;```&#x27;</span> + <span class="string">&#x27;&lt;｜tool▁call▁end｜&gt;&#x27;</span>&#125;&#125;&#123;&#123;<span class="string">&#x27;&lt;｜tool▁calls▁end｜&gt;&lt;｜end▁of▁sentence｜&gt;&#x27;</span>&#125;&#125;&#123;%- endif %&#125;&#123;%- endfor %&#125;&#123;%- endif %&#125;&#123;%- <span class="keyword">if</span> message[<span class="string">&#x27;role&#x27;</span>] == <span class="string">&#x27;assistant&#x27;</span> <span class="keyword">and</span> message[<span class="string">&#x27;content&#x27;</span>] <span class="keyword">is</span> <span class="keyword">not</span> none %&#125;&#123;%- <span class="keyword">if</span> ns.is_tool %&#125;&#123;&#123;<span class="string">&#x27;&lt;｜tool▁outputs▁end｜&gt;&#x27;</span> + message[<span class="string">&#x27;content&#x27;</span>] + <span class="string">&#x27;&lt;｜end▁of▁sentence｜&gt;&#x27;</span>&#125;&#125;&#123;%- <span class="built_in">set</span> ns.is_tool = false -%&#125;&#123;%- <span class="keyword">else</span> %&#125;&#123;% <span class="built_in">set</span> content = message[<span class="string">&#x27;content&#x27;</span>] %&#125;&#123;% <span class="keyword">if</span> <span class="string">&#x27;&lt;/think&gt;&#x27;</span> <span class="keyword">in</span> content %&#125;&#123;% <span class="built_in">set</span> content = content.split(<span class="string">&#x27;&lt;/think&gt;&#x27;</span>)[-<span class="number">1</span>] %&#125;&#123;% endif %&#125;&#123;&#123;<span class="string">&#x27;&lt;｜Assistant｜&gt;&#x27;</span> + content + <span class="string">&#x27;&lt;｜end▁of▁sentence｜&gt;&#x27;</span>&#125;&#125;&#123;%- endif %&#125;&#123;%- endif %&#125;&#123;%- <span class="keyword">if</span> message[<span class="string">&#x27;role&#x27;</span>] == <span class="string">&#x27;tool&#x27;</span> %&#125;&#123;%- <span class="built_in">set</span> ns.is_tool = true -%&#125;&#123;%- <span class="keyword">if</span> ns.is_output_first %&#125;&#123;&#123;<span class="string">&#x27;&lt;｜tool▁outputs▁begin｜&gt;&lt;｜tool▁output▁begin｜&gt;&#x27;</span> + message[<span class="string">&#x27;content&#x27;</span>] + <span class="string">&#x27;&lt;｜tool▁output▁end｜&gt;&#x27;</span>&#125;&#125;&#123;%- <span class="built_in">set</span> ns.is_output_first = false %&#125;&#123;%- <span class="keyword">else</span> %&#125;&#123;&#123;<span class="string">&#x27;\n&lt;｜tool▁output▁begin｜&gt;&#x27;</span> + message[<span class="string">&#x27;content&#x27;</span>] + <span class="string">&#x27;&lt;｜tool▁output▁end｜&gt;&#x27;</span>&#125;&#125;&#123;%- endif %&#125;&#123;%- endif %&#125;&#123;%- endfor -%&#125;&#123;% <span class="keyword">if</span> ns.is_tool %&#125;&#123;&#123;<span class="string">&#x27;&lt;｜tool▁outputs▁end｜&gt;&#x27;</span>&#125;&#125;&#123;% endif %&#125;&#123;% <span class="keyword">if</span> add_generation_prompt <span class="keyword">and</span> <span class="keyword">not</span> ns.is_tool %&#125;&#123;&#123;<span class="string">&#x27;&lt;｜Assistant｜&gt;&lt;think&gt;\n&#x27;</span>&#125;&#125;&#123;% endif %&#125;</span><br><span class="line">INFO:hf-to-gguf:Exporting model...</span><br><span class="line">INFO:hf-to-gguf:gguf: loading model weight <span class="built_in">map</span> <span class="keyword">from</span> <span class="string">&#x27;pytorch_model.bin.index.json&#x27;</span></span><br><span class="line">INFO:hf-to-gguf:gguf: loading model part <span class="string">&#x27;pytorch_model-00001-of-00004.bin&#x27;</span></span><br><span class="line">INFO:hf-to-gguf:token_embd.weight,           torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">128256</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.0</span>.attn_q.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.0</span>.attn_k.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.0</span>.attn_v.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.0</span>.attn_output.weight,    torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.0</span>.ffn_gate.weight,       torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.0</span>.ffn_up.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.0</span>.ffn_down.weight,       torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.0</span>.attn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.0</span>.ffn_norm.weight,       torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.1</span>.attn_q.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.1</span>.attn_k.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.1</span>.attn_v.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.1</span>.attn_output.weight,    torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.1</span>.ffn_gate.weight,       torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.1</span>.ffn_up.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.1</span>.ffn_down.weight,       torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.1</span>.attn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.1</span>.ffn_norm.weight,       torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.2</span>.attn_q.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.2</span>.attn_k.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.2</span>.attn_v.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.2</span>.attn_output.weight,    torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.2</span>.ffn_gate.weight,       torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.2</span>.ffn_up.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.2</span>.ffn_down.weight,       torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.2</span>.attn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.2</span>.ffn_norm.weight,       torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.3</span>.attn_q.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.3</span>.attn_k.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.3</span>.attn_v.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.3</span>.attn_output.weight,    torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.3</span>.ffn_gate.weight,       torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.3</span>.ffn_up.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.3</span>.ffn_down.weight,       torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.3</span>.attn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.3</span>.ffn_norm.weight,       torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.4</span>.attn_q.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.4</span>.attn_k.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.4</span>.attn_v.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.4</span>.attn_output.weight,    torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.4</span>.ffn_gate.weight,       torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.4</span>.ffn_up.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.4</span>.ffn_down.weight,       torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.4</span>.attn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.4</span>.ffn_norm.weight,       torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.5</span>.attn_q.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.5</span>.attn_k.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.5</span>.attn_v.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.5</span>.attn_output.weight,    torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.5</span>.ffn_gate.weight,       torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.5</span>.ffn_up.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.5</span>.ffn_down.weight,       torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.5</span>.attn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.5</span>.ffn_norm.weight,       torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.6</span>.attn_q.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.6</span>.attn_k.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.6</span>.attn_v.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.6</span>.attn_output.weight,    torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.6</span>.ffn_gate.weight,       torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.6</span>.ffn_up.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.6</span>.ffn_down.weight,       torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.6</span>.attn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.6</span>.ffn_norm.weight,       torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.7</span>.attn_q.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.7</span>.attn_k.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.7</span>.attn_v.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.7</span>.attn_output.weight,    torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.7</span>.ffn_gate.weight,       torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.7</span>.ffn_up.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.7</span>.ffn_down.weight,       torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.7</span>.attn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.7</span>.ffn_norm.weight,       torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.8</span>.attn_q.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.8</span>.attn_k.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.8</span>.attn_v.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.8</span>.attn_output.weight,    torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.8</span>.ffn_gate.weight,       torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.8</span>.ffn_up.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.8</span>.ffn_down.weight,       torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.8</span>.attn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.8</span>.ffn_norm.weight,       torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:gguf: loading model part <span class="string">&#x27;pytorch_model-00002-of-00004.bin&#x27;</span></span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.9</span>.attn_q.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.9</span>.attn_k.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.9</span>.attn_v.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.9</span>.attn_output.weight,    torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.9</span>.ffn_gate.weight,       torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.9</span>.ffn_up.weight,         torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.9</span>.ffn_down.weight,       torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.9</span>.attn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.9</span>.ffn_norm.weight,       torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.10</span>.attn_q.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.10</span>.attn_k.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.10</span>.attn_v.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.10</span>.attn_output.weight,   torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.10</span>.ffn_gate.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.10</span>.ffn_up.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.10</span>.ffn_down.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.10</span>.attn_norm.weight,     torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.10</span>.ffn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.11</span>.attn_q.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.11</span>.attn_k.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.11</span>.attn_v.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.11</span>.attn_output.weight,   torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.11</span>.ffn_gate.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.11</span>.ffn_up.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.11</span>.ffn_down.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.11</span>.attn_norm.weight,     torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.11</span>.ffn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.12</span>.attn_q.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.12</span>.attn_k.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.12</span>.attn_v.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.12</span>.attn_output.weight,   torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.12</span>.ffn_gate.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.12</span>.ffn_up.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.12</span>.ffn_down.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.12</span>.attn_norm.weight,     torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.12</span>.ffn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.13</span>.attn_q.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.13</span>.attn_k.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.13</span>.attn_v.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.13</span>.attn_output.weight,   torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.13</span>.ffn_gate.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.13</span>.ffn_up.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.13</span>.ffn_down.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.13</span>.attn_norm.weight,     torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.13</span>.ffn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.14</span>.attn_q.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.14</span>.attn_k.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.14</span>.attn_v.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.14</span>.attn_output.weight,   torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.14</span>.ffn_gate.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.14</span>.ffn_up.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.14</span>.ffn_down.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.14</span>.attn_norm.weight,     torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.14</span>.ffn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.15</span>.attn_q.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.15</span>.attn_k.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.15</span>.attn_v.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.15</span>.attn_output.weight,   torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.15</span>.ffn_gate.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.15</span>.ffn_up.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.15</span>.ffn_down.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.15</span>.attn_norm.weight,     torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.15</span>.ffn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.16</span>.attn_q.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.16</span>.attn_k.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.16</span>.attn_v.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.16</span>.attn_output.weight,   torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.16</span>.ffn_gate.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.16</span>.ffn_up.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.16</span>.ffn_down.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.16</span>.attn_norm.weight,     torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.16</span>.ffn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.17</span>.attn_q.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.17</span>.attn_k.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.17</span>.attn_v.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.17</span>.attn_output.weight,   torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.17</span>.ffn_gate.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.17</span>.ffn_up.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.17</span>.ffn_down.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.17</span>.attn_norm.weight,     torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.17</span>.ffn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.18</span>.attn_q.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.18</span>.attn_k.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.18</span>.attn_v.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.18</span>.attn_output.weight,   torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.18</span>.ffn_gate.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.18</span>.ffn_up.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.18</span>.ffn_down.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.18</span>.attn_norm.weight,     torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.18</span>.ffn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.19</span>.attn_q.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.19</span>.attn_k.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.19</span>.attn_v.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.19</span>.attn_output.weight,   torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.19</span>.ffn_gate.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.19</span>.ffn_up.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.19</span>.ffn_down.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.19</span>.attn_norm.weight,     torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.19</span>.ffn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.20</span>.attn_q.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.20</span>.attn_k.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.20</span>.attn_v.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.20</span>.attn_output.weight,   torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.20</span>.ffn_gate.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:gguf: loading model part <span class="string">&#x27;pytorch_model-00003-of-00004.bin&#x27;</span></span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.20</span>.ffn_up.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.20</span>.ffn_down.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.20</span>.attn_norm.weight,     torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.20</span>.ffn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.21</span>.attn_q.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.21</span>.attn_k.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.21</span>.attn_v.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.21</span>.attn_output.weight,   torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.21</span>.ffn_gate.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.21</span>.ffn_up.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.21</span>.ffn_down.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.21</span>.attn_norm.weight,     torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.21</span>.ffn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.22</span>.attn_q.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.22</span>.attn_k.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.22</span>.attn_v.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.22</span>.attn_output.weight,   torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.22</span>.ffn_gate.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.22</span>.ffn_up.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.22</span>.ffn_down.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.22</span>.attn_norm.weight,     torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.22</span>.ffn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.23</span>.attn_q.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.23</span>.attn_k.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.23</span>.attn_v.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.23</span>.attn_output.weight,   torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.23</span>.ffn_gate.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.23</span>.ffn_up.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.23</span>.ffn_down.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.23</span>.attn_norm.weight,     torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.23</span>.ffn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.24</span>.attn_q.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.24</span>.attn_k.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.24</span>.attn_v.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.24</span>.attn_output.weight,   torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.24</span>.ffn_gate.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.24</span>.ffn_up.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.24</span>.ffn_down.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.24</span>.attn_norm.weight,     torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.24</span>.ffn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.25</span>.attn_q.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.25</span>.attn_k.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.25</span>.attn_v.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.25</span>.attn_output.weight,   torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.25</span>.ffn_gate.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.25</span>.ffn_up.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.25</span>.ffn_down.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.25</span>.attn_norm.weight,     torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.25</span>.ffn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.26</span>.attn_q.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.26</span>.attn_k.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.26</span>.attn_v.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.26</span>.attn_output.weight,   torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.26</span>.ffn_gate.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.26</span>.ffn_up.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.26</span>.ffn_down.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.26</span>.attn_norm.weight,     torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.26</span>.ffn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.27</span>.attn_q.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.27</span>.attn_k.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.27</span>.attn_v.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.27</span>.attn_output.weight,   torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.27</span>.ffn_gate.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.27</span>.ffn_up.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.27</span>.ffn_down.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.27</span>.attn_norm.weight,     torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.27</span>.ffn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.28</span>.attn_q.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.28</span>.attn_k.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.28</span>.attn_v.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.28</span>.attn_output.weight,   torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.28</span>.ffn_gate.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.28</span>.ffn_up.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.28</span>.ffn_down.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.28</span>.attn_norm.weight,     torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.28</span>.ffn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.29</span>.attn_q.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.29</span>.attn_k.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.29</span>.attn_v.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.29</span>.attn_output.weight,   torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.29</span>.ffn_gate.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.29</span>.ffn_up.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.29</span>.ffn_down.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.29</span>.attn_norm.weight,     torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.29</span>.ffn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.30</span>.attn_q.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.30</span>.attn_k.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.30</span>.attn_v.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.30</span>.attn_output.weight,   torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.30</span>.ffn_gate.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.30</span>.ffn_up.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.30</span>.ffn_down.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.30</span>.attn_norm.weight,     torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.30</span>.ffn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.31</span>.attn_q.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.31</span>.attn_k.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.31</span>.attn_v.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">1024</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.31</span>.attn_output.weight,   torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.31</span>.ffn_gate.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.31</span>.ffn_up.weight,        torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">14336</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:gguf: loading model part <span class="string">&#x27;pytorch_model-00004-of-00004.bin&#x27;</span></span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.31</span>.ffn_down.weight,      torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">14336</span>, <span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.31</span>.attn_norm.weight,     torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:blk<span class="number">.31</span>.ffn_norm.weight,      torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:output_norm.weight,          torch.float16 --&gt; F32, shape = &#123;<span class="number">4096</span>&#125;</span><br><span class="line">INFO:hf-to-gguf:output.weight,               torch.float16 --&gt; Q8_0, shape = &#123;<span class="number">4096</span>, <span class="number">128256</span>&#125;</span><br><span class="line">INFO:gguf.gguf_writer:Writing the following files:</span><br><span class="line">INFO:gguf.gguf_writer:/content/caihaoran/fortunetelling1/unsloth.Q8_0.gguf: n_tensors = <span class="number">291</span>, total_size = <span class="number">8.5</span>G</span><br><span class="line">Writing: <span class="number">100</span>%|██████████| <span class="number">8.53</span>G/<span class="number">8.53</span>G [03:<span class="number">16</span>&lt;<span class="number">00</span>:<span class="number">00</span>, <span class="number">43.4</span>Mbyte/s]</span><br><span class="line">INFO:hf-to-gguf:Model successfully exported to /content/caihaoran/fortunetelling1/unsloth.Q8_0.gguf</span><br><span class="line">Unsloth: Conversion completed! Output location: /content/caihaoran/fortunetelling1/unsloth.Q8_0.gguf</span><br><span class="line">Unsloth: Uploading GGUF to Huggingface Hub...</span><br><span class="line"><span class="number">100</span>%</span><br><span class="line"> <span class="number">1</span>/<span class="number">1</span> [01:<span class="number">18</span>&lt;<span class="number">00</span>:<span class="number">00</span>, <span class="number">78.21</span>s/it]</span><br><span class="line">unsloth.Q8_0.gguf: </span><br><span class="line"> <span class="number">8.54</span>G/? [01:<span class="number">17</span>&lt;<span class="number">00</span>:<span class="number">00</span>, 383MB/s]</span><br><span class="line">Unsloth: <span class="comment">##### The current model auto adds a BOS token.</span></span><br><span class="line">Unsloth: <span class="comment">##### We removed it in GGUF&#x27;s chat template for you.</span></span><br><span class="line">Saved GGUF to https://huggingface.co/caihaoran/fortunetelling1</span><br></pre></td></tr></table></figure>

<blockquote>
<p>我转化成GGUF的模型在ollama中运行不起来（Error:unable to load model: usr&#x2F;share&#x2F;ollama&#x2F;.ollama&#x2F;models&#x2F;blobs&#x2F;sha256-…）</p>
</blockquote>
</li>
</ol>
<hr>
<h3 id="本地Jupyter-notebook运行"><a href="#本地Jupyter-notebook运行" class="headerlink" title="本地Jupyter notebook运行"></a>本地Jupyter notebook运行</h3><p>上面的llama.cpp整了好几次没正好，T4 GPU运行时给弄限额了，还是回到ubuntu本机的Jupyter notebook运行吧，运行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">mkdir fortunetelling</span><br><span class="line">cd fortunetelling</span><br><span class="line">conda create -n unsloth python=<span class="number">3.11</span></span><br><span class="line">conda activate unsloth</span><br><span class="line">pip install unsloth datasets trl bitsandbytes unsloth_zoo</span><br><span class="line">pip install Xformer  <span class="comment"># 很重要，小友可以试下先不安装这个库进行实验🤨（顺便猜猜为什么我知道它很重要）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 给conda环境创建特殊内核</span></span><br><span class="line">conda install ipykernel</span><br><span class="line">python -m ipykernel install --user --name unsloth --display-name <span class="string">&quot;Python (unsloth)&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 回到base环境</span></span><br><span class="line">jupyter kernelspec <span class="built_in">list</span> <span class="comment"># 即可看到unsloth</span></span><br><span class="line">jupyter notebook  <span class="comment"># 启动jupyter notebook </span></span><br></pre></td></tr></table></figure>

<p>好的，将代码复制过来<br>但是运行第一段下载8B模型的时候报错：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">OSError                                   Traceback (most recent call last)</span><br><span class="line">Cell In[1], line 9</span><br><span class="line">      6 load_in_4bit = True  <span class="comment"># 使用4位量化来节省内存，就像把大箱子压缩成小箱子</span></span><br><span class="line">      8 <span class="comment"># 加载预训练模型，并获取tokenizer工具</span></span><br><span class="line">----&gt; 9 model, tokenizer = FastLanguageModel.from_pretrained(</span><br><span class="line">     10     model_name=<span class="string">&quot;unsloth/DeepSeek-R1-Distill-Llama-8B&quot;</span>,  <span class="comment"># 指定要加载的模型名称</span></span><br><span class="line">     11     max_seq_length=max_seq_length,  <span class="comment"># 使用前面设置的最大长度</span></span><br><span class="line">     12     dtype=dtype,  <span class="comment"># 使用前面设置的数据类型</span></span><br><span class="line">     13     load_in_4bit=load_in_4bit,  <span class="comment"># 使用4位量化</span></span><br><span class="line">     14     <span class="comment"># token=&quot;hf_...&quot;,  # 如果需要访问授权模型，可以在这里填入密钥</span></span><br><span class="line">     15 )</span><br><span class="line"></span><br><span class="line">File ~/anaconda3/envs/unsloth/lib/python3.11/site-packages/unsloth/models/loader.py:363, <span class="keyword">in</span> FastLanguageModel.from_pretrained(model_name, max_seq_length, dtype, load_in_4bit, load_in_8bit, full_finetuning, token, device_map, rope_scaling, fix_tokenizer, trust_remote_code, use_gradient_checkpointing, resize_model_vocab, revision, use_exact_model_name, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, *args, **kwargs)</span><br><span class="line">    360     pass</span><br><span class="line">    361 pass</span><br><span class="line">--&gt; 363 model, tokenizer = dispatch_model.from_pretrained(</span><br><span class="line">    364     model_name        = model_name,</span><br><span class="line">    365     max_seq_length    = max_seq_length,</span><br><span class="line">    366     dtype             = _get_dtype(dtype),</span><br><span class="line">    367     load_in_4bit      = load_in_4bit,</span><br><span class="line">    368     token             = token,</span><br><span class="line">    369     device_map        = device_map,</span><br><span class="line">    370     rope_scaling      = rope_scaling,</span><br><span class="line">    371     fix_tokenizer     = fix_tokenizer,</span><br><span class="line">    372     model_patcher     = dispatch_model,</span><br><span class="line">    373     tokenizer_name    = tokenizer_name,</span><br><span class="line">    374     trust_remote_code = trust_remote_code,</span><br><span class="line">    375     revision          = revision <span class="keyword">if</span> not is_peft <span class="keyword">else</span> None,</span><br><span class="line">    376 </span><br><span class="line">    377     fast_inference    = fast_inference,</span><br><span class="line">    378     gpu_memory_utilization = gpu_memory_utilization,</span><br><span class="line">    379     float8_kv_cache   = float8_kv_cache,</span><br><span class="line">    380     random_state      = random_state,</span><br><span class="line">    381     max_lora_rank     = max_lora_rank,</span><br><span class="line">    382     disable_log_stats = disable_log_stats,</span><br><span class="line">    383     *args, **kwargs,</span><br><span class="line">    384 )</span><br><span class="line">    386 <span class="keyword">if</span> resize_model_vocab is not None:</span><br><span class="line">    387     model.resize_token_embeddings(resize_model_vocab)</span><br><span class="line"></span><br><span class="line">File ~/anaconda3/envs/unsloth/lib/python3.11/site-packages/unsloth/models/llama.py:1780, <span class="keyword">in</span> FastLlamaModel.from_pretrained(model_name, max_seq_length, dtype, load_in_4bit, token, device_map, rope_scaling, fix_tokenizer, model_patcher, tokenizer_name, trust_remote_code, fast_inference, gpu_memory_utilization, float8_kv_cache, random_state, max_lora_rank, disable_log_stats, **kwargs)</span><br><span class="line">   1777 <span class="keyword">if</span> load_in_4bit: kwargs[<span class="string">&quot;quantization_config&quot;</span>] = bnb_config</span><br><span class="line">   1779 <span class="keyword">if</span> not fast_inference:</span><br><span class="line">-&gt; 1780     model = AutoModelForCausalLM.from_pretrained(</span><br><span class="line">   1781         model_name,</span><br><span class="line">   1782         device_map              = device_map,</span><br><span class="line">   1783         torch_dtype             = dtype,</span><br><span class="line">   1784         <span class="comment"># quantization_config     = bnb_config,</span></span><br><span class="line">   1785         token                   = token,</span><br><span class="line">   1786         max_position_embeddings = max_position_embeddings,</span><br><span class="line">   1787         trust_remote_code       = trust_remote_code,</span><br><span class="line">   1788         attn_implementation     = <span class="string">&quot;eager&quot;</span>,</span><br><span class="line">   1789         **kwargs,</span><br><span class="line">   1790     )</span><br><span class="line">   1791     model.fast_generate = model.generate</span><br><span class="line">   1792     model.fast_generate_batches = None</span><br><span class="line"></span><br><span class="line">File ~/anaconda3/envs/unsloth/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:573, <span class="keyword">in</span> _BaseAutoModelClass.from_pretrained(cls, pretrained_model_name_or_path, *model_args, **kwargs)</span><br><span class="line">    571 <span class="keyword">elif</span> <span class="built_in">type</span>(config) <span class="keyword">in</span> cls._model_mapping.keys():</span><br><span class="line">    572     model_class = _get_model_class(config, cls._model_mapping)</span><br><span class="line">--&gt; 573     <span class="built_in">return</span> model_class.from_pretrained(</span><br><span class="line">    574         pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs</span><br><span class="line">    575     )</span><br><span class="line">    576 raise ValueError(</span><br><span class="line">    577     f<span class="string">&quot;Unrecognized configuration class &#123;config.__class__&#125; for this kind of AutoModel: &#123;cls.__name__&#125;.\n&quot;</span></span><br><span class="line">    578     f<span class="string">&quot;Model type should be one of &#123;&#x27;, &#x27;.join(c.__name__ for c in cls._model_mapping.keys())&#125;.&quot;</span></span><br><span class="line">    579 )</span><br><span class="line"></span><br><span class="line">File ~/anaconda3/envs/unsloth/lib/python3.11/site-packages/transformers/modeling_utils.py:272, <span class="keyword">in</span> restore_default_torch_dtype.&lt;locals&gt;._wrapper(*args, **kwargs)</span><br><span class="line">    270 old_dtype = torch.get_default_dtype()</span><br><span class="line">    271 try:</span><br><span class="line">--&gt; 272     <span class="built_in">return</span> func(*args, **kwargs)</span><br><span class="line">    273 finally:</span><br><span class="line">    274     torch.set_default_dtype(old_dtype)</span><br><span class="line"></span><br><span class="line">File ~/anaconda3/envs/unsloth/lib/python3.11/site-packages/transformers/modeling_utils.py:4317, <span class="keyword">in</span> PreTrainedModel.from_pretrained(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)</span><br><span class="line">   4312 <span class="keyword">if</span> gguf_file is not None and hf_quantizer is not None:</span><br><span class="line">   4313     raise ValueError(</span><br><span class="line">   4314         <span class="string">&quot;You cannot combine Quantization and loading a model from a GGUF file, try again by making sure you did not passed a `quantization_config` or that you did not load a quantized model from the Hub.&quot;</span></span><br><span class="line">   4315     )</span><br><span class="line">-&gt; 4317 checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(</span><br><span class="line">   4318     pretrained_model_name_or_path=pretrained_model_name_or_path,</span><br><span class="line">   4319     subfolder=subfolder,</span><br><span class="line">   4320     variant=variant,</span><br><span class="line">   4321     gguf_file=gguf_file,</span><br><span class="line">   4322     from_tf=from_tf,</span><br><span class="line">   4323     from_flax=from_flax,</span><br><span class="line">   4324     use_safetensors=use_safetensors,</span><br><span class="line">   4325     cache_dir=cache_dir,</span><br><span class="line">   4326     force_download=force_download,</span><br><span class="line">   4327     proxies=proxies,</span><br><span class="line">   4328     local_files_only=local_files_only,</span><br><span class="line">   4329     token=token,</span><br><span class="line">   4330     user_agent=user_agent,</span><br><span class="line">   4331     revision=revision,</span><br><span class="line">   4332     commit_hash=commit_hash,</span><br><span class="line">   4333 )</span><br><span class="line">   4335 is_sharded = sharded_metadata is not None</span><br><span class="line">   4336 is_quantized = hf_quantizer is not None</span><br><span class="line"></span><br><span class="line">File ~/anaconda3/envs/unsloth/lib/python3.11/site-packages/transformers/modeling_utils.py:1110, <span class="keyword">in</span> _get_resolved_checkpoint_files(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash)</span><br><span class="line">   1102 has_file_kwargs = &#123;</span><br><span class="line">   1103     <span class="string">&quot;revision&quot;</span>: revision,</span><br><span class="line">   1104     <span class="string">&quot;proxies&quot;</span>: proxies,</span><br><span class="line">   (...)</span><br><span class="line">   1107     <span class="string">&quot;local_files_only&quot;</span>: local_files_only,</span><br><span class="line">   1108 &#125;</span><br><span class="line">   1109 <span class="keyword">if</span> has_file(pretrained_model_name_or_path, TF2_WEIGHTS_NAME, **has_file_kwargs):</span><br><span class="line">-&gt; 1110     raise EnvironmentError(</span><br><span class="line">   1111         f<span class="string">&quot;&#123;pretrained_model_name_or_path&#125; does not appear to have a file named&quot;</span></span><br><span class="line">   1112         f<span class="string">&quot; &#123;_add_variant(WEIGHTS_NAME, variant)&#125; but there is a file for TensorFlow weights.&quot;</span></span><br><span class="line">   1113         <span class="string">&quot; Use `from_tf=True` to load this model from those weights.&quot;</span></span><br><span class="line">   1114     )</span><br><span class="line">   1115 <span class="keyword">elif</span> has_file(pretrained_model_name_or_path, FLAX_WEIGHTS_NAME, **has_file_kwargs):</span><br><span class="line">   1116     raise EnvironmentError(</span><br><span class="line">   1117         f<span class="string">&quot;&#123;pretrained_model_name_or_path&#125; does not appear to have a file named&quot;</span></span><br><span class="line">   1118         f<span class="string">&quot; &#123;_add_variant(WEIGHTS_NAME, variant)&#125; but there is a file for Flax weights. Use&quot;</span></span><br><span class="line">   1119         <span class="string">&quot; `from_flax=True` to load this model from those weights.&quot;</span></span><br><span class="line">   1120     )</span><br><span class="line"></span><br><span class="line">OSError: unsloth/deepseek-r1-distill-llama-8b-unsloth-bnb-4bit does not appear to have a file named pytorch_model.bin but there is a file <span class="keyword">for</span> TensorFlow weights. Use `from_tf=True` to load this model from those weights.</span><br></pre></td></tr></table></figure>

<p>叽里呱啦的说一大堆，看着是下载的模型与想要的模型格式不匹配，但是我花时间下载的模型文件呢！不能用就给我删了！？算了，我直接git下载模型，然后指定本地模型路径得了，在<code>fortunetelling</code>文件夹下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://huggingface.co/unsloth/DeepSeek-R1-Distill-Llama-8B</span><br></pre></td></tr></table></figure>
<p>下载完成后，将<code>model_name</code>改成<code>./DeepSeek-R1-Distill-Llama-8B</code>，由于Jupyter Notebook不像Colab可以方便的设置秘钥，所以最后的代码需要显式指定（我是这么做的）HUGGINGFACE_TOKEN，好的，还有最后一个大坑，保存微调后的模型文件需要使用<code>llama.cpp</code>的<code>llama.cpp/quantize</code>，但新版本的<code>Llama.cpp</code>库没有quantize（不在一级目录下）,解决方式：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">rm</span> -rf llama.cpp  <span class="comment"># 删除掉现在的llama.cpp</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/ggml-org/llama.cpp.git</span><br><span class="line"><span class="built_in">cd</span> llama.cpp</span><br><span class="line">git checkout b3345</span><br><span class="line">git submodule update --init --recursive</span><br><span class="line">make clean</span><br><span class="line">make all -j</span><br><span class="line">git <span class="built_in">log</span> -1</span><br><span class="line"></span><br><span class="line">就畅通无阻了</span><br></pre></td></tr></table></figure>

<blockquote>
<p>我这里转化成GGUF的模型在ollama中也运行不起来（Error:unable to load model: usr&#x2F;share&#x2F;ollama&#x2F;.ollama&#x2F;models&#x2F;blobs&#x2F;sha256-…）(彻底疯狂.gif)</p>
</blockquote>
<hr>
<h3 id="vLLM运行"><a href="#vLLM运行" class="headerlink" title="vLLM运行"></a>vLLM运行</h3><p>好好好，怎么整在<code>ollama</code>中都运行不起来，但是下载大佬的<code>GGUF</code>模型却能运行起来，没招了，我还是用<code>vLLM</code>运行它吧。</p>
<p>鉴于我在4090上如果使用8B的Llama模型，只能设置<code>--max-model-len=1024</code>，所以我又微调了个<code>Qwen2.5 7b</code>，知识模型变了下，其他都没变，在代码最后加上：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.save_pretrained_merged(<span class="string">&quot;model_vllm_qwen&quot;</span>, tokenizer, save_method = <span class="string">&quot;merged_16bit&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>用来保存微调后的完整模型，用于vLLM方式启动服务端：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">python -m vllm.entrypoints.openai.api_server --model model_vllm_qwen  --served-model-name Qwen --<span class="built_in">max</span>-model-<span class="built_in">len</span>=<span class="number">4096</span></span><br></pre></td></tr></table></figure>

<p>下载<a href="https://cherry-ai.com/download">CHERRY STUDIO</a>，然后：</p>
<img src="/2025/03/25/%E5%A6%82%E4%BD%95%E5%B0%86%E4%BD%A0%E7%9A%84DeepSeek-R1%E5%BE%AE%E8%B0%83%E6%88%90%E6%9F%90%E4%B8%AA%E9%A2%86%E5%9F%9F%E7%9A%84%E4%B8%93%E5%AE%B6%EF%BC%88%E5%AE%9E%E6%88%98%E7%AF%87%EF%BC%89/image-20250328210656222.png" class="" title="image-20250328210656222">

<img src="/2025/03/25/%E5%A6%82%E4%BD%95%E5%B0%86%E4%BD%A0%E7%9A%84DeepSeek-R1%E5%BE%AE%E8%B0%83%E6%88%90%E6%9F%90%E4%B8%AA%E9%A2%86%E5%9F%9F%E7%9A%84%E4%B8%93%E5%AE%B6%EF%BC%88%E5%AE%9E%E6%88%98%E7%AF%87%EF%BC%89/image-20250328210753041.png" class="" title="image-20250328210753041">

<p>点击确定后，API秘钥随意（我填的是EMPTY)，API地址是<a href="http://192.168.0.138:8000/">http://192.168.0.138:8000</a>(根据自己的来)，点击添加，写入模型ID，即为你服务端指定的<code>--served-model-name</code></p>
<img src="/2025/03/25/%E5%A6%82%E4%BD%95%E5%B0%86%E4%BD%A0%E7%9A%84DeepSeek-R1%E5%BE%AE%E8%B0%83%E6%88%90%E6%9F%90%E4%B8%AA%E9%A2%86%E5%9F%9F%E7%9A%84%E4%B8%93%E5%AE%B6%EF%BC%88%E5%AE%9E%E6%88%98%E7%AF%87%EF%BC%89/image-20250328210939841.png" class="" title="image-20250328210939841">

<p>回到对话栏，就可以选择刚才添加的模型了：</p>
<img src="/2025/03/25/%E5%A6%82%E4%BD%95%E5%B0%86%E4%BD%A0%E7%9A%84DeepSeek-R1%E5%BE%AE%E8%B0%83%E6%88%90%E6%9F%90%E4%B8%AA%E9%A2%86%E5%9F%9F%E7%9A%84%E4%B8%93%E5%AE%B6%EF%BC%88%E5%AE%9E%E6%88%98%E7%AF%87%EF%BC%89/image-20250328211431024.png" class="" title="image-20250328211431024">

<p>现在就可以愉快的交流了，那么看看咱们微调的对比效果吧：</p>
<p><strong>原始</strong></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">Q<span class="punctuation">:</span><span class="number">1992</span>年闰四月初九巳时生人，女，想了解健康运势</span><br><span class="line"></span><br><span class="line">A<span class="punctuation">:</span>好，我现在要帮用户分析一下她<span class="number">1992</span>年闰四月初九巳时生的健康运势。首先，用户是女性，所以可能需要关注一些女性特有的健康问题。闰四月这个时间点在农历中比较特殊，可能会对她的身体健康产生影响。</span><br><span class="line"></span><br><span class="line">首先，我应该考虑她的出生时间，闰四月初九巳时，这可能意味着她的生日在公历的<span class="number">4</span>月<span class="number">9</span>日，或者在农历闰四月的某一天。我需要明确她的生日到底是哪一天，但可能用户只是大致的时间，所以可能需要根据农历转换成公历日期。</span><br><span class="line"></span><br><span class="line">接下来，我应该分析她的五行。她的出生时间是巳时，也就是下午<span class="number">4</span>点左右，属于巳时。在五行中，巳对应的地支是已，已为土。所以她的五行可能以土为主，但还需要结合具体的日干来判断。<span class="number">1992</span>年是龙年，地支是龙，对应的日干是木。所以她的五行应该是木 dominant，可能带有火的性质，因为龙年通常有木和火的元素。</span><br><span class="line"></span><br><span class="line">五行方面，木生火，火生土，土生金，金生水，水生木。所以木的五行比较旺，可能她的身体在木相关的方面较强，比如肝木、肺火等。但五行过旺也可能带来一些问题，比如容易上火、口干舌燥等。</span><br><span class="line"></span><br><span class="line">接下来，我需要分析她的命宫和宫位。四月初九，农历四月是春季，四月初九可能在清明节前后，这是一个比较重要的节气，可能影响她的健康。四月初九属于四月的中下旬，可能与肝胆有关，因为四月在农历中对应的是胆和肝。</span><br><span class="line"></span><br><span class="line">她属于闰年中的初九，可能她的身体状况在春天容易出现一些问题，比如消化不良、容易上火等。作为女性，她的月经周期也可能受到影响，需要特别注意。</span><br><span class="line"></span><br><span class="line">接下来，我应该考虑她的五行相克。木生火，所以她的火性可能比较强，容易导致口干舌燥、容易生气、情绪波动大等问题。土生金，所以她的金属性也可能较强，可能在学习、工作效率上有优势，但可能在某些方面容易固执。</span><br><span class="line"></span><br><span class="line">水生木，水比较弱的话，可能在她的身体上会有一定的滋养作用，帮助调节木旺带来的问题。金生水，可能她的金元素比较弱，容易导致情绪低落、容易焦虑等。</span><br><span class="line"></span><br><span class="line">在健康运势方面，可能需要注意以下几点：</span><br><span class="line"><span class="number">1.</span> 生活作息：要注意规律，避免熬夜，尤其是晚上容易上火的时候，可以适当减少电子设备的使用时间。</span><br><span class="line"><span class="number">2.</span> 饮食调理：多吃清淡的食物，避免油腻和辛辣，多喝水，保持一定的水分，避免干燥。</span><br><span class="line"><span class="number">3.</span> 气候变化：春天容易变化无常，注意保暖，避免着凉，特别是在晚上。</span><br><span class="line"><span class="number">4.</span> 作息时间：保证充足的睡眠，特别是在晚上容易上火的时候，可以适当减少咖啡因和糖分的摄入。</span><br><span class="line"><span class="number">5.</span> 环境调整：尽量保持居住环境的干燥，避免潮湿和异味，可能需要使用一些除湿设备。</span><br><span class="line"></span><br><span class="line">此外，作为女性，她的月经周期可能会受到影响，需要特别关注自己的身体状态，避免过度劳累或情绪波动过大。如果有不适，可能需要及时就医咨询。</span><br><span class="line"></span><br><span class="line">总的来说，她的健康运势可能以木旺为主，需要注意调节火性，保持身体的平衡。同时，注意情绪的调节，避免长期情绪低落，可能会对身体健康产生负面影响。</span><br><span class="line"></span><br><span class="line">最后，我应该提醒用户，健康运势仅供参考，遇到身体不适时，应尽早就医，不要延误治疗。同时，保持良好的生活习惯，注意饮食和作息，对整体健康有积极的影响。</span><br><span class="line">&lt;/think&gt;</span><br><span class="line"></span><br><span class="line">根据你<span class="number">1992</span>年闰四月初九巳时的出生时间，以下是针对你的健康运势的分析和建议：</span><br><span class="line"></span><br><span class="line">### 健康运势分析：</span><br><span class="line"></span><br><span class="line"><span class="number">1.</span> **五行分析**：</span><br><span class="line">   - 你的五行以木为主，木生火，火生土，土生金，金生水，水生木。木旺可能带来消化不良、口干舌燥等问题，但水的滋养作用可以调节木旺带来的不适。</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> **命宫分析**：</span><br><span class="line">   - 闰四月初九属于四月，四月在农历中对应胆和肝。作为女性，你可能在春季容易出现消化不良或情绪波动。</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span> **五行相克**：</span><br><span class="line">   - 火性较强，可能引起口干舌燥、生气等不适。</span><br><span class="line">   - 土性较弱，可能影响情绪稳定性，容易出现焦虑。</span><br><span class="line"></span><br><span class="line">### 健康建议：</span><br><span class="line"></span><br><span class="line"><span class="number">1.</span> **作息调整**：</span><br><span class="line">   - 注意规律作息，避免熬夜，尤其是晚上容易上火时，减少电子设备使用时间。</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> **饮食调理**：</span><br><span class="line">   - 多吃清淡食物，避免油腻和辛辣，保持适量饮水，保持身体湿润。</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span> **气候适应**：</span><br><span class="line">   - 春天气候多变，注意保暖，避免着凉。晚上尽量减少空调使用，保持舒适环境。</span><br><span class="line"></span><br><span class="line"><span class="number">4.</span> **作息安排**：</span><br><span class="line">   - 保证充足睡眠，晚上减少咖啡因和糖分摄入，帮助身体调节。</span><br><span class="line"></span><br><span class="line"><span class="number">5.</span> **环境调整**：</span><br><span class="line">   - 保持居住环境干燥，使用除湿设备，避免潮湿和异味。</span><br><span class="line"></span><br><span class="line">### 情绪建议：</span><br><span class="line"></span><br><span class="line">- 注意情绪调节，避免长期情绪低落，可能影响身体健康。保持乐观心态，必要时寻求心理咨询。</span><br><span class="line"></span><br><span class="line">### 注意事项：</span><br><span class="line"></span><br><span class="line">- 女性月经周期可能受到影响，注意观察身体状况，避免过度劳累。</span><br><span class="line"></span><br><span class="line">### 总结：</span><br><span class="line"></span><br><span class="line">你的健康运势以木旺为主，需要注意调节火性，保持身体平衡。同时，注意作息和饮食，避免上火，保持良好的心态。如出现不适，及时就医咨询。</span><br><span class="line"></span><br><span class="line">健康运势仅供参考，生活中的健康问题请以专业医生的诊断为准。</span><br></pre></td></tr></table></figure>

<p><strong>后</strong></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">好的，用户提供了出生日期和时辰，想知道健康运势。首先，我需要确认<span class="number">1992</span>年的闰四月初九巳时是否符合传统命理分析。闰年、月份、日期和时辰都是关键因素。</span><br><span class="line"></span><br><span class="line">接下来，我需要查一下<span class="number">1992</span>年的农历四月初九的具体日期对应的公历日期，以及当时的时辰转换成现代时间，以便更好地分析。闰四月意味着这一年有<span class="number">13</span>个月，可能会影响月份的节气和重要日期。</span><br><span class="line"></span><br><span class="line">然后，考虑八字排盘。需要将阳历日期转换成农历，再排出年柱、月柱、日柱和时柱。年柱是甲申年，月柱是丙辰月，日柱需要根据具体的公历日期转换成农历，再查对应的天干地支。时辰是巳时，对应的地支是巳，需要转换成<span class="number">24</span>小时制的时辰，方便排四柱。</span><br><span class="line"></span><br><span class="line">接下来，分析五行。甲木日主，日主偏强，可能需要看是否有用神。月柱丙火，丙火为阴火，需看是否得时令火生。时柱巳时为午时，午时对应的五行属土，可能与日主木相合，但需要看具体的生克关系。</span><br><span class="line"></span><br><span class="line">健康方面，甲木为根，木为阴，可能有湿热或缺水的问题。要注意饮食、作息和情绪管理。日主偏强，可能有压力或情绪波动，需注意情绪调节。月柱丙火，火为阴，可能有阴气过重，需注意保暖。时柱土，土为阳，可能有疲劳或消化问题，需注意劳逸结合。</span><br><span class="line"></span><br><span class="line">需要提醒用户，命理分析仅供参考，需结合实际生活调整。同时，建议咨询专业 astrologer 进行更详细的解读。</span><br><span class="line"></span><br><span class="line">最后，整理这些信息，用中文口语化的方式表达，保持自然流畅，结构清晰，分点说明。注意避免使用专业术语过多，让用户容易理解。确保内容准确，同时保持积极鼓励的态度，让用户感到被关心和支持。</span><br><span class="line">&lt;/think&gt;</span><br><span class="line"></span><br><span class="line">**<span class="number">1992</span>年闰四月初九巳时女命健康运势解析**</span><br><span class="line"></span><br><span class="line">### **八字排盘**</span><br><span class="line">**年柱：甲申年**（阳干甲木，阴支申金）</span><br><span class="line">**月柱：丙辰月**（阳支辰土，阴支辰土）</span><br><span class="line">**日柱：**（需根据公历日期转换成农历，再排）</span><br><span class="line">**时柱：巳时**（阳时火，阴时火）</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">### **五行平衡分析**</span><br><span class="line"><span class="number">1.</span> **日主（甲木）**：</span><br><span class="line">   甲木为根，偏强，需火生木。月柱（丙辰土）为阴土，土生木，但土过强，木被土耗尽，形成“火土相克”的关系。建议注意情绪管理，避免过度焦虑或压力。</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> **月支（辰土）**：</span><br><span class="line">   土为阴性，土为阴气过重，需用火来生土。时柱（巳火）为阳火，火旺生土，但火过旺，土被火耗尽，形成“木土相克”的关系。注意防寒保暖，避免久坐或久站。</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span> **时柱（巳火）**：</span><br><span class="line">   火为阳，火为阳气过旺，需用土来克火。日柱（甲木）为木，木生火，但木过弱，火被木耗尽，形成“火木相克”的关系。建议适量运动，保持身体活性。</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">### **健康提示**</span><br><span class="line"><span class="number">1.</span> **饮食方面**：</span><br><span class="line">   - **注意事项**：避免过热或油腻食物，尤其是午间（火旺时）不宜过多进补。</span><br><span class="line">   - **建议**：多摄入新鲜蔬菜水果（木生火，火生土），如胡萝卜、苹果、绿叶菜等。</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> **作息方面**：</span><br><span class="line">   - **注意事项**：午间（<span class="number">13</span><span class="number">-15</span>点）避免剧烈运动或久坐，以免火气耗尽。</span><br><span class="line">   - **建议**：午间可以进行轻微拉伸或深呼吸，增强气机平衡。</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span> **情绪管理**：</span><br><span class="line">   - **注意事项**：注意情绪波动，避免因压力过大的情绪耗尽木气。</span><br><span class="line">   - **建议**：每天安排<span class="number">15</span><span class="number">-30</span>分钟的冥想或深呼吸练习，保持心身平衡。</span><br><span class="line"></span><br><span class="line"><span class="number">4.</span> **禁忌**：</span><br><span class="line">   - 避免在火旺的时段（如正午）进行剧烈运动、烹饪或使用电子设备。</span><br><span class="line">   - 避免穿过于紧身或厚重的衣服，以免耗尽土气。</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">### **综合建议**</span><br><span class="line"><span class="number">1.</span> **日常防护**：</span><br><span class="line">   - 饮食宜清淡，多食清热解毒的食物（如菊花茶、苦瓜、银耳）。</span><br><span class="line">   - 保持充足的睡眠（每晚<span class="number">11</span>点前入睡），避免熬夜。</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> **重要节点**：</span><br><span class="line">   - **农历初九**：此日为“冲日”，注意防风防寒。</span><br><span class="line">   - **农历四月初九**：此日为“四正”，宜选择阴凉处避暑，避免阳气过旺。</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span> **重要时间**：</span><br><span class="line">   - **卯时（<span class="number">6</span><span class="number">-8</span>点）**：卯时属土，土生木，此时宜做有助于木气提升的活动（如太极拳、打坐）。</span><br><span class="line">   - **巳时（<span class="number">13</span><span class="number">-15</span>点）**：巳时属火，火耗木，此时宜避免剧烈运动，可做轻微拉伸。</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">**注**：以上分析基于传统命理理论，具体健康问题还需结合个人实际情况和专业医疗建议。</span><br></pre></td></tr></table></figure>

<p><strong>前</strong></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">大门对着路有忌讳吗</span><br><span class="line">嗯，大门对着路，这在风水学上是不是有什么忌讳呢？首先，我需要了解一下大门对着路在中国传统文化中的意义。在中国，大门象征着家庭的 entrance 和迎接的 start of the day. 对着路，可能意味着家庭与外界的连接。但是，从风水的角度来看，这可能涉及到气场的流动和能量的平衡。</span><br><span class="line"></span><br><span class="line">我记得风水学中提到，大门是家庭能量的入口，如果大门对着路，可能会导致气场外泄，影响家庭的内部环境和成员的健康。此外，路象征着外面的世界和外界的干扰，如果大门直接对着路，可能会让家庭成员感到孤独或缺乏安全感。</span><br><span class="line"></span><br><span class="line">另外，我还听说过“阳气过旺”和“气场不稳定”的说法，这可能与大门对着路有关。阳气过旺可能会影响家庭成员的健康，甚至导致一些不吉利的事情发生。</span><br><span class="line"></span><br><span class="line">不过，我也听说过“聚气”和“纳气”的概念，如果大门对着路，可能会影响家庭成员的运势和事业。聚气指的是家庭成员聚集的气场，而纳气指的是家庭成员吸收外界能量的能力。如果大门对着路，可能会影响家庭成员的运势，甚至导致一些问题。</span><br><span class="line"></span><br><span class="line">另外，我还想了解一下，是否有其他风水师建议，说大门对着路是不吉利的，还是有人认为这是正常的。可能还需要查阅一些风水书籍或咨询专业的风水师，以获得更准确的信息。</span><br><span class="line"></span><br><span class="line">总的来说，我觉得大门对着路在中国传统文化中可能有一定的忌讳，但具体情况还需要根据家庭的实际情况来判断。如果家庭成员对此有疑虑，可以考虑调整大门的位置，以达到更好的风水效果。</span><br><span class="line">&lt;/think&gt;</span><br><span class="line"></span><br><span class="line">在中国传统文化中，大门是对家庭能量的象征，象征着家庭的迎接和外部的连接。一般来说，大门对着路可能会被认为有一定的忌讳，因为这可能导致气场外泄，影响家庭的内部环境和成员的健康。以下是一些具体的解释和建议：</span><br><span class="line"></span><br><span class="line"><span class="number">1.</span> **气场流动**：</span><br><span class="line">   - 大门对着路，可能让气场更容易外泄，影响到家庭内部的和谐与平衡。气场的外泄可能导致成员感到孤独、不安，甚至影响到他们的健康状况。</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> **外部干扰**：</span><br><span class="line">   - 大门对着路，意味着家庭外部的干扰可能更多，这可能让家庭成员感到外界的不稳定和不安全。这对于需要外界支持的家庭成员来说，可能是一种压力。</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span> **聚气与纳气**：</span><br><span class="line">   - 聚气指的是家庭成员聚集的气场，而纳气指的是家庭成员吸收外界能量的能力。大门对着路可能会影响家庭成员的运势和事业，因为这可能导致气场的不稳定，影响他们的运势。</span><br><span class="line"></span><br><span class="line"><span class="number">4.</span> **风水建议**：</span><br><span class="line">   - 如果家庭的大门确实对着路，可以考虑在大门前放置一些有助于稳定气场的物品，如植物、镜子等，以减少气场外泄的影响。</span><br><span class="line">   - 另外，还可以通过调整室内的气场布局，如使用风水物品、悬挂 appropriate 的书法作品等，来改善家庭的气场环境。</span><br><span class="line"></span><br><span class="line"><span class="number">5.</span> **家庭成员的健康**：</span><br><span class="line">   - 对于家庭成员的健康来说，大门对着路可能会影响他们的身体健康。如果家庭成员对此有疑虑，可以考虑调整大门的位置，以达到更好的风水效果。</span><br><span class="line"></span><br><span class="line">总之，虽然大门对着路在中国传统文化中可能有一些忌讳，但具体情况还需要根据家庭的实际情况来判断。如果家庭成员对此有疑虑，可以咨询专业的风水师，以获得更准确的建议。</span><br></pre></td></tr></table></figure>

<p><strong>后</strong></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">好的，用户询问的是“大门对着路有忌讳吗”。首先，我需要理解用户的问题背景。用户可能在选择房屋布局或者 house design 时遇到了问题，想知道大门对着路是否符合传统风水原则。这可能涉及到对风水知识的不了解，或者他们正在做室内设计，想要优化空间布局。</span><br><span class="line"></span><br><span class="line">接下来，我需要回忆一下风水中关于大门的方向和朝向的指导。一般来说，大门应该朝南，因为南方属阳气，与男性的阳气相合，有助于驱邪纳气。如果大门对路，可能会影响气场的流动。需要解释这一点，同时也要提到不同文化或地方的差异，说明风水学是地方性的，可能因地区而异。</span><br><span class="line"></span><br><span class="line">然后，要分析大门对路的具体影响。比如，如果大门正对街道，可能会导致财气外泄，不利财运。或者，如果对的是正门，可能需要采取补救措施，比如设置屏风、安装植物等，来化解煞气。同时，还要提到现代风水中的一些新观点，比如传统风水与现代建筑的关系，提醒用户现代设计中可能需要结合实际需求。</span><br><span class="line"></span><br><span class="line">还要考虑用户可能的深层需求。他们可能担心自己的风水布局是否正确，或者对风水有误解，需要进一步解释。另外，用户可能对风水有一定的兴趣，但不确定具体的禁忌，所以需要提供实用的建议，而不仅仅是理论。</span><br><span class="line"></span><br><span class="line">需要注意的是，避免绝对化的说法，比如“绝对忌讳”或“绝对没问题”，因为风水学是传统文化的一部分，因人而异，需要结合个人情况。同时，要保持中立，不鼓励用户迷信，但提供合理的解释和建议。</span><br><span class="line"></span><br><span class="line">最后，要确保回答结构清晰，分点说明问题、原因、建议，以及注意事项，让用户能够一目了然。还要注意用词要通俗易懂，避免使用过于专业的术语，但又不失准确性。</span><br><span class="line"></span><br><span class="line">总结一下，回答应包括以下几点：</span><br><span class="line"><span class="number">1.</span> 传统风水中大门对路的忌讳。</span><br><span class="line"><span class="number">2.</span> 原因分析（如财气外泄）。</span><br><span class="line"><span class="number">3.</span> 解决方法（如设置屏风、植物等）。</span><br><span class="line"><span class="number">4.</span> 现代视角下的应对策略。</span><br><span class="line"><span class="number">5.</span> 需要结合实际，避免绝对化。</span><br><span class="line"><span class="number">6.</span> 鼓励科学理性，避免迷信。</span><br><span class="line"></span><br><span class="line">这样既满足了用户的疑问，又提供了实用的建议，同时保持了中立和科学的态度。</span><br><span class="line">&lt;/think&gt;</span><br><span class="line"></span><br><span class="line">在中国传统文化中，风水学确实对大门的方向和朝向有特定的指导原则，但需要注意的是，风水学更多是地方性和文化背景的习俗，具体是否“忌讳”需要结合个人命理、空间布局以及地方习俗来综合判断。以下是一些常见的风水观念，供参考：</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">### **传统风水观点**</span><br><span class="line"><span class="number">1.</span> **大门对路是否忌讳？**</span><br><span class="line">   - 在传统风水中，大门的方向和朝向与“气场”流动有关。如果大门正对街道（即“对路”），可能会形成“通途”（通路）的概念，认为这种方向可能带来“财气外泄”或“煞气冲出”，对居住者的运势产生负面影响。</span><br><span class="line">   - 但需要注意的是，这种说法更多是针对“起居”“办公”等特定用途的房间，而非“大门”本身。大门的主要作用是引导气流进入室内，对“通路”（即街道）的指向性可能有不同的解释。</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> **具体原因：**</span><br><span class="line">   - **财气外泄**：大门正对街道可能被认为“财气外泄”，尤其是对正对的正门（即街道方向），容易导致财富、资源外流，影响运势。</span><br><span class="line">   - **煞气冲出**：如果大门正对正门，可能形成“煞气冲出”，尤其是如果大门正对正门，且大门本身没有遮挡物（如屏风、植物等），可能对健康、财运产生负面影响。</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">### **化解方法**</span><br><span class="line">如果大门正对街道（正门或正对正门），可以通过以下方式化解：</span><br><span class="line"><span class="number">1.</span> **设置遮挡物**：</span><br><span class="line">   - 在大门正前方设置屏风、植物墙或隔断，形成“隔断”“屏气”之感，避免“通路”或“煞气”直冲而来。</span><br><span class="line">   - 如果是正对正门，可以将门框朝内倾斜，形成“冲破正门”的效果，但需注意倾斜过大可能会导致室内气流紊乱。</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> **使用风水物品**：</span><br><span class="line">   - 在大门正前方放置绿植（如发财树、绿萝），有助于“生财”“纳气”。</span><br><span class="line">   - 如果是正对正门，可以放置红色（红色代表火，生土，土生木，木生火）的植物或红色系的装饰物，形成“五行相生”的效果。</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span> **调整朝向**：</span><br><span class="line">   - 如果无法改变大门方向，可以将家具或装饰物偏向正门（例如将沙发、书架等偏向正门方向），形成“冲正门”的效果，避免正对正门的煞气直冲。</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">### **现代视角**</span><br><span class="line">风水学在现代社会中逐渐被科学化、理性化，更多关注能量流动和空间设计的科学性。例如：</span><br><span class="line"><span class="number">1.</span> **现代风水师**可能建议使用“方位传感器”或“气流追踪设备”来分析室内气流流动方向。</span><br><span class="line"><span class="number">2.</span> **大门正对街道**是否需要避免，更多取决于个人对“通路”“煞气”的主观感受，而不是绝对的“忌讳”。</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">### **综合建议**</span><br><span class="line"><span class="number">1.</span> **大门正对街道是否需要特别处理？**</span><br><span class="line">   - 如果是正对正门，且大门本身没有遮挡物，建议设置屏风或植物化解煞气。</span><br><span class="line">   - 如果是正对街道（但正对正门），可以尝试将门框朝内倾斜，形成“冲正门”的效果。</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> **避免绝对化**</span><br><span class="line">   - 风水学是传统文化的一部分，更多是地方性习俗，具体是否“忌讳”需要结合个人命理、空间布局和实际需求来判断。</span><br><span class="line">   - 也可以通过现代建筑技术（如flowsuite、V型结构）来优化室内能量流动，减少对大门方向的影响。</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span> **理性看待**</span><br><span class="line">   - 风水更多是“趋吉避凶”的建议，而不是绝对的“迷信”。如果对“忌讳”有疑虑，可以通过科学方法（如测量气流、使用气流净化设备）来验证风水布局对健康、运势的影响。</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">### **总结**</span><br><span class="line">**大门正对街道（尤其是正对正门）**在传统风水中可能被认为“通路”或“煞气冲出”，但现代风水更注重能量流动的科学性，建议结合实际需求和空间布局，通过合理的布局和设计来优化气场流动。</span><br></pre></td></tr></table></figure>

<p><strong>前</strong></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">最近感觉有点霉运，怎么改运</span><br><span class="line"></span><br><span class="line">嗯，最近感觉有点霉运，想改运。首先，我应该了解一下霉运是什么意思。霉运在风水学中通常指的是不利的气场或不顺利的情况，可能影响健康、事业、感情等方面。那么，为什么会有霉运呢？可能是因为个人的五行不平衡，或者环境因素，比如居住环境的气场不稳定。</span><br><span class="line"></span><br><span class="line">首先，我需要确认自己的五行情况。五行包括金、木、水、火、土，不同的五行组合会影响运势。如果五行不均衡，可能会导致霉运。例如，五行缺失或者过旺都可能导致霉运。</span><br><span class="line"></span><br><span class="line">接下来，我应该检查一下自己的居住环境。大门对着路，这可能是一个霉运的开始，因为气场容易外泄，影响内部环境。我需要调整大门的方向或位置，确保气场能够稳定下来。可能需要使用一些风水物品，比如植物、镜子等，来平衡气场。</span><br><span class="line"></span><br><span class="line">另外，生活作息也很重要。如果睡眠不足或者饮食不规律，可能会导致身体和心理上的霉运。我应该调整作息时间，保证充足的睡眠，同时注意饮食健康，避免过多的辛辣、油腻食物。</span><br><span class="line"></span><br><span class="line">情绪管理也是一个关键点。如果最近情绪波动较大，可能会影响到霉运。我需要学会调节情绪，保持乐观的心态，必要时可以寻求心理咨询或朋友的建议。</span><br><span class="line"></span><br><span class="line">还有，事业和财运方面，如果最近感觉工作或财运不顺，可能需要调整工作方式或财运布局。比如，寻找新的工作机会，调整预算，避免不必要的开支。</span><br><span class="line"></span><br><span class="line">环境布置也需要注意。家中摆放的物品应该有助于稳定气场，比如绿色植物、镜子等。避免使用一些过于 Sharp 或者装饰过于繁复的物品，以免分散气场。</span><br><span class="line"></span><br><span class="line">此外，还需要关注身体健康。如果最近身体有不适，比如疲劳、头痛等，可能与霉运有关。我应该注意锻炼身体，保持良好的身体状态，避免过度劳累。</span><br><span class="line"></span><br><span class="line">最后，如果霉运持续时间较长，影响了生活和工作，可能需要寻求专业的风水师或心理咨询师的帮助，进行更深入的调整和指导。</span><br><span class="line"></span><br><span class="line">总的来说，改运需要从多个方面入手，包括五行平衡、居住环境调整、生活习惯改善、情绪管理、财运布局和身体健康等。需要耐心和坚持，逐步改善霉运带来的影响。</span><br><span class="line">&lt;/think&gt;</span><br><span class="line"></span><br><span class="line">改运是一个系统性的过程，需要从多个方面进行调整和改善。以下是一些具体的步骤和建议，帮助你改运：</span><br><span class="line"></span><br><span class="line">### <span class="number">1.</span> **确认五行平衡**</span><br><span class="line">   - **五行分析**：首先，了解你的五行组合，确认五行是否均衡。如果五行缺失或过旺，可以通过调整饮食、作息和环境来平衡五行。</span><br><span class="line">   - **五行建议**：</span><br><span class="line">     - **金不足**：可以适当增加金元素，如佩戴金饰、接触金质物品、进行太极拳等。</span><br><span class="line">     - **木不足**：增加木元素，如种植树木、养宠物、进行户外活动等。</span><br><span class="line">     - **水不足**：增加水元素，如喝温水、泡脚、阅读等。</span><br><span class="line">     - **火不足**：减少火元素，如避免使用大火烹饪、少看电视等。</span><br><span class="line">     - **土不足**：增加土元素，如种植花草、进行室内运动等。</span><br><span class="line"></span><br><span class="line">### <span class="number">2.</span> **调整居住环境**</span><br><span class="line">   - **大门方向**：确保大门正对正门，避免对着路或墙壁。如果确实无法调整，可以使用风水物品如红色帘子、铜镜等来遮挡。</span><br><span class="line">   - **气场平衡**：在客厅、卧室等主要房间放置绿色植物，如发财树、绿萝等，有助于平衡气场。</span><br><span class="line">   - **消除煞气**：如果家中有煞气，可以通过悬挂 appropriate 的书法作品、放置 appropriate 的装饰来化解。</span><br><span class="line"></span><br><span class="line">### <span class="number">3.</span> **改善作息和饮食**</span><br><span class="line">   - **作息规律**：保证充足的睡眠，避免熬夜。早晨起床后进行简单的锻炼，如太极拳或八段锦。</span><br><span class="line">   - **饮食调理**：选择清淡、营养均衡的饮食，避免过多的辛辣、油腻食物。多吃水果、蔬菜，保持身体湿润。</span><br><span class="line">   - **五谷四时**：遵循五谷四时的原则，多吃时令水果，保持身体的平衡。</span><br><span class="line"></span><br><span class="line">### <span class="number">4.</span> **情绪管理与心理健康**</span><br><span class="line">   - **情绪调节**：学会调节情绪，避免长期处于不良情绪中。可以通过冥想、深呼吸等方式来缓解压力。</span><br><span class="line">   - **寻求帮助**：如果情绪波动较大，可以寻求朋友、家人或专业的心理咨询师的帮助。</span><br><span class="line">   - **培养兴趣**：通过培养兴趣爱好，转移注意力，缓解霉运带来的影响。</span><br><span class="line"></span><br><span class="line">### <span class="number">5.</span> **调整财运和事业运势**</span><br><span class="line">   - **财运布局**：如果最近财运不顺，可以通过调整预算、寻找新的工作机会或投资来改善。避免过度依赖某一种方式，保持多元化。</span><br><span class="line">   - **职业调整**：如果事业上遇到困难，可以通过调整工作方式、学习新技能或寻找合作伙伴来改善。</span><br><span class="line"></span><br><span class="line">### <span class="number">6.</span> **增强身体免疫力**</span><br><span class="line">   - **锻炼身体**：每天进行适量的锻炼，增强体质。可以进行瑜伽、太极拳等慢节奏的运动。</span><br><span class="line">   - **保持水分**：多喝水，保持身体湿润，避免干燥引起的不适。</span><br><span class="line">   - **避免过度劳累**：合理安排工作和生活，避免长时间的高强度工作，防止疲劳。</span><br><span class="line"></span><br><span class="line">### <span class="number">7.</span> **风水布置**</span><br><span class="line">   - **室内布置**：在家中摆放适当的装饰品，如镜子、书法作品等，以平衡气场。</span><br><span class="line">   - **使用风水物品**：如绿色植物、红色 pendulum 等，有助于稳定气场，改善霉运。</span><br><span class="line">   - **避免负面物品**：避免放置负面物品，如镜子中的倒影或装饰过于 Sharp 的物品，以免影响气场。</span><br><span class="line"></span><br><span class="line">### <span class="number">8.</span> **关注心理健康**</span><br><span class="line">   - **定期体检**：关注身体健康，定期进行体检，排除潜在的健康问题。</span><br><span class="line">   - **保持乐观**：保持积极的心态，避免过度悲观，霉运往往与消极情绪有关。</span><br><span class="line"></span><br><span class="line">### <span class="number">9.</span> **寻求专业帮助**</span><br><span class="line">   - **风水师咨询**：如果霉运持续时间较长，影响了生活和工作，可以寻求专业的风水师或命师的帮助，进行详细分析和调整。</span><br><span class="line">   - **心理咨询**：如果情绪问题严重，可以寻求心理咨询师的帮助，进行心理辅导和治疗。</span><br><span class="line"></span><br><span class="line">### <span class="number">10.</span> **总结与反思**</span><br><span class="line">   - **定期总结**：每隔一段时间，回顾一下自己的生活和运势，找出问题所在，并进行相应的调整。</span><br><span class="line">   - **持续改进**：霉运的改善是一个长期的过程，需要持续的努力和调整，逐步达到理想的状态。</span><br><span class="line"></span><br><span class="line">通过以上步骤和建议，你可以逐步改善霉运带来的影响，提升整体运势。记住，改运需要耐心和坚持，不要急于求成，逐步调整，你会发现霉运带来的影响正在逐步减少。</span><br></pre></td></tr></table></figure>

<p><strong>后</strong></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">好的，用户最近感觉有点霉运，想改运。首先，我需要理解用户的具体情况。用户没有提供太多细节，比如性别、出生时间、五行强弱等，这可能会影响命理分析。不过，我可以先从常见的霉运原因入手，比如事业、健康、人际关系等方面。</span><br><span class="line"></span><br><span class="line">霉运在风水学中通常与“煞气”“煞星”相关，但用户可能更关心的是如何改善当前的状态。需要避免使用过于绝对化的说法，而是提供实际可行的建议。比如，调整风水布局、调整作息、保持心态等。</span><br><span class="line"></span><br><span class="line">接下来，要结合用户可能的性别（女）和时间（<span class="number">1992</span>年），但没有具体日期，可能需要泛指。需要提醒用户风水是传统文化，需结合实际情况，避免绝对化。同时，提供科学合理的建议，比如调整床铺、保持充足睡眠、运动等。</span><br><span class="line"></span><br><span class="line">还要注意用户的心理预期，避免让用户感到被批评，而是给予鼓励和支持。最后，建议用户多关注自己的状态，调整心态，保持积极。</span><br><span class="line"></span><br><span class="line">在回复时，要结构清晰，分点说明，避免使用过于专业的术语，让用户容易理解。同时，保持语气友好，让用户感到被理解和支持。</span><br><span class="line"></span><br><span class="line">最后，检查是否有遗漏的信息，比如用户是否有特别的生肖或命理特点，但用户没有提供，所以需要保持普遍适用性。确保建议具体、实用，帮助用户实际改善运势。</span><br><span class="line"></span><br><span class="line">&lt;/div&gt;</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">### **霉运分析与改运建议（基于<span class="number">1992</span>年闰四月初九巳时女命）**</span><br><span class="line"></span><br><span class="line">#### **一、霉运成因（结合八字分析）**</span><br><span class="line"><span class="number">1.</span> **命理特点**</span><br><span class="line">   - **日主（甲木）**：木为阴性，需火生土，但火土过旺，土被火耗尽，形成“火土相克”。</span><br><span class="line">   - **时柱（巳火）**：火为阳性，火过旺，木被火耗尽，形成“火木相克”。</span><br><span class="line">   - **地支（申金）**：金为阳性，土生金，但土过旺，金被土耗尽，形成“土金相克”。</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> **常见霉运方向**</span><br><span class="line">   - **事业**：火土过旺，易引发压力或人际关系矛盾，建议调整工作方式。</span><br><span class="line">   - **健康**：土被火耗尽，易引发湿热或肝火过旺的健康问题，建议注意饮食和作息。</span><br><span class="line">   - **人际关系**：火木相克，易引发口舌之争或事业上的合作冲突，建议多沟通化解。</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">#### **二、改运核心要点**</span><br><span class="line"><span class="number">1.</span> **五行平衡**</span><br><span class="line">   - **补火**：建议选择火元素（如-safe fire）的物品，如紫砂壶、黄水晶等，增强木气。</span><br><span class="line">   - **补土**：在卧室摆放植物（如发财树、绿萝）或使用五行土的装饰品，增强土气。</span><br><span class="line">   - **生木**：多接触绿色植物（如绿植、绿萝），保持木气活跃。</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> **风水布局**</span><br><span class="line">   - **卧室**：</span><br><span class="line">     - 卧室正对正门时，建议将床铺朝内倾斜（<span class="number">45</span>度）以“冲破正门”；</span><br><span class="line">     - 正门正对正门时，可放置土元素（如红色门帘或红色 plush）化解“土土相克”。</span><br><span class="line">   - **厨房**：</span><br><span class="line">     - 灶头火位（需具体调整）避免正对正门或正对正门正对正门的“煞气”。</span><br><span class="line">     - 灶头火位可放置红色或绿色的石子（五行木）化解火土过旺的问题。</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span> **作息调整**</span><br><span class="line">   - **作息时间**：</span><br><span class="line">     - 早起后进行<span class="number">10</span>分钟的“阳起”（如太极拳或气功练习），增强阳气。</span><br><span class="line">     - 晚上<span class="number">11</span>点前<span class="number">1</span>小时进行<span class="number">10</span>分钟的“阴闭”（如冥想或静坐），平衡五行。</span><br><span class="line">   - **饮食**：</span><br><span class="line">     - 早餐避免过热或油腻，选择清淡的绿色（木）食物（如菠菜、银耳）。</span><br><span class="line">     - 晚餐避免过量饮酒（酒属火，火过旺）。</span><br><span class="line"></span><br><span class="line"><span class="number">4.</span> **情绪管理**</span><br><span class="line">   - **正念冥想**：每天早起或睡前<span class="number">15</span>分钟进行<span class="number">5</span>分钟的正念冥想（如六字真言或八段锦），保持心气平衡。</span><br><span class="line">   - **化解冲突**：遇到口舌之争时，保持冷静，通过沟通或化解（如换位思考）化解矛盾。</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">#### **三、重要节点建议**</span><br><span class="line"><span class="number">1.</span> **<span class="number">2024</span>年**</span><br><span class="line">   - **<span class="number">2</span>月**（农历二月）：木气增强，适合进行补土或补火的活动。</span><br><span class="line">   - **<span class="number">8</span>月**（农历七月）：木气耗尽，注意防寒保暖，避免剧烈运动。</span><br><span class="line"><span class="number">2.</span> **<span class="number">2025</span>年**</span><br><span class="line">   - **<span class="number">4</span>月**（农历四月）：木气恢复，适合进行补土或补火的活动。</span><br><span class="line">   - **<span class="number">12</span>月**（农历December）：木气过旺，注意调节情绪，避免过度劳累。</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">#### **四、注意事项**</span><br><span class="line"><span class="number">1.</span> **风水与科学结合**</span><br><span class="line">   风水是传统文化的一部分，需结合现代科学（如心理调适、健康检查）进行综合调理。</span><br><span class="line"><span class="number">2.</span> **避免绝对化**</span><br><span class="line">   风水学更多是“趋吉避凶”的建议，具体是否“霉运”还需结合个人状态进行判断。</span><br><span class="line"><span class="number">3.</span> **长期调整**</span><br><span class="line">   霉运并非一朝一夕，需通过长期的风水布局与作息调整来改善，避免过度依赖单一方法。</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">### **总结**</span><br><span class="line">霉运是命理规律的提醒，而非绝对的“厄运”。通过五行平衡、风水调整和科学生活方式的结合，可以显著改善当前状态。建议从**补火**（如紫砂壶）、**补土**（如发财树）和**生木**（如绿色植物）三个方面入手，同时结合个人命理和实际情况进行调整。霉运并非终点，改运的关键在于**坚持与耐心**。</span><br></pre></td></tr></table></figure>

<p><strong>前</strong></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">卫生间和厨房挨着，有忌讳吗，需要化解吗</span><br><span class="line"></span><br><span class="line">嗯，用户之前问过关于大门对着路的霉运问题，现在又提到了卫生间和厨房挨着是否会有忌讳，需要化解。看来他对风水问题很感兴趣，可能是在装修或布置房间的时候遇到了困扰。</span><br><span class="line"></span><br><span class="line">首先，我需要明确卫生间和厨房挨着在风水上是否真的有忌讳。根据我的了解，传统风水中，卧室和起居区需要保持一定的距离，而厨房和卫生间虽然功能不同，但并没有明确的忌讳。不过，用户可能担心这样的布局会影响家庭的气场或运势，所以想了解是否需要采取措施化解。</span><br><span class="line"></span><br><span class="line">接下来，我会思考用户可能的深层需求。他可能在装修过程中发现厨房和卫生间挨着，担心这会带来不好的影响，比如健康问题或生活上的不便。因此，他希望得到一些建议，如何通过风水调整来改善这种情况。</span><br><span class="line"></span><br><span class="line">在解释厨房和卫生间挨着的问题时，我需要指出这并不符合传统风水的禁忌，但一些布局上的不合理可能会带来一些负面影响。比如，厨房是烹饪的地方，与卫生间相邻可能会导致湿气过重，影响健康。同时，卫生间的隐私问题也可能导致心理压力。</span><br><span class="line"></span><br><span class="line">然后，我会提供一些化解的方法。首先，保持厨房和卫生间的基本整洁，避免卫生问题。其次，考虑在厨房和卫生间之间放置一些隔断或装饰物，减少功能上的干扰。另外，调整床铺的位置，确保卧室与厨房和卫生间保持一定的距离，有助于改善气场。</span><br><span class="line"></span><br><span class="line">我还需要提醒用户，如果霉运持续，可能需要更深入的风水调整，比如调整家具的位置或使用风水物品来平衡气场。同时，保持良好的生活习惯和积极的心态也很重要。</span><br><span class="line"></span><br><span class="line">最后，我应该总结一下，厨房和卫生间挨着并不算禁忌，但合理的布局和适当的调整可以减少负面影响，帮助用户更好地生活和改善运势。</span><br><span class="line">&lt;/think&gt;</span><br><span class="line"></span><br><span class="line">卫生间和厨房挨着并不是传统风水中明确的忌讳，但具体情况需要结合实际情况来判断。以下是关于这一布局的分析以及可能的化解建议：</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">### <span class="number">1.</span> **传统风水中的布局要求**</span><br><span class="line">- **卧室与起居区需要保持距离**：卧室和起居区（如客厅、厨房、卫生间等）需要有一定的距离，以保持气场的平衡和生活的安宁。</span><br><span class="line">- **厨房与卧室的关系**：厨房是烹饪和储存食物的地方，与卧室（尤其是主卧）的距离一般要求在<span class="number">2</span>米以上，以避免气场的干扰。</span><br><span class="line">- **卫生间与卧室的关系**：卫生间主要负责清洁和存储生活用品，与卧室的距离一般也需要保持在<span class="number">1</span>米以上。</span><br><span class="line"></span><br><span class="line">因此，厨房和卫生间挨着并不违反传统风水的禁忌，但可能会因为功能上的干扰而带来一些负面影响。</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">### <span class="number">2.</span> **厨房和卫生间挨着的潜在问题**</span><br><span class="line">- **湿气过重**：厨房和卫生间通常都比较潮湿，如果这两个房间直接挨在一起，容易导致整体环境过于潮湿，尤其是卫生间的湿气可能通过墙壁或地面传到厨房，影响整体的干燥环境。</span><br><span class="line">- **隐私问题**：如果厨房和卫生间靠近，可能会因为声音或光线的干扰影响到生活，尤其是当有人在使用卫生间的设备时，可能会感到心理压力。</span><br><span class="line">- **气场干扰**：厨房和卫生间是家庭中功能较为特殊的空间，如果这两个空间过于靠近，可能会对整体的气场产生干扰，导致生活中的不稳定感。</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">### <span class="number">3.</span> **如何化解厨房和卫生间挨着的问题**</span><br><span class="line">如果厨房和卫生间确实挨着，可以通过以下方式来化解：</span><br><span class="line"></span><br><span class="line">#### （<span class="number">1</span>）**保持基本整洁**</span><br><span class="line">- **定期清理卫生间的污渍**：保持卫生间的清洁，避免因为卫生间的污渍影响厨房的环境。</span><br><span class="line">- **合理分区**：厨房和卫生间的功能分区明确，避免因日常使用中出现混淆或干扰。</span><br><span class="line"></span><br><span class="line">#### （<span class="number">2</span>）**使用隔断或装饰物**</span><br><span class="line">- **安装防雾柜或隔板**：在厨房的橱柜中安装防雾柜或隔板，可以有效减少卫生间的湿气对厨房的影响。</span><br><span class="line">- **装饰物隔开空间**：在厨房和卫生间的门框上放置一些装饰物，如植物或镜子，来隔开空间，减少功能上的干扰。</span><br><span class="line"></span><br><span class="line">#### （<span class="number">3</span>）**调整家具和床铺位置**</span><br><span class="line">- **保持卧室与厨房、卫生间的距离**：如果卧室与厨房、卫生间过于靠近，可以通过调整家具的位置（如床铺、书桌等）来增加卧室与其他房间的间距。</span><br><span class="line">- **使用家具隔断**：在卧室和厨房之间放置一张桌子或书架，起到分割空间的作用。</span><br><span class="line"></span><br><span class="line">#### （<span class="number">4</span>）**使用风水物品**</span><br><span class="line">- **放置绿色植物**：在厨房和卫生间的门frame 或窗台上放置一些绿色植物（如发财树、绿萝等），可以吸收湿气，平衡气场。</span><br><span class="line">- **悬挂书法作品或镜子**：在厨房和卫生间的门frame 悬挂一些书法作品或镜子，可以平衡气场，减少压力。</span><br><span class="line"></span><br><span class="line">#### （<span class="number">5</span>）**保持良好的生活习惯**</span><br><span class="line">- **定期清洁卫生间的设备**：避免卫生间的设备长时间处于湿润状态，影响厨房的环境。</span><br><span class="line">- **合理安排使用时间**：尽量避免在厨房和卫生间的使用时间上有重叠，减少功能上的干扰。</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">### <span class="number">4.</span> **总结**</span><br><span class="line">厨房和卫生间挨着并不是风水上的大忌，但可以通过合理的布局和适当的调整来改善整体环境。如果发现家中有明显的负面影响，可以通过以上方法进行优化。同时，保持良好的生活习惯和积极的心态，也能帮助改善整体的运势和居住环境。</span><br></pre></td></tr></table></figure>

<p><strong>后</strong></p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">好的，用户问的是“卫生间和厨房挨着，有忌讳吗，需要化解吗”。首先，我需要分析用户的需求。用户可能对风水有一定的了解，或者最近在布置房间时发现厨房和卫生间相邻，担心风水有问题，想要确认是否需要采取措施化解。</span><br><span class="line"></span><br><span class="line">接下来，我需要回顾一下风水中关于相邻房间的禁忌。根据传统风水学，厨房和卫生间相邻属于“三合”或“三害”，因为厨房属火，卫生间属水，火和水相克，可能带来水土过旺或火土过旺的气场问题。同时，厨房和卫生间是生财和储存财位的房间，相邻可能会影响财气的流动。</span><br><span class="line"></span><br><span class="line">然后，我要考虑用户的具体情况。用户提到“女命<span class="number">1992</span>年”，需要结合八字分析。但用户没有提供具体出生日期，所以只能基于一般情况分析。同时，用户没有提到具体的命理问题，比如五行强弱，因此需要给出一般性的建议。</span><br><span class="line"></span><br><span class="line">接下来，我需要分点解释，先说明风水上的问题，再给出化解方法。首先，解释厨房和卫生间相邻的风水问题，包括“三合”或“三害”的概念，以及对财气、健康和人际关系的影响。然后，分点列出化解方法，如使用风水物品、调整床铺、保持清洁等。</span><br><span class="line"></span><br><span class="line">需要注意的是，风水学是传统文化的一部分，现代科学对此有不同看法，用户可能希望结合实际生活进行调整。因此，建议在保持风水化解的同时，结合现代生活习惯，比如保持厨房和卫生间清洁，合理布局，避免过度使用风水物品。</span><br><span class="line"></span><br><span class="line">还要确保语言通俗易懂，避免使用过于专业的术语，让用户容易理解和操作。同时，避免绝对化，强调风水是趋吉避凶的建议，需结合个人实际情况。最后，提醒用户风水是传统文化，需结合个人命理和实际需求，避免过度迷信。</span><br><span class="line"></span><br><span class="line">总结来说，用户需要的是关于厨房和卫生间相邻的风水问题分析和化解建议。要全面解释问题，提供可行的方法，同时结合现代生活习惯，让用户既能遵循风水，又能适应现代需求。最后，鼓励用户保持积极心态，风水只是参考，实际生活更重要。</span><br><span class="line"></span><br><span class="line">&lt;/div&gt;</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">### **厨房与卫生间相邻的风水分析与化解建议**</span><br><span class="line"></span><br><span class="line">#### **一、风水问题（基于女命<span class="number">1992</span>年）**</span><br><span class="line"><span class="number">1.</span> **“三合”或“三害”**</span><br><span class="line">   - 厨房属火，卫生间属水，火水相克，形成“三合”或“三害”（三合为“水火相克”；三害为“水火相克”）。</span><br><span class="line">   - 会导致“水土过旺”或“火土过旺”的气场问题，影响财气流动、健康状况和人际关系。</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> **具体影响**</span><br><span class="line">   - **财气**：厨房和卫生间是生财之位，相邻可能形成“财气外泄”，导致财运不稳定或财运受限。</span><br><span class="line">   - **健康**：水火相克易引发湿热或肝火过旺的问题，如口舌不清、胃火过旺等。</span><br><span class="line">   - **人际关系**：水火相克易引发口舌之争或合作冲突，建议化解冲突时多沟通或换位思考。</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">#### **二、化解方法**</span><br><span class="line"><span class="number">1.</span> **风水化解**</span><br><span class="line">   - **床铺调整**</span><br><span class="line">     - 将厨房正门正对的床铺朝内倾斜（<span class="number">45</span>度），形成“冲破正门”效果。</span><br><span class="line">     - 在床尾放置红色（火元素）或黑色（水元素）的装饰物，平衡五行。</span><br><span class="line">   - **使用风水物品**</span><br><span class="line">     - 在卫生间摆放红色门帘或红色 plush（如门帘、窗帘），增强五行土的平衡。</span><br><span class="line">     - 墙壁挂“生门”（绿色）或“死门”（红色）装饰，避免“死门冲门”。</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> **现代科学结合**</span><br><span class="line">   - **保持整洁**</span><br><span class="line">     - 厨房和卫生间保持整洁，避免污物形成“水土过旺”之气。</span><br><span class="line">     - 使用防滑地垫或防滑地毯，减少湿滑对健康的影响。</span><br><span class="line">   - **合理布局**</span><br><span class="line">     - 厨卫分开使用，避免“三合”或“三害”气场的相互影响。</span><br><span class="line">     - 使用“四合”或“五合”布局（如将厨房和卫生间分别放置在房间的不同方位，避免正对正门）。</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span> **调整作息**</span><br><span class="line">   - **早起时间**</span><br><span class="line">     - 早起后进行<span class="number">10</span>分钟“阳起”（如太极拳或气功），增强阳气。</span><br><span class="line">     - 晚上<span class="number">11</span>点前<span class="number">1</span>小时进行<span class="number">10</span>分钟“阴闭”（如冥想或静坐），平衡五行。</span><br><span class="line">   - **饮食**</span><br><span class="line">     - 早餐选择绿色（木元素）食物（如菠菜、银耳），避免过热或油腻。</span><br><span class="line">     - 晚餐避免过量饮酒（酒属火，火过旺）。</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">#### **三、重要节点建议**</span><br><span class="line"><span class="number">1.</span> **<span class="number">2024</span>年**</span><br><span class="line">   - **<span class="number">2</span>月**（农历二月）：木气增强，适合进行补土或补火的调整。</span><br><span class="line">   - **<span class="number">8</span>月**（农历七月）：木气耗尽，注意防寒保暖，避免剧烈运动。</span><br><span class="line"><span class="number">2.</span> **<span class="number">2025</span>年**</span><br><span class="line">   - **<span class="number">4</span>月**（农历四月）：木气恢复，适合进行补土或补火的调整。</span><br><span class="line">   - **<span class="number">12</span>月**（农历December）：木气过旺，注意调节情绪，避免过度劳累。</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">#### **四、注意事项**</span><br><span class="line"><span class="number">1.</span> **风水与科学结合**</span><br><span class="line">   风水是传统文化的一部分，需结合现代科学（如心理调适、健康检查）进行综合调理。</span><br><span class="line"><span class="number">2.</span> **避免绝对化**</span><br><span class="line">   风水是趋吉避凶的建议，需结合个人状态和实际需求进行调整。</span><br><span class="line"><span class="number">3.</span> **长期调整**</span><br><span class="line">   霉运并非一朝一夕，需通过长期的风水布局与作息调整来改善，避免过度依赖单一方法。</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">### **总结**</span><br><span class="line">厨房与卫生间相邻属于“三合”或“三害”，可能影响财气、健康和人际关系。通过调整床铺、使用风水物品、保持整洁和合理布局等方法，可以有效化解不利影响。建议结合个人命理和实际需求进行调整，风水是趋吉避凶的参考，实际生活更重要。</span><br></pre></td></tr></table></figure>

<p><strong>我看是微调后的看着更厉害些</strong>（不明觉厉）😄。好的就这样吧。</p>
<hr>
<h3 id="unsloth官方示例"><a href="#unsloth官方示例" class="headerlink" title="unsloth官方示例"></a>unsloth官方示例</h3><p><a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb#scrollTo=IqircWtpYuqj">链接</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%%capture</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">if</span> <span class="string">&quot;COLAB_&quot;</span> <span class="keyword">not</span> <span class="keyword">in</span> <span class="string">&quot;&quot;</span>.join(os.environ.keys()):</span><br><span class="line">    !pip install unsloth</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># Do this only in Colab notebooks! Otherwise use pip install unsloth</span></span><br><span class="line">    !pip install --no-deps bitsandbytes accelerate xformers==<span class="number">0.0</span><span class="number">.29</span>.post3 peft trl triton cut_cross_entropy unsloth_zoo</span><br><span class="line">    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer</span><br><span class="line">    !pip install --no-deps unsloth</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>检测是否运行在 Google Colab</strong>，如果不是，则直接 <code>pip install unsloth</code>。</li>
<li><strong>如果在 Colab</strong>，则手动安装 <code>unsloth</code> 及其相关依赖，以避免 Colab 可能的依赖冲突。</li>
<li><strong><code>--no-deps</code></strong> 选项用于防止 <code>pip</code> 自动安装依赖，可能是因为 Colab 自带了一些库，而 <code>pip</code> 的自动安装可能会导致库版本冲突。</li>
</ul>
<p>这段代码主要用于<strong>确保 <code>unsloth</code> 在不同环境下的安装稳定性</strong>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> unsloth <span class="keyword">import</span> FastLanguageModel</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">max_seq_length = <span class="number">2048</span> <span class="comment"># Choose any! We auto support RoPE Scaling internally!</span></span><br><span class="line">dtype = <span class="literal">None</span> <span class="comment"># None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+</span></span><br><span class="line">load_in_4bit = <span class="literal">True</span> <span class="comment"># Use 4bit quantization to reduce memory usage. Can be False.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4bit pre quantized models we support for 4x faster downloading + no OOMs.</span></span><br><span class="line">fourbit_models = [</span><br><span class="line">    <span class="string">&quot;unsloth/mistral-7b-v0.3-bnb-4bit&quot;</span>,      <span class="comment"># New Mistral v3 2x faster!</span></span><br><span class="line">    <span class="string">&quot;unsloth/mistral-7b-instruct-v0.3-bnb-4bit&quot;</span>,</span><br><span class="line">    <span class="string">&quot;unsloth/llama-3-8b-bnb-4bit&quot;</span>,           <span class="comment"># Llama-3 15 trillion tokens model 2x faster!</span></span><br><span class="line">    <span class="string">&quot;unsloth/llama-3-8b-Instruct-bnb-4bit&quot;</span>,</span><br><span class="line">    <span class="string">&quot;unsloth/llama-3-70b-bnb-4bit&quot;</span>,</span><br><span class="line">    <span class="string">&quot;unsloth/Phi-3-mini-4k-instruct&quot;</span>,        <span class="comment"># Phi-3 2x faster!</span></span><br><span class="line">    <span class="string">&quot;unsloth/Phi-3-medium-4k-instruct&quot;</span>,</span><br><span class="line">    <span class="string">&quot;unsloth/mistral-7b-bnb-4bit&quot;</span>,</span><br><span class="line">    <span class="string">&quot;unsloth/gemma-7b-bnb-4bit&quot;</span>,             <span class="comment"># Gemma 2.2x faster!</span></span><br><span class="line">] <span class="comment"># More models at https://huggingface.co/unsloth</span></span><br><span class="line"></span><br><span class="line">model, tokenizer = FastLanguageModel.from_pretrained(</span><br><span class="line">    model_name = <span class="string">&quot;unsloth/llama-3-8b-bnb-4bit&quot;</span>,</span><br><span class="line">    max_seq_length = max_seq_length,</span><br><span class="line">    dtype = dtype,</span><br><span class="line">    load_in_4bit = load_in_4bit,</span><br><span class="line">    <span class="comment"># token = &quot;hf_...&quot;, # use one if using gated models like meta-llama/Llama-2-7b-hf</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>和上文代码基本一样，这里<code>unsloth.FastLanguageModel</code>：Unsloth 提供的<strong>高效语言模型加载器</strong>，优化了 Hugging Face <code>transformers</code> 的 <code>AutoModelForCausalLM</code>。比 <code>transformers.AutoModelForCausalLM.from_pretrained</code> <strong>加载速度快 2-4 倍</strong>，并且优化了推理性能。</p>
<p>但是这里加载的模型已经是<code>4bit</code>量化的了，又让<code>load_in_4bit = True</code>不知意义何在。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = FastLanguageModel.get_peft_model(</span><br><span class="line">    model,</span><br><span class="line">    r = <span class="number">16</span>, <span class="comment"># Choose any number &gt; 0 ! Suggested 8, 16, 32, 64, 128</span></span><br><span class="line">    target_modules = [<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;k_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>, <span class="string">&quot;o_proj&quot;</span>,</span><br><span class="line">                      <span class="string">&quot;gate_proj&quot;</span>, <span class="string">&quot;up_proj&quot;</span>, <span class="string">&quot;down_proj&quot;</span>,],</span><br><span class="line">    lora_alpha = <span class="number">16</span>,</span><br><span class="line">    lora_dropout = <span class="number">0</span>, <span class="comment"># Supports any, but = 0 is optimized</span></span><br><span class="line">    bias = <span class="string">&quot;none&quot;</span>,    <span class="comment"># Supports any, but = &quot;none&quot; is optimized</span></span><br><span class="line">    <span class="comment"># [NEW] &quot;unsloth&quot; uses 30% less VRAM, fits 2x larger batch sizes!</span></span><br><span class="line">    use_gradient_checkpointing = <span class="string">&quot;unsloth&quot;</span>, <span class="comment"># True or &quot;unsloth&quot; for very long context</span></span><br><span class="line">    random_state = <span class="number">3407</span>,</span><br><span class="line">    use_rslora = <span class="literal">False</span>,  <span class="comment"># We support rank stabilized LoRA</span></span><br><span class="line">    loftq_config = <span class="literal">None</span>, <span class="comment"># And LoftQ</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>与上文代码一样，</p>
<p>使用LoRA轻量微调方法，它不会更新整个 LLM 的权重，而是对特定层（如 <code>q_proj</code>、<code>k_proj</code>）添加低秩适配矩阵。这样：<strong>大幅减少参数更新量</strong>，<strong>降低显存占用</strong>，<strong>加快训练速度</strong>.</p>
<p>关键参数：<code>r=16</code>表示LoRA <strong>秩（rank）</strong>，控制适配矩阵的大小，通常选择 <strong>8、16、32、64、128</strong>。<code>r</code> 越大，<strong>微调效果更强，但显存占用更高</strong>。<code>r=16</code> 是一个<strong>平衡点</strong>，适合大多数任务。<code>target_modules</code>选择 <strong>哪些 Transformer 层</strong> 进行 LoRA 适配。这里选择了 <strong>自注意力（q_proj, k_proj, v_proj, o_proj）</strong> 和 <strong>前馈网络（gate_proj, up_proj, down_proj）</strong> 层，这些层对模型性能影响最大。</p>
<p>lora_alpha:<strong>LoRA 缩放系数</strong>，相当于学习率的放大因子。<strong><code>lora_alpha / r</code> 是实际的学习率</strong>，这里是 <code>16 / 16 = 1</code>，是一个标准选择。</p>
<p>lora_dropout:LoRA 训练时的 Dropout 概率。<strong><code>0</code> 是最优配置</strong>，确保最大化利用适配矩阵，不丢失信息。</p>
<p>LoRA 是否对模型的 <code>bias</code> 进行微调。<strong><code>none</code> 是最优选择</strong>，意味着 <strong>仅调整 LoRA 矩阵，而不调整 bias</strong>，可以减少不必要的参数更新。</p>
<p>use_gradient_checkpointing:<strong>启用梯度检查点</strong>（Gradient Checkpointing），减少训练显存占用。<code>use_gradient_checkpointing = &quot;unsloth&quot;</code> <strong>比标准 Gradient Checkpointing 省 30% 显存，并支持更长的上下文（context length）</strong>。<strong>适合长文本训练，例如 4K、8K 上下文长度的 LoRA 训练</strong>。</p>
<p>random_state:<strong>随机种子</strong>，用于<strong>保证训练可复现</strong>。</p>
<p><strong>是否使用 Rank-Stabilized LoRA（RsLoRA）</strong>。RsLoRA 是一种 <strong>动态调整 <code>r</code> 的方法</strong>，在训练过程中逐渐降低 <code>r</code> 以减少参数，但它尚未完全成熟，所以默认 <strong><code>False</code></strong>。</p>
<p><strong>是否使用 LoftQ（LoRA-Friendly Quantization）</strong>。LoftQ 是一种 <strong>优化 LoRA 训练的量化方法</strong>，可以在 LoRA 训练过程中使用量化模型。<strong>默认 <code>None</code> 关闭 LoftQ</strong>，如果要用 LoftQ，需要传入量化配置。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;vicgalle/alpaca-gpt4&quot;</span>, split=<span class="string">&quot;train&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(dataset.column_names)</span><br></pre></td></tr></table></figure>

<p>与上文代码一样，这个数据集是<strong>基于原始 Stanford Alpaca（基于 GPT-3.5）数据集</strong>，但是由 <strong>GPT-4 重新生成</strong>，质量更高，常用于<strong>指令微调（Instruction Tuning）</strong>，<code>dataset.column_names</code> 获取 <strong>数据集的所有列名</strong> 并打印出来。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> unsloth <span class="keyword">import</span> to_sharegpt</span><br><span class="line"></span><br><span class="line">dataset = to_sharegpt(</span><br><span class="line">    dataset,</span><br><span class="line">    merged_prompt=<span class="string">&quot;&#123;instruction&#125;[[\nYour input is:\n&#123;input&#125;]]&quot;</span>,</span><br><span class="line">    output_column_name=<span class="string">&quot;output&quot;</span>,</span><br><span class="line">    conversation_extension=<span class="number">3</span>,  <span class="comment"># Select more to handle longer conversations</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p><strong>将 <code>vicgalle/alpaca-gpt4</code> 数据集转换为 ShareGPT 格式，以用于对话模型的微调</strong>。<code>to_sharegpt</code> 是 <code>Unsloth</code> 提供的 <strong>数据预处理工具</strong>，用于将 <strong>普通文本指令数据集（如 Alpaca）转换为 ShareGPT 格式</strong>。ShareGPT 格式<strong>更适合训练聊天对话模型</strong>，因为它可以表示多轮对话结构。</p>
<ul>
<li><p><strong><code>dataset</code></strong>: 传入 <strong>Alpaca-GPT4 数据集</strong>。</p>
</li>
<li><p><strong><code>merged_prompt</code></strong>: 定义 <strong>输入格式</strong>，将 <code>instruction</code> 和 <code>input</code> 组合成 ShareGPT 适用的格式：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&#123;instruction&#125;[[\nYour input is:\n&#123;input&#125;]]&quot;</span></span><br></pre></td></tr></table></figure>

<ul>
<li><code>[[\nYour input is:\n&#123;input&#125;]]</code>：<ul>
<li><code>[[...]]</code> 是 <code>Unsloth</code> 处理对话边界的特殊标记。</li>
<li><code>Your input is:\n&#123;input&#125;</code> 让 LLM 知道 <code>input</code> 是用户的额外上下文（如果存在）。</li>
</ul>
</li>
</ul>
<p><strong><code>output_column_name=&quot;output&quot;</code></strong>: 指定数据集 <code>output</code> 列为 <strong>模型的目标输出</strong>（训练时的正确答案）。</p>
<p><strong><code>conversation_extension=3</code></strong>:</p>
<ul>
<li><strong>扩展对话能力</strong>，用于处理 <strong>更长的对话历史</strong>。</li>
<li><code>conversation_extension=3</code> 意味着 <strong>3 轮对话上下文</strong>，适合<strong>微调多轮对话模型</strong>。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> unsloth <span class="keyword">import</span> standardize_sharegpt</span><br><span class="line"></span><br><span class="line">dataset = standardize_sharegpt(dataset)</span><br></pre></td></tr></table></figure>

<p><strong>将数据集标准化，使其完全符合 ShareGPT 格式</strong>，以便用于<strong>训练对话模型</strong>（如 Llama、Mistral 等）。</p>
<p>例（仅做说明，帮助理解，不保证真实性）：</p>
<p>标准化前：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;merged_prompt&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Summarize the following text.[[\nYour input is:\nMeditation is an ancient practice...]]&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Meditation is a time-tested method for relaxation.&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>

<p>标准化后：</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;conversations&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span><span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;user&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Summarize the following text.\n\nYour input is:\nMeditation is an ancient practice...&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="punctuation">&#123;</span><span class="attr">&quot;role&quot;</span><span class="punctuation">:</span> <span class="string">&quot;assistant&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Meditation is a time-tested method for relaxation.&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">chat_template = <span class="string">&quot;&quot;&quot;Below are some instructions that describe some tasks. Write responses that appropriately complete each request.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">### Instruction:</span></span><br><span class="line"><span class="string">&#123;INPUT&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">### Response:</span></span><br><span class="line"><span class="string">&#123;OUTPUT&#125;&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> unsloth <span class="keyword">import</span> apply_chat_template</span><br><span class="line"></span><br><span class="line">dataset = apply_chat_template(</span><br><span class="line">    dataset,</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    chat_template=chat_template,</span><br><span class="line">    <span class="comment"># default_system_message = &quot;You are a helpful assistant&quot;, &lt;&lt; [OPTIONAL]</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p><strong>将数据集转换为符合 Chat 格式的 Prompt 结构</strong>，以适配 Tokenizer 和模型训练。 <strong><code>chat_template</code></strong> 定义了一个对话格式，包含：</p>
<ul>
<li><code>Instruction</code>（用户指令）</li>
<li><code>Response</code>（模型的回答）</li>
</ul>
<p><code>&#123;INPUT&#125;</code> 和 <code>&#123;OUTPUT&#125;</code> 是 <strong>占位符</strong>，会被 <code>dataset</code> 里的具体 <code>instruction</code> 和 <code>output</code> 填充。</p>
<p><code>apply_chat_template()</code> 是 <code>Unsloth</code> 提供的工具，用于<strong>格式化数据并使其适配 tokenizer</strong>。</p>
<p><strong><code>dataset</code></strong>: 传入预处理后的数据集。</p>
<p><strong><code>tokenizer</code></strong>: 使用 <code>Unsloth</code> 加载的 <code>tokenizer</code>，确保数据符合 Tokenizer 规则。</p>
<p><strong><code>chat_template=chat_template</code></strong>: 指定 <strong>对话格式</strong>，确保数据按照 <code>Instruction → Response</code> 结构组织。</p>
<p><strong><code>default_system_message</code></strong>（可选）:</p>
<ul>
<li>如果设定，<strong>会添加系统消息</strong>，如 <code>&quot;You are a helpful assistant&quot;</code>。</li>
</ul>
</li>
</ul>
<p><strong>训练模型</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> trl <span class="keyword">import</span> SFTTrainer</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> TrainingArguments</span><br><span class="line"><span class="keyword">from</span> unsloth <span class="keyword">import</span> is_bfloat16_supported</span><br><span class="line"></span><br><span class="line">trainer = SFTTrainer(</span><br><span class="line">    model = model,</span><br><span class="line">    tokenizer = tokenizer,</span><br><span class="line">    train_dataset = dataset,</span><br><span class="line">    dataset_text_field = <span class="string">&quot;text&quot;</span>,</span><br><span class="line">    max_seq_length = max_seq_length,</span><br><span class="line">    dataset_num_proc = <span class="number">2</span>,</span><br><span class="line">    packing = <span class="literal">False</span>, <span class="comment"># Can make training 5x faster for short sequences.</span></span><br><span class="line">    args = TrainingArguments(</span><br><span class="line">        per_device_train_batch_size = <span class="number">2</span>,</span><br><span class="line">        gradient_accumulation_steps = <span class="number">4</span>,</span><br><span class="line">        warmup_steps = <span class="number">5</span>,</span><br><span class="line">        max_steps = <span class="number">60</span>,</span><br><span class="line">        <span class="comment"># num_train_epochs = 1, # For longer training runs!</span></span><br><span class="line">        learning_rate = <span class="number">2e-4</span>,</span><br><span class="line">        fp16 = <span class="keyword">not</span> is_bfloat16_supported(),</span><br><span class="line">        bf16 = is_bfloat16_supported(),</span><br><span class="line">        logging_steps = <span class="number">1</span>,</span><br><span class="line">        optim = <span class="string">&quot;adamw_8bit&quot;</span>,</span><br><span class="line">        weight_decay = <span class="number">0.01</span>,</span><br><span class="line">        lr_scheduler_type = <span class="string">&quot;linear&quot;</span>,</span><br><span class="line">        seed = <span class="number">3407</span>,</span><br><span class="line">        output_dir = <span class="string">&quot;outputs&quot;</span>,</span><br><span class="line">        report_to = <span class="string">&quot;none&quot;</span>, <span class="comment"># Use this for WandB etc</span></span><br><span class="line">    ),</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>与上文代码基本一致。</p>
<p><strong>查看当前gpu状态</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># @title Show current memory stats</span></span><br><span class="line">gpu_stats = torch.cuda.get_device_properties(<span class="number">0</span>)</span><br><span class="line">start_gpu_memory = <span class="built_in">round</span>(torch.cuda.max_memory_reserved() / <span class="number">1024</span> / <span class="number">1024</span> / <span class="number">1024</span>, <span class="number">3</span>)</span><br><span class="line">max_memory = <span class="built_in">round</span>(gpu_stats.total_memory / <span class="number">1024</span> / <span class="number">1024</span> / <span class="number">1024</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;GPU = <span class="subst">&#123;gpu_stats.name&#125;</span>. Max memory = <span class="subst">&#123;max_memory&#125;</span> GB.&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;start_gpu_memory&#125;</span> GB of memory reserved.&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>执行训练</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">trainer_stats = trainer.train()</span><br></pre></td></tr></table></figure>

<p><strong>显示最终内存和时间统计</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># @title Show final memory and time stats</span><br><span class="line">used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)</span><br><span class="line">used_memory_for_lora = round(used_memory - start_gpu_memory, 3)</span><br><span class="line">used_percentage = round(used_memory / max_memory * 100, 3)</span><br><span class="line">lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)</span><br><span class="line">print(f&quot;&#123;trainer_stats.metrics[&#x27;train_runtime&#x27;]&#125; seconds used for training.&quot;)</span><br><span class="line">print(</span><br><span class="line">    f&quot;&#123;round(trainer_stats.metrics[&#x27;train_runtime&#x27;]/60, 2)&#125; minutes used for training.&quot;</span><br><span class="line">)</span><br><span class="line">print(f&quot;Peak reserved memory = &#123;used_memory&#125; GB.&quot;)</span><br><span class="line">print(f&quot;Peak reserved memory for training = &#123;used_memory_for_lora&#125; GB.&quot;)</span><br><span class="line">print(f&quot;Peak reserved memory % of max memory = &#123;used_percentage&#125; %.&quot;)</span><br><span class="line">print(f&quot;Peak reserved memory for training % of max memory = &#123;lora_percentage&#125; %.&quot;)</span><br></pre></td></tr></table></figure>

<p><strong>推理</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">FastLanguageModel.for_inference(model) <span class="comment"># Enable native 2x faster inference</span></span><br><span class="line">messages = [                    <span class="comment"># Change below!</span></span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;Continue the fibonacci sequence! Your input is 1, 1, 2, 3, 5, 8,&quot;</span>&#125;,</span><br><span class="line">]</span><br><span class="line">input_ids = tokenizer.apply_chat_template(</span><br><span class="line">    messages,</span><br><span class="line">    add_generation_prompt = <span class="literal">True</span>,</span><br><span class="line">    return_tensors = <span class="string">&quot;pt&quot;</span>,</span><br><span class="line">).to(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> TextStreamer</span><br><span class="line">text_streamer = TextStreamer(tokenizer, skip_prompt = <span class="literal">True</span>)</span><br><span class="line">_ = model.generate(input_ids, streamer = text_streamer, max_new_tokens = <span class="number">128</span>, pad_token_id = tokenizer.eos_token_id)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">FastLanguageModel.for_inference(model) <span class="comment"># Enable native 2x faster inference</span></span><br><span class="line">messages = [                         <span class="comment"># Change below!</span></span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>,      <span class="string">&quot;content&quot;</span>: <span class="string">&quot;Continue the fibonacci sequence! Your input is 1, 1, 2, 3, 5, 8&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;assistant&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;The fibonacci sequence continues as 13, 21, 34, 55 and 89.&quot;</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>,      <span class="string">&quot;content&quot;</span>: <span class="string">&quot;What is France&#x27;s tallest tower called?&quot;</span>&#125;,</span><br><span class="line">]</span><br><span class="line">input_ids = tokenizer.apply_chat_template(</span><br><span class="line">    messages,</span><br><span class="line">    add_generation_prompt = <span class="literal">True</span>,</span><br><span class="line">    return_tensors = <span class="string">&quot;pt&quot;</span>,</span><br><span class="line">).to(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> TextStreamer</span><br><span class="line">text_streamer = TextStreamer(tokenizer, skip_prompt = <span class="literal">True</span>)</span><br><span class="line">_ = model.generate(input_ids, streamer = text_streamer, max_new_tokens = <span class="number">128</span>, pad_token_id = tokenizer.eos_token_id)</span><br></pre></td></tr></table></figure>

<p><strong>保存和加载模型</strong></p>
<ul>
<li>保存Lora模型</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.save_pretrained(<span class="string">&quot;lora_model&quot;</span>)  <span class="comment"># Local saving</span></span><br><span class="line">tokenizer.save_pretrained(<span class="string">&quot;lora_model&quot;</span>)</span><br><span class="line"><span class="comment"># model.push_to_hub(&quot;your_name/lora_model&quot;, token = &quot;...&quot;) # Online saving</span></span><br><span class="line"><span class="comment"># tokenizer.push_to_hub(&quot;your_name/lora_model&quot;, token = &quot;...&quot;) # Online saving</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="literal">False</span>:	<span class="comment"># 需要加载微调后的模型时设置为True</span></span><br><span class="line">    <span class="keyword">from</span> unsloth <span class="keyword">import</span> FastLanguageModel</span><br><span class="line">    model, tokenizer = FastLanguageModel.from_pretrained(</span><br><span class="line">        model_name = <span class="string">&quot;lora_model&quot;</span>, <span class="comment"># YOUR MODEL YOU USED FOR TRAINING</span></span><br><span class="line">        max_seq_length = max_seq_length,</span><br><span class="line">        dtype = dtype,</span><br><span class="line">        load_in_4bit = load_in_4bit,</span><br><span class="line">    )</span><br><span class="line">    FastLanguageModel.for_inference(model) <span class="comment"># Enable native 2x faster inference</span></span><br><span class="line"><span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">messages = [                    <span class="comment"># Change below!</span></span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;Describe anything special about a sequence. Your input is 1, 1, 2, 3, 5, 8,&quot;</span>&#125;,</span><br><span class="line">]</span><br><span class="line">input_ids = tokenizer.apply_chat_template(</span><br><span class="line">    messages,</span><br><span class="line">    add_generation_prompt = <span class="literal">True</span>,</span><br><span class="line">    return_tensors = <span class="string">&quot;pt&quot;</span>,</span><br><span class="line">).to(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> TextStreamer</span><br><span class="line">text_streamer = TextStreamer(tokenizer, skip_prompt = <span class="literal">True</span>)</span><br><span class="line">_ = model.generate(input_ids, streamer = text_streamer, max_new_tokens = <span class="number">128</span>, pad_token_id = tokenizer.eos_token_id)</span><br></pre></td></tr></table></figure>

<ul>
<li><p>保存微调后的整个模型</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.save_pretrained_merged(<span class="string">&quot;model_vllm&quot;</span>, tokenizer, save_method = <span class="string">&quot;merged_16bit&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>看这个名字你就知道我想做什么了吧🤪。</p>
</li>
</ul>
<p><strong>制作ollama支持的GGUF文件</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Save to 8bit Q8_0</span></span><br><span class="line"><span class="keyword">if</span> <span class="literal">True</span>: model.save_pretrained_gguf(<span class="string">&quot;model&quot;</span>, tokenizer,)</span><br><span class="line"><span class="comment"># Remember to go to https://huggingface.co/settings/tokens for a token!</span></span><br><span class="line"><span class="comment"># And change hf to your username!</span></span><br><span class="line"><span class="keyword">if</span> <span class="literal">False</span>: model.push_to_hub_gguf(<span class="string">&quot;hf/model&quot;</span>, tokenizer, token = <span class="string">&quot;&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>依旧是重新编译<code>llama.cpp</code>，然后制作好<code>GGUF</code>文件后，<code>ollama</code>加载不成功，累了，毁灭吧🙂。</p>
<hr>
<p>附录</p>
<p><strong>自定义对话模板</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">alpaca_prompt = <span class="string">&quot;&quot;&quot;Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">### Instruction:</span></span><br><span class="line"><span class="string">&#123;&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">### Input:</span></span><br><span class="line"><span class="string">&#123;&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">### Response:</span></span><br><span class="line"><span class="string">&#123;&#125;&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>





<hr>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol>
<li>w</li>
<li><a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb#scrollTo=IqircWtpYuqj">https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb#scrollTo=IqircWtpYuqj</a></li>
</ol>
]]></content>
      <categories>
        <category>theory</category>
      </categories>
      <tags>
        <tag>llm</tag>
        <tag>unsloth</tag>
        <tag>deepseek</tag>
        <tag>ollama</tag>
        <tag>huggingface</tag>
        <tag>llama-8b</tag>
        <tag>fine-tune</tag>
        <tag>colab</tag>
      </tags>
  </entry>
</search>
